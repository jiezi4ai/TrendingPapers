<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2109.00375</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2109.00375</id><created>2021-09-01</created><updated>2025-02-04</updated><authors><author><keyname>Tan</keyname><forenames>Linda S. L.</forenames></author></authors><title>Analytic natural gradient updates for Cholesky factor in Gaussian   variational approximation</title><categories>stat.CO</categories><doi>10.1093/jrsssb/qkaf001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural gradients can improve convergence in stochastic variational inference significantly but inverting the Fisher information matrix is daunting in high dimensions. Moreover, in Gaussian variational approximation, natural gradient updates of the precision matrix do not ensure positive definiteness. To tackle this issue, we derive analytic natural gradient updates of the Cholesky factor of the covariance or precision matrix, and consider sparsity constraints representing different posterior correlation structures. Stochastic normalized natural gradient ascent with momentum is proposed for implementation in generalized linear mixed models and deep neural networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2208.10790</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2208.10790</id><created>2022-08-23</created><updated>2025-02-04</updated><authors><author><keyname>Brunzema</keyname><forenames>Paul</forenames></author><author><keyname>von Rohr</keyname><forenames>Alexander</forenames></author><author><keyname>Solowjow</keyname><forenames>Friedrich</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Event-Triggered Time-Varying Bayesian Optimization</title><categories>cs.LG stat.ML</categories><comments>Published in Transactions on Machine Learning Research (TMLR)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Current approaches to TVBO require prior knowledge of a constant rate of change to cope with stale data arising from time variations. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function and then resets the dataset. This allows the algorithm to adapt online to realized temporal changes without the need for exact prior knowledge. The event trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We derive regret bounds for adaptive resets without exact prior knowledge of the temporal changes and show in numerical experiments that ET-GP-UCB outperforms competing GP-UCB algorithms on both synthetic and real-world data. The results demonstrate that ET-GP-UCB is readily applicable without extensive hyperparameter tuning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2305.06116</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2305.06116</id><created>2023-05-10</created><updated>2025-02-04</updated><authors><author><keyname>Catalano</keyname><forenames>Marta</forenames></author><author><keyname>Lavenant</keyname><forenames>Hugo</forenames></author></authors><title>Merging Rate of Opinions via Optimal Transport on Random Measures</title><categories>math.ST math.PR stat.TH</categories><comments>Substantial modifications compared to v1 of this preprint</comments><msc-class>60G55, 60G57, 49Q22, 62C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random measures provide flexible parameters for Bayesian nonparametric models. Given two different priors for a random measure, we develop a natural framework to investigate the rate at which the corresponding posteriors merge, as the sample size increases. We define a new distance between the laws of random measures that is built as a Wasserstein distance on the ground space of unbalanced measures, endowed with the bounded Lipschitz metric. We develop tight analytical bounds for its specification to completely random measures, including the special case of Poisson and gamma random measures. The bounds are interpreted in terms of an adapted extended Wasserstein distance between the L\'evy measures and are used to investigate the merging between the posteriors of normalized gamma and generalized gamma priors. After a careful study on the identifiability of the law of the random measure, interesting asymptotic and finite-sample insights are derived without putting \emph{any} assumption on the true data generating process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2306.01727</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2306.01727</id><created>2023-06-02</created><updated>2025-02-04</updated><authors><author><keyname>Briend</keyname><forenames>Simon</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Lugosi</keyname><forenames>Gabor</forenames></author></authors><title>Broadcasting in random recursive dags</title><categories>stat.ML cs.LG cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A uniform $k$-{\sc dag} generalizes the uniform random recursive tree by picking $k$ parents uniformly at random from the existing nodes. It starts with $k$ ''roots''. Each of the $k$ roots is assigned a bit. These bits are propagated by a noisy channel. The parents' bits are flipped with probability $p$, and a majority vote is taken. When all nodes have received their bits, the $k$-{\sc dag} is shown without identifying the roots. The goal is to estimate the majority bit among the roots. We identify the threshold for $p$ as a function of $k$ below which the majority rule among all nodes yields an error $c+o(1)$ with $c&lt;1/2$. Above the threshold the majority rule errs with probability $1/2+o(1)$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2306.02813</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2306.02813</id><created>2023-06-05</created><updated>2024-07-16</updated><authors><author><keyname>Tan</keyname><forenames>Linda S. L.</forenames></author><author><keyname>Chen</keyname><forenames>Aoxiang</forenames></author></authors><title>Variational inference based on a subclass of closed skew normals</title><categories>stat.ME</categories><comments>keywords: Closed skew normal; Gaussian variational approximation;   natural gradient; centered parametrization; LU decomposition</comments><doi>10.1080/10618600.2024.2402278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian distributions are widely used in Bayesian variational inference to approximate intractable posterior densities, but the ability to accommodate skewness can improve approximation accuracy significantly, when data or prior information is scarce. We study the properties of a subclass of closed skew normals constructed using affine transformation of independent standardized univariate skew normals as the variational density, and illustrate how it provides increased flexibility and accuracy in approximating the joint posterior in various applications, by overcoming limitations in existing skew normal variational approximations. The evidence lower bound is optimized using stochastic gradient ascent, where analytic natural gradient updates are derived. We also demonstrate how problems in maximum likelihood estimation of skew normal parameters occur similarly in stochastic variational inference, and can be resolved using the centered parametrization. Supplemental materials are available online. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.09766</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.09766</id><created>2023-10-15</created><updated>2025-02-03</updated><authors><author><keyname>Chen</keyname><forenames>Haoxian</forenames></author><author><keyname>Lam</keyname><forenames>Henry</forenames></author></authors><title>Pseudo-Bayesian Optimization</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-based methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a suitable "randomized prior" construction to quantify uncertainty, not only guarantees convergence but also consistently outperforms state-of-the-art benchmarks in examples ranging from high-dimensional synthetic experiments to realistic hyperparameter tuning and robotic applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.14531</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.14531</id><created>2024-01-25</created><updated>2025-02-03</updated><authors><author><keyname>Mandjes</keyname><forenames>Michel</forenames></author><author><keyname>Wang</keyname><forenames>Jiesen</forenames></author></authors><title>Estimation of on- and off-time distributions in a dynamic   Erd\H{o}s-R\'enyi random graph</title><categories>math.ST math.PR stat.TH</categories><msc-class>05C80, 62M09, 62F12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a dynamic Erd\H{o}s-R\'enyi graph in which edges, according to an alternating renewal process, change from present to absent and vice versa. The objective is to estimate the on- and off-time distributions while only observing the aggregate number of edges. This inverse problem is dealt with, in a parametric context, by setting up an estimator based on the method of moments. We provide conditions under which the estimator is asymptotically normal, and we point out how the corresponding covariance matrix can be identified. It is also demonstrated how to adapt the estimation procedure if alternative subgraph counts are observed, such as the number of wedges or triangles. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.08283</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.08283</id><created>2024-02-13</created><updated>2024-10-24</updated><authors><author><keyname>Ghosh</keyname><forenames>Annesha</forenames></author><author><keyname>Ghosh</keyname><forenames>Anil K.</forenames></author><author><keyname>SahaRay</keyname><forenames>Rita</forenames></author><author><keyname>Sarkar</keyname><forenames>Soham</forenames></author></authors><title>Classification Using Global and Local Mahalanobis Distances</title><categories>stat.ME stat.ML</categories><doi>10.1016/j.jmva.2025.105417</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel semiparametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric modeling assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose another classifier based on a generalized additive model that uses the local Mahalanobis distances as features. This nonparametric classifier usually performs like the Mahalanobis distance based semiparametric classifier when the underlying distributions are elliptic, but outperforms it for several non-elliptic and multimodal distributions. We also investigate the behaviour of these two classifiers in high dimension, low sample size situations. A thorough numerical study involving several simulated and real datasets demonstrate the usefulness of the proposed classifiers in comparison to many state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.10018</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.10018</id><created>2024-02-15</created><updated>2025-02-04</updated><authors><author><keyname>Portnoy</keyname><forenames>Ayelet C.</forenames></author><author><keyname>Solomon</keyname><forenames>Amit</forenames></author><author><keyname>Cohen</keyname><forenames>Alejandro</forenames></author></authors><title>Non-Adaptive Multi-Stage Algorithm and Bounds for Group Testing with   Prior Statistics</title><categories>cs.IT math.IT q-bio.QM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient multi-stage algorithm for non-adaptive Group Testing (GT) with general correlated prior statistics. The proposed solution can be applied to any correlated statistical prior represented in trellis, e.g., finite state machines and Markov processes. We introduce a variation of List Viterbi Algorithm (LVA) to enable accurate recovery using much fewer tests than objectives, which efficiently gains from the correlated prior statistics structure. We also provide a sufficiency bound to the number of pooled tests required by any Maximum A Posteriori (MAP) decoder with an arbitrary correlation between infected items. Our numerical results demonstrate that the proposed Multi-Stage GT (MSGT) algorithm can obtain the optimal MAP performance with feasible complexity in practical regimes, such as with COVID-19 and sparse signal recovery applications, and reduce in the scenarios tested the number of pooled tests by at least 25% compared to existing classical low complexity GT algorithms. Moreover, we analytically characterize the complexity of the proposed MSGT algorithm that guarantees its efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.07628</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.07628</id><created>2024-03-12</created><updated>2025-02-04</updated><authors><author><keyname>Bornemann</keyname><forenames>Folkmar</forenames></author></authors><title>Asymptotic Expansions of the Limit Laws of Gaussian and Laguerre   (Wishart) Ensembles at the Soft Edge</title><categories>math.PR math-ph math.MP math.ST stat.TH</categories><comments>V5: using an alternative expression for the parameter tau that better   fits the style of the other parameters in the Laguerre/Wishart cases, more   remarks on the rationale of the scaling in the symplectic cases; 70 pages, 8   figures</comments><msc-class>60B20, 15B52, 62E20, 41A60, 33C15, 33C45, 33E17, 34E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The large-matrix limit laws of the rescaled largest eigenvalue of the orthogonal, unitary, and symplectic $n$-dimensional Gaussian ensembles -- and of the corresponding Laguerre ensembles (Wishart distributions) for various regimes of the parameter $\alpha$ (degrees of freedom $p$) -- are known to be the Tracy-Widom distributions $F_\beta$ ($\beta=1,2,4$). We establish (paying particular attention to large or small ratios $p/n$) that, with careful choices of the rescaling constants and of the expansion parameter $h$, the limit laws embed into asymptotic expansions in powers of $h$, where $h \asymp n^{-2/3}$ resp. $h \asymp (n\,\wedge\,p)^{-2/3}$. We find explicit analytic expressions of the first few expansion terms as linear combinations of higher-order derivatives of the limit law $F_\beta$ with rational polynomial coefficients. The parametrizations are fine-tuned so that the expansion coefficients in the Gaussian cases are, for given $n$, the limits $p\to\infty$ of those of the Laguerre cases. Whereas the results for $\beta=2$ are presented with proof, the discussion of the cases $\beta=1,4$ is based on some hypotheses, focusing on the algebraic aspects of actually computing the polynomial coefficients. For the purposes of illustration and validation, the various results are checked against simulation data with large sample sizes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.19448</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.19448</id><created>2024-03-28</created><updated>2025-02-03</updated><authors><author><keyname>Müller</keyname><forenames>Johannes</forenames></author><author><keyname>Çaycı</keyname><forenames>Semih</forenames></author><author><keyname>Montúfar</keyname><forenames>Guido</forenames></author></authors><title>Fisher-Rao Gradient Flows of Linear Programs and State-Action Natural   Policy Gradients</title><categories>math.OC cs.LG cs.NA cs.SY eess.SY math.NA stat.ML</categories><comments>25 pages, 4 figures, to appear at SIAM Journal on Optimization</comments><msc-class>65K05, 90C05, 90C08, 90C40, 90C53</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kakade's natural policy gradient method has been studied extensively in recent years, showing linear convergence with and without regularization. We study another natural gradient method based on the Fisher information matrix of the state-action distributions which has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher-Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher-Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher-Rao gradient flows and natural gradient flows up to an approximation error. In particular, these general results cover the case of state-action natural policy gradients. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.00820</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.00820</id><created>2024-03-31</created><updated>2025-02-03</updated><authors><author><keyname>Erdely</keyname><forenames>Arturo</forenames></author><author><keyname>Rubio-Sanchez</keyname><forenames>Manuel</forenames></author></authors><title>Visual analysis of bivariate dependence between continuous random   variables</title><categories>stat.ME</categories><comments>10 pages, 11 figures, 1 table</comments><msc-class>62P99</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scatter plots are widely recognized as fundamental tools for illustrating the relationship between two numerical variables. Despite this, based on solid theoretical foundations, scatter plots generated from pairs of continuous random variables may not serve as reliable tools for assessing dependence. Sklar's Theorem implies that scatter plots created from ranked data are preferable for such analysis as they exclusively convey information pertinent to dependence. This is in stark contrast to conventional scatter plots, which also encapsulate information about the variables' marginal distributions. Such additional information is extraneous to dependence analysis and can obscure the visual interpretation of the variables' relationship. In this article, we delve into the theoretical underpinnings of these ranked data scatter plots, hereafter referred to as rank plots. We offer insights into interpreting the information they reveal and examine their connections with various association measures, including Pearson's and Spearman's correlation coefficients, as well as Schweizer-Wolff's measure of dependence. Furthermore, we introduce a novel graphical combination for dependence analysis, termed a dplot, and demonstrate its efficacy through real data examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.03096</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.03096</id><created>2024-05-05</created><updated>2025-02-03</updated><authors><author><keyname>Tam</keyname><forenames>Edric</forenames></author><author><keyname>Dunson</keyname><forenames>David B.</forenames></author><author><keyname>Duan</keyname><forenames>Leo L.</forenames></author></authors><title>Exact Sampling of Spanning Trees via Fast-forwarded Random Walks</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tree graphs are routinely used in statistics. When estimating a Bayesian model with a tree component, sampling the posterior remains a core difficulty. Existing Markov chain Monte Carlo methods tend to rely on local moves, often leading to poor mixing. A promising approach is to instead directly sample spanning trees on an auxiliary graph. Current spanning tree samplers, such as the celebrated Aldous--Broder algorithm, predominantly rely on simulating random walks that are required to visit all the nodes of the graph. Such algorithms are prone to getting stuck in certain sub-graphs. We formalize this phenomenon using the bottlenecks in the random walk's transition probability matrix. We then propose a novel fast-forwarded cover algorithm that can break free from bottlenecks. The core idea is a marginalization argument that leads to a closed-form expression which allows for fast-forwarding to the event of visiting a new node. Unlike many existing approximation algorithms, our algorithm yields exact samples. We demonstrate the enhanced efficiency of the fast-forwarded cover algorithm, and illustrate its application in fitting a Bayesian dendrogram model on a Massachusetts crimes and communities dataset. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.07482</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.07482</id><created>2024-05-13</created><updated>2025-02-03</updated><authors><author><keyname>Nguyen</keyname><forenames>Khai</forenames></author><author><keyname>Nguyen</keyname><forenames>Hai</forenames></author><author><keyname>Ho</keyname><forenames>Nhat</forenames></author></authors><title>Towards Marginal Fairness Sliced Wasserstein Barycenter</title><categories>stat.ML cs.GR cs.LG</categories><comments>Accepted to ICLR 2025, 29 pages, 15 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sliced Wasserstein barycenter (SWB) is a widely acknowledged method for efficiently generalizing the averaging operation within probability measure spaces. However, achieving marginal fairness SWB, ensuring approximately equal distances from the barycenter to marginals, remains unexplored. The uniform weighted SWB is not necessarily the optimal choice to obtain the desired marginal fairness barycenter due to the heterogeneous structure of marginals and the non-optimality of the optimization. As the first attempt to tackle the problem, we define the marginal fairness sliced Wasserstein barycenter (MFSWB) as a constrained SWB problem. Due to the computational disadvantages of the formal definition, we propose two hyperparameter-free and computationally tractable surrogate MFSWB problems that implicitly minimize the distances to marginals and encourage marginal fairness at the same time. To further improve the efficiency, we perform slicing distribution selection and obtain the third surrogate definition by introducing a new slicing distribution that focuses more on marginally unfair projecting directions. We discuss the relationship of the three proposed problems and their relationship to sliced multi-marginal Wasserstein distance. Finally, we conduct experiments on finding 3D point-clouds averaging, color harmonization, and training of sliced Wasserstein autoencoder with class-fairness representation to show the favorable performance of the proposed surrogate MFSWB problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.08203</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.08203</id><created>2024-05-13</created><updated>2025-01-27</updated><authors><author><keyname>Candellone</keyname><forenames>Elena</forenames></author><author><keyname>van Kesteren</keyname><forenames>Erik-Jan</forenames></author><author><keyname>Chelmi</keyname><forenames>Sofia</forenames></author><author><keyname>Garcia-Bernardo</keyname><forenames>Javier</forenames></author></authors><title>Community detection in bipartite signed networks is highly dependent on   parameter choice</title><categories>physics.soc-ph cs.SI stat.ME</categories><doi>10.1142/S0219525925400028</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decision-making processes often involve voting. Human interactions with exogenous entities such as legislations or products can be effectively modeled as two-mode (bipartite) signed networks-where people can either vote positively, negatively, or abstain from voting on the entities. Detecting communities in such networks could help us understand underlying properties: for example ideological camps or consumer preferences. While community detection is an established practice separately for bipartite and signed networks, it remains largely unexplored in the case of bipartite signed networks. In this paper, we systematically evaluate the efficacy of community detection methods on projected bipartite signed networks using a synthetic benchmark and real-world datasets. Our findings reveal that when no communities are present in the data, these methods often recover spurious user communities. When communities are present, the algorithms exhibit promising performance, although their performance is highly susceptible to parameter choice. This indicates that researchers using community detection methods in the context of bipartite signed networks should not take the communities found at face value: it is essential to assess the robustness of parameter choices or perform domain-specific external validation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.16351</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.16351</id><created>2024-05-25</created><updated>2025-02-04</updated><authors><author><keyname>Malik</keyname><forenames>Zachariah</forenames></author><author><keyname>Huang</keyname><forenames>Yu-Jui</forenames></author></authors><title>A Differential Equation Approach for Wasserstein GANs and Beyond</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new theoretical lens to view Wasserstein generative adversarial networks (WGANs). To minimize the Wasserstein-1 distance between the true data distribution and our estimate of it, we derive a distribution-dependent ordinary differential equation (ODE) which represents the gradient flow of the Wasserstein-1 loss, and show that a forward Euler discretization of the ODE converges. This inspires a new class of generative models that naturally integrates persistent training (which we call W1-FE). When persistent training is turned off, we prove that W1-FE reduces to WGAN. When we intensify persistent training, W1-FE is shown to outperform WGAN in training experiments from low to high dimensions, in terms of both convergence speed and training results. Intriguingly, one can reap the benefits only when persistent training is carefully integrated through our ODE perspective. As demonstrated numerically, a naive inclusion of persistent training in WGAN (without relying on our ODE framework) can significantly worsen training results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.17508</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.17508</id><created>2024-05-26</created><updated>2025-02-03</updated><authors><author><keyname>Qian</keyname><forenames>Linglong</forenames></author><author><keyname>Yang</keyname><forenames>Yiyuan</forenames></author><author><keyname>Du</keyname><forenames>Wenjie</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Dobsoni</keyname><forenames>Richard</forenames></author><author><keyname>Ibrahim</keyname><forenames>Zina</forenames></author></authors><title>Beyond Random Missingness: Clinically Rethinking for Healthcare Time   Series Imputation</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study investigates the impact of masking strategies on time series imputation models in healthcare settings. While current approaches predominantly rely on random masking for model evaluation, this practice fails to capture the structured nature of missing patterns in clinical data. Using the PhysioNet Challenge 2012 dataset, we analyse how different masking implementations affect both imputation accuracy and downstream clinical predictions across eleven imputation methods. Our results demonstrate that masking choices significantly influence model performance, while recurrent architectures show more consistent performance across strategies. Analysis of downstream mortality prediction reveals that imputation accuracy doesn't necessarily translate to optimal clinical prediction capabilities. Our findings emphasise the need for clinically-informed masking strategies that better reflect real-world missing patterns in healthcare data, suggesting current evaluation frameworks may need reconsideration for reliable clinical deployment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.01793</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.01793</id><created>2024-06-03</created><updated>2025-02-03</updated><authors><author><keyname>Schlaginhaufen</keyname><forenames>Andreas</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author></authors><title>Towards the Transferability of Rewards Recovered via Regularized Inverse   Reinforcement Learning</title><categories>cs.LG cs.AI stat.ML</categories><comments>The Thirty-Eighth Annual Conference on Neural Information Processing   Systems (NeurIPS 2024)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inverse reinforcement learning (IRL) aims to infer a reward from expert demonstrations, motivated by the idea that the reward, rather than the policy, is the most succinct and transferable description of a task [Ng et al., 2000]. However, the reward corresponding to an optimal policy is not unique, making it unclear if an IRL-learned reward is transferable to new transition laws in the sense that its optimal policy aligns with the optimal policy corresponding to the expert's true reward. Past work has addressed this problem only under the assumption of full access to the expert's policy, guaranteeing transferability when learning from two experts with the same reward but different transition laws that satisfy a specific rank condition [Rolland et al., 2022]. In this work, we show that the conditions developed under full access to the expert's policy cannot guarantee transferability in the more practical scenario where we have access only to demonstrations of the expert. Instead of a binary rank condition, we propose principal angles as a more refined measure of similarity and dissimilarity between transition laws. Based on this, we then establish two key results: 1) a sufficient condition for transferability to any transition laws when learning from at least two experts with sufficiently different transition laws, and 2) a sufficient condition for transferability to local changes in the transition law when learning from a single expert. Furthermore, we also provide a probably approximately correct (PAC) algorithm and an end-to-end analysis for learning transferable rewards from demonstrations of multiple experts. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.03696</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.03696</id><created>2024-06-05</created><updated>2025-02-03</updated><authors><author><keyname>Lok</keyname><forenames>Jackie</forenames></author><author><keyname>Sonthalia</keyname><forenames>Rishi</forenames></author><author><keyname>Rebrova</keyname><forenames>Elizaveta</forenames></author></authors><title>Error dynamics of mini-batch gradient descent with random reshuffling   for least squares regression</title><categories>stat.ML cs.LG math.OC</categories><comments>33 pages. Accepted at ALT 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the discrete dynamics of mini-batch gradient descent with random reshuffling for least squares regression. We show that the training and generalization errors depend on a sample cross-covariance matrix $Z$ between the original features $X$ and a set of new features $\widetilde{X}$ in which each feature is modified by the mini-batches that appear before it during the learning process in an averaged way. Using this representation, we establish that the dynamics of mini-batch and full-batch gradient descent agree up to leading order with respect to the step size using the linear scaling rule. However, mini-batch gradient descent with random reshuffling exhibits a subtle dependence on the step size that a gradient flow analysis cannot detect, such as converging to a limit that depends on the step size. By comparing $Z$, a non-commutative polynomial of random matrices, with the sample covariance matrix of $X$ asymptotically, we demonstrate that batching affects the dynamics by resulting in a form of shrinkage on the spectrum. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.05911</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.05911</id><created>2024-06-09</created><updated>2025-02-03</updated><authors><author><keyname>Prasadan</keyname><forenames>Akshay</forenames></author><author><keyname>Neykov</keyname><forenames>Matey</forenames></author></authors><title>Some facts about the optimality of the LSE in the Gaussian sequence   model with convex constraint</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider a convex constrained Gaussian sequence model and characterize necessary and sufficient conditions for the least squares estimator (LSE) to be minimax optimal. For a closed convex set $K\subset \mathbb{R}^n$ we observe $Y=\mu+\xi$ for $\xi\sim \mathcal{N}(0,\sigma^2\mathbb{I}_n)$ and $\mu\in K$ and aim to estimate $\mu$. We characterize the worst case risk of the LSE in multiple ways by analyzing the behavior of the local Gaussian width on $K$. We demonstrate that optimality is equivalent to a Lipschitz property of the local Gaussian width mapping. We also provide theoretical algorithms that search for the worst case risk. We then provide examples showing optimality or suboptimality of the LSE on various sets, including $\ell_p$ balls for $p\in[1,2]$, pyramids, solids of revolution, and multivariate isotonic regression, among others. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.09521</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.09521</id><created>2024-06-13</created><updated>2025-02-04</updated><authors><author><keyname>Ritzwoller</keyname><forenames>David M.</forenames></author><author><keyname>Romano</keyname><forenames>Joseph P.</forenames></author><author><keyname>Shaikh</keyname><forenames>Azeem M.</forenames></author></authors><title>Randomization Inference: Theory and Applications</title><categories>econ.EM stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We review approaches to statistical inference based on randomization. Permutation tests are treated as an important special case. Under a certain group invariance property, referred to as the ``randomization hypothesis,'' randomization tests achieve exact control of the Type I error rate in finite samples. Although this unequivocal precision is very appealing, the range of problems that satisfy the randomization hypothesis is somewhat limited. We show that randomization tests are often asymptotically, or approximately, valid and efficient in settings that deviate from the conditions required for finite-sample error control. When randomization tests fail to offer even asymptotic Type 1 error control, their asymptotic validity may be restored by constructing an asymptotically pivotal test statistic. Randomization tests can then provide exact error control for tests of highly structured hypotheses with good performance in a wider class of problems. We give a detailed overview of several prominent applications of randomization tests, including two-sample permutation tests, regression, and conformal inference. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.14026</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.14026</id><created>2024-06-20</created><updated>2025-02-03</updated><authors><author><keyname>Jin</keyname><forenames>Xisen</forenames></author><author><keyname>Ren</keyname><forenames>Xiang</forenames></author></authors><title>Demystifying Language Model Forgetting with Low-rank Example   Associations</title><categories>cs.LG cs.CL stat.ML</categories><comments>8 pages; preprint</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Large Language models (LLMs) suffer from forgetting of upstream data when fine-tuned. Despite efforts on mitigating forgetting, few have investigated whether, and how forgotten upstream examples are dependent on newly learned tasks. Insights on such dependencies enable efficient and targeted mitigation of forgetting. In this paper, we empirically analyze forgetting that occurs in $N$ upstream examples of language modeling or instruction-tuning after fine-tuning LLMs on one of $M$ new tasks, visualized in $M\times N$ matrices. We show that the matrices are often well-approximated with low-rank matrices, indicating the dominance of simple associations between the learned tasks and forgotten upstream examples. Leveraging the analysis, we predict forgetting of upstream examples when fine-tuning on unseen tasks with matrix completion over the empirical associations. This enables fast identification of most forgotten examples without expensive inference on the entire upstream data. The approach, despite simplicity, outperforms prior approaches that learn semantic relationships of learned tasks and upstream examples with LMs for predicting forgetting. We demonstrate the practical utility of our analysis by showing statistically significantly reduced forgetting as we upweight predicted examples for replay at fine-tuning. Project page: https://inklab.usc.edu/lm-forgetting-prediction/ </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.03389</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.03389</id><created>2024-07-03</created><updated>2025-02-04</updated><authors><author><keyname>Costa</keyname><forenames>Efthymios</forenames></author><author><keyname>Papatsouma</keyname><forenames>Ioanna</forenames></author><author><keyname>Markos</keyname><forenames>Angelos</forenames></author></authors><title>A Deterministic Information Bottleneck Method for Clustering Mixed-Type   Data</title><categories>stat.ME cs.LG stat.ML</categories><comments>30 pages</comments><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we present an information-theoretic method for clustering mixed-type data, that is, data consisting of both continuous and categorical variables. The proposed approach is built on the deterministic variant of the Information Bottleneck algorithm, designed to optimally compress data while preserving its relevant structural information. We evaluate the performance of our method against four well-established clustering techniques for mixed-type data -- KAMILA, K-Prototypes, Factor Analysis for Mixed Data with K-Means, and Partitioning Around Medoids using Gower's dissimilarity -- using both simulated and real-world datasets. The results highlight that the proposed approach offers a competitive alternative to traditional clustering techniques, particularly under specific conditions where heterogeneity in data poses significant challenges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.15532</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.15532</id><created>2024-07-22</created><updated>2025-02-03</updated><authors><author><keyname>Korangi</keyname><forenames>Kamesh</forenames></author><author><keyname>Mues</keyname><forenames>Christophe</forenames></author><author><keyname>Bravo</keyname><forenames>Cristián</forenames></author></authors><title>Large-scale Time-Varying Portfolio Optimisation using Graph Attention   Networks</title><categories>q-fin.PM cs.AI cs.SI q-fin.RM stat.ML</categories><comments>39 pages, 10 figures, v2</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Apart from assessing individual asset performance, investors in financial markets also need to consider how a set of firms performs collectively as a portfolio. Whereas traditional Markowitz-based mean-variance portfolios are widespread, network-based optimisation techniques offer a more flexible tool to capture complex interdependencies between asset values. However, most of the existing studies do not contain firms at risk of default and remove any firms that drop off indices over a certain time. This is the first study to also incorporate such firms in portfolio optimisation on a large scale. We propose and empirically test a novel method that leverages Graph Attention networks (GATs), a subclass of Graph Neural Networks (GNNs). GNNs, as deep learning-based models, can exploit network data to uncover nonlinear relationships. Their ability to handle high-dimensional data and accommodate customised layers for specific purposes makes them appealing for large-scale problems such as mid- and small-cap portfolio optimisation. This study utilises 30 years of data on mid-cap firms, creating graphs of firms using distance correlation and the Triangulated Maximally Filtered Graph approach. These graphs are the inputs to a GAT model incorporating weight and allocation constraints and a loss function derived from the Sharpe ratio, thus focusing on maximising portfolio risk-adjusted returns. This new model is benchmarked against a network characteristic-based portfolio, a mean variance-based portfolio, and an equal-weighted portfolio. The results show that the portfolio produced by the GAT-based model outperforms all benchmarks and is consistently superior to other strategies over a long period, while also being informative of market dynamics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.16134</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.16134</id><created>2024-07-22</created><updated>2025-02-04</updated><authors><author><keyname>Fu</keyname><forenames>Hengyu</forenames></author><author><keyname>Dou</keyname><forenames>Zehao</forenames></author><author><keyname>Guo</keyname><forenames>Jiawei</forenames></author><author><keyname>Wang</keyname><forenames>Mengdi</forenames></author><author><keyname>Chen</keyname><forenames>Minshuo</forenames></author></authors><title>Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory   for Gaussian Process Data</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>56 pages, 13 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation. Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies. These dependencies represent the underlying dynamic model and are critical to validate the generated data. In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies. Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns. We highlight how the spatial-temporal dependencies are captured and affect learning efficiency. Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm. We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.02326</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.02326</id><created>2024-08-05</created><updated>2025-02-04</updated><authors><author><keyname>Aguilera</keyname><forenames>Miguel</forenames></author><author><keyname>Morales</keyname><forenames>Pablo A.</forenames></author><author><keyname>Rosas</keyname><forenames>Fernando E.</forenames></author><author><keyname>Shimazaki</keyname><forenames>Hideaki</forenames></author></authors><title>Explosive neural networks via higher-order interactions in curved   statistical manifolds</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT nlin.AO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order interactions underlie complex phenomena in systems such as biological and artificial neural networks, but their study is challenging due to the scarcity of tractable models. By leveraging a generalisation of the maximum entropy principle, here we introduce curved neural networks as a class of prototypical models with a limited number of parameters that are particularly well-suited for studying higher-order phenomena. Through exact mean-field descriptions, we show that these curved neural networks implement a self-regulating annealing process that can accelerate memory retrieval, leading to explosive order-disorder phase transitions with multi-stability and hysteresis effects. Moreover, by analytically exploring their memory-retrieval capacity using the replica trick near ferromagnetic and spin-glass phase boundaries, we demonstrate that these networks can enhance memory capacity and robustness of retrieval over classical associative-memory networks. Overall, the proposed framework provides parsimonious models amenable to analytical study, revealing novel higher-order phenomena in complex networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.07463</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.07463</id><created>2024-08-14</created><updated>2025-02-04</updated><authors><author><keyname>Costa</keyname><forenames>Efthymios</forenames></author><author><keyname>Papatsouma</keyname><forenames>Ioanna</forenames></author></authors><title>A novel framework for quantifying nominal outlyingness</title><categories>stat.ME</categories><comments>24 pages</comments><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Outlier detection is an important data mining tool that becomes particularly challenging when dealing with nominal data. First and foremost, flagging observations as outlying requires a well-defined notion of nominal outlyingness. This paper presents a definition of nominal outlyingness and introduces a general framework for quantifying outlyingness of nominal data. The proposed framework makes use of ideas from the association rule mining literature and can be used for calculating scores that indicate how outlying a nominal observation is. Methods for determining the involved hyperparameter values are presented and the concepts of variable contributions and outlyingness depth are introduced, in an attempt to enhance interpretability of the results. The proposed framework is evaluated on both synthetic and real-world data sets, demonstrating comparable performance to state-of-the-art frequent pattern mining algorithms and even outperforming them in certain cases. The ideas presented can serve as a tool for assessing the degree to which an observation differs from the rest of the data, under the assumption of sequences of nominal levels having been generated from a Multinomial distribution with varying event probabilities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.08062</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.08062</id><created>2024-08-15</created><updated>2025-02-04</updated><authors><author><keyname>Champneys</keyname><forenames>Max D.</forenames></author><author><keyname>Rogers</keyname><forenames>Timothy J.</forenames></author></authors><title>BINDy -- Bayesian identification of nonlinear dynamics with   reversible-jump Markov-chain Monte-Carlo</title><categories>stat.ML cs.LG math.DS</categories><doi>10.1098/rspa.2024.0620</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Model parsimony is an important \emph{cognitive bias} in data-driven modelling that aids interpretability and helps to prevent over-fitting. Sparse identification of nonlinear dynamics (SINDy) methods are able to learn sparse representations of complex dynamics directly from data, given a basis of library functions. In this work, a novel Bayesian treatment of dictionary learning system identification, as an alternative to SINDy, is envisaged. The proposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is distinct from previous approaches in that it targets the full joint posterior distribution over both the terms in the library and their parameterisation in the model. This formulation confers the advantage that an arbitrary prior may be placed over the model structure to produce models that are sparse in the model space rather than in parameter space. Because this posterior is defined over parameter vectors that can change in dimension, the inference cannot be performed by standard techniques. Instead, a Gibbs sampler based on reversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare favourably to ensemble SINDy in three benchmark case-studies. In particular, it is seen that the proposed method is better able to assign high probability to correct model terms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.19546</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.19546</id><created>2024-09-29</created><updated>2025-02-03</updated><authors><author><keyname>Blaser</keyname><forenames>Ethan</forenames></author><author><keyname>Zhang</keyname><forenames>Shangtong</forenames></author></authors><title>Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic   Approximations with Markovian Noise</title><categories>cs.LG cs.AI math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Stochastic approximation is an important class of algorithms, and a large body of previous analysis focuses on stochastic approximations driven by contractive operators, which is not applicable in some important reinforcement learning settings. This work instead investigates stochastic approximations with merely nonexpansive operators. In particular, we study nonexpansive stochastic approximations with Markovian noise, providing both asymptotic and finite sample analysis. Key to our analysis are a few novel bounds of noise terms resulting from the Poisson equation. As an application, we prove, for the first time, that the classical tabular average reward temporal difference learning converges to a sample path dependent fixed point. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.12538</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.12538</id><created>2024-10-16</created><updated>2025-02-03</updated><authors><author><keyname>Rahmani</keyname><forenames>Saeed</forenames></author><author><keyname>Xu</keyname><forenames>Zhenlin</forenames></author><author><keyname>Calvert</keyname><forenames>Simeon C.</forenames></author><author><keyname>van Arem</keyname><forenames>Bart</forenames></author></authors><title>Automated Vehicles at Unsignalized Intersections: Safety and Efficiency   Implications of Mixed-Human-Automated Traffic</title><categories>cs.RO cs.AI stat.AP</categories><comments>This work has been submitted to Transportation Research Record for   potential publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of automated vehicles (AVs) into transportation systems presents an unprecedented opportunity to enhance road safety and efficiency. However, understanding the interactions between AVs and human-driven vehicles (HVs) at intersections remains an open research question. This study aims to bridge this gap by examining behavioral differences and adaptations of AVs and HVs at unsignalized intersections by utilizing two large-scale AV datasets from Waymo and Lyft. By using a systematic methodology, the research identifies and analyzes merging and crossing conflicts by calculating key safety and efficiency metrics, including time to collision (TTC), post-encroachment time (PET), maximum required deceleration (MRD), time advantage (TA), and speed and acceleration profiles. The findings reveal a paradox in mixed traffic flow: while AVs maintain larger safety margins, their conservative behavior can lead to unexpected situations for human drivers, potentially causing unsafe conditions. From a performance point of view, human drivers exhibit more consistent behavior when interacting with AVs versus other HVs, suggesting AVs may contribute to harmonizing traffic flow patterns. Moreover, notable differences were observed between Waymo and Lyft vehicles, which highlights the importance of considering manufacturer-specific AV behaviors in traffic modeling and management strategies for the safe integration of AVs. The processed dataset utilized in this study is openly published to foster the research on AV-HV interactions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.21154</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.21154</id><created>2024-10-28</created><updated>2025-02-04</updated><authors><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Pu</keyname><forenames>Yuan</forenames></author><author><keyname>Kawamura</keyname><forenames>Yuki</forenames></author><author><keyname>Loza</keyname><forenames>Andrew</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Shung</keyname><forenames>Dennis L.</forenames></author><author><keyname>Tong</keyname><forenames>Alexander</forenames></author></authors><title>Trajectory Flow Matching with Applications to Clinical Time Series   Modeling</title><categories>cs.LG cs.AI stat.ML</categories><comments>NeurIPS 2024 Spotlight</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling stochastic and irregularly sampled time series is a challenging problem found in a wide range of applications, especially in medicine. Neural stochastic differential equations (Neural SDEs) are an attractive modeling technique for this problem, which parameterize the drift and diffusion terms of an SDE with neural networks. However, current algorithms for training Neural SDEs require backpropagation through the SDE dynamics, greatly limiting their scalability and stability. To address this, we propose Trajectory Flow Matching (TFM), which trains a Neural SDE in a simulation-free manner, bypassing backpropagation through the dynamics. TFM leverages the flow matching technique from generative modeling to model time series. In this work we first establish necessary conditions for TFM to learn time series data. Next, we present a reparameterization trick which improves training stability. Finally, we adapt TFM to the clinical time series setting, demonstrating improved performance on three clinical time series datasets both in terms of absolute performance and uncertainty prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.01694</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.01694</id><created>2024-11-03</created><updated>2025-02-03</updated><authors><author><keyname>Bayisa</keyname><forenames>Fekadu L.</forenames></author><author><keyname>Seals</keyname><forenames>Christopher L.</forenames></author><author><keyname>Leeper</keyname><forenames>Hannah J.</forenames></author><author><keyname>Steury</keyname><forenames>Todd D.</forenames></author><author><keyname>Ceyhan</keyname><forenames>Elvan</forenames></author></authors><title>Modeling Home Range and Intra-Specific Spatial Interaction in Wild   Animal Populations</title><categories>stat.AP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions among individuals from the same-species of wild animals are an important component of population dynamics. An interaction can be either static (based on overlap of space use) or dynamic (based on movement). The goal of this work is to determine the level of static interactions between individuals from the same-species of wild animals using 95\% and 50\% home ranges, as well as to model their movement interactions, which could include attraction, avoidance (or repulsion), or lack of interaction, in order to gain new insights and improve our understanding of ecological processes. Home range estimation methods (minimum convex polygon, kernel density estimator, and autocorrelated kernel density estimator), inhomogeneous multitype (or cross-type) summary statistics, and envelope testing methods (pointwise and global envelope tests) were proposed to study the nature of the same-species wild-animal spatial interactions. This study provides comprehensive, self-contained methodological details for investigating spatial interactions between individuals of the same species in wildlife populations. Using GPS collar data, we applied the methods to quantify both static and dynamic interactions between black bears in southern Alabama, USA. In general, our findings suggest that the black bears in our dataset showed no significant preference to live together or apart, i.e., there was no significant deviation from independence toward association or avoidance (i.e., segregation) between the bears. This can be loosely interpreted to mean that a black bear is generally indifferent to the presence of other black bears living or wandering nearby. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.16715</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.16715</id><created>2024-11-22</created><updated>2025-02-04</updated><authors><author><keyname>Pohland</keyname><forenames>Sara</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire</forenames></author></authors><title>PaRCE: Probabilistic and Reconstruction-based Competency Estimation for   CNN-based Image Classification</title><categories>cs.CV cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:2409.06111</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNNs) are extremely popular and effective for image classification tasks but tend to be overly confident in their predictions. Various works have sought to quantify uncertainty associated with these models, detect out-of-distribution (OOD) inputs, or identify anomalous regions in an image, but limited work has sought to develop a holistic approach that can accurately estimate perception model confidence across various sources of uncertainty. We develop a probabilistic and reconstruction-based competency estimation (PaRCE) method and compare it to existing approaches for uncertainty quantification and OOD detection. We find that our method can best distinguish between correctly classified, misclassified, and OOD samples with anomalous regions, as well as between samples with visual image modifications resulting in high, medium, and low prediction accuracy. We describe how to extend our approach for anomaly localization tasks and demonstrate the ability of our approach to distinguish between regions in an image that are familiar to the perception model from those that are unfamiliar. We find that our method generates interpretable scores that most reliably capture a holistic notion of perception model confidence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.05906</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.05906</id><created>2024-12-08</created><updated>2025-02-04</updated><authors><author><keyname>Li</keyname><forenames>Lucky</forenames></author></authors><title>Reinforcement Learning for a Discrete-Time Linear-Quadratic Control   Problem with an Application</title><categories>stat.ML cs.LG math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the discrete-time linear-quadratic (LQ) control model using reinforcement learning (RL). Using entropy to measure the cost of exploration, we prove that the optimal feedback policy for the problem must be Gaussian type. Then, we apply the results of the discrete-time LQ model to solve the discrete-time mean-variance asset-liability management problem and prove our RL algorithm's policy improvement and convergence. Finally, a numerical example sheds light on the theoretical results established using simulations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20553</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20553</id><created>2024-12-29</created><updated>2025-02-04</updated><authors><author><keyname>Andreyev</keyname><forenames>Arseniy</forenames></author><author><keyname>Beneventano</keyname><forenames>Pierfrancesco</forenames></author></authors><title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title><categories>cs.LG math.OC stat.ML</categories><comments>35 pages, 26 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent findings by Cohen et al., 2021, demonstrate that when training neural networks with full-batch gradient descent with a step size of $\eta$, the largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently stabilizes at $\lambda_{\max} = 2/\eta$. These results have significant implications for convergence and generalization. This, however, is not the case of mini-batch stochastic gradient descent (SGD), limiting the broader applicability of its consequences. We show that SGD trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/\eta$ is *Batch Sharpness*: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $\lambda_{\max}$--which is generally smaller than Batch Sharpness--is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06653</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06653</id><created>2025-01-11</created><authors><author><keyname>Zhao</keyname><forenames>Mengyu</forenames></author><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author></authors><title>Theoretical Characterization of Effect of Masks in Snapshot Compressive   Imaging</title><categories>cs.IT eess.IV math.IT stat.AP</categories><comments>27 pages. arXiv admin note: substantial text overlap with   arXiv:2307.07796</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Snapshot compressive imaging (SCI) refers to the recovery of three-dimensional data cubes-such as videos or hyperspectral images-from their two-dimensional projections, which are generated by a special encoding of the data with a mask. SCI systems commonly use binary-valued masks that follow certain physical constraints. Optimizing these masks subject to these constraints is expected to improve system performance. However, prior theoretical work on SCI systems focuses solely on independently and identically distributed (i.i.d.) Gaussian masks, which do not permit such optimization. On the other hand, existing practical mask optimizations rely on computationally intensive joint optimizations that provide limited insight into the role of masks and are expected to be sub-optimal due to the non-convexity and complexity of the optimization. In this paper, we analytically characterize the performance of SCI systems employing binary masks and leverage our analysis to optimize hardware parameters. Our findings provide a comprehensive and fundamental understanding of the role of binary masks - with both independent and dependent elements - and their optimization. We also present simulation results that confirm our theoretical findings and further illuminate different aspects of mask design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08945</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08945</id><created>2025-01-15</created><updated>2025-02-04</updated><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>Zhu</keyname><forenames>Ke</forenames></author><author><keyname>Han</keyname><forenames>Larry</forenames></author><author><keyname>Yang</keyname><forenames>Shu</forenames></author></authors><title>COADVISE: Covariate Adjustment with Variable Selection and Missing Data   Imputation in Randomized Controlled Trials</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adjusting for covariates in randomized controlled trials can enhance the credibility and efficiency of treatment effect estimation. However, handling numerous covariates and their non-linear transformations is challenging, particularly when outcomes and covariates have missing data. In this tutorial, we propose a principled Covariate Adjustment with Variable Selection and Missing Data Imputation (COADVISE) framework that enables (i) variable selection for covariates most relevant to the outcome, (ii) nonlinear adjustments, and (iii) robust imputation of missing data for both outcomes and covariates. This framework ensures consistent estimates with improved efficiency over unadjusted estimators and provides robust variance estimation, even under outcome model misspecification. We demonstrate efficiency gains through theoretical analysis and conduct extensive simulations to compare alternative variable selection strategies, offering cautionary recommendations. We showcase the practical utility of COADVISE by applying it to the Best Apnea Interventions for Research trial data from the National Sleep Research Resource. A user-friendly R package, Coadvise, facilitates implementation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12737</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12737</id><created>2025-01-22</created><updated>2025-02-04</updated><authors><author><keyname>Yang</keyname><forenames>Jiaqi</forenames></author><author><keyname>Xie</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Xiaohua</forenames></author></authors><title>Stability and Generalization of Quantum Neural Networks</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum neural networks (QNNs) play an important role as an emerging technology in the rapidly growing field of quantum machine learning. While their empirical success is evident, the theoretical explorations of QNNs, particularly their generalization properties, are less developed and primarily focus on the uniform convergence approach. In this paper, we exploit an advanced tool in classical learning theory, i.e., algorithmic stability, to study the generalization of QNNs. We first establish high-probability generalization bounds for QNNs via uniform stability. Our bounds shed light on the key factors influencing the generalization performance of QNNs and provide practical insights into both the design and training processes. We next explore the generalization of QNNs on near-term noisy intermediate-scale quantum (NISQ) devices, highlighting the potential benefits of quantum noise. Moreover, we argue that our previous analysis characterizes worst-case generalization guarantees, and we establish a refined optimization-dependent generalization bound for QNNs via on-average stability. Numerical experiments on various real-world datasets support our theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.15194</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.15194</id><created>2025-01-25</created><updated>2025-02-04</updated><authors><author><keyname>Yao</keyname><forenames>Zhihao</forenames></author><author><keyname>Yin</keyname><forenames>Jixuan</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author></authors><title>Reliable Pseudo-labeling via Optimal Transport with Attention for Short   Text Clustering</title><categories>cs.LG stat.CO stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Short text clustering has gained significant attention in the data mining community. However, the limited valuable information contained in short texts often leads to low-discriminative representations, increasing the difficulty of clustering. This paper proposes a novel short text clustering framework, called Reliable \textbf{P}seudo-labeling via \textbf{O}ptimal \textbf{T}ransport with \textbf{A}ttention for Short Text Clustering (\textbf{POTA}), that generate reliable pseudo-labels to aid discriminative representation learning for clustering. Specially, \textbf{POTA} first implements an instance-level attention mechanism to capture the semantic relationships among samples, which are then incorporated as a semantic consistency regularization term into an optimal transport problem. By solving this OT problem, we can yield reliable pseudo-labels that simultaneously account for sample-to-sample semantic consistency and sample-to-cluster global structure information. Additionally, the proposed OT can adaptively estimate cluster distributions, making \textbf{POTA} well-suited for varying degrees of imbalanced datasets. Then, we utilize the pseudo-labels to guide contrastive learning to generate discriminative representations and achieve efficient clustering. Extensive experiments demonstrate \textbf{POTA} outperforms state-of-the-art methods. The code is available at: \href{https://github.com/YZH0905/POTA-STC/tree/main}{https://github.com/YZH0905/POTA-STC/tree/main}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.16730</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.16730</id><created>2025-01-28</created><updated>2025-02-04</updated><authors><author><keyname>Cong</keyname><forenames>Lin William</forenames></author><author><keyname>Feng</keyname><forenames>Guanhao</forenames></author><author><keyname>He</keyname><forenames>Jingyu</forenames></author><author><keyname>He</keyname><forenames>Xin</forenames></author></authors><title>Growing the Efficient Frontier on Panel Trees</title><categories>cs.LG q-fin.PR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of tree-based models, P-Trees, for analyzing (unbalanced) panel of individual asset returns, generalizing high-dimensional sorting with economic guidance and interpretability. Under the mean-variance efficient framework, P-Trees construct test assets that significantly advance the efficient frontier compared to commonly used test assets, with alphas unexplained by benchmark pricing models. P-Tree tangency portfolios also constitute traded factors, recovering the pricing kernel and outperforming popular observable and latent factor models for investments and cross-sectional pricing. Finally, P-Trees capture the complexity of asset returns with sparsity, achieving out-of-sample Sharpe ratios close to those attained only by over-parameterized large models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.17446</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.17446</id><created>2025-01-29</created><updated>2025-02-03</updated><authors><author><keyname>Satoh</keyname><forenames>Kenichi</forenames></author></authors><title>Applying non-negative matrix factorization with covariates to   multivariate time series data as a vector autoregression model</title><categories>stat.ME</categories><comments>8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative matrix factorization (NMF) is a powerful technique for dimensionality reduction, but its application to time series data remains limited. This paper proposes a novel framework that integrates NMF with a vector autoregression (VAR) model to capture both latent structure and temporal dependencies in multivariate time series data. By representing the NMF coefficient matrix as a VAR model, the framework leverages the interpretability of NMF while incorporating the dynamic characteristics of time series data. This approach allows for the extraction of meaningful features and accurate predictions in time series data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.00298</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.00298</id><created>2025-01-31</created><updated>2025-02-03</updated><authors><author><keyname>Moreno</keyname><forenames>Alexander</forenames></author><author><keyname>Xiao</keyname><forenames>Justin</forenames></author><author><keyname>Mei</keyname><forenames>Jonathan</forenames></author></authors><title>The Price of Linear Time: Error Analysis of Structured Kernel   Interpolation</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Structured Kernel Interpolation (SKI) (Wilson et al. 2015) helps scale Gaussian Processes (GPs) by approximating the kernel matrix via interpolation at inducing points, achieving linear computational complexity. However, it lacks rigorous theoretical error analysis. This paper bridges the gap: we prove error bounds for the SKI Gram matrix and examine the error's effect on hyperparameter estimation and posterior inference. We further provide a practical guide to selecting the number of inducing points under convolutional cubic interpolation: they should grow as $n^{d/3}$ for error control. Crucially, we identify two dimensionality regimes governing the trade-off between SKI Gram matrix spectral norm error and computational complexity. For $d \leq 3$, any error tolerance can achieve linear time for sufficiently large sample size. For $d &gt; 3$, the error must increase with sample size to maintain linear time. Our analysis provides key insights into SKI's scalability-accuracy trade-offs, establishing precise conditions for achieving linear-time GP inference with controlled approximation error. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01672</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01672</id><created>2025-02-01</created><authors><author><keyname>Liu</keyname><forenames>Manqing</forenames></author><author><keyname>Beam</keyname><forenames>Andrew L.</forenames></author></authors><title>Doubly Robust Monte Carlo Tree Search</title><categories>stat.ML cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present Doubly Robust Monte Carlo Tree Search (DR-MCTS), a novel algorithm that integrates Doubly Robust (DR) off-policy estimation into Monte Carlo Tree Search (MCTS) to enhance sample efficiency and decision quality in complex environments. Our approach introduces a hybrid estimator that combines MCTS rollouts with DR estimation, offering theoretical guarantees of unbiasedness and variance reduction under specified conditions. Empirical evaluations in Tic-Tac-Toe and the partially observable VirtualHome environment demonstrate DR-MCTS's superior performance over standard MCTS. In Tic-Tac-Toe, DR-MCTS achieves an 88% win rate compared to a 10% win rate for standard MCTS. In compound VirtualHome tasks, DR-MCTS attains a 20.7% success rate versus 10.3% for standard MCTS. Our scaling analysis reveals that DR-MCTS exhibits better sample efficiency, notably outperforming standard MCTS with larger language models while using a smaller model. These results underscore DR-MCTS's potential for efficient decision-making in complex, real-world scenarios where sample efficiency is paramount. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01694</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01694</id><created>2025-02-02</created><authors><author><keyname>Kim</keyname><forenames>Juno</forenames></author><author><keyname>Wu</keyname><forenames>Denny</forenames></author><author><keyname>Lee</keyname><forenames>Jason</forenames></author><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author></authors><title>Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of   Search, RL and Distillation</title><categories>cs.AI cs.LG stat.ML</categories><comments>55 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A key paradigm to improve the reasoning capabilities of large language models (LLMs) is to allocate more inference-time compute to search against a verifier or reward model. This process can then be utilized to refine the pretrained model or distill its reasoning patterns into more efficient models. In this paper, we study inference-time compute by viewing chain-of-thought (CoT) generation as a metastable Markov process: easy reasoning steps (e.g., algebraic manipulations) form densely connected clusters, while hard reasoning steps (e.g., applying a relevant theorem) create sparse, low-probability edges between clusters, leading to phase transitions at longer timescales. Under this framework, we prove that implementing a search protocol that rewards sparse edges improves CoT by decreasing the expected number of steps to reach different clusters. In contrast, we establish a limit on reasoning capability when the model is restricted to local information of the pretrained graph. We also show that the information gained by search can be utilized to obtain a better reasoning model: (1) the pretrained model can be directly finetuned to favor sparse edges via policy gradient methods, and moreover (2) a compressed metastable representation of the reasoning dynamics can be distilled into a smaller, more efficient model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01701</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01701</id><created>2025-02-03</created><authors><author><keyname>Lalanne</keyname><forenames>Clément</forenames><affiliation>IMT, ANITI</affiliation></author><author><keyname>Loubes</keyname><forenames>Jean-Michel</forenames><affiliation>IMT, ANITI</affiliation></author><author><keyname>Rodríguez-Vítores</keyname><forenames>David</forenames><affiliation>UVa, IMUVA</affiliation></author></authors><title>Learning with Differentially Private (Sliced) Wasserstein Gradients</title><categories>cs.LG math.ST stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce a novel framework for privately optimizing objectives that rely on Wasserstein distances between data-dependent empirical measures. Our main theoretical contribution is, based on an explicit formulation of the Wasserstein gradient in a fully discrete setting, a control on the sensitivity of this gradient to individual data points, allowing strong privacy guarantees at minimal utility cost. Building on these insights, we develop a deep learning approach that incorporates gradient and activations clipping, originally designed for DP training of problems with a finite-sum structure. We further demonstrate that privacy accounting methods extend to Wasserstein-based objectives, facilitating large-scale private training. Empirical results confirm that our framework effectively balances accuracy and privacy, offering a theoretically sound solution for privacy-preserving machine learning tasks relying on optimal transport distances such as Wasserstein distance or sliced-Wasserstein distance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01763</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01763</id><created>2025-02-03</created><authors><author><keyname>Zhang</keyname><forenames>Thomas T.</forenames></author><author><keyname>Moniri</keyname><forenames>Behrad</forenames></author><author><keyname>Nagwekar</keyname><forenames>Ansh</forenames></author><author><keyname>Rahman</keyname><forenames>Faraz</forenames></author><author><keyname>Xue</keyname><forenames>Anton</forenames></author><author><keyname>Hassani</keyname><forenames>Hamed</forenames></author><author><keyname>Matni</keyname><forenames>Nikolai</forenames></author></authors><title>On The Concurrence of Layer-wise Preconditioning Methods and Provable   Feature Learning</title><categories>cs.LG math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Layer-wise preconditioning methods are a family of memory-efficient optimization algorithms that introduce preconditioners per axis of each layer's weight tensors. These methods have seen a recent resurgence, demonstrating impressive performance relative to entry-wise ("diagonal") preconditioning methods such as Adam(W) on a wide range of neural network optimization tasks. Complementary to their practical performance, we demonstrate that layer-wise preconditioning methods are provably necessary from a statistical perspective. To showcase this, we consider two prototypical models, linear representation learning and single-index learning, which are widely used to study how typical algorithms efficiently learn useful features to enable generalization. In these problems, we show SGD is a suboptimal feature learner when extending beyond ideal isotropic inputs $\mathbf{x} \sim \mathsf{N}(\mathbf{0}, \mathbf{I})$ and well-conditioned settings typically assumed in prior work. We demonstrate theoretically and numerically that this suboptimality is fundamental, and that layer-wise preconditioning emerges naturally as the solution. We further show that standard tools like Adam preconditioning and batch-norm only mildly mitigate these issues, supporting the unique benefits of layer-wise preconditioning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01780</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01780</id><created>2025-02-03</created><authors><author><keyname>Park</keyname><forenames>Hongju</forenames></author><author><keyname>Bai</keyname><forenames>Shuyang</forenames></author><author><keyname>Ye</keyname><forenames>Zhenyao</forenames></author><author><keyname>Lee</keyname><forenames>Hwiyoung</forenames></author><author><keyname>Ma</keyname><forenames>Tianzhou</forenames></author><author><keyname>Chen</keyname><forenames>Shuo</forenames></author></authors><title>Graph Canonical Correlation Analysis</title><categories>stat.ML cs.LG</categories><comments>40 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Canonical correlation analysis (CCA) is a widely used technique for estimating associations between two sets of multi-dimensional variables. Recent advancements in CCA methods have expanded their application to decipher the interactions of multiomics datasets, imaging-omics datasets, and more. However, conventional CCA methods are limited in their ability to incorporate structured patterns in the cross-correlation matrix, potentially leading to suboptimal estimations. To address this limitation, we propose the graph Canonical Correlation Analysis (gCCA) approach, which calculates canonical correlations based on the graph structure of the cross-correlation matrix between the two sets of variables. We develop computationally efficient algorithms for gCCA, and provide theoretical results for finite sample analysis of best subset selection and canonical correlation estimation by introducing concentration inequalities and stopping time rule based on martingale theories. Extensive simulations demonstrate that gCCA outperforms competing CCA methods. Additionally, we apply gCCA to a multiomics dataset of DNA methylation and RNA-seq transcriptomics, identifying both positively and negatively regulated gene expression pathways by DNA methylation pathways. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01810</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01810</id><created>2025-02-03</created><authors><author><keyname>Mele</keyname><forenames>Angelo</forenames></author></authors><title>Estimating Network Models using Neural Networks</title><categories>cs.SI econ.EM stat.CO stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Exponential random graph models (ERGMs) are very flexible for modeling network formation but pose difficult estimation challenges due to their intractable normalizing constant. Existing methods, such as MCMC-MLE, rely on sequential simulation at every optimization step. We propose a neural network approach that trains on a single, large set of parameter-simulation pairs to learn the mapping from parameters to average network statistics. Once trained, this map can be inverted, yielding a fast and parallelizable estimation method. The procedure also accommodates extra network statistics to mitigate model misspecification. Some simple illustrative examples show that the method performs well in practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01861</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01861</id><created>2025-02-03</created><authors><author><keyname>Harvey</keyname><forenames>Ethan</forenames></author><author><keyname>Petrov</keyname><forenames>Mikhail</forenames></author><author><keyname>Hughes</keyname><forenames>Michael C.</forenames></author></authors><title>Learning Hyperparameters via a Data-Emphasized Variational Objective</title><categories>cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:2410.19675</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When training large flexible models, practitioners often rely on grid search to select hyperparameters that control over-fitting. This grid search has several disadvantages: the search is computationally expensive, requires carving out a validation set that reduces the available data for training, and requires users to specify candidate values. In this paper, we propose an alternative: directly learning regularization hyperparameters on the full training set via the evidence lower bound ("ELBo") objective from variational methods. For deep neural networks with millions of parameters, we recommend a modified ELBo that upweights the influence of the data likelihood relative to the prior. Our proposed technique overcomes all three disadvantages of grid search. In a case study on transfer learning of image classifiers, we show how our method reduces the 88+ hour grid search of past work to under 3 hours while delivering comparable accuracy. We further demonstrate how our approach enables efficient yet accurate approximations of Gaussian processes with learnable length-scale kernels. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01886</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01886</id><created>2025-02-03</created><authors><author><keyname>Díaz</keyname><forenames>Mateo</forenames></author><author><keyname>Drusvyatskiy</keyname><forenames>Dmitriy</forenames></author><author><keyname>Kendrick</keyname><forenames>Jack</forenames></author><author><keyname>Thomas</keyname><forenames>Rekha R.</forenames></author></authors><title>Invariant Kernels: Rank Stabilization and Generalization Across   Dimensions</title><categories>math.OC math.RT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry arises often when learning from high dimensional data. For example, data sets consisting of point clouds, graphs, and unordered sets appear routinely in contemporary applications, and exhibit rich underlying symmetries. Understanding the benefits of symmetry on the statistical and numerical efficiency of learning algorithms is an active area of research. In this work, we show that symmetry has a pronounced impact on the rank of kernel matrices. Specifically, we compute the rank of a polynomial kernel of fixed degree that is invariant under various groups acting independently on its two arguments. In concrete circumstances, including the three aforementioned examples, symmetry dramatically decreases the rank making it independent of the data dimension. In such settings, we show that a simple regression procedure is minimax optimal for estimating an invariant polynomial from finitely many samples drawn across different dimensions. We complete the paper with numerical experiments that illustrate our findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01892</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01892</id><created>2025-02-03</created><authors><author><keyname>Stivala</keyname><forenames>Alex</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Lomi</keyname><forenames>Alessandro</forenames></author></authors><title>Improving exponential-family random graph models for bipartite networks</title><categories>stat.ME stat.AP</categories><comments>54 pages including appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bipartite graphs, representing two-mode networks, arise in many research fields. These networks have two disjoint node sets representing distinct entity types, for example persons and groups, with edges representing associations between the two entity types. In bipartite graphs, the smallest possible cycle is a cycle of length four, and hence four-cycles are the smallest structure to model closure in such networks. Exponential-family random graph models (ERGMs) are a widely used model for social, and other, networks, including specifically bipartite networks. Existing ERGM terms to model four-cycles in bipartite networks, however, are relatively rarely used. In this work we demonstrate some problems with these existing terms to model four-cycles, and define new ERGM terms to help overcome these problems. The position of the new terms in the ERGM dependence hierarchy, and their interpretation, is discussed. The new terms are demonstrated in simulation experiments, and their application illustrated with ERGM models of empirical networks ranging in size from hundreds of nodes to hundreds of thousands of nodes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01919</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01919</id><created>2025-02-03</created><authors><author><keyname>James</keyname><forenames>Lancelot F.</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Pandey</keyname><forenames>Abhinav</forenames></author></authors><title>Poisson Hierarchical Indian Buffet Processes for Within and Across Group   Sharing of Latent Features-With Indications for Microbiome Species Sampling   Models</title><categories>stat.ML cs.LG math.PR math.ST stat.TH</categories><comments>experiments to be added</comments><msc-class>60C05, 60G09 (Primary), 60G57, 60E99 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we present a comprehensive Bayesian posterior analysis of what we term Poisson Hierarchical Indian Buffet Processes, designed for complex random sparse count species sampling models that allow for the sharing of information across and within groups. This analysis covers a potentially infinite number of species and unknown parameters, which, within a Bayesian machine learning context, we are able to learn from as more information is sampled. To achieve our refined results, we employ a range of methodologies drawn from Bayesian latent feature models, random occupancy models, and excursion theory. Despite this complexity, our goal is to make our findings accessible to practitioners, including those who may not be familiar with these areas. To facilitate understanding, we adopt a pseudo-expository style that emphasizes clarity and practical utility. We aim to express our findings in a language that resonates with experts in microbiome and ecological studies, addressing gaps in modeling capabilities while acknowledging that we are not experts ourselves in these fields. This approach encourages the use of our models as basic components of more sophisticated frameworks employed by domain experts, embodying the spirit of the seminal work on the Dirichlet Process. Ultimately, our refined posterior analysis not only yields tractable computational procedures but also enables practical statistical implementation and provides a clear mapping to relevant quantities in microbiome analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01947</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01947</id><created>2025-02-03</created><authors><author><keyname>Zheng</keyname><forenames>Runbing</forenames></author></authors><title>Detection and estimation of vertex-wise latent position shifts across   networks</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pairwise network comparison is essential for various applications, including neuroscience, disease research, and dynamic network analysis. While existing literature primarily focuses on comparing entire network structures, we address a vertex-wise comparison problem where two random networks share the same set of vertices but allow for structural variations in some vertices, enabling a more detailed and flexible analysis of network differences. In our framework, some vertices retain their latent positions between networks, while others undergo shifts. To identify the shifted and unshifted vertices and estimate their latent position shifts, we propose a method that first derives vertex embeddings in a low-rank Euclidean space for each network, then aligns these estimated vertex latent positions into a common space to resolve potential non-identifiability, and finally tests whether each vertex is shifted or not and estimates the vertex shifts. Our theoretical results establish the test statistic for the algorithms, guide parameter selection, and provide performance guarantees. Simulation studies and real data applications, including a case-control study in disease research and dynamic network analysis, demonstrate that the proposed algorithms are both computationally efficient and effective in extracting meaningful insights from network comparisons. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01953</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01953</id><created>2025-02-03</created><authors><author><keyname>Asgari</keyname><forenames>Kiana</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Saeed</keyname><forenames>Basil</forenames></author></authors><title>Local minima of the empirical risk in high dimension: General theorems   and convex examples</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>95 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general model for high-dimensional empirical risk minimization whereby the data $\mathbf{x}_i$ are $d$-dimensional isotropic Gaussian vectors, the model is parametrized by $\mathbf{\Theta}\in\mathbb{R}^{d\times k}$, and the loss depends on the data via the projection $\mathbf{\Theta}^\mathsf{T}\mathbf{x}_i$. This setting covers as special cases classical statistics methods (e.g. multinomial regression and other generalized linear models), but also two-layer fully connected neural networks with $k$ hidden neurons. We use the Kac-Rice formula from Gaussian process theory to derive a bound on the expected number of local minima of this empirical risk, under the proportional asymptotics in which $n,d\to\infty$, with $n\asymp d$. Via Markov's inequality, this bound allows to determine the positions of these minimizers (with exponential deviation bounds) and hence derive sharp asymptotics on the estimation and prediction error. In this paper, we apply our characterization to convex losses, where high-dimensional asymptotics were not (in general) rigorously established for $k\ge 2$. We show that our approach is tight and allows to prove previously conjectured results. In addition, we characterize the spectrum of the Hessian at the minimizer. A companion paper applies our general result to non-convex examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01995</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01995</id><created>2025-02-03</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author><author><keyname>Bondell</keyname><forenames>Howard</forenames></author></authors><title>Theoretical and Practical Analysis of Fr\'echet Regression via   Comparison Geometry</title><categories>stat.ML cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fr\'echet regression extends classical regression methods to non-Euclidean metric spaces, enabling the analysis of data relationships on complex structures such as manifolds and graphs. This work establishes a rigorous theoretical analysis for Fr\'echet regression through the lens of comparison geometry which leads to important considerations for its use in practice. The analysis provides key results on the existence, uniqueness, and stability of the Fr\'echet mean, along with statistical guarantees for nonparametric regression, including exponential concentration bounds and convergence rates. Additionally, insights into angle stability reveal the interplay between curvature of the manifold and the behavior of the regression estimator in these non-Euclidean contexts. Empirical experiments validate the theoretical findings, demonstrating the effectiveness of proposed hyperbolic mappings, particularly for data with heteroscedasticity, and highlighting the practical usefulness of these results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02000</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02000</id><created>2025-02-03</created><authors><author><keyname>Lu</keyname><forenames>Yuchen</forenames></author><author><keyname>Lee</keyname><forenames>Ben Seiyon</forenames></author><author><keyname>Doss-Gollin</keyname><forenames>James</forenames></author></authors><title>Bayesian Spatiotemporal Nonstationary Model Quantifies Robust Increases   in Daily Extreme Rainfall Across the Western Gulf Coast</title><categories>stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precipitation exceedance probabilities are widely used in engineering design, risk assessment, and floodplain management. While common approaches like NOAA Atlas 14 assume that extreme precipitation characteristics are stationary over time, this assumption may underestimate current and future hazards due to anthropogenic climate change. However, the incorporation of nonstationarity in the statistical modeling of extreme precipitation has faced practical challenges that have restricted its applications. In particular, random sampling variability challenges the reliable estimation of trends and parameters, especially when observational records are limited. To address this methodological gap, we propose the Spatially Varying Covariates Model, a hierarchical Bayesian spatial framework that integrates nonstationarity and regionalization for robust frequency analysis of extreme precipitation. This model draws from extreme value theory, spatial statistics, and Bayesian statistics, and is validated through cross-validation and multiple performance metrics. Applying this framework to a case study of daily rainfall in the Western Gulf Coast, we identify robustly increasing trends in extreme precipitation intensity and variability throughout the study area, with notable spatial heterogeneity. This flexible model accommodates stations with varying observation records, yields smooth return level estimates, and can be straightforwardly adapted to the analysis of precipitation frequencies at different durations and for other regions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02002</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02002</id><created>2025-02-03</created><authors><author><keyname>Gruntkowska</keyname><forenames>Kaja</forenames></author><author><keyname>Li</keyname><forenames>Hanmin</forenames></author><author><keyname>Rane</keyname><forenames>Aadi</forenames></author><author><keyname>Richtárik</keyname><forenames>Peter</forenames></author></authors><title>The Ball-Proximal (="Broximal") Point Method: a New Algorithm,   Convergence Theory, and Applications</title><categories>math.OC cs.LG stat.ML</categories><comments>44 pages, 3 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Non-smooth and non-convex global optimization poses significant challenges across various applications, where standard gradient-based methods often struggle. We propose the Ball-Proximal Point Method, Broximal Point Method, or Ball Point Method (BPM) for short - a novel algorithmic framework inspired by the classical Proximal Point Method (PPM) (Rockafellar, 1976), which, as we show, sheds new light on several foundational optimization paradigms and phenomena, including non-convex and non-smooth optimization, acceleration, smoothing, adaptive stepsize selection, and trust-region methods. At the core of BPM lies the ball-proximal ("broximal") operator, which arises from the classical proximal operator by replacing the quadratic distance penalty by a ball constraint. Surprisingly, and in sharp contrast with the sublinear rate of PPM in the nonsmooth convex regime, we prove that BPM converges linearly and in a finite number of steps in the same regime. Furthermore, by introducing the concept of ball-convexity, we prove that BPM retains the same global convergence guarantees under weaker assumptions, making it a powerful tool for a broader class of potentially non-convex optimization problems. Just like PPM plays the role of a conceptual method inspiring the development of practically efficient algorithms and algorithmic elements, e.g., gradient descent, adaptive step sizes, acceleration (Ahn &amp; Sra, 2020), and "W" in AdamW (Zhuang et al., 2022), we believe that BPM should be understood in the same manner: as a blueprint and inspiration for further development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02006</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02006</id><created>2025-02-03</created><authors><author><keyname>Robinson</keyname><forenames>Benjamin D.</forenames></author><author><keyname>Latimer</keyname><forenames>Van</forenames></author></authors><title>Nonlinear Covariance Shrinkage for Hotelling's $T^2$ in High Dimension</title><categories>math.ST math.PR stat.ME stat.TH</categories><comments>41 pages, 9 figures</comments><msc-class>62H15</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we study the problem of comparing the means of a single observation and a reference sample in the presence of a common data covariance matrix, where the data dimension $p$ grows linearly with the number of samples $n$ and $p/n$ converges to a number between 0 and 1. The approach we take is to replace the sample covariance matrix with a nonlinear shrinkage estimator -- i.e., a matrix with the same eigenvectors -- in Hotelling's $T^2$ test. Current approaches of this sort typically assume that the data covariance matrix has a condition number or spiked rank that increases slowly with dimension. However, this assumption is ill-suited to data sets containing many strongly correlated background covariates, as often found in finance, genetics, and remote sensing. To address this problem we construct, using variational methods and new local random-matrix laws, a nonlinear covariance shrinkage method tailored to optimize detection performance across a broad range of spiked ranks and condition numbers. We then demonstrate, via both simulated and real-world data, that our method outperforms existing approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02020</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02020</id><created>2025-02-04</created><authors><author><keyname>Zhao</keyname><forenames>Yijia</forenames></author><author><keyname>Zhou</keyname><forenames>Qing</forenames></author></authors><title>Causal bandits with backdoor adjustment on unknown Gaussian DAGs</title><categories>cs.LG stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The causal bandit problem aims to sequentially learn the intervention that maximizes the expectation of a reward variable within a system governed by a causal graph. Most existing approaches assume prior knowledge of the graph structure, or impose unrealistically restrictive conditions on the graph. In this paper, we assume a Gaussian linear directed acyclic graph (DAG) over arms and the reward variable, and study the causal bandit problem when the graph structure is unknown. We identify backdoor adjustment sets for each arm using sequentially generated experimental and observational data during the decision process, which allows us to estimate causal effects and construct upper confidence bounds. By integrating estimates from both data sources, we develop a novel bandit algorithm, based on modified upper confidence bounds, to sequentially determine the optimal intervention. We establish both case-dependent and case-independent upper bounds on the cumulative regret for our algorithm, which improve upon the bounds of the standard multi-armed bandit algorithms. Our empirical study demonstrates its advantage over existing methods with respect to cumulative regret and computation time. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02032</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02032</id><created>2025-02-04</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author></authors><title>Heteroscedastic Double Bayesian Elastic Net</title><categories>stat.ME cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In many practical applications, regression models are employed to uncover relationships between predictors and a response variable, yet the common assumption of constant error variance is frequently violated. This issue is further compounded in high-dimensional settings where the number of predictors exceeds the sample size, necessitating regularization for effective estimation and variable selection. To address this problem, we propose the Heteroscedastic Double Bayesian Elastic Net (HDBEN), a novel framework that jointly models the mean and log-variance using hierarchical Bayesian priors incorporating both $\ell_1$ and $\ell_2$ penalties. Our approach simultaneously induces sparsity and grouping in the regression coefficients and variance parameters, capturing complex variance structures in the data. Theoretical results demonstrate that proposed HDBEN achieves posterior concentration, variable selection consistency, and asymptotic normality under mild conditions which justifying its behavior. Simulation studies further illustrate that HDBEN outperforms existing methods, particularly in scenarios characterized by heteroscedasticity and high dimensionality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02103</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02103</id><created>2025-02-04</created><authors><author><keyname>Oursland</keyname><forenames>Alan</forenames></author></authors><title>Neural Networks Learn Distance Metrics</title><categories>cs.LG cs.AI stat.ML</categories><comments>14 pages, 1 figures. Code and additional resources available at   https://github.com/alanoursland/neural_networks_learn_distance_metrics</comments><msc-class>68T07 (Primary) 62H12 (Secondary)</msc-class><acm-class>I.5.1; G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural networks may naturally favor distance-based representations, where smaller activations indicate closer proximity to learned prototypes. This contrasts with intensity-based approaches, which rely on activation magnitudes. To test this hypothesis, we conducted experiments with six MNIST architectural variants constrained to learn either distance or intensity representations. Our results reveal that the underlying representation affects model performance. We develop a novel geometric framework that explains these findings and introduce OffsetL2, a new architecture based on Mahalanobis distance equations, to further validate this framework. This work highlights the importance of considering distance-based learning in neural network design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02110</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02110</id><created>2025-02-04</created><authors><author><keyname>Venkatasubramaniam</keyname><forenames>Ashwini</forenames></author><author><keyname>Wolfson</keyname><forenames>Julian</forenames></author></authors><title>Multi-Study Causal Forest (MCF): A flexible framework for data borrowing   in the presence of varying treatment effect heterogeneity</title><categories>stat.ME</categories><comments>5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tailoring treatment assignment to specific individuals can improve the health outcomes, but a single study may offer inadequate information for this purpose. The ability to leverage information from an auxiliary data source deemed to be `most similar' to a primary data source has been shown to improve estimates of treatment effects. In this paper, we introduce a framework, the Multi-Study Causal Forest (MCF), to borrow individual patient-level data from an auxiliary data source in the presence of `varying sources' of treatment effect heterogeneity. We utilise a simulation study to demonstrate the superiority of the MCF in the presence of varying treatment allocation models (between-study heterogeneity) in addition to being able to account for the presence of within-study heterogeneity. This approach can combine data from randomised controlled trials, observational studies or a combination of both. We illustrate using Breast cancer data that the MCF performs favourably compared to an existing methodology in the presence of varying sources of (both between and within) heterogeneity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02121</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02121</id><created>2025-02-04</created><authors><author><keyname>Chew</keyname><forenames>Ruth Wan Theng</forenames></author><author><keyname>Nguyen</keyname><forenames>Quoc Phong</forenames></author><author><keyname>Low</keyname><forenames>Bryan Kian Hsiang</forenames></author></authors><title>BILBO: BILevel Bayesian Optimization</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bilevel optimization is characterized by a two-level optimization structure, where the upper-level problem is constrained by optimal lower-level solutions, and such structures are prevalent in real-world problems. The constraint by optimal lower-level solutions poses significant challenges, especially in noisy, constrained, and derivative-free settings, as repeating lower-level optimizations is sample inefficient and predicted lower-level solutions may be suboptimal. We present BILevel Bayesian Optimization (BILBO), a novel Bayesian optimization algorithm for general bilevel problems with blackbox functions, which optimizes both upper- and lower-level problems simultaneously, without the repeated lower-level optimization required by existing methods. BILBO samples from confidence-bounds based trusted sets, which bounds the suboptimality on the lower level. Moreover, BILBO selects only one function query per iteration, where the function query selection strategy incorporates the uncertainty of estimated lower-level solutions and includes a conditional reassignment of the query to encourage exploration of the lower-level objective. The performance of BILBO is theoretically guaranteed with a sublinear regret bound for commonly used kernels and is empirically evaluated on several synthetic and real-world problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02132</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02132</id><created>2025-02-04</created><authors><author><keyname>Cattaneo</keyname><forenames>Matias D.</forenames></author><author><keyname>Shigida</keyname><forenames>Boris</forenames></author></authors><title>How Memory in Optimization Algorithms Implicitly Modifies the Loss</title><categories>cs.LG cs.AI math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In modern optimization methods used in deep learning, each update depends on the history of previous iterations, often referred to as memory, and this dependence decays fast as the iterates go further into the past. For example, gradient descent with momentum has exponentially decaying memory through exponentially averaged past gradients. We introduce a general technique for identifying a memoryless algorithm that approximates an optimization algorithm with memory. It is obtained by replacing all past iterates in the update by the current one, and then adding a correction term arising from memory (also a function of the current iterate). This correction term can be interpreted as a perturbation of the loss, and the nature of this perturbation can inform how memory implicitly (anti-)regularizes the optimization dynamics. As an application of our theory, we find that Lion does not have the kind of implicit anti-regularization induced by memory that AdamW does, providing a theory-based explanation for Lion's better generalization performance recently documented. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02140</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02140</id><created>2025-02-04</created><authors><author><keyname>Gouverneur</keyname><forenames>Amaury</forenames></author><author><keyname>Gálvez</keyname><forenames>Borja Rodriguez</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>An Information-Theoretic Analysis of Thompson Sampling with Infinite   Action Spaces</title><categories>stat.ML cs.LG</categories><comments>5 pages, accepted to ICASSP</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the Bayesian regret of the Thompson Sampling algorithm for bandit problems, building on the information-theoretic framework introduced by Russo and Van Roy (2015). Specifically, it extends the rate-distortion analysis of Dong and Van Roy (2018), which provides near-optimal bounds for linear bandits. A limitation of these results is the assumption of a finite action space. We address this by extending the analysis to settings with infinite and continuous action spaces. Additionally, we specialize our results to bandit problems with expected rewards that are Lipschitz continuous with respect to the action space, deriving a regret bound that explicitly accounts for the complexity of the action space. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02148</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02148</id><created>2025-02-04</created><authors><author><keyname>Hemmens</keyname><forenames>Christopher</forenames></author><author><keyname>Robert-Nicoud</keyname><forenames>Stephan</forenames></author></authors><title>Can linear algebra create perfect knockoffs?</title><categories>stat.ME</categories><comments>11 pages</comments><journal-ref>Big Data and Internet of Things. BDIoT 2024. Lecture Notes in   Networks and Systems, vol 887. Springer, Cham</journal-ref><doi>10.1007/978-3-031-74491-4_81</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As new Model-X knockoff construction techniques are developed, primarily concerned with determining the correct conditional distribution from which to sample, we focus less on deriving the correct multivariate distribution and instead ask if ``perfect'' knockoffs can be constructed using linear algebra. Using mean absolute correlation between knockoffs and features as a measure of quality, we do produce knockoffs that are pseudo-perfect, however, the optimization algorithm is computationally very expensive. We outline a series of methods to significantly reduce the computation time of the algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02160</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02160</id><created>2025-02-04</created><authors><author><keyname>Pistone</keyname><forenames>Giovanni</forenames></author></authors><title>Information geometry of Bayes computations</title><categories>math.ST stat.TH</categories><comments>First version of a submitted conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Amari's Information Geometry is a dually affine formalism for parametric probability models. The literature proposes various nonparametric functional versions. Our approach uses classical Weyl's axioms so that the affine velocity of a one-parameter statistical model equals the classical Fisher's score. In the present note, we first offer a concise review of the notion of a statistical bundle as a set of couples of probability densities and Fisher's scores. Then, we show how the nonparametric dually affine setup deals with the basic Bayes and Kullback-Leibler divergence computations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02177</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02177</id><created>2025-02-04</created><authors><author><keyname>Pistone</keyname><forenames>Giovanni</forenames></author></authors><title>Affine calculus for constrained minima of the Kullback-Leibler   divergence</title><categories>math.ST stat.TH</categories><comments>First version of a submitted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper showcases general computations derived from our version of Amari's dually affine Information Geometry. We especially focus on statistics and machine learning algorithms involving the constrained minimization of the Kullback-Liebler divergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02206</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02206</id><created>2025-02-04</created><authors><author><keyname>Llorente</keyname><forenames>F.</forenames></author><author><keyname>Martino</keyname><forenames>L.</forenames></author><author><keyname>Delgado</keyname><forenames>D.</forenames></author></authors><title>Target-aware Bayesian inference via generalized thermodynamic   integration</title><categories>stat.CO cs.CE stat.ME</categories><journal-ref>Computational Statistics, Volume 38, Pages 2097-2119, year 2023</journal-ref><doi>10.1007/s00180-023-01358-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian inference, we are usually interested in the numerical approximation of integrals that are posterior expectations or marginal likelihoods (a.k.a., Bayesian evidence). In this paper, we focus on the computation of the posterior expectation of a function $f(\x)$. We consider a \emph{target-aware} scenario where $f(\x)$ is known in advance and can be exploited in order to improve the estimation of the posterior expectation. In this scenario, this task can be reduced to perform several independent marginal likelihood estimation tasks. The idea of using a path of tempered posterior distributions has been widely applied in the literature for the computation of marginal likelihoods. Thermodynamic integration, path sampling and annealing importance sampling are well-known examples of algorithms belonging to this family of methods. In this work, we introduce a generalized thermodynamic integration (GTI) scheme which is able to perform a target-aware Bayesian inference, i.e., GTI can approximate the posterior expectation of a given function. Several scenarios of application of GTI are discussed and different numerical simulations are provided. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02213</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02213</id><created>2025-02-04</created><authors><author><keyname>Rasines</keyname><forenames>Daniel García</forenames></author><author><keyname>Young</keyname><forenames>G. Alastair</forenames></author></authors><title>Sampling models for selective inference</title><categories>math.ST stat.TH</categories><comments>16 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper explores the challenges of constructing suitable inferential models in scenarios where the parameter of interest is determined in light of the data, such as regression after variable selection. Two compelling arguments for conditioning converge in this context, whose interplay can introduce ambiguity in the choice of conditioning strategy: the Conditionality Principle, from classical statistics, and the `condition on selection' paradigm, central to selective inference. We discuss two general principles that can be employed to resolve this ambiguity in some recurrent contexts. The first one refers to the consideration of how information is processed at the selection stage. The second one concerns an exploration of ancillarity in the presence of selection. We demonstrate that certain notions of ancillarity are preserved after conditioning on the selection event, supporting the application of the Conditionality Principle. We illustrate these concepts through examples and provide guidance on the adequate inferential approach in some common scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02216</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02216</id><created>2025-02-04</created><authors><author><keyname>Chen</keyname><forenames>Dexiong</forenames></author><author><keyname>Krimmel</keyname><forenames>Markus</forenames></author><author><keyname>Borgwardt</keyname><forenames>Karsten</forenames></author></authors><title>Flatten Graphs as Sequences: Transformers are Scalable Graph Generators</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce AutoGraph, a novel autoregressive framework for generating large attributed graphs using decoder-only transformers. At the core of our approach is a reversible "flattening" process that transforms graphs into random sequences. By sampling and learning from these sequences, AutoGraph enables transformers to model and generate complex graph structures in a manner akin to natural language. In contrast to diffusion models that rely on computationally intensive node features, our approach operates exclusively on these sequences. The sampling complexity and sequence length scale linearly with the number of edges, making AutoGraph highly scalable for generating large sparse graphs. Empirically, AutoGraph achieves state-of-the-art performance across diverse synthetic and molecular graph generation benchmarks, while delivering a 100-fold generation and a 3-fold training speedup compared to leading diffusion models. Additionally, it demonstrates promising transfer capabilities and supports substructure-conditioned generation without additional fine-tuning. By extending language modeling techniques to graph generation, this work paves the way for developing graph foundation models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02221</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02221</id><created>2025-02-04</created><authors><author><keyname>Němeček</keyname><forenames>Jiří</forenames></author><author><keyname>Kozdoba</keyname><forenames>Mark</forenames></author><author><keyname>Kryvoviaz</keyname><forenames>Illia</forenames></author><author><keyname>Pevný</keyname><forenames>Tomáš</forenames></author><author><keyname>Mareček</keyname><forenames>Jakub</forenames></author></authors><title>Bias Detection via Maximum Subgroup Discrepancy</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bias evaluation is fundamental to trustworthy AI, both in terms of checking data quality and in terms of checking the outputs of AI systems. In testing data quality, for example, one may study a distance of a given dataset, viewed as a distribution, to a given ground-truth reference dataset. However, classical metrics, such as the Total Variation and the Wasserstein distances, are known to have high sample complexities and, therefore, may fail to provide meaningful distinction in many practical scenarios.   In this paper, we propose a new notion of distance, the Maximum Subgroup Discrepancy (MSD). In this metric, two distributions are close if, roughly, discrepancies are low for all feature subgroups. While the number of subgroups may be exponential, we show that the sample complexity is linear in the number of features, thus making it feasible for practical applications. Moreover, we provide a practical algorithm for the evaluation of the distance, based on Mixed-integer optimization (MIO). We also note that the proposed distance is easily interpretable, thus providing clearer paths to fixing the biases once they have been identified. It also provides guarantees for all subgroups. Finally, we empirically evaluate, compare with other metrics, and demonstrate the above properties of MSD on real-world datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02233</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02233</id><created>2025-02-04</created><authors><author><keyname>Sahoo</keyname><forenames>Satyajeet</forenames></author><author><keyname>Maiti</keyname><forenames>Jhareswar</forenames></author></authors><title>Variance-Adjusted Cosine Distance as Similarity Metric</title><categories>stat.ML cs.LG</categories><comments>6 Pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Cosine similarity is a popular distance measure that measures the similarity between two vectors in the inner product space. It is widely used in many data classification algorithms like K-Nearest Neighbors, Clustering etc. This study demonstrates limitations of application of cosine similarity. Particularly, this study demonstrates that traditional cosine similarity metric is valid only in the Euclidean space, whereas the original data resides in a random variable space. When there is variance and correlation in the data, then cosine distance is not a completely accurate measure of similarity. While new similarity and distance metrics have been developed to make up for the limitations of cosine similarity, these metrics are used as substitutes to cosine distance, and do not make modifications to cosine distance to overcome its limitations. Subsequently, we propose a modified cosine similarity metric, where cosine distance is adjusted by variance-covariance of the data. Application of variance-adjusted cosine distance gives better similarity performance compared to traditional cosine distance. KNN modelling on the Wisconsin Breast Cancer Dataset is performed using both traditional and modified cosine similarity measures and compared. The modified formula shows 100% test accuracy on the data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02270</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02270</id><created>2025-02-04</created><authors><author><keyname>Alcalde</keyname><forenames>Albert</forenames></author><author><keyname>Fantuzzi</keyname><forenames>Giovanni</forenames></author><author><keyname>Zuazua</keyname><forenames>Enrique</forenames></author></authors><title>Exact Sequence Classification with Hardmax Transformers</title><categories>cs.LG math.OC stat.ML</categories><comments>14 pages, 5 figures. Funded by the European Union (Horizon Europe   MSCA project ModConFlex, grant number 101073558)</comments><msc-class>68T07, 68T50</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We prove that hardmax attention transformers perfectly classify datasets of $N$ labeled sequences in $\mathbb{R}^d$, $d\geq 2$. Specifically, given $N$ sequences with an arbitrary but finite length in $\mathbb{R}^d$, we construct a transformer with $\mathcal{O}(N)$ blocks and $\mathcal{O}(Nd)$ parameters perfectly classifying this dataset. Our construction achieves the best complexity estimate to date, independent of the length of the sequences, by innovatively alternating feed-forward and self-attention layers and by capitalizing on the clustering effect inherent to the latter. Our novel constructive method also uses low-rank parameter matrices within the attention mechanism, a common practice in real-life transformer implementations. Consequently, our analysis holds twofold significance: it substantially advances the mathematical theory of transformers and it rigorously justifies their exceptional real-world performance in sequence classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02296</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02296</id><created>2025-02-04</created><authors><author><keyname>Rakitzis</keyname><forenames>Athanasios C.</forenames></author></authors><title>On The Performance of a Two-Sided Shewhart Chart for Continuous   Proportions with Estimated Parameters</title><categories>stat.ME stat.AP</categories><comments>33 pages, 13 figures</comments><msc-class>62P30</msc-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  During the recent years there was an increased interest in studying the performance of different types of control charts, under various distributional models for continuous proportions, such as percentages and rates. In this work we consider the Kumaraswamy distribution, a popular and flexible distributional model for data in the unit interval (0,1) and investigate further the properties of a two-sided chart for individual observations for monitoring these types of processes, when the process parameters are unknown. Specifically, using Monte Carlo simulation, we evaluate the performance of the chart under a conditional perspective and provide empirical rules on how to select the appropriate size for the Phase I sample. In addition, we explore possible adjustments on the control limits of the chart, which take into account the available Phase I sample. The performance of the chart is also investigated for several out-of-control situations. The results show that for small and moderate size Phase I samples, practitioners have to choose whether they prefer a guaranteed in-control performance or an improved out-of-control performance. The implementation of the considered methods in practice is discussed via two numerical examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02305</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02305</id><created>2025-02-04</created><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Information-Theoretic Proofs for Diffusion Sampling</title><categories>stat.ML cs.IT cs.LG math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper provides an elementary, self-contained analysis of diffusion-based sampling methods for generative modeling. In contrast to existing approaches that rely on continuous-time processes and then discretize, our treatment works directly with discrete-time stochastic processes and yields precise non-asymptotic convergence guarantees under broad assumptions. The key insight is to couple the sampling process of interest with an idealized comparison process that has an explicit Gaussian-convolution structure. We then leverage simple identities from information theory, including the I-MMSE relationship, to bound the discrepancy (in terms of the Kullback-Leibler divergence) between these two discrete-time processes. In particular, we show that, if the diffusion step sizes are chosen sufficiently small and one can approximate certain conditional mean estimators well, then the sampling distribution is provably close to the target distribution. Our results also provide a transparent view on how to accelerate convergence by introducing additional randomness in each step to match higher order moments in the comparison process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02331</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02331</id><created>2025-02-04</created><authors><author><keyname>Tsoy</keyname><forenames>Nikita</forenames></author><author><keyname>Kirev</keyname><forenames>Ivan</forenames></author><author><keyname>Rahimiyazdi</keyname><forenames>Negin</forenames></author><author><keyname>Konstantinov</keyname><forenames>Nikola</forenames></author></authors><title>On the Impact of Performative Risk Minimization for Binary Random   Variables</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Performativity, the phenomenon where outcomes are influenced by predictions, is particularly prevalent in social contexts where individuals strategically respond to a deployed model. In order to preserve the high accuracy of machine learning models under distribution shifts caused by performativity, Perdomo et al. (2020) introduced the concept of performative risk minimization (PRM). While this framework ensures model accuracy, it overlooks the impact of the PRM on the underlying distributions and the predictions of the model. In this paper, we initiate the analysis of the impact of PRM, by studying performativity for a sequential performative risk minimization problem with binary random variables and linear performative shifts. We formulate two natural measures of impact. In the case of full information, where the distribution dynamics are known, we derive explicit formulas for the PRM solution and our impact measures. In the case of partial information, we provide performative-aware statistical estimators, as well as simulations. Our analysis contrasts PRM to alternatives that do not model data shift and indicates that PRM can have amplified side effects compared to such methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02363</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02363</id><created>2025-02-04</created><authors><author><keyname>Cortinovis</keyname><forenames>Stefano</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>FAB-PPI: Frequentist, Assisted by Bayes, Prediction-Powered Inference</title><categories>stat.ML cs.LG</categories><comments>28 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction-powered inference (PPI) enables valid statistical inference by combining experimental data with machine learning predictions. When a sufficient number of high-quality predictions is available, PPI results in more accurate estimates and tighter confidence intervals than traditional methods. In this paper, we propose to inform the PPI framework with prior knowledge on the quality of the predictions. The resulting method, which we call frequentist, assisted by Bayes, PPI (FAB-PPI), improves over PPI when the observed prediction quality is likely under the prior, while maintaining its frequentist guarantees. Furthermore, when using heavy-tailed priors, FAB-PPI adaptively reverts to standard PPI in low prior probability regions. We demonstrate the benefits of FAB-PPI in real and synthetic examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02364</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02364</id><created>2025-02-04</created><authors><author><keyname>Baillie</keyname><forenames>Nils</forenames></author><author><keyname>Van Biesbroeck</keyname><forenames>Antoine</forenames></author><author><keyname>Gauchy</keyname><forenames>Clément</forenames></author></authors><title>Variational inference for approximate reference priors using neural   networks</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian statistics, the choice of the prior can have an important influence on the posterior and the parameter estimation, especially when few data samples are available. To limit the added subjectivity from a priori information, one can use the framework of reference priors. However, computing such priors is a difficult task in general. We develop in this paper a flexible algorithm based on variational inference which computes approximations of reference priors from a set of parametric distributions using neural networks. We also show that our algorithm can retrieve reference priors when constraints are specified in the optimization problem to ensure the solution is proper. We propose a simple method to recover a relevant approximation of the parametric posterior distribution using Markov Chain Monte Carlo (MCMC) methods even if the density function of the parametric prior is not known in general. Numerical experiments on several statistical models of increasing complexity are presented. We show the usefulness of this approach by recovering the target distribution. The performance of the algorithm is evaluated on the prior distributions as well as the posterior distributions, jointly using variational inference and MCMC sampling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02369</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02369</id><created>2025-02-04</created><authors><author><keyname>Brinks</keyname><forenames>Ralph</forenames></author></authors><title>Estimation of the incidence rate and mortality rate ratio for chronic   conditions based on aggregated current status data</title><categories>stat.AP q-bio.PE</categories><comments>10 pages, 3 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that the transition rates of the illness-death model (IDM) for chronic conditions are related to the percentages of people in the states by a three-dimensional system of differential equations [Bri24]. The aim of this article is to introduce a method to estimate the age-specific incidence rate together with the mortality rate ratio from aggregated current status (ACS) data. By ACS data we mean counts of (non-necessarily different) people in the three states of the IDM at different points in time. ACS data stem from epidemiological studies where only current disease status and vital status data need to be collected without following-up people (as, for example, in cohort studies). As an application, we use the theory in a simulation study about diabetes in Germany with 600 study subjects at eleven repeated cross-sections each of which with 50% participation quote. Special focus is given to stochastic dependency of the sampled participants. We find a good agreement between the estimates and the input parameters used for the simulation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02379</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02379</id><created>2025-02-04</created><authors><author><keyname>Coupette</keyname><forenames>Corinna</forenames></author><author><keyname>Wayland</keyname><forenames>Jeremy</forenames></author><author><keyname>Simons</keyname><forenames>Emily</forenames></author><author><keyname>Rieck</keyname><forenames>Bastian</forenames></author></authors><title>No Metric to Rule Them All: Toward Principled Evaluations of   Graph-Learning Datasets</title><categories>cs.LG cs.SI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Benchmark datasets have proved pivotal to the success of graph learning, and good benchmark datasets are crucial to guide the development of the field. Recent research has highlighted problems with graph-learning datasets and benchmarking practices -- revealing, for example, that methods which ignore the graph structure can outperform graph-based approaches on popular benchmark datasets. Such findings raise two questions: (1) What makes a good graph-learning dataset, and (2) how can we evaluate dataset quality in graph learning? Our work addresses these questions. As the classic evaluation setup uses datasets to evaluate models, it does not apply to dataset evaluation. Hence, we start from first principles. Observing that graph-learning datasets uniquely combine two modes -- the graph structure and the node features -- , we introduce RINGS, a flexible and extensible mode-perturbation framework to assess the quality of graph-learning datasets based on dataset ablations -- i.e., by quantifying differences between the original dataset and its perturbed representations. Within this framework, we propose two measures -- performance separability and mode complementarity -- as evaluation tools, each assessing, from a distinct angle, the capacity of a graph dataset to benchmark the power and efficacy of graph-learning methods. We demonstrate the utility of our framework for graph-learning dataset evaluation in an extensive set of experiments and derive actionable recommendations for improving the evaluation of graph-learning methods. Our work opens new research directions in data-centric graph learning, and it constitutes a first step toward the systematic evaluation of evaluations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02392</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02392</id><created>2025-02-04</created><authors><author><keyname>Aloni</keyname><forenames>Ofek</forenames></author><author><keyname>Perelman</keyname><forenames>Gal</forenames></author><author><keyname>Fishbain</keyname><forenames>Barak</forenames></author></authors><title>Synthetic Random Environmental Time Series Generation with Similarity   Control, Preserving Original Signal's Statistical Characteristics</title><categories>stat.ME</categories><comments>Accepted for publication 27 November 2024. Code available at   https://github.com/Al-Ofek/stsg.git</comments><journal-ref>Environmental Modelling &amp; Software, Volume 185, February 2025,   106283</journal-ref><doi>10.1016/j.envsoft.2024.106283</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Synthetic datasets are widely used in many applications, such as missing data imputation, examining non-stationary scenarios, in simulations, training data-driven models, and analyzing system robustness. Typically, synthetic data are based on historical data obtained from the observed system. The data needs to represent a specific behavior of the system, yet be new and diverse enough so that the system is challenged with a broad range of inputs. This paper presents a method, based on discrete Fourier transform, for generating synthetic time series with similar statistical moments for any given signal. The suggested method makes it possible to control the level of similarity between the given signal and the generated synthetic signals. Proof shows analytically that this method preserves the first two statistical moments of the input signal, and its autocorrelation function. The method is compared to known methods, ARMA, GAN, and CoSMoS. A large variety of environmental datasets with different temporal resolutions, and from different domains are used, testing the generality and flexibility of the method. A Python library implementing this method is made available as open-source software. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02397</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02397</id><created>2025-02-04</created><authors><author><keyname>Calvi</keyname><forenames>Annalisa</forenames></author><author><keyname>Laa</keyname><forenames>Ursula</forenames></author><author><keyname>Cook</keyname><forenames>Dianne</forenames></author></authors><title>Is this normal? A new projection pursuit index to assess a sample   against a multivariate null distribution</title><categories>stat.ME stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many data problems contain some reference or normal conditions, upon which to compare newly collected data. This scenario occurs in data collected as part of clinical trials to detect adverse events, or for measuring climate change against historical norms. The data is typically multivariate, and often the normal ranges are specified by a multivariate normal distribution. The work presented in this paper develops methods to compare the new sample against the reference distribution with high-dimensional visualisation. It uses a projection pursuit guided tour to produce a sequence of low-dimensional projections steered towards those where the new sample is most different from the reference. A new projection pursuit index is defined for this purpose. The tour visualisation also includes drawing of the projected ellipse, which is computed analytically, corresponding to the reference distribution. The methods are implemented in the R package, tourr. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02407</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02407</id><created>2025-02-04</created><authors><author><keyname>Singh</keyname><forenames>Sidak Pal</forenames></author><author><keyname>Mobahi</keyname><forenames>Hossein</forenames></author><author><keyname>Agarwala</keyname><forenames>Atish</forenames></author><author><keyname>Dauphin</keyname><forenames>Yann</forenames></author></authors><title>Avoiding spurious sharpness minimization broadens applicability of SAM</title><categories>cs.LG cs.CL stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Curvature regularization techniques like Sharpness Aware Minimization (SAM) have shown great promise in improving generalization on vision tasks. However, we find that SAM performs poorly in domains like natural language processing (NLP), often degrading performance -- even with twice the compute budget. We investigate the discrepancy across domains and find that in the NLP setting, SAM is dominated by regularization of the logit statistics -- instead of improving the geometry of the function itself. We use this observation to develop an alternative algorithm we call Functional-SAM, which regularizes curvature only through modification of the statistics of the overall function implemented by the neural network, and avoids spurious minimization through logit manipulation. Furthermore, we argue that preconditioning the SAM perturbation also prevents spurious minimization, and when combined with Functional-SAM, it gives further improvements. Our proposed algorithms show improved performance over AdamW and SAM baselines when trained for an equal number of steps, in both fixed-length and Chinchilla-style training settings, at various model scales (including billion-parameter scale). On the whole, our work highlights the importance of more precise characterizations of sharpness in broadening the applicability of curvature regularization to large language models (LLMs). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02410</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02410</id><created>2025-02-04</created><authors><author><keyname>Schuchardt</keyname><forenames>Jan</forenames></author><author><keyname>Dalirrooyfard</keyname><forenames>Mina</forenames></author><author><keyname>Guzelkabaagac</keyname><forenames>Jed</forenames></author><author><keyname>Schneider</keyname><forenames>Anderson</forenames></author><author><keyname>Nevmyvaka</keyname><forenames>Yuriy</forenames></author><author><keyname>Günnemann</keyname><forenames>Stephan</forenames></author></authors><title>Privacy Amplification by Structured Subsampling for Deep Differentially   Private Time Series Forecasting</title><categories>cs.LG cs.CR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with timeseries-specific tasks like forecasting, since they rely on the privacy amplification attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this structured subsampling to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02430</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02430</id><created>2025-02-04</created><authors><author><keyname>Busa-Fekete</keyname><forenames>Róbert</forenames></author><author><keyname>Zimmert</keyname><forenames>Julian</forenames></author><author><keyname>György</keyname><forenames>András</forenames></author><author><keyname>Qiu</keyname><forenames>Linhai</forenames></author><author><keyname>Sung</keyname><forenames>Tzu-Wei</forenames></author><author><keyname>Shen</keyname><forenames>Hao</forenames></author><author><keyname>Choi</keyname><forenames>Hyomin</forenames></author><author><keyname>Subramaniam</keyname><forenames>Sharmila</forenames></author><author><keyname>Xiao</keyname><forenames>Li</forenames></author></authors><title>A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals</title><categories>stat.ML cs.IR cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Web refresh crawling is the problem of keeping a cache of web pages fresh, that is, having the most recent copy available when a page is requested, given a limited bandwidth available to the crawler. Under the assumption that the change and request events, resp., to each web page follow independent Poisson processes, the optimal scheduling policy was derived by Azar et al. 2018. In this paper, we study an extension of this problem where side information indicating content changes, such as various types of web pings, for example, signals from sitemaps, content delivery networks, etc., is available. Incorporating such side information into the crawling policy is challenging, because (i) the signals can be noisy with false positive events and with missing change events; and (ii) the crawler should achieve a fair performance over web pages regardless of the quality of the side information, which might differ from web page to web page. We propose a scalable crawling algorithm which (i) uses the noisy side information in an optimal way under mild assumptions; (ii) can be deployed without heavy centralized computation; (iii) is able to crawl web pages at a constant total rate without spikes in the total bandwidth usage over any time interval, and automatically adapt to the new optimal solution when the total bandwidth changes without centralized computation. Experiments clearly demonstrate the versatility of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02450</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02450</id><created>2025-02-04</created><authors><author><keyname>Laplante</keyname><forenames>William</forenames></author><author><keyname>Altamirano</keyname><forenames>Matias</forenames></author><author><keyname>Duncan</keyname><forenames>Andrew</forenames></author><author><keyname>Knoblauch</keyname><forenames>Jeremias</forenames></author><author><keyname>Briol</keyname><forenames>François-Xavier</forenames></author></authors><title>Robust and Conjugate Spatio-Temporal Gaussian Processes</title><categories>stat.CO stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  State-space formulations allow for Gaussian process (GP) regression with linear-in-time computational cost in spatio-temporal settings, but performance typically suffers in the presence of outliers. In this paper, we adapt and specialise the robust and conjugate GP (RCGP) framework of Altamirano et al. (2024) to the spatio-temporal setting. In doing so, we obtain an outlier-robust spatio-temporal GP with a computational cost comparable to classical spatio-temporal GPs. We also overcome the three main drawbacks of RCGPs: their unreliable performance when the prior mean is chosen poorly, their lack of reliable uncertainty quantification, and the need to carefully select a hyperparameter by hand. We study our method extensively in finance and weather forecasting applications, demonstrating that it provides a reliable approach to spatio-temporal modelling in the presence of outliers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02463</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02463</id><created>2025-02-04</created><authors><author><keyname>Whittle</keyname><forenames>George</forenames></author><author><keyname>Ziomek</keyname><forenames>Juliusz</forenames></author><author><keyname>Rawling</keyname><forenames>Jacob</forenames></author><author><keyname>Osborne</keyname><forenames>Michael A</forenames></author></authors><title>Distribution Transformers: Fast Approximate Bayesian Inference With   On-The-Fly Prior Adaptation</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  While Bayesian inference provides a principled framework for reasoning under uncertainty, its widespread adoption is limited by the intractability of exact posterior computation, necessitating the use of approximate inference. However, existing methods are often computationally expensive, or demand costly retraining when priors change, limiting their utility, particularly in sequential inference problems such as real-time sensor fusion. To address these challenges, we introduce the Distribution Transformer -- a novel architecture that can learn arbitrary distribution-to-distribution mappings. Our method can be trained to map a prior to the corresponding posterior, conditioned on some dataset -- thus performing approximate Bayesian inference. Our novel architecture represents a prior distribution as a (universally-approximating) Gaussian Mixture Model (GMM), and transforms it into a GMM representation of the posterior. The components of the GMM attend to each other via self-attention, and to the datapoints via cross-attention. We demonstrate that Distribution Transformers both maintain flexibility to vary the prior, and significantly reduces computation times-from minutes to milliseconds-while achieving log-likelihood performance on par with or superior to existing approximate inference methods across tasks such as sequential inference, quantum system parameter inference, and Gaussian Process predictive posterior inference with hyperpriors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02472</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02472</id><created>2025-02-04</created><authors><author><keyname>Bartosh</keyname><forenames>Grigory</forenames></author><author><keyname>Vetrov</keyname><forenames>Dmitry</forenames></author><author><keyname>Naesseth</keyname><forenames>Christian A.</forenames></author></authors><title>SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic   Differential Equations</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Latent Stochastic Differential Equation (SDE) is a powerful tool for time series and sequence modeling. However, training Latent SDEs typically relies on adjoint sensitivity methods, which depend on simulation and backpropagation through approximate SDE solutions, which limit scalability. In this work, we propose SDE Matching, a new simulation-free method for training Latent SDEs. Inspired by modern Score- and Flow Matching algorithms for learning generative dynamics, we extend these ideas to the domain of stochastic dynamics for time series and sequence modeling, eliminating the need for costly numerical simulations. Our results demonstrate that SDE Matching achieves performance comparable to adjoint sensitivity methods while drastically reducing computational complexity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02483</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02483</id><created>2025-02-04</created><authors><author><keyname>De Bortoli</keyname><forenames>Valentin</forenames></author><author><keyname>Galashov</keyname><forenames>Alexandre</forenames></author><author><keyname>Guntupalli</keyname><forenames>J. Swaroop</forenames></author><author><keyname>Zhou</keyname><forenames>Guangyao</forenames></author><author><keyname>Murphy</keyname><forenames>Kevin</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Doucet</keyname><forenames>Arnaud</forenames></author></authors><title>Distributional Diffusion Models with Scoring Rules</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion models generate high-quality synthetic data. They operate by defining a continuous-time forward process which gradually adds Gaussian noise to data until fully corrupted. The corresponding reverse process progressively "denoises" a Gaussian sample into a sample from the data distribution. However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process. This is expensive and has motivated the development of many acceleration methods. We propose to accomplish sample generation by learning the posterior {\em distribution} of clean data samples given their noisy versions, instead of only the mean of this distribution. This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output. This is accomplished by replacing the standard regression loss used to estimate conditional means with a scoring rule. We validate our method on image and robot trajectory generation, where we consistently outperform standard diffusion models at few discretization steps. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02486</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02486</id><created>2025-02-04</created><authors><author><keyname>Ye</keyname><forenames>Chenlu</forenames></author><author><keyname>Jin</keyname><forenames>Yujia</forenames></author><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Catoni Contextual Bandits are Robust to Heavy-tailed Rewards</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Typical contextual bandit algorithms assume that the rewards at each round lie in some fixed range $[0, R]$, and their regret scales polynomially with this reward range $R$. However, many practical scenarios naturally involve heavy-tailed rewards or rewards where the worst-case range can be substantially larger than the variance. In this paper, we develop an algorithmic approach building on Catoni's estimator from robust statistics, and apply it to contextual bandits with general function approximation. When the variance of the reward at each round is known, we use a variance-weighted regression approach and establish a regret bound that depends only on the cumulative reward variance and logarithmically on the reward range $R$ as well as the number of rounds $T$. For the unknown-variance case, we further propose a careful peeling-based algorithm and remove the need for cumbersome variance estimation. With additional dependence on the fourth moment, our algorithm also enjoys a variance-based bound with logarithmic reward-range dependence. Moreover, we demonstrate the optimality of the leading-order term in our regret bound through a matching lower bound. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02496</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02496</id><created>2025-02-04</created><authors><author><keyname>Kolb</keyname><forenames>Chris</forenames></author><author><keyname>Weber</keyname><forenames>Tobias</forenames></author><author><keyname>Bischl</keyname><forenames>Bernd</forenames></author><author><keyname>Rügamer</keyname><forenames>David</forenames></author></authors><title>Deep Weight Factorization: Sparse Learning Through the Lens of   Artificial Symmetries</title><categories>cs.LG stat.ML</categories><comments>accepted at ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse regularization techniques are well-established in machine learning, yet their application in neural networks remains challenging due to the non-differentiability of penalties like the $L_1$ norm, which is incompatible with stochastic gradient descent. A promising alternative is shallow weight factorization, where weights are decomposed into two factors, allowing for smooth optimization of $L_1$-penalized neural networks by adding differentiable $L_2$ regularization to the factors. In this work, we introduce deep weight factorization, extending previous shallow approaches to more than two factors. We theoretically establish equivalence of our deep factorization with non-convex sparse regularization and analyze its impact on training dynamics and optimization. Due to the limitations posed by standard training practices, we propose a tailored initialization scheme and identify important learning rate requirements necessary for training factorized networks. We demonstrate the effectiveness of our deep weight factorization through experiments on various architectures and datasets, consistently outperforming its shallow counterpart and widely used pruning methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02516</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02516</id><created>2025-02-04</created><authors><author><keyname>Russo</keyname><forenames>Alessio</forenames></author><author><keyname>Pacchiano</keyname><forenames>Aldo</forenames></author></authors><title>Adaptive Exploration for Multi-Reward Multi-Policy Evaluation</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the policy evaluation problem in an online multi-reward multi-policy discounted setting, where multiple reward functions must be evaluated simultaneously for different policies. We adopt an $(\epsilon,\delta)$-PAC perspective to achieve $\epsilon$-accurate estimates with high confidence across finite or convex sets of rewards, a setting that has not been investigated in the literature. Building on prior work on Multi-Reward Best Policy Identification, we adapt the MR-NaS exploration scheme to jointly minimize sample complexity for evaluating different policies across different reward sets. Our approach leverages an instance-specific lower bound revealing how the sample complexity scales with a measure of value deviation, guiding the design of an efficient exploration policy. Although computing this bound entails a hard non-convex optimization, we propose an efficient convex approximation that holds for both finite and convex reward sets. Experiments in tabular domains demonstrate the effectiveness of this adaptive exploration scheme. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02529</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02529</id><created>2025-02-04</created><authors><author><keyname>Hult</keyname><forenames>Henrik</forenames></author><author><keyname>Lindhe</keyname><forenames>Adam</forenames></author><author><keyname>Nyquist</keyname><forenames>Pierre</forenames></author><author><keyname>Wu</keyname><forenames>Guo-Jhen</forenames></author></authors><title>A weak convergence approach to large deviations for stochastic   approximations</title><categories>math.PR math.OC stat.ML</categories><comments>60 p</comments><msc-class>60F10, 62L20, 60J20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of stochastic approximations form the theoretical foundation for studying convergence properties of many popular recursive learning algorithms in statistics, machine learning and statistical physics. Large deviations for stochastic approximations provide asymptotic estimates of the probability that the learning algorithm deviates from its expected path, given by a limit ODE, and the large deviation rate function gives insights to the most likely way that such deviations occur.   In this paper we prove a large deviation principle for general stochastic approximations with state-dependent Markovian noise and decreasing step size. Using the weak convergence approach to large deviations, we generalize previous results for stochastic approximations and identify the appropriate scaling sequence for the large deviation principle. We also give a new representation for the rate function, in which the rate function is expressed as an action functional involving the family of Markov transition kernels. Examples of learning algorithms that are covered by the large deviation principle include stochastic gradient descent, persistent contrastive divergence and the Wang-Landau algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02531</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02531</id><created>2025-02-04</created><updated>2025-02-05</updated><authors><author><keyname>Bordelon</keyname><forenames>Blake</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Deep Linear Network Training Dynamics from Random Initialization: Data,   Width, Depth, and Hyperparameter Transfer</title><categories>cs.LG cond-mat.dis-nn stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data. Our theory captures the ``wider is better" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width. We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\sqrt{\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration. Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02552</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02552</id><created>2025-02-04</created><authors><author><keyname>Zhu</keyname><forenames>Haonan</forenames></author><author><keyname>Goncalves</keyname><forenames>Andre R.</forenames></author><author><keyname>Valdes</keyname><forenames>Camilo</forenames></author><author><keyname>Ranganathan</keyname><forenames>Hiranmayi</forenames></author><author><keyname>Zhang</keyname><forenames>Boya</forenames></author><author><keyname>Martí</keyname><forenames>Jose Manuel</forenames></author><author><keyname>Kok</keyname><forenames>Car Reen</forenames></author><author><keyname>Borucki</keyname><forenames>Monica K.</forenames></author><author><keyname>Mulakken</keyname><forenames>Nisha J.</forenames></author><author><keyname>Thissen</keyname><forenames>James B.</forenames></author><author><keyname>Jaing</keyname><forenames>Crystal</forenames></author><author><keyname>Hero</keyname><forenames>Alfred</forenames></author><author><keyname>Be</keyname><forenames>Nicholas A.</forenames></author></authors><title>Hierarchical Sparse Bayesian Multitask Model with Scalable Inference for   Microbiome Analysis</title><categories>cs.LG q-bio.BM stat.AP stat.CO stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a hierarchical Bayesian multitask learning model that is applicable to the general multi-task binary classification learning problem where the model assumes a shared sparsity structure across different tasks. We derive a computationally efficient inference algorithm based on variational inference to approximate the posterior distribution. We demonstrate the potential of the new approach on various synthetic datasets and for predicting human health status based on microbiome profile. Our analysis incorporates data pooled from multiple microbiome studies, along with a comprehensive comparison with other benchmark methods. Results in synthetic datasets show that the proposed approach has superior support recovery property when the underlying regression coefficients share a common sparsity structure across different tasks. Our experiments on microbiome classification demonstrate the utility of the method in extracting informative taxa while providing well-calibrated predictions with uncertainty quantification and achieving competitive performance in terms of prediction metrics. Notably, despite the heterogeneity of the pooled datasets (e.g., different experimental objectives, laboratory setups, sequencing equipment, patient demographics), our method delivers robust results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02561</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02561</id><created>2025-02-04</created><authors><author><keyname>Kiyani</keyname><forenames>Shayan</forenames></author><author><keyname>Pappas</keyname><forenames>George</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Hassani</keyname><forenames>Hamed</forenames></author></authors><title>Decision Theoretic Foundations for Conformal Prediction: Optimal   Uncertainty Quantification for Risk-Averse Agents</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions in ways that can usefully inform downstream action. This interface between prediction uncertainty and decision-making is especially important in risk-sensitive domains, such as medicine. In this paper, we develop decision-theoretic foundations that connect uncertainty quantification using prediction sets with risk-averse decision-making. Specifically, we answer three fundamental questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. Answering these questions naturally leads to an algorithm, Risk-Averse Calibration (RAC), which follows a provably optimal design for deriving action policies from predictions. RAC is designed to be both practical-capable of leveraging the quality of predictions in a black-box manner to enhance downstream utility-and safe-adhering to a user-defined risk threshold and optimizing the corresponding risk quantile of the user's downstream utility. Finally, we experimentally demonstrate the significant advantages of RAC in applications such as medical diagnosis and recommendation systems. Specifically, we show that RAC achieves a substantially improved trade-off between safety and utility, offering higher utility compared to existing methods while maintaining the safety guarantee. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02562</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02562</id><created>2025-02-04</created><authors><author><keyname>Schenck</keyname><forenames>Connor</forenames></author><author><keyname>Reid</keyname><forenames>Isaac</forenames></author><author><keyname>Jacob</keyname><forenames>Mithun George</forenames></author><author><keyname>Bewley</keyname><forenames>Alex</forenames></author><author><keyname>Ainslie</keyname><forenames>Joshua</forenames></author><author><keyname>Rendleman</keyname><forenames>David</forenames></author><author><keyname>Jain</keyname><forenames>Deepali</forenames></author><author><keyname>Sharma</keyname><forenames>Mohit</forenames></author><author><keyname>Dubey</keyname><forenames>Avinava</forenames></author><author><keyname>Wahid</keyname><forenames>Ayzaan</forenames></author><author><keyname>Singh</keyname><forenames>Sumeet</forenames></author><author><keyname>Wagner</keyname><forenames>Rene</forenames></author><author><keyname>Ding</keyname><forenames>Tianli</forenames></author><author><keyname>Fu</keyname><forenames>Chuyuan</forenames></author><author><keyname>Byravan</keyname><forenames>Arunkumar</forenames></author><author><keyname>Varley</keyname><forenames>Jake</forenames></author><author><keyname>Gritsenko</keyname><forenames>Alexey</forenames></author><author><keyname>Minderer</keyname><forenames>Matthias</forenames></author><author><keyname>Kalashnikov</keyname><forenames>Dmitry</forenames></author><author><keyname>Tompson</keyname><forenames>Jonathan</forenames></author><author><keyname>Sindhwani</keyname><forenames>Vikas</forenames></author><author><keyname>Choromanski</keyname><forenames>Krzysztof</forenames></author></authors><title>Learning the RoPEs: Better 2D and 3D Position Encodings with STRING</title><categories>cs.LG cs.AI cs.CV cs.RO stat.ML</categories><comments>Videos of STRING-based robotics controllers can be found here:   https://sites.google.com/view/string-robotics</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce STRING: Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers. We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02580</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02580</id><created>2025-02-04</created><updated>2025-02-04</updated><authors><author><keyname>Huang</keyname><forenames>Chengzhu</forenames></author><author><keyname>Gu</keyname><forenames>Yuqi</forenames></author></authors><title>Minimax-Optimal Dimension-Reduced Clustering for High-Dimensional   Nonspherical Mixtures</title><categories>math.ST stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mixture models, nonspherical (anisotropic) noise within each cluster is widely present in real-world data. We study both the minimax rate and optimal statistical procedure for clustering under high-dimensional nonspherical mixture models. In high-dimensional settings, we first establish the information-theoretic limits for clustering under Gaussian mixtures. The minimax lower bound unveils an intriguing informational dimension-reduction phenomenon: there exists a substantial gap between the minimax rate and the oracle clustering risk, with the former determined solely by the projected centers and projected covariance matrices in a low-dimensional space. Motivated by the lower bound, we propose a novel computationally efficient clustering method: Covariance Projected Spectral Clustering (COPO). Its key step is to project the high-dimensional data onto the low-dimensional space spanned by the cluster centers and then use the projected covariance matrices in this space to enhance clustering. We establish tight algorithmic upper bounds for COPO, both for Gaussian noise with flexible covariance and general noise with local dependence. Our theory indicates the minimax-optimality of COPO in the Gaussian case and highlights its adaptivity to a broad spectrum of dependent noise. Extensive simulation studies under various noise structures and real data analysis demonstrate our method's superior performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1401.1137</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1401.1137</id><created>2014-01-06</created><updated>2015-03-27</updated><authors><author><keyname>Caron</keyname><forenames>François</forenames></author><author><keyname>Fox</keyname><forenames>Emily B.</forenames></author></authors><title>Sparse graphs using exchangeable random measures</title><categories>stat.ME cs.SI math.ST stat.ML stat.TH</categories><comments>New title. Extended version</comments><journal-ref>Journal of the Royal Statistical Society Series B: Statistical   Methodology, Volume 79, Issue 5, November 2017, Pages 1295-1366</journal-ref><doi>10.1111/rssb.12233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical network modeling has focused on representing the graph as a discrete structure, namely the adjacency matrix, and considering the exchangeability of this array. In such cases, the Aldous-Hoover representation theorem (Aldous, 1981;Hoover, 1979} applies and informs us that the graph is necessarily either dense or empty. In this paper, we instead consider representing the graph as a measure on $\mathbb{R}_+^2$. For the associated definition of exchangeability in this continuous space, we rely on the Kallenberg representation theorem (Kallenberg, 2005). We show that for certain choices of such exchangeable random measures underlying our graph construction, our network process is sparse with power-law degree distribution. In particular, we build on the framework of completely random measures (CRMs) and use the theory associated with such processes to derive important network properties, such as an urn representation for our analysis and network simulation. Our theoretical results are explored empirically and compared to common network models. We then present a Hamiltonian Monte Carlo algorithm for efficient exploration of the posterior distribution and demonstrate that we are able to recover graphs ranging from dense to sparse--and perform associated tests--based on our flexible CRM-based formulation. We explore network properties in a range of real datasets, including Facebook social circles, a political blogosphere, protein networks, citation networks, and world wide web networks, including networks with hundreds of thousands of nodes and millions of edges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1602.02114</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1602.02114</id><created>2016-02-05</created><updated>2017-08-23</updated><authors><author><keyname>Todeschini</keyname><forenames>Adrien</forenames></author><author><keyname>Miscouridou</keyname><forenames>Xenia</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Exchangeable Random Measures for Sparse and Modular Graphs with   Overlapping Communities</title><categories>stat.ME cs.SI physics.soc-ph stat.ML</categories><journal-ref>Journal of the Royal Statistical Society Series B: Statistical   Methodology, Volume 82, Issue 2, April 2020, Pages 487-520</journal-ref><doi>10.1111/rssb.12363</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel statistical model for sparse networks with overlapping community structure. The model is based on representing the graph as an exchangeable point process, and naturally generalizes existing probabilistic models with overlapping block-structure to the sparse regime. Our construction builds on vectors of completely random measures, and has interpretable parameters, each node being assigned a vector representing its level of affiliation to some latent communities. We develop methods for simulating this class of random graphs, as well as to perform posterior inference. We show that the proposed approach can recover interpretable structure from two real-world networks and can handle graphs with thousands of nodes and tens of thousands of edges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1708.03120</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1708.03120</id><created>2017-08-10</created><updated>2022-11-01</updated><authors><author><keyname>Caron</keyname><forenames>François</forenames></author><author><keyname>Panero</keyname><forenames>Francesca</forenames></author><author><keyname>Rousseau</keyname><forenames>Judith</forenames></author></authors><title>On sparsity, power-law and clustering properties of graphex processes</title><categories>math.ST math.PR stat.TH</categories><journal-ref>Advances in Applied Probability, Volume 55, Issue 4, December   2023, pp. 1211 - 1253</journal-ref><doi>10.1017/apr.2022.75</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates properties of the class of graphs based on exchangeable point processes. We provide asymptotic expressions for the number of edges, number of nodes and degree distributions, identifying four regimes: (i) a dense regime, (ii) a sparse almost dense regime, (iii) a sparse regime with power-law behaviour, and (iv) an almost extremely sparse regime. We show that under mild assumptions, both the global and local clustering coefficients converge to constants which may or may not be the same. We also derive a central limit theorem for the number of nodes. Finally, we propose a class of models within this framework where one can separately control the latent structure and the global sparsity/power-law properties of the graph. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1902.04714</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1902.04714</id><created>2019-02-12</created><updated>2019-07-09</updated><authors><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Beyond the Chinese Restaurant and Pitman-Yor processes: Statistical   Models with Double Power-law Behavior</title><categories>stat.ML cs.LG</categories><journal-ref>Proceedings of the 36th International Conference on Machine   Learning, PMLR 97:395-404, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian nonparametric approaches, in particular the Pitman-Yor process and the associated two-parameter Chinese Restaurant process, have been successfully used in applications where the data exhibit a power-law behavior. Examples include natural language processing, natural images or networks. There is also growing empirical evidence that some datasets exhibit a two-regime power-law behavior: one regime for small frequencies, and a second regime, with a different exponent, for high frequencies. In this paper, we introduce a class of completely random measures which are doubly regularly-varying. Contrary to the Pitman-Yor process, we show that when completely random measures in this class are normalized to obtain random probability measures and associated random partitions, such partitions exhibit a double power-law behavior. We discuss in particular three models within this class: the beta prime process (Broderick et al. (2015, 2018), a novel process called generalized BFRY process, and a mixture construction. We derive efficient Markov chain Monte Carlo algorithms to estimate the parameters of these models. Finally, we show that the proposed models provide a better fit than the Pitman-Yor process on various datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1905.09059</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1905.09059</id><created>2019-05-22</created><authors><author><keyname>Rathasamuth</keyname><forenames>Wanthanee</forenames></author><author><keyname>Pasupa</keyname><forenames>Kitsuchart</forenames></author><author><keyname>Tongsima</keyname><forenames>Sissades</forenames></author></authors><title>Selection of a Minimal Number of Significant Porcine SNPs by an   Information Gain and Genetic Algorithm Hybrid Model</title><categories>q-bio.QM cs.NE stat.AP</categories><comments>16 pages, 9 figures, preprint submitted to Malaysian Journal of   Computer Science</comments><journal-ref>Malaysian Journal of Computer Science, SI2, 79--95 (2019)</journal-ref><doi>10.22452/mjcs.sp2019no2.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A panel of large number of common Single Nucleotide Polymorphisms (SNPs) distributed across an entire porcine genome has been widely used to represent genetic variability of pig. With the advent of SNP-array technology, a genome-wide genetic profile of a specimen can be easily observed. Among the large number of such variations, there exist a much smaller subset of the SNP panel that could equally be used to correctly identify the corresponding breed. This work presents a SNP selection heuristic that can still be used effectively in the breed classification process. The proposed feature selection was done by the approach of combining a filter method and a wrapper method--information gain method and genetic algorithm--plus a feature frequency selection step, while classification was done by support vector machine. The approach was able to reduce the number of significant SNPs to 0.86 % of the total number of SNPs in a swine dataset and provided a high classification accuracy of 94.80 %. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1905.10733</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1905.10733</id><created>2019-05-26</created><authors><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Miscouridou</keyname><forenames>Xenia</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>A unified construction for series representations and finite   approximations of completely random measures</title><categories>math.ST cs.LG stat.ML stat.TH</categories><journal-ref>Bernoulli 29(3): 2142-2166, 2023</journal-ref><doi>10.3150/22-BEJ1536</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infinite-activity completely random measures (CRMs) have become important building blocks of complex Bayesian nonparametric models. They have been successfully used in various applications such as clustering, density estimation, latent feature models, survival analysis or network science. Popular infinite-activity CRMs include the (generalized) gamma process and the (stable) beta process. However, except in some specific cases, exact simulation or scalable inference with these models is challenging and finite-dimensional approximations are often considered. In this work, we propose a general and unified framework to derive both series representations and finite-dimensional approximations of CRMs. Our framework can be seen as an extension of constructions based on size-biased sampling of Poisson point process [Perman1992]. It includes as special cases several known series representations as well as novel ones. In particular, we show that one can get novel series representations for the generalized gamma process and the stable beta process. We also provide some analysis of the truncation error. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1911.06869</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1911.06869</id><created>2019-11-15</created><updated>2025-02-05</updated><authors><author><keyname>Bhadra</keyname><forenames>Somnath</forenames></author><author><keyname>Chakraborty</keyname><forenames>Kaustav</forenames></author><author><keyname>Sengupta</keyname><forenames>Srijan</forenames></author><author><keyname>Lahiri</keyname><forenames>Soumendra</forenames></author></authors><title>A Bootstrap-based Method for Testing Network Similarity</title><categories>stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the matched network inference problem, where the goal is to determine if two networks, defined on a common set of nodes, exhibit a specific form of stochastic similarity. Two notions of similarity are considered: (i) equality, i.e., testing whether the networks arise from the same random graph model, and (ii) scaling, i.e., testing whether their probability matrices are proportional for some unknown scaling constant. We develop a testing framework based on a parametric bootstrap approach and a Frobenius norm-based test statistic. The proposed approach is highly versatile as it covers both the equality and scaling problems, and ensures adaptability under various model settings, including stochastic blockmodels, Chung-Lu models, and random dot product graph models. We establish theoretical consistency of the proposed tests and demonstrate their empirical performance through extensive simulations under a wide range of model classes. Our results establish the flexibility and computational efficiency of the proposed method compared to existing approaches. We also report a real-world application involving the Aarhus network dataset, which reveals meaningful sociological patterns across different communication layers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2006.10968</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2006.10968</id><created>2020-06-19</created><updated>2022-11-28</updated><authors><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>The Normal-Generalised Gamma-Pareto process: A novel pure-jump L\'evy   process with flexible tail and jump-activity properties</title><categories>stat.ME math.ST stat.TH</categories><journal-ref>Bayesian Anal. 19(1): 123-152, 2024</journal-ref><doi>10.1214/22-BA1343</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pure-jump L\'evy processes are popular classes of stochastic processes which have found many applications in finance, statistics or machine learning. In this paper, we propose a novel family of self-decomposable L\'evy processes where one can control separately the tail behavior and the jump activity of the process, via two different parameters. Crucially, we show that one can sample exactly increments of this process, at any time scale; this allows the implementation of likelihood-free Markov chain Monte Carlo algorithms for (asymptotically) exact posterior inference. We use this novel process in L\'evy-based stochastic volatility models to predict the returns of stock market data, and show that the proposed class of models leads to superior predictive performances compared to classical alternatives. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2007.14717</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2007.14717</id><created>2020-07-29</created><updated>2024-06-05</updated><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames></author><author><keyname>Dreveton</keyname><forenames>Maximilien</forenames></author></authors><title>Almost exact recovery in noisy semi-supervised learning</title><categories>cs.LG math.ST stat.ML stat.TH</categories><msc-class>62F12, 62H30, 68T10</msc-class><journal-ref>Prob. Eng. Inf. Sci. 39 (2025) 1-22</journal-ref><doi>10.1017/S0269964824000135</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graph-based semi-supervised learning methods combine the graph structure and labeled data to classify unlabeled data. In this work, we study the effect of a noisy oracle on classification. In particular, we derive the Maximum A Posteriori (MAP) estimator for clustering a Degree Corrected Stochastic Block Model (DC-SBM) when a noisy oracle reveals a fraction of the labels. We then propose an algorithm derived from a continuous relaxation of the MAP, and we establish its consistency. Numerical experiments show that our approach achieves promising performance on synthetic and real data sets, even in the case of very noisy labeled data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2010.08891</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2010.08891</id><created>2020-10-17</created><updated>2025-02-04</updated><authors><author><keyname>Shrestha</keyname><forenames>Aayam</forenames></author><author><keyname>Lee</keyname><forenames>Stefan</forenames></author><author><keyname>Tadepalli</keyname><forenames>Prasad</forenames></author><author><keyname>Fern</keyname><forenames>Alan</forenames></author></authors><title>DeepAveragers: Offline Reinforcement Learning by Solving Derived   Non-Parametric MDPs</title><categories>cs.LG cs.AI stat.ML</categories><comments>Camera Ready ICLR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an approach to offline reinforcement learning (RL) based on optimally solving finitely-represented MDPs derived from a static dataset of experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals. Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL. DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model. In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2011.01591</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2011.01591</id><created>2020-11-03</created><updated>2025-02-05</updated><authors><author><keyname>Hermann</keyname><forenames>Philipp</forenames></author><author><keyname>Holzmann</keyname><forenames>Hajo</forenames></author></authors><title>Support estimation in high-dimensional heteroscedastic mean regression</title><categories>math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A current strand of research in high-dimensional statistics deals with robustifying the available methodology with respect to deviations from the pervasive light-tail assumptions. In this paper we consider a linear mean regression model with random design and potentially heteroscedastic, heavy-tailed errors, and investigate support estimation in this framework. We use a strictly convex, smooth variant of the Huber loss function with tuning parameter depending on the parameters of the problem, as well as the adaptive LASSO penalty for computational efficiency. For the resulting estimator we show sign-consistency and optimal rates of convergence in the $\ell_\infty$ norm as in the homoscedastic, light-tailed setting. In our analysis, we have to deal with the issue that the support of the target parameter in the linear mean regression model and its robustified version may differ substantially even for small values of the tuning parameter of the Huber loss function. Simulations illustrate the favorable numerical performance of the proposed methodology. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2101.07718</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2101.07718</id><created>2021-01-19</created><updated>2025-02-04</updated><authors><author><keyname>Wang</keyname><forenames>Zhu</forenames></author></authors><title>Unified Robust Boosting</title><categories>stat.CO</categories><msc-class>62H30, 62G35, 68Q32</msc-class><journal-ref>Journal of Data Science, 2025, 23(1): 90-108</journal-ref><doi>10.6339/24-JDS1138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting is a popular algorithm in supervised machine learning with wide applications in regression and classification problems. It combines weak learners, such as regression trees, to obtain accurate predictions. However, in the presence of outliers, traditional boosting may yield inferior results since the algorithm optimizes a convex loss function. Recent literature has proposed boosting algorithms that optimize robust nonconvex loss functions. Nevertheless, there is a lack of weighted estimation to indicate the outlier status of observations. This article introduces the iteratively reweighted boosting (IRBoost) algorithm, which combines robust loss optimization and weighted estimation. It can be conveniently constructed with existing software. The output includes weights as valuable diagnostics for the outlier status of observations. For practitioners interested in the boosting algorithm, the new method can be interpreted as a way to tune robust observation weights. IRBoost is implemented in the R package irboost and is demonstrated using publicly available data in generalized linear models, classification, and survival data analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2107.00587</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2107.00587</id><created>2021-07-01</created><authors><author><keyname>Lecestre</keyname><forenames>Alexandre</forenames></author></authors><title>Robust Estimation in Finite Mixture Models</title><categories>math.ST stat.TH</categories><msc-class>62G05, 62G35, 62F35 (Primary) 62G07 (Secondary)</msc-class><journal-ref>ESAIM:PS, 27(2023), 402--460</journal-ref><doi>10.1051/ps/2023004</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We observe a $n$-sample, the distribution of which is assumed to belong, or at least to be close enough, to a given mixture model. We propose an estimator of this distribution that belongs to our model and possesses some robustness properties with respect to a possible misspecification of it. We establish a non-asymptotic deviation bound for the Hellinger distance between the target distribution and its estimator when the model consists of a mixture of densities that belong to VC-subgraph classes. Under suitable assumptions and when the mixture model is well-specified, we derive risk bounds for the parameters of the mixture. Finally, we design a statistical procedure that allows us to select from the data the number of components as well as suitable models for each of the densities that are involved in the mixture. These models are chosen among a collection of candidate ones and we show that our selection rule combined with our estimation strategy result in an estimator which satisfies an oracle-type inequality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2107.01120</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2107.01120</id><created>2021-07-02</created><updated>2022-05-25</updated><authors><author><keyname>Naulet</keyname><forenames>Zacharie</forenames></author><author><keyname>Rousseau</keyname><forenames>Judith</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Asymptotic Analysis of Statistical Estimators related to MultiGraphex   Processes under Misspecification</title><categories>math.ST stat.TH</categories><journal-ref>Bernoulli 30(4): 2644-2675, 2024</journal-ref><doi>10.3150/23-BEJ1689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the asymptotic properties of Bayesian or frequentist estimators of a vector of parameters related to structural properties of sequences of graphs. The estimators studied originate from a particular class of graphex model introduced by Caron and Fox. The analysis is however performed here under very weak assumptions on the underlying data generating process, which may be different from the model of Caron and Fox or from a graphex model. In particular, we consider generic sparse graph models, with unbounded degree, whose degree distribution satisfies some assumptions. We show that one can relate the limit of the estimator of one of the parameters to the sparsity constant of the true graph generating process. When taking a Bayesian approach, we also show that the posterior distribution is asymptotically normal. We discuss situations where classical random graphs models such as configuration models, sparse graphon models, edge exchangeable models or graphon processes satisfy our assumptions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2109.00375</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2109.00375</id><created>2021-09-01</created><updated>2025-02-04</updated><authors><author><keyname>Tan</keyname><forenames>Linda S. L.</forenames></author></authors><title>Analytic natural gradient updates for Cholesky factor in Gaussian   variational approximation</title><categories>stat.CO</categories><doi>10.1093/jrsssb/qkaf001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural gradients can improve convergence in stochastic variational inference significantly but inverting the Fisher information matrix is daunting in high dimensions. Moreover, in Gaussian variational approximation, natural gradient updates of the precision matrix do not ensure positive definiteness. To tackle this issue, we derive analytic natural gradient updates of the Cholesky factor of the covariance or precision matrix, and consider sparsity constraints representing different posterior correlation structures. Stochastic normalized natural gradient ascent with momentum is proposed for implementation in generalized linear mixed models and deep neural networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2110.06250</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2110.06250</id><created>2021-10-12</created><updated>2025-02-05</updated><authors><author><keyname>Weinstein</keyname><forenames>Asaf</forenames></author></authors><title>On the Minimum Attainable Risk in Permutation Invariant Problems</title><categories>math.ST stat.TH</categories><comments>1 figure</comments><msc-class>62C05, 62C12, 62C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a broad class of permutation invariant statistical problems by extending the standard decision theoretic definition to allow also selective inference tasks, where the target is specified only after seeing the data. For any such problem we show that, among all permutation invariant procedures, the minimizer of the risk at $\boldsymbol{\theta}$ is precisely the rule that minimizes the Bayes risk under a (postulated) discrete prior assigning equal probability to every permutation of $\boldsymbol{\theta}$. This gives an explicit characterization of the greatest lower bound on the risk of every sensible procedure in a wide range of problems. Furthermore, in a permutation invariant problem of estimating the parameter of a selected population under squared loss, we prove that this lower bound coincides asymptotically with a simpler lower bound, attained by the Bayes solution that replaces the aforementioned uniform prior on all permutations of $\boldsymbol{\theta}$ by the i.i.d. prior with the same marginals. This has important algorithmic implications because it suggests that our greatest lower bound is asymptotically attainable uniformly in $\boldsymbol{\theta}$ by an empirical Bayes procedure. Altogether, the above extends theory that has been established in the existing literature only for the very special case of compound decision problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.03513</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.03513</id><created>2022-02-07</created><updated>2025-02-05</updated><authors><author><keyname>Díaz</keyname><forenames>Iván</forenames></author><author><keyname>Hoffman</keyname><forenames>Katherine L</forenames></author><author><keyname>Hejazi</keyname><forenames>Nima S.</forenames></author></authors><title>Causal survival analysis under competing risks using longitudinal   modified treatment policies</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Longitudinal modified treatment policies (LMTP) have been recently developed as a novel method to define and estimate causal parameters that depend on the natural value of treatment. LMTPs represent an important advancement in causal inference for longitudinal studies as they allow the non-parametric definition and estimation of the joint effect of multiple categorical, numerical, or continuous exposures measured at several time points. We extend the LMTP methodology to problems in which the outcome is a time-to-event variable subject to right-censoring and competing risks. We present identification results and non-parametric locally efficient estimators that use flexible data-adaptive regression techniques to alleviate model misspecification bias, while retaining important asymptotic properties such as $\sqrt{n}$-consistency. We present an application to the estimation of the effect of the time-to-intubation on acute kidney injury amongst COVID-19 hospitalized patients, where death by other causes is taken to be the competing event. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.11886</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.11886</id><created>2022-02-23</created><updated>2025-02-04</updated><authors><author><keyname>Jeong</keyname><forenames>Yujin</forenames></author><author><keyname>Rothenhäusler</keyname><forenames>Dominik</forenames></author></authors><title>Calibrated inference: statistical inference that accounts for both   sampling uncertainty and distributional uncertainty</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  How can we draw trustworthy scientific conclusions? One criterion is that a study can be replicated by independent teams. While replication is critically important, it is arguably insufficient. If a study is biased for some reason and other studies recapitulate the approach then findings might be consistently incorrect. It has been argued that trustworthy scientific conclusions require disparate sources of evidence. However, different methods might have shared biases, making it difficult to judge the trustworthiness of a result. We formalize this issue by introducing a "distributional uncertainty model", wherein dense distributional shifts emerge as the superposition of numerous small random changes. The distributional perturbation model arises under a symmetry assumption on distributional shifts and is strictly weaker than assuming that the data is i.i.d. from the target distribution. We show that a stability analysis on a single data set allows us to construct confidence intervals that account for both sampling uncertainty and distributional uncertainty. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2205.08187</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2205.08187</id><created>2022-05-17</created><updated>2023-09-11</updated><authors><author><keyname>Lee</keyname><forenames>Hoil</forenames></author><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Jung</keyname><forenames>Paul</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Yang</keyname><forenames>Hongseok</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Deep neural networks with dependent weights: Gaussian Process mixture   limit, heavy tails, sparsity and compressibility</title><categories>stat.ML cs.LG math.PR math.ST stat.TH</categories><comments>96 pages, 15 figures, 9 tables</comments><msc-class>68T07 (Primary), 62M45, 60F99 (Secondary)</msc-class><journal-ref>Journal Of Machine Learning Research, 24(289):1-78, 2023</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the infinite-width limit of deep feedforward neural networks whose weights are dependent, and modelled via a mixture of Gaussian distributions. Each hidden node of the network is assigned a nonnegative random variable that controls the variance of the outgoing weights of that node. We make minimal assumptions on these per-node random variables: they are iid and their sum, in each layer, converges to some finite random variable in the infinite-width limit. Under this model, we show that each layer of the infinite-width neural network can be characterised by two simple quantities: a non-negative scalar parameter and a L\'evy measure on the positive reals. If the scalar parameters are strictly positive and the L\'evy measures are trivial at all hidden layers, then one recovers the classical Gaussian process (GP) limit, obtained with iid Gaussian weights. More interestingly, if the L\'evy measure of at least one layer is non-trivial, we obtain a mixture of Gaussian processes (MoGP) in the large-width limit. The behaviour of the neural network in this regime is very different from the GP regime. One obtains correlated outputs, with non-Gaussian distributions, possibly with heavy tails. Additionally, we show that, in this regime, the weights are compressible, and some nodes have asymptotically non-negligible contributions, therefore representing important hidden features. Many sparsity-promoting neural network models can be recast as special cases of our approach, and we discuss their infinite-width limits; we also present an asymptotic analysis of the pruning error. We illustrate some of the benefits of the MoGP regime over the GP regime in terms of representation learning and compressibility on simulated, MNIST and Fashion MNIST datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2206.02204</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2206.02204</id><created>2022-06-05</created><updated>2025-02-05</updated><authors><author><keyname>Lu</keyname><forenames>Jun</forenames></author><author><keyname>Mao</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Li</keyname><forenames>Mengyao</forenames></author><author><keyname>Hou</keyname><forenames>Chenping</forenames></author></authors><title>Adaptive weighted approach for high-dimensional statistical learning and   inference</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We propose a new weighted average estimator for the high dimensional parameters under the distributed learning system, in which the weight assigned to each coordinate is precisely proportional to the inverse of the variance of the local estimates for that coordinate. This strategy empowers the new estimator to achieve a minimal mean squared error, comparable to the current state-of-the-art one-shot distributed learning methods. While at the same time, the new weighting approach maintains remarkably low communication costs, as each agent is required to transmit only two vectors to the central server. As a result, the newly proposed method achieves optimal statistical efficiency while significantly reducing communication overhead. We further demonstrate the effectiveness of the new estimator by investigating the error bound and the asymptotic properties of the estimation, as well as the numerical performance on some simulated examples and a real data analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2208.07853</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2208.07853</id><created>2022-08-16</created><updated>2025-02-05</updated><authors><author><keyname>Neto</keyname><forenames>Jeova Farias Sales Rocha</forenames></author></authors><title>Estimating Appearance Models for Image Segmentation via Tensor   Factorization</title><categories>cs.CV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Image Segmentation is one of the core tasks in Computer Vision and solving it often depends on modeling the image appearance data via the color distributions of each it its constituent regions. Whereas many segmentation algorithms handle the appearance models dependence using alternation or implicit methods, we propose here a new approach to directly estimate them from the image without prior information on the underlying segmentation. Our method uses local high order color statistics from the image as an input to tensor factorization-based estimator for latent variable models. This approach is able to estimate models in multiregion images and automatically output the regions proportions without prior user interaction, overcoming the drawbacks from a prior attempt to this problem. We also demonstrate the performance of our proposed method in many challenging synthetic and real imaging scenarios and show that it leads to an efficient segmentation algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2208.10790</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2208.10790</id><created>2022-08-23</created><updated>2025-02-04</updated><authors><author><keyname>Brunzema</keyname><forenames>Paul</forenames></author><author><keyname>von Rohr</keyname><forenames>Alexander</forenames></author><author><keyname>Solowjow</keyname><forenames>Friedrich</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Event-Triggered Time-Varying Bayesian Optimization</title><categories>cs.LG stat.ML</categories><comments>Published in Transactions on Machine Learning Research (TMLR)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Current approaches to TVBO require prior knowledge of a constant rate of change to cope with stale data arising from time variations. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function and then resets the dataset. This allows the algorithm to adapt online to realized temporal changes without the need for exact prior knowledge. The event trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We derive regret bounds for adaptive resets without exact prior knowledge of the temporal changes and show in numerical experiments that ET-GP-UCB outperforms competing GP-UCB algorithms on both synthetic and real-world data. The results demonstrate that ET-GP-UCB is readily applicable without extensive hyperparameter tuning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2211.02609</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2211.02609</id><created>2022-11-04</created><updated>2025-02-05</updated><authors><author><keyname>Costello</keyname><forenames>Fintan</forenames></author><author><keyname>Watts</keyname><forenames>Paul</forenames></author></authors><title>How to Tell When a Result Will Replicate: Significance and Replication   in Distributional Null Hypothesis Tests</title><categories>stat.ME math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  There is a well-known problem in Null Hypothesis Significance Testing: many statistically significant results fail to replicate in subsequent experiments. We show that this problem arises because standard `point-form null' significance tests consider only within-experiment but ignore between-experiment variation, and so systematically underestimate the degree of random variation in results. We give an extension to standard significance testing that addresses this problem by analysing both within- and between-experiment variation. This `distributional null' approach does not underestimate experimental variability and so is not overconfident in identifying significance; because this approach addresses between-experiment variation, it gives mathematically coherent estimates for the probability of replication of significant results. Using a large-scale replication dataset (the first `Many Labs' project), we show that many experimental results that appear statistically significant in standard tests are in fact consistent with random variation when both within- and between-experiment variation are taken into account in this approach. Further, grouping experiments in this dataset into `predictor-target' pairs we show that the predicted replication probabilities for target experiments produced in this approach (given predictor experiment results and the sample sizes of the two experiments) are strongly correlated with observed replication rates. Distributional null hypothesis testing thus gives researchers a statistical tool for identifying statistically significant and reliably replicable results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2303.11293</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2303.11293</id><created>2023-03-13</created><updated>2025-02-05</updated><authors><author><keyname>Pran</keyname><forenames>Rakib Hassan</forenames></author></authors><title>Advancing Network Securing Strategies with Network Algorithms for   Integrated Air Defense System (IADS) Missile Batteries</title><categories>cs.SI stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently, the Integrated Air Defense System (IADS) has become vital for the defense system as the military defense system is vital for national security. Placing Integrated Air Defense System batteries among locations to protect locations assets is a crucial problem because optimal solutions are needed for interceptor missiles to intercept attacker missiles for maximizing protection of assets across locations or places. In this research, the procedures of using network algorithms along with developing several network algorithms are going to be demonstrated to develop a model for sequential development of seven network securing strategies of placing Surface to Air Missile (SAM) batteries to maximize the protection of assets across locations (based on given asset values) by generating optimal solutions through computation to destroy maximum attacker missiles by using minimum interceptor missiles with given intercept probability. This network securing strategies can be implemented not only for Integrated Air Defense System (IADS) planning but also Counter Air (CA) planning as Integrated Air Defense System (IADS) is conducted with defensive counter air supported by attack operations in offensive counter air. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.05242</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.05242</id><created>2023-04-11</created><updated>2025-02-05</updated><authors><author><keyname>Baouan</keyname><forenames>Ali</forenames></author><author><keyname>Coustou</keyname><forenames>Sébastien</forenames></author><author><keyname>Lacome</keyname><forenames>Mathieu</forenames></author><author><keyname>Pulido</keyname><forenames>Sergio</forenames></author><author><keyname>Rosenbaum</keyname><forenames>Mathieu</forenames></author></authors><title>Generation of Threat: Crediting football players for creating dangerous   actions in an unbiased way</title><categories>stat.AP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We introduce an innovative methodology to identify football players at the origin of threatening actions in a team. In our framework, a threat is defined as entering the opposing team's danger area. We investigate the timing of threat events and ball touches of players, and capture their correlation using Hawkes processes. Our model-based approach allows us to evaluate a player's ability to create danger both directly and through interactions with teammates. We define a new index, called Generation of Threat (GoT), that measures in an unbiased way the contribution of a player to threat generation. For illustration, we present a detailed analysis of Chelsea's 2016-2017 season, with a standout performance from Eden Hazard. We are able to credit each player for his involvement in danger creation and determine the main circuits leading to threat. In the same spirit, we investigate the danger generation process of Stade Rennais in the 2021-2022 season. Furthermore, we establish a comprehensive ranking of Ligue 1 players based on their generated threat in the 2021-2022 season. Our analysis reveals surprising results, with players such as Jason Berthomier, Moses Simon and Frederic Guilbert among the top performers in the GoT rankings. We also present a ranking of Ligue 1 central defenders in terms of generation of threat and confirm the great performance of some center-back pairs, such as Nayef Aguerd and Warmed Omari. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.12218</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.12218</id><created>2023-04-24</created><updated>2025-02-05</updated><authors><author><keyname>Clarke</keyname><forenames>Bertrand</forenames></author><author><keyname>Yao</keyname><forenames>Yuling</forenames></author></authors><title>A Cheat Sheet for Bayesian Prediction</title><categories>stat.ME</categories><comments>23 pages</comments><msc-class>62-02</msc-class><journal-ref>Statist. Sci. 2025, Vol. 40, 3-24</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper reviews the growing field of Bayesian prediction. Bayes point and interval prediction are defined and exemplified and situated in statistical prediction more generally. Then, four general approaches to Bayes prediction are defined and we turn to predictor selection. This can be done predictively or non-predictively and predictors can be based on single models or multiple models. We call these latter cases unitary predictors and model average predictors, respectively. Then we turn to the most recent aspect of prediction to emerge, namely prediction in the context of large observational data sets and discuss three further classes of techniques. We conclude with a summary and statement of several current open problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2305.06116</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2305.06116</id><created>2023-05-10</created><updated>2025-02-04</updated><authors><author><keyname>Catalano</keyname><forenames>Marta</forenames></author><author><keyname>Lavenant</keyname><forenames>Hugo</forenames></author></authors><title>Merging Rate of Opinions via Optimal Transport on Random Measures</title><categories>math.ST math.PR stat.TH</categories><comments>Substantial modifications compared to v1 of this preprint</comments><msc-class>60G55, 60G57, 49Q22, 62C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random measures provide flexible parameters for Bayesian nonparametric models. Given two different priors for a random measure, we develop a natural framework to investigate the rate at which the corresponding posteriors merge, as the sample size increases. We define a new distance between the laws of random measures that is built as a Wasserstein distance on the ground space of unbalanced measures, endowed with the bounded Lipschitz metric. We develop tight analytical bounds for its specification to completely random measures, including the special case of Poisson and gamma random measures. The bounds are interpreted in terms of an adapted extended Wasserstein distance between the L\'evy measures and are used to investigate the merging between the posteriors of normalized gamma and generalized gamma priors. After a careful study on the identifiability of the law of the random measure, interesting asymptotic and finite-sample insights are derived without putting \emph{any} assumption on the true data generating process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2306.01727</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2306.01727</id><created>2023-06-02</created><updated>2025-02-04</updated><authors><author><keyname>Briend</keyname><forenames>Simon</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Lugosi</keyname><forenames>Gabor</forenames></author></authors><title>Broadcasting in random recursive dags</title><categories>stat.ML cs.LG cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A uniform $k$-{\sc dag} generalizes the uniform random recursive tree by picking $k$ parents uniformly at random from the existing nodes. It starts with $k$ ''roots''. Each of the $k$ roots is assigned a bit. These bits are propagated by a noisy channel. The parents' bits are flipped with probability $p$, and a majority vote is taken. When all nodes have received their bits, the $k$-{\sc dag} is shown without identifying the roots. The goal is to estimate the majority bit among the roots. We identify the threshold for $p$ as a function of $k$ below which the majority rule among all nodes yields an error $c+o(1)$ with $c&lt;1/2$. Above the threshold the majority rule errs with probability $1/2+o(1)$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2306.02813</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2306.02813</id><created>2023-06-05</created><updated>2024-07-16</updated><authors><author><keyname>Tan</keyname><forenames>Linda S. L.</forenames></author><author><keyname>Chen</keyname><forenames>Aoxiang</forenames></author></authors><title>Variational inference based on a subclass of closed skew normals</title><categories>stat.ME</categories><comments>keywords: Closed skew normal; Gaussian variational approximation;   natural gradient; centered parametrization; LU decomposition</comments><doi>10.1080/10618600.2024.2402278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian distributions are widely used in Bayesian variational inference to approximate intractable posterior densities, but the ability to accommodate skewness can improve approximation accuracy significantly, when data or prior information is scarce. We study the properties of a subclass of closed skew normals constructed using affine transformation of independent standardized univariate skew normals as the variational density, and illustrate how it provides increased flexibility and accuracy in approximating the joint posterior in various applications, by overcoming limitations in existing skew normal variational approximations. The evidence lower bound is optimized using stochastic gradient ascent, where analytic natural gradient updates are derived. We also demonstrate how problems in maximum likelihood estimation of skew normal parameters occur similarly in stochastic variational inference, and can be resolved using the centered parametrization. Supplemental materials are available online. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.09766</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.09766</id><created>2023-10-15</created><updated>2025-02-03</updated><authors><author><keyname>Chen</keyname><forenames>Haoxian</forenames></author><author><keyname>Lam</keyname><forenames>Henry</forenames></author></authors><title>Pseudo-Bayesian Optimization</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-based methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a suitable "randomized prior" construction to quantify uncertainty, not only guarantees convergence but also consistently outperforms state-of-the-art benchmarks in examples ranging from high-dimensional synthetic experiments to realistic hyperparameter tuning and robotic applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.05153</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.05153</id><created>2023-12-08</created><updated>2025-02-05</updated><authors><author><keyname>Reiser</keyname><forenames>Philipp</forenames></author><author><keyname>Aguilar</keyname><forenames>Javier Enrique</forenames></author><author><keyname>Guthke</keyname><forenames>Anneli</forenames></author><author><keyname>Bürkner</keyname><forenames>Paul-Christian</forenames></author></authors><title>Uncertainty Quantification and Propagation in Surrogate-based Bayesian   Inference</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Surrogate models are statistical or conceptual approximations for more complex simulation models. In this context, it is crucial to propagate the uncertainty induced by limited simulation budget and surrogate approximation error to predictions, inference, and subsequent decision-relevant quantities. However, quantifying and then propagating the uncertainty of surrogates is usually limited to special analytic cases or is otherwise computationally very expensive. In this paper, we propose a framework enabling a scalable, Bayesian approach to surrogate modeling with thorough uncertainty quantification, propagation, and validation. Specifically, we present three methods for Bayesian inference with surrogate models given measurement data. This is a task where the propagation of surrogate uncertainty is especially relevant, because failing to account for it may lead to biased and/or overconfident estimates of the parameters of interest. We showcase our approach in three detailed case studies for linear and nonlinear real-world modeling scenarios. Uncertainty propagation in surrogate models enables more reliable and safe approximation of expensive simulators and will therefore be useful in various fields of applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.14531</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.14531</id><created>2024-01-25</created><updated>2025-02-03</updated><authors><author><keyname>Mandjes</keyname><forenames>Michel</forenames></author><author><keyname>Wang</keyname><forenames>Jiesen</forenames></author></authors><title>Estimation of on- and off-time distributions in a dynamic   Erd\H{o}s-R\'enyi random graph</title><categories>math.ST math.PR stat.TH</categories><msc-class>05C80, 62M09, 62F12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a dynamic Erd\H{o}s-R\'enyi graph in which edges, according to an alternating renewal process, change from present to absent and vice versa. The objective is to estimate the on- and off-time distributions while only observing the aggregate number of edges. This inverse problem is dealt with, in a parametric context, by setting up an estimator based on the method of moments. We provide conditions under which the estimator is asymptotically normal, and we point out how the corresponding covariance matrix can be identified. It is also demonstrated how to adapt the estimation procedure if alternative subgraph counts are observed, such as the number of wedges or triangles. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.04933</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.04933</id><created>2024-02-07</created><updated>2025-02-05</updated><authors><author><keyname>Liang</keyname><forenames>Biyonka</forenames></author><author><keyname>Xu</keyname><forenames>Lily</forenames></author><author><keyname>Taneja</keyname><forenames>Aparna</forenames></author><author><keyname>Tambe</keyname><forenames>Milind</forenames></author><author><keyname>Janson</keyname><forenames>Lucas</forenames></author></authors><title>Context in Public Health for Underserved Communities: A Bayesian   Approach to Online Restless Bandits</title><categories>cs.LG stat.AP</categories><comments>29 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public health programs often provide interventions to encourage program adherence, and effectively allocating interventions is vital for producing the greatest overall health outcomes, especially in underserved communities where resources are limited. Such resource allocation problems are often modeled as restless multi-armed bandits (RMABs) with unknown underlying transition dynamics, hence requiring online reinforcement learning (RL). We present Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs that novelly combines techniques in Bayesian modeling with Thompson sampling to flexibly model the complex RMAB settings present in public health program adherence problems, namely context and non-stationarity. BCoR's key strength is the ability to leverage shared information within and between arms to learn the unknown RMAB transition dynamics quickly in intervention-scarce settings with relatively short time horizons, which is common in public health applications. Empirically, BCoR achieves substantially higher finite-sample performance over a range of experimental settings, including a setting using real-world adherence data that was developed in collaboration with ARMMAN, an NGO in India which runs a large-scale maternal mHealth program, showcasing BCoR practical utility and potential for real-world deployment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.08283</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.08283</id><created>2024-02-13</created><updated>2024-10-24</updated><authors><author><keyname>Ghosh</keyname><forenames>Annesha</forenames></author><author><keyname>Ghosh</keyname><forenames>Anil K.</forenames></author><author><keyname>SahaRay</keyname><forenames>Rita</forenames></author><author><keyname>Sarkar</keyname><forenames>Soham</forenames></author></authors><title>Classification Using Global and Local Mahalanobis Distances</title><categories>stat.ME stat.ML</categories><doi>10.1016/j.jmva.2025.105417</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel semiparametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric modeling assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose another classifier based on a generalized additive model that uses the local Mahalanobis distances as features. This nonparametric classifier usually performs like the Mahalanobis distance based semiparametric classifier when the underlying distributions are elliptic, but outperforms it for several non-elliptic and multimodal distributions. We also investigate the behaviour of these two classifiers in high dimension, low sample size situations. A thorough numerical study involving several simulated and real datasets demonstrate the usefulness of the proposed classifiers in comparison to many state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.10018</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.10018</id><created>2024-02-15</created><updated>2025-02-04</updated><authors><author><keyname>Portnoy</keyname><forenames>Ayelet C.</forenames></author><author><keyname>Solomon</keyname><forenames>Amit</forenames></author><author><keyname>Cohen</keyname><forenames>Alejandro</forenames></author></authors><title>Non-Adaptive Multi-Stage Algorithm and Bounds for Group Testing with   Prior Statistics</title><categories>cs.IT math.IT q-bio.QM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient multi-stage algorithm for non-adaptive Group Testing (GT) with general correlated prior statistics. The proposed solution can be applied to any correlated statistical prior represented in trellis, e.g., finite state machines and Markov processes. We introduce a variation of List Viterbi Algorithm (LVA) to enable accurate recovery using much fewer tests than objectives, which efficiently gains from the correlated prior statistics structure. We also provide a sufficiency bound to the number of pooled tests required by any Maximum A Posteriori (MAP) decoder with an arbitrary correlation between infected items. Our numerical results demonstrate that the proposed Multi-Stage GT (MSGT) algorithm can obtain the optimal MAP performance with feasible complexity in practical regimes, such as with COVID-19 and sparse signal recovery applications, and reduce in the scenarios tested the number of pooled tests by at least 25% compared to existing classical low complexity GT algorithms. Moreover, we analytically characterize the complexity of the proposed MSGT algorithm that guarantees its efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.14645</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.14645</id><created>2024-02-22</created><updated>2025-02-04</updated><authors><author><keyname>Gupte</keyname><forenames>Aparna</forenames></author><author><keyname>Vafa</keyname><forenames>Neekon</forenames></author><author><keyname>Vaikuntanathan</keyname><forenames>Vinod</forenames></author></authors><title>Sparse Linear Regression and Lattice Problems</title><categories>cs.LG stat.ML</categories><comments>TCC 2024; minor edits</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse linear regression (SLR) is a well-studied problem in statistics where one is given a design matrix $X\in\mathbb{R}^{m\times n}$ and a response vector $y=X\theta^*+w$ for a $k$-sparse vector $\theta^*$ (that is, $\|\theta^*\|_0\leq k$) and small, arbitrary noise $w$, and the goal is to find a $k$-sparse $\widehat{\theta} \in \mathbb{R}^n$ that minimizes the mean squared prediction error $\frac{1}{m}\|X\widehat{\theta}-X\theta^*\|^2_2$. While $\ell_1$-relaxation methods such as basis pursuit, Lasso, and the Dantzig selector solve SLR when the design matrix is well-conditioned, no general algorithm is known, nor is there any formal evidence of hardness in an average-case setting with respect to all efficient algorithms.   We give evidence of average-case hardness of SLR w.r.t. all efficient algorithms assuming the worst-case hardness of lattice problems. Specifically, we give an instance-by-instance reduction from a variant of the bounded distance decoding (BDD) problem on lattices to SLR, where the condition number of the lattice basis that defines the BDD instance is directly related to the restricted eigenvalue condition of the design matrix, which characterizes some of the classical statistical-computational gaps for sparse linear regression. Also, by appealing to worst-case to average-case reductions from the world of lattices, this shows hardness for a distribution of SLR instances; while the design matrices are ill-conditioned, the resulting SLR instances are in the identifiable regime.   Furthermore, for well-conditioned (essentially) isotropic Gaussian design matrices, where Lasso is known to behave well in the identifiable regime, we show hardness of outputting any good solution in the unidentifiable regime where there are many solutions, assuming the worst-case hardness of standard and well-studied lattice problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.18213</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.18213</id><created>2024-02-28</created><updated>2025-02-04</updated><authors><author><keyname>Sukthanker</keyname><forenames>Rhea Sanjay</forenames></author><author><keyname>Zela</keyname><forenames>Arber</forenames></author><author><keyname>Staffler</keyname><forenames>Benedikt</forenames></author><author><keyname>Dooley</keyname><forenames>Samuel</forenames></author><author><keyname>Grabocka</keyname><forenames>Josif</forenames></author><author><keyname>Hutter</keyname><forenames>Frank</forenames></author></authors><title>Multi-objective Differentiable Neural Architecture Search</title><categories>cs.LG cs.CV stat.ML</categories><comments>44 pages, 34 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Pareto front profiling in multi-objective optimization (MOO), i.e., finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives that require training a neural network. Typically, in MOO for neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a computationally expensive search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences to trade-off performance and hardware metrics, yielding representative and diverse architectures across multiple devices in just a single search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot transferability to new devices. Extensive experiments involving up to 19 hardware devices and 3 different objectives demonstrate the effectiveness and scalability of our method. Finally, we show that, without any additional costs, our method outperforms existing MOO NAS methods across a broad range of qualitatively different search spaces and datasets, including MobileNetV3 on ImageNet-1k, an encoder-decoder transformer space for machine translation and a decoder-only space for language modelling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.02233</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.02233</id><created>2024-03-04</created><updated>2025-02-05</updated><authors><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Wen</keyname><forenames>Zixin</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author></authors><title>A Theoretical Analysis of Self-Supervised Learning for Vision   Transformers</title><categories>cs.LG math.OC stat.ML</categories><comments>Accepted by ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-supervised learning has become a cornerstone in computer vision, primarily divided into reconstruction-based methods like masked autoencoders (MAE) and discriminative methods such as contrastive learning (CL). Recent empirical observations reveal that MAE and CL capture different types of representations: CL tends to focus on global patterns, while MAE adeptly captures both global and subtle local information simultaneously. Despite a flurry of recent empirical investigations to shed light on this difference, theoretical understanding remains limited, especially on the dominant architecture vision transformers (ViTs). In this paper, to provide rigorous insights, we model the visual data distribution by considering two types of spatial features: dominant global features and comparatively minuscule local features, and study the impact of imbalance among these features. We analyze the training dynamics of one-layer softmax-based ViTs on both MAE and CL objectives using gradient descent. Our analysis shows that as the degree of feature imbalance varies, ViTs trained with the MAE objective effectively learn both global and local features to achieve near-optimal reconstruction, while the CL-trained ViTs favor predominantly global features, even under mild imbalance. These results provide a theoretical explanation for distinct behaviors of MAE and CL observed in empirical studies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.05038</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.05038</id><created>2024-03-07</created><updated>2025-02-04</updated><authors><author><keyname>Krantz</keyname><forenames>Sebastian</forenames></author></authors><title>collapse: Advanced and Fast Statistical Computing and Data   Transformation in R</title><categories>stat.CO</categories><comments>32 pages, 0 figures. Submitted to the Journal of Statistical Software</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  collapse is a large C/C++-based infrastructure package facilitating complex statistical computing, data transformation, and exploration tasks in R - at outstanding levels of performance and memory efficiency. It also implements a class-agnostic approach to R programming, supporting vector, matrix and data frame-like objects and their popular extensions (units, integer64, xts, tibble, data.table, sf, pdata.frame), enabling its seamless integration with large parts of the R ecosystem. This article introduces the package's key components and design principles in a structured way, supported by a rich set of examples. A small benchmark demonstrates its computational performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.07628</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.07628</id><created>2024-03-12</created><updated>2025-02-04</updated><authors><author><keyname>Bornemann</keyname><forenames>Folkmar</forenames></author></authors><title>Asymptotic Expansions of the Limit Laws of Gaussian and Laguerre   (Wishart) Ensembles at the Soft Edge</title><categories>math.PR math-ph math.MP math.ST stat.TH</categories><comments>V5: using an alternative expression for the parameter tau that better   fits the style of the other parameters in the Laguerre/Wishart cases, more   remarks on the rationale of the scaling in the symplectic cases; 70 pages, 8   figures</comments><msc-class>60B20, 15B52, 62E20, 41A60, 33C15, 33C45, 33E17, 34E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The large-matrix limit laws of the rescaled largest eigenvalue of the orthogonal, unitary, and symplectic $n$-dimensional Gaussian ensembles -- and of the corresponding Laguerre ensembles (Wishart distributions) for various regimes of the parameter $\alpha$ (degrees of freedom $p$) -- are known to be the Tracy-Widom distributions $F_\beta$ ($\beta=1,2,4$). We establish (paying particular attention to large or small ratios $p/n$) that, with careful choices of the rescaling constants and of the expansion parameter $h$, the limit laws embed into asymptotic expansions in powers of $h$, where $h \asymp n^{-2/3}$ resp. $h \asymp (n\,\wedge\,p)^{-2/3}$. We find explicit analytic expressions of the first few expansion terms as linear combinations of higher-order derivatives of the limit law $F_\beta$ with rational polynomial coefficients. The parametrizations are fine-tuned so that the expansion coefficients in the Gaussian cases are, for given $n$, the limits $p\to\infty$ of those of the Laguerre cases. Whereas the results for $\beta=2$ are presented with proof, the discussion of the cases $\beta=1,4$ is based on some hypotheses, focusing on the algebraic aspects of actually computing the polynomial coefficients. For the purposes of illustration and validation, the various results are checked against simulation data with large sample sizes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.19448</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.19448</id><created>2024-03-28</created><updated>2025-02-03</updated><authors><author><keyname>Müller</keyname><forenames>Johannes</forenames></author><author><keyname>Çaycı</keyname><forenames>Semih</forenames></author><author><keyname>Montúfar</keyname><forenames>Guido</forenames></author></authors><title>Fisher-Rao Gradient Flows of Linear Programs and State-Action Natural   Policy Gradients</title><categories>math.OC cs.LG cs.NA cs.SY eess.SY math.NA stat.ML</categories><comments>25 pages, 4 figures, to appear at SIAM Journal on Optimization</comments><msc-class>65K05, 90C05, 90C08, 90C40, 90C53</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kakade's natural policy gradient method has been studied extensively in recent years, showing linear convergence with and without regularization. We study another natural gradient method based on the Fisher information matrix of the state-action distributions which has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher-Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher-Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher-Rao gradient flows and natural gradient flows up to an approximation error. In particular, these general results cover the case of state-action natural policy gradients. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.00820</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.00820</id><created>2024-03-31</created><updated>2025-02-03</updated><authors><author><keyname>Erdely</keyname><forenames>Arturo</forenames></author><author><keyname>Rubio-Sanchez</keyname><forenames>Manuel</forenames></author></authors><title>Visual analysis of bivariate dependence between continuous random   variables</title><categories>stat.ME</categories><comments>10 pages, 11 figures, 1 table</comments><msc-class>62P99</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scatter plots are widely recognized as fundamental tools for illustrating the relationship between two numerical variables. Despite this, based on solid theoretical foundations, scatter plots generated from pairs of continuous random variables may not serve as reliable tools for assessing dependence. Sklar's Theorem implies that scatter plots created from ranked data are preferable for such analysis as they exclusively convey information pertinent to dependence. This is in stark contrast to conventional scatter plots, which also encapsulate information about the variables' marginal distributions. Such additional information is extraneous to dependence analysis and can obscure the visual interpretation of the variables' relationship. In this article, we delve into the theoretical underpinnings of these ranked data scatter plots, hereafter referred to as rank plots. We offer insights into interpreting the information they reveal and examine their connections with various association measures, including Pearson's and Spearman's correlation coefficients, as well as Schweizer-Wolff's measure of dependence. Furthermore, we introduce a novel graphical combination for dependence analysis, termed a dplot, and demonstrate its efficacy through real data examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.14337</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.14337</id><created>2024-04-22</created><updated>2025-02-05</updated><authors><author><keyname>Sadeghi</keyname><forenames>Agathe</forenames></author><author><keyname>Feinstein</keyname><forenames>Zachary</forenames></author></authors><title>Statistical Validation of Contagion Centrality in Financial Networks</title><categories>q-fin.MF q-fin.RM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an impact centrality measure to evaluate shock propagation on financial networks capturing a notion of contagion and systemic risk contributions, permitting comparisons of these risks over time. In addition, we provide a statistical validation method when the network is estimated from data, as is done in practice. This statistical test allows us to reliably assess the computed centrality values. We validate our methodology on simulated data and conduct empirical case studies using financial data. We find that our proposed centrality measure increases significantly during times of financial distress and is able to provide insights into the (market implied) risk-levels of different firms and sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.02140</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.02140</id><created>2024-05-03</created><updated>2024-06-26</updated><authors><author><keyname>Correia</keyname><forenames>Alvaro H. C.</forenames></author><author><keyname>Massoli</keyname><forenames>Fabio Valerio</forenames></author><author><keyname>Louizos</keyname><forenames>Christos</forenames></author><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author></authors><title>An Information Theoretic Perspective on Conformal Prediction</title><categories>cs.LG cs.IT math.IT stat.ML</categories><journal-ref>Advances in Neural Information Processing Systems 37 (NeurIPS   2024)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conformal Prediction (CP) is a distribution-free uncertainty estimation framework that constructs prediction sets guaranteed to contain the true answer with a user-specified probability. Intuitively, the size of the prediction set encodes a general notion of uncertainty, with larger sets associated with higher degrees of uncertainty. In this work, we leverage information theory to connect conformal prediction to other notions of uncertainty. More precisely, we prove three different ways to upper bound the intrinsic uncertainty, as described by the conditional entropy of the target variable given the inputs, by combining CP with information theoretical inequalities. Moreover, we demonstrate two direct and useful applications of such connection between conformal prediction and information theory: (i) more principled and effective conformal training objectives that generalize previous approaches and enable end-to-end training of machine learning models from scratch, and (ii) a natural mechanism to incorporate side information into conformal prediction. We empirically validate both applications in centralized and federated learning settings, showing our theoretical results translate to lower inefficiency (average prediction set size) for popular CP methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.03096</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.03096</id><created>2024-05-05</created><updated>2025-02-03</updated><authors><author><keyname>Tam</keyname><forenames>Edric</forenames></author><author><keyname>Dunson</keyname><forenames>David B.</forenames></author><author><keyname>Duan</keyname><forenames>Leo L.</forenames></author></authors><title>Exact Sampling of Spanning Trees via Fast-forwarded Random Walks</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tree graphs are routinely used in statistics. When estimating a Bayesian model with a tree component, sampling the posterior remains a core difficulty. Existing Markov chain Monte Carlo methods tend to rely on local moves, often leading to poor mixing. A promising approach is to instead directly sample spanning trees on an auxiliary graph. Current spanning tree samplers, such as the celebrated Aldous--Broder algorithm, predominantly rely on simulating random walks that are required to visit all the nodes of the graph. Such algorithms are prone to getting stuck in certain sub-graphs. We formalize this phenomenon using the bottlenecks in the random walk's transition probability matrix. We then propose a novel fast-forwarded cover algorithm that can break free from bottlenecks. The core idea is a marginalization argument that leads to a closed-form expression which allows for fast-forwarding to the event of visiting a new node. Unlike many existing approximation algorithms, our algorithm yields exact samples. We demonstrate the enhanced efficiency of the fast-forwarded cover algorithm, and illustrate its application in fitting a Bayesian dendrogram model on a Massachusetts crimes and communities dataset. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.05238</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.05238</id><created>2024-05-08</created><updated>2025-02-04</updated><authors><author><keyname>Glazer</keyname><forenames>Amanda K.</forenames></author><author><keyname>Stark</keyname><forenames>Philip B.</forenames></author></authors><title>Fast Conservative Monte Carlo Confidence Intervals</title><categories>stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Extant "fast" algorithms for Monte Carlo confidence sets are limited to univariate shift parameters for the one-sample and two-sample problems using the sample mean as the test statistic; moreover, some do not converge reliably and most do not produce conservative confidence sets. We outline general methods for constructing confidence sets for real-valued and multidimensional parameters by inverting Monte Carlo tests using any test statistic and a broad range of randomization schemes. The method exploits two facts that, to our knowledge, had not been combined: (i) there are Monte Carlo tests that are conservative despite relying on simulation, and (ii) since the coverage probability of confidence sets depends only on the significance level of the test of the true null, every null can be tested using the same Monte Carlo sample. The Monte Carlo sample can be arbitrarily small, although the highest nontrivial attainable confidence level generally increases as the number $N$ of Monte Carlo replicates increases. We present open-source Python and R implementations of new algorithms to compute conservative confidence sets for real-valued and multidimensional parameters from Monte Carlo tests, for test statistics and randomization schemes that yield $P$-values that are monotone or weakly unimodal in the parameter, with the data and Monte Carlo sample held fixed. In this case, the new method finds conservative confidence sets for real-valued parameters in $O(n)$ time, where $n$ is the number of data. The values of some test statistics for different simulations and parameter values have a simple relationship that makes more savings possible. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.07432</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.07432</id><created>2024-05-12</created><updated>2025-02-04</updated><authors><author><keyname>Hou</keyname><forenames>Boya</forenames></author><author><keyname>Sanjari</keyname><forenames>Sina</forenames></author><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author></authors><title>Nonparametric Sparse Online Learning of the Koopman Operator</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>49 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.07482</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.07482</id><created>2024-05-13</created><updated>2025-02-03</updated><authors><author><keyname>Nguyen</keyname><forenames>Khai</forenames></author><author><keyname>Nguyen</keyname><forenames>Hai</forenames></author><author><keyname>Ho</keyname><forenames>Nhat</forenames></author></authors><title>Towards Marginal Fairness Sliced Wasserstein Barycenter</title><categories>stat.ML cs.GR cs.LG</categories><comments>Accepted to ICLR 2025, 29 pages, 15 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sliced Wasserstein barycenter (SWB) is a widely acknowledged method for efficiently generalizing the averaging operation within probability measure spaces. However, achieving marginal fairness SWB, ensuring approximately equal distances from the barycenter to marginals, remains unexplored. The uniform weighted SWB is not necessarily the optimal choice to obtain the desired marginal fairness barycenter due to the heterogeneous structure of marginals and the non-optimality of the optimization. As the first attempt to tackle the problem, we define the marginal fairness sliced Wasserstein barycenter (MFSWB) as a constrained SWB problem. Due to the computational disadvantages of the formal definition, we propose two hyperparameter-free and computationally tractable surrogate MFSWB problems that implicitly minimize the distances to marginals and encourage marginal fairness at the same time. To further improve the efficiency, we perform slicing distribution selection and obtain the third surrogate definition by introducing a new slicing distribution that focuses more on marginally unfair projecting directions. We discuss the relationship of the three proposed problems and their relationship to sliced multi-marginal Wasserstein distance. Finally, we conduct experiments on finding 3D point-clouds averaging, color harmonization, and training of sliced Wasserstein autoencoder with class-fairness representation to show the favorable performance of the proposed surrogate MFSWB problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.08203</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.08203</id><created>2024-05-13</created><updated>2025-01-27</updated><authors><author><keyname>Candellone</keyname><forenames>Elena</forenames></author><author><keyname>van Kesteren</keyname><forenames>Erik-Jan</forenames></author><author><keyname>Chelmi</keyname><forenames>Sofia</forenames></author><author><keyname>Garcia-Bernardo</keyname><forenames>Javier</forenames></author></authors><title>Community detection in bipartite signed networks is highly dependent on   parameter choice</title><categories>physics.soc-ph cs.SI stat.ME</categories><doi>10.1142/S0219525925400028</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decision-making processes often involve voting. Human interactions with exogenous entities such as legislations or products can be effectively modeled as two-mode (bipartite) signed networks-where people can either vote positively, negatively, or abstain from voting on the entities. Detecting communities in such networks could help us understand underlying properties: for example ideological camps or consumer preferences. While community detection is an established practice separately for bipartite and signed networks, it remains largely unexplored in the case of bipartite signed networks. In this paper, we systematically evaluate the efficacy of community detection methods on projected bipartite signed networks using a synthetic benchmark and real-world datasets. Our findings reveal that when no communities are present in the data, these methods often recover spurious user communities. When communities are present, the algorithms exhibit promising performance, although their performance is highly susceptible to parameter choice. This indicates that researchers using community detection methods in the context of bipartite signed networks should not take the communities found at face value: it is essential to assess the robustness of parameter choices or perform domain-specific external validation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.11751</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.11751</id><created>2024-05-19</created><updated>2025-02-04</updated><authors><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author><author><keyname>Letey</keyname><forenames>Mary I.</forenames></author><author><keyname>Zavatone-Veth</keyname><forenames>Jacob A.</forenames></author><author><keyname>Maiti</keyname><forenames>Anindita</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Asymptotic theory of in-context learning by linear attention</title><categories>stat.ML cond-mat.dis-nn cs.LG</categories><comments>17 pages (main doc), 6 figures, and supplementary information (23   pages)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transformers have a remarkable ability to learn and execute tasks based on examples provided within the input itself, without explicit prior training. It has been argued that this capability, known as in-context learning (ICL), is a cornerstone of Transformers' success, yet questions about the necessary sample complexity, pretraining task diversity, and context length for successful ICL remain unresolved. Here, we provide a precise answer to these questions in an exactly solvable model of ICL of a linear regression task by linear attention. We derive sharp asymptotics for the learning curve in a phenomenologically-rich scaling regime where the token dimension is taken to infinity; the context length and pretraining task diversity scale proportionally with the token dimension; and the number of pretraining examples scales quadratically. We demonstrate a double-descent learning curve with increasing pretraining examples, and uncover a phase transition in the model's behavior between low and high task diversity regimes: In the low diversity regime, the model tends toward memorization of training tasks, whereas in the high diversity regime, it achieves genuine in-context learning and generalization beyond the scope of pretrained tasks. These theoretical insights are empirically validated through experiments with both linear attention and full nonlinear Transformer architectures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.13690</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.13690</id><created>2024-05-22</created><updated>2025-02-05</updated><authors><author><keyname>Massa</keyname><forenames>Emanuele</forenames></author><author><keyname>Coolen</keyname><forenames>Anthony</forenames></author></authors><title>Observable asymptotics of regularized Cox regression models with   standard Gaussian designs: a statistical mechanics approach</title><categories>math.ST cond-mat.dis-nn stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic behaviour of the Regularized Maximum Partial Likelihood Estimator (RMPLE) in the proportional limit, considering an arbitrary convex regularizer and assuming that the covariates $\mathbf{X}_i\in\mathbb{R}^{p}$ follow a multivariate Gaussian law with covariance $\mathbf{I}_p/p$ for each $i=1, \dots, n$. In order to efficiently compute the estimator under investigation, we propose a modified Approximate Message Passing (AMP) algorithm, that we name COX-AMP, and compare its performance with the Coordinate-wise Descent (CD) algorithm, which is taken as reference. By means of the Replica method, we derive a set of six Replica Symmetric (RS) equations that we show to correctly describe the average behaviour of the estimators when the sample size and the number of covariates is large and commensurate. These equations cannot be solved in practice, as the data generating process (that we are trying to estimate) is not known. However, the update equations of COX-AMP suggest the construction of a local field that can in turn be used to accurately estimate all the RS order parameters of the theory \emph{solely from the data}, \emph{without} actually solving the RS equations. We emphasize that this approach can be applied when the estimator is computed via any method and is not restricted to COX-AMP. Once the RS order parameters are estimated, we have access to the amount of signal and noise in the RMPLE, but also its generalization error, directly from the data. Although we focus on the Partial Likelihood objective, we envisage broader application of the methodology proposed here, for instance to GLMs with nuisance parameters, which include some non-proportional hazards models, e.g. Accelerated Failure Time models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.15885</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.15885</id><created>2024-05-24</created><updated>2025-02-05</updated><authors><author><keyname>Zheng</keyname><forenames>Kaiwen</forenames></author><author><keyname>He</keyname><forenames>Guande</forenames></author><author><keyname>Chen</keyname><forenames>Jianfei</forenames></author><author><keyname>Bao</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>Jun</forenames></author></authors><title>Diffusion Bridge Implicit Models</title><categories>cs.LG stat.ML</categories><comments>Accepted at ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at https://github.com/thu-ml/DiffusionBridge. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.15887</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.15887</id><created>2024-05-24</created><updated>2025-02-04</updated><authors><author><keyname>Thiyageswaran</keyname><forenames>Vydhourie</forenames></author><author><keyname>McCormick</keyname><forenames>Tyler</forenames></author><author><keyname>Brennan</keyname><forenames>Jennifer</forenames></author></authors><title>Data-adaptive exposure thresholds for the Horvitz-Thompson estimator of   the Average Treatment Effect in experiments with network interference</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Randomized controlled trials often suffer from interference, a violation of the Stable Unit Treatment Values Assumption (SUTVA) in which a unit's treatment assignment affects the outcomes of its neighbors. This interference causes bias in naive estimators of the average treatment effect (ATE). A popular method to achieve unbiasedness is to pair the Horvitz-Thompson estimator of the ATE with a known exposure mapping: a function that identifies which units in a given randomization are not subject to interference. For example, an exposure mapping can specify that any unit with at least $h$-fraction of its neighbors having the same treatment status does not experience interference. However, this threshold $h$ is difficult to elicit from domain experts, and a misspecified threshold can induce bias. In this work, we propose a data-adaptive method to select the "$h$"-fraction threshold that minimizes the mean squared error of the Hortvitz-Thompson estimator. Our method estimates the bias and variance of the Horvitz-Thompson estimator under different thresholds using a linear dose-response model of the potential outcomes. We present simulations illustrating that our method improves upon non-adaptive choices of the threshold. We further illustrate the performance of our estimator by running experiments on a publicly-available Amazon product similarity graph. Furthermore, we demonstrate that our method is robust to deviations from the linear potential outcomes model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.16351</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.16351</id><created>2024-05-25</created><updated>2025-02-04</updated><authors><author><keyname>Malik</keyname><forenames>Zachariah</forenames></author><author><keyname>Huang</keyname><forenames>Yu-Jui</forenames></author></authors><title>A Differential Equation Approach for Wasserstein GANs and Beyond</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new theoretical lens to view Wasserstein generative adversarial networks (WGANs). To minimize the Wasserstein-1 distance between the true data distribution and our estimate of it, we derive a distribution-dependent ordinary differential equation (ODE) which represents the gradient flow of the Wasserstein-1 loss, and show that a forward Euler discretization of the ODE converges. This inspires a new class of generative models that naturally integrates persistent training (which we call W1-FE). When persistent training is turned off, we prove that W1-FE reduces to WGAN. When we intensify persistent training, W1-FE is shown to outperform WGAN in training experiments from low to high dimensions, in terms of both convergence speed and training results. Intriguingly, one can reap the benefits only when persistent training is carefully integrated through our ODE perspective. As demonstrated numerically, a naive inclusion of persistent training in WGAN (without relying on our ODE framework) can significantly worsen training results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.17508</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.17508</id><created>2024-05-26</created><updated>2025-02-03</updated><authors><author><keyname>Qian</keyname><forenames>Linglong</forenames></author><author><keyname>Yang</keyname><forenames>Yiyuan</forenames></author><author><keyname>Du</keyname><forenames>Wenjie</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Dobsoni</keyname><forenames>Richard</forenames></author><author><keyname>Ibrahim</keyname><forenames>Zina</forenames></author></authors><title>Beyond Random Missingness: Clinically Rethinking for Healthcare Time   Series Imputation</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study investigates the impact of masking strategies on time series imputation models in healthcare settings. While current approaches predominantly rely on random masking for model evaluation, this practice fails to capture the structured nature of missing patterns in clinical data. Using the PhysioNet Challenge 2012 dataset, we analyse how different masking implementations affect both imputation accuracy and downstream clinical predictions across eleven imputation methods. Our results demonstrate that masking choices significantly influence model performance, while recurrent architectures show more consistent performance across strategies. Analysis of downstream mortality prediction reveals that imputation accuracy doesn't necessarily translate to optimal clinical prediction capabilities. Our findings emphasise the need for clinically-informed masking strategies that better reflect real-world missing patterns in healthcare data, suggesting current evaluation frameworks may need reconsideration for reliable clinical deployment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.19466</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.19466</id><created>2024-05-29</created><updated>2025-02-05</updated><authors><author><keyname>Cai</keyname><forenames>Tiffany Tianhui</forenames></author><author><keyname>Namkoong</keyname><forenames>Hongseok</forenames></author><author><keyname>Russo</keyname><forenames>Daniel</forenames></author><author><keyname>Zhang</keyname><forenames>Kelly W</forenames></author></authors><title>Active Exploration via Autoregressive Generation of Missing Data</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We pose uncertainty quantification and exploration in online decision-making as a problem of training and generation from an autoregressive sequence model, an area experiencing rapid innovation. Our approach rests on viewing uncertainty as arising from missing future outcomes that would be revealed through appropriate action choices, rather than from unobservable latent parameters of the environment. This reformulation aligns naturally with modern machine learning capabilities: we can i) train generative models through next-outcome prediction rather than fit explicit priors, ii) assess uncertainty through autoregressive generation rather than parameter sampling, and iii) adapt to new information through in-context learning rather than explicit posterior updating. To showcase these ideas, we formulate a challenging meta-bandit problem where effective performance requires leveraging unstructured prior information (like text features) while exploring judiciously to resolve key remaining uncertainties. We validate our approach through both theory and experiments. Our theory establishes a reduction, showing success at offline next-outcome prediction translates to reliable online uncertainty quantification and decision-making, even with strategically collected data. Semi-synthetic experiments show our insights bear out in a news-article recommendation task, where article text can be leveraged to minimize exploration. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.01793</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.01793</id><created>2024-06-03</created><updated>2025-02-03</updated><authors><author><keyname>Schlaginhaufen</keyname><forenames>Andreas</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author></authors><title>Towards the Transferability of Rewards Recovered via Regularized Inverse   Reinforcement Learning</title><categories>cs.LG cs.AI stat.ML</categories><comments>The Thirty-Eighth Annual Conference on Neural Information Processing   Systems (NeurIPS 2024)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inverse reinforcement learning (IRL) aims to infer a reward from expert demonstrations, motivated by the idea that the reward, rather than the policy, is the most succinct and transferable description of a task [Ng et al., 2000]. However, the reward corresponding to an optimal policy is not unique, making it unclear if an IRL-learned reward is transferable to new transition laws in the sense that its optimal policy aligns with the optimal policy corresponding to the expert's true reward. Past work has addressed this problem only under the assumption of full access to the expert's policy, guaranteeing transferability when learning from two experts with the same reward but different transition laws that satisfy a specific rank condition [Rolland et al., 2022]. In this work, we show that the conditions developed under full access to the expert's policy cannot guarantee transferability in the more practical scenario where we have access only to demonstrations of the expert. Instead of a binary rank condition, we propose principal angles as a more refined measure of similarity and dissimilarity between transition laws. Based on this, we then establish two key results: 1) a sufficient condition for transferability to any transition laws when learning from at least two experts with sufficiently different transition laws, and 2) a sufficient condition for transferability to local changes in the transition law when learning from a single expert. Furthermore, we also provide a probably approximately correct (PAC) algorithm and an end-to-end analysis for learning transferable rewards from demonstrations of multiple experts. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.03696</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.03696</id><created>2024-06-05</created><updated>2025-02-03</updated><authors><author><keyname>Lok</keyname><forenames>Jackie</forenames></author><author><keyname>Sonthalia</keyname><forenames>Rishi</forenames></author><author><keyname>Rebrova</keyname><forenames>Elizaveta</forenames></author></authors><title>Error dynamics of mini-batch gradient descent with random reshuffling   for least squares regression</title><categories>stat.ML cs.LG math.OC</categories><comments>33 pages. Accepted at ALT 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the discrete dynamics of mini-batch gradient descent with random reshuffling for least squares regression. We show that the training and generalization errors depend on a sample cross-covariance matrix $Z$ between the original features $X$ and a set of new features $\widetilde{X}$ in which each feature is modified by the mini-batches that appear before it during the learning process in an averaged way. Using this representation, we establish that the dynamics of mini-batch and full-batch gradient descent agree up to leading order with respect to the step size using the linear scaling rule. However, mini-batch gradient descent with random reshuffling exhibits a subtle dependence on the step size that a gradient flow analysis cannot detect, such as converging to a limit that depends on the step size. By comparing $Z$, a non-commutative polynomial of random matrices, with the sample covariance matrix of $X$ asymptotically, we demonstrate that batching affects the dynamics by resulting in a form of shrinkage on the spectrum. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.05242</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.05242</id><created>2024-06-07</created><updated>2025-02-05</updated><authors><author><keyname>Yuan</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Guanyang</forenames></author></authors><title>Markov chain Monte Carlo without evaluating the target: an auxiliary   variable approach</title><categories>stat.CO stat.ME stat.ML</categories><comments>62 pages, 13 figures, 3 tables. Add additional illustrations and   experiments. Codes available at https://github.com/ywwes26/MCMC-Auxiliary</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sampling tasks, it is common for target distributions to be known up to a normalizing constant. However, in many situations, even evaluating the unnormalized distribution can be costly or infeasible. This issue arises in scenarios such as sampling from the Bayesian posterior for tall datasets and the 'doubly-intractable' distributions. In this paper, we begin by observing that seemingly different Markov chain Monte Carlo (MCMC) algorithms, such as the exchange algorithm, PoissonMH, and TunaMH, can be unified under a simple common procedure. We then extend this procedure into a novel framework that allows the use of auxiliary variables in both the proposal and the acceptance-rejection step. Several new MCMC algorithms emerge from this framework that utilize estimated gradients to guide the proposal moves. They have demonstrated significantly better performance than existing methods on both synthetic and real datasets. Additionally, we develop the theory of the new framework and apply it to existing algorithms to simplify and extend their results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.05911</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.05911</id><created>2024-06-09</created><updated>2025-02-03</updated><authors><author><keyname>Prasadan</keyname><forenames>Akshay</forenames></author><author><keyname>Neykov</keyname><forenames>Matey</forenames></author></authors><title>Some facts about the optimality of the LSE in the Gaussian sequence   model with convex constraint</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider a convex constrained Gaussian sequence model and characterize necessary and sufficient conditions for the least squares estimator (LSE) to be minimax optimal. For a closed convex set $K\subset \mathbb{R}^n$ we observe $Y=\mu+\xi$ for $\xi\sim \mathcal{N}(0,\sigma^2\mathbb{I}_n)$ and $\mu\in K$ and aim to estimate $\mu$. We characterize the worst case risk of the LSE in multiple ways by analyzing the behavior of the local Gaussian width on $K$. We demonstrate that optimality is equivalent to a Lipschitz property of the local Gaussian width mapping. We also provide theoretical algorithms that search for the worst case risk. We then provide examples showing optimality or suboptimality of the LSE on various sets, including $\ell_p$ balls for $p\in[1,2]$, pyramids, solids of revolution, and multivariate isotonic regression, among others. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.09521</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.09521</id><created>2024-06-13</created><updated>2025-02-04</updated><authors><author><keyname>Ritzwoller</keyname><forenames>David M.</forenames></author><author><keyname>Romano</keyname><forenames>Joseph P.</forenames></author><author><keyname>Shaikh</keyname><forenames>Azeem M.</forenames></author></authors><title>Randomization Inference: Theory and Applications</title><categories>econ.EM stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We review approaches to statistical inference based on randomization. Permutation tests are treated as an important special case. Under a certain group invariance property, referred to as the ``randomization hypothesis,'' randomization tests achieve exact control of the Type I error rate in finite samples. Although this unequivocal precision is very appealing, the range of problems that satisfy the randomization hypothesis is somewhat limited. We show that randomization tests are often asymptotically, or approximately, valid and efficient in settings that deviate from the conditions required for finite-sample error control. When randomization tests fail to offer even asymptotic Type 1 error control, their asymptotic validity may be restored by constructing an asymptotically pivotal test statistic. Randomization tests can then provide exact error control for tests of highly structured hypotheses with good performance in a wider class of problems. We give a detailed overview of several prominent applications of randomization tests, including two-sample permutation tests, regression, and conformal inference. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.14026</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.14026</id><created>2024-06-20</created><updated>2025-02-03</updated><authors><author><keyname>Jin</keyname><forenames>Xisen</forenames></author><author><keyname>Ren</keyname><forenames>Xiang</forenames></author></authors><title>Demystifying Language Model Forgetting with Low-rank Example   Associations</title><categories>cs.LG cs.CL stat.ML</categories><comments>8 pages; preprint</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Large Language models (LLMs) suffer from forgetting of upstream data when fine-tuned. Despite efforts on mitigating forgetting, few have investigated whether, and how forgotten upstream examples are dependent on newly learned tasks. Insights on such dependencies enable efficient and targeted mitigation of forgetting. In this paper, we empirically analyze forgetting that occurs in $N$ upstream examples of language modeling or instruction-tuning after fine-tuning LLMs on one of $M$ new tasks, visualized in $M\times N$ matrices. We show that the matrices are often well-approximated with low-rank matrices, indicating the dominance of simple associations between the learned tasks and forgotten upstream examples. Leveraging the analysis, we predict forgetting of upstream examples when fine-tuning on unseen tasks with matrix completion over the empirical associations. This enables fast identification of most forgotten examples without expensive inference on the entire upstream data. The approach, despite simplicity, outperforms prior approaches that learn semantic relationships of learned tasks and upstream examples with LMs for predicting forgetting. We demonstrate the practical utility of our analysis by showing statistically significantly reduced forgetting as we upweight predicted examples for replay at fine-tuning. Project page: https://inklab.usc.edu/lm-forgetting-prediction/ </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.02700</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.02700</id><created>2024-07-02</created><updated>2025-02-04</updated><authors><author><keyname>Rojas</keyname><forenames>Helder</forenames></author><author><keyname>Rojas</keyname><forenames>Nilton</forenames></author><author><keyname>B.</keyname><forenames>Espinoza J.</forenames></author><author><keyname>Huamanchumo</keyname><forenames>Luis</forenames></author></authors><title>A simple algorithm for output range analysis for deep neural networks</title><categories>cs.LG math.PR stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a novel approach for the output range estimation problem in Deep Neural Networks (DNNs) by integrating a Simulated Annealing (SA) algorithm tailored to operate within constrained domains and ensure convergence towards global optima. The method effectively addresses the challenges posed by the lack of local geometric information and the high non-linearity inherent to DNNs, making it applicable to a wide variety of architectures, with a special focus on Residual Networks (ResNets) due to their practical importance. Unlike existing methods, our algorithm imposes minimal assumptions on the internal architecture of neural networks, thereby extending its usability to complex models. Theoretical analysis guarantees convergence, while extensive empirical evaluations-including optimization tests involving functions with multiple local minima-demonstrate the robustness of our algorithm in navigating non-convex response surfaces. The experimental results highlight the algorithm's efficiency in accurately estimating DNN output ranges, even in scenarios characterized by high non-linearity and complex constraints. For reproducibility, Python codes and datasets used in the experiments are publicly available through our GitHub repository. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.03389</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.03389</id><created>2024-07-03</created><updated>2025-02-04</updated><authors><author><keyname>Costa</keyname><forenames>Efthymios</forenames></author><author><keyname>Papatsouma</keyname><forenames>Ioanna</forenames></author><author><keyname>Markos</keyname><forenames>Angelos</forenames></author></authors><title>A Deterministic Information Bottleneck Method for Clustering Mixed-Type   Data</title><categories>stat.ME cs.LG stat.ML</categories><comments>30 pages</comments><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we present an information-theoretic method for clustering mixed-type data, that is, data consisting of both continuous and categorical variables. The proposed approach is built on the deterministic variant of the Information Bottleneck algorithm, designed to optimally compress data while preserving its relevant structural information. We evaluate the performance of our method against four well-established clustering techniques for mixed-type data -- KAMILA, K-Prototypes, Factor Analysis for Mixed Data with K-Means, and Partitioning Around Medoids using Gower's dissimilarity -- using both simulated and real-world datasets. The results highlight that the proposed approach offers a competitive alternative to traditional clustering techniques, particularly under specific conditions where heterogeneity in data poses significant challenges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.15532</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.15532</id><created>2024-07-22</created><updated>2025-02-03</updated><authors><author><keyname>Korangi</keyname><forenames>Kamesh</forenames></author><author><keyname>Mues</keyname><forenames>Christophe</forenames></author><author><keyname>Bravo</keyname><forenames>Cristián</forenames></author></authors><title>Large-scale Time-Varying Portfolio Optimisation using Graph Attention   Networks</title><categories>q-fin.PM cs.AI cs.SI q-fin.RM stat.ML</categories><comments>39 pages, 10 figures, v2</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Apart from assessing individual asset performance, investors in financial markets also need to consider how a set of firms performs collectively as a portfolio. Whereas traditional Markowitz-based mean-variance portfolios are widespread, network-based optimisation techniques offer a more flexible tool to capture complex interdependencies between asset values. However, most of the existing studies do not contain firms at risk of default and remove any firms that drop off indices over a certain time. This is the first study to also incorporate such firms in portfolio optimisation on a large scale. We propose and empirically test a novel method that leverages Graph Attention networks (GATs), a subclass of Graph Neural Networks (GNNs). GNNs, as deep learning-based models, can exploit network data to uncover nonlinear relationships. Their ability to handle high-dimensional data and accommodate customised layers for specific purposes makes them appealing for large-scale problems such as mid- and small-cap portfolio optimisation. This study utilises 30 years of data on mid-cap firms, creating graphs of firms using distance correlation and the Triangulated Maximally Filtered Graph approach. These graphs are the inputs to a GAT model incorporating weight and allocation constraints and a loss function derived from the Sharpe ratio, thus focusing on maximising portfolio risk-adjusted returns. This new model is benchmarked against a network characteristic-based portfolio, a mean variance-based portfolio, and an equal-weighted portfolio. The results show that the portfolio produced by the GAT-based model outperforms all benchmarks and is consistently superior to other strategies over a long period, while also being informative of market dynamics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.16134</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.16134</id><created>2024-07-22</created><updated>2025-02-04</updated><authors><author><keyname>Fu</keyname><forenames>Hengyu</forenames></author><author><keyname>Dou</keyname><forenames>Zehao</forenames></author><author><keyname>Guo</keyname><forenames>Jiawei</forenames></author><author><keyname>Wang</keyname><forenames>Mengdi</forenames></author><author><keyname>Chen</keyname><forenames>Minshuo</forenames></author></authors><title>Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory   for Gaussian Process Data</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>56 pages, 13 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation. Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies. These dependencies represent the underlying dynamic model and are critical to validate the generated data. In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies. Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns. We highlight how the spatial-temporal dependencies are captured and affect learning efficiency. Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm. We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.02326</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.02326</id><created>2024-08-05</created><updated>2025-02-04</updated><authors><author><keyname>Aguilera</keyname><forenames>Miguel</forenames></author><author><keyname>Morales</keyname><forenames>Pablo A.</forenames></author><author><keyname>Rosas</keyname><forenames>Fernando E.</forenames></author><author><keyname>Shimazaki</keyname><forenames>Hideaki</forenames></author></authors><title>Explosive neural networks via higher-order interactions in curved   statistical manifolds</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT nlin.AO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order interactions underlie complex phenomena in systems such as biological and artificial neural networks, but their study is challenging due to the scarcity of tractable models. By leveraging a generalisation of the maximum entropy principle, here we introduce curved neural networks as a class of prototypical models with a limited number of parameters that are particularly well-suited for studying higher-order phenomena. Through exact mean-field descriptions, we show that these curved neural networks implement a self-regulating annealing process that can accelerate memory retrieval, leading to explosive order-disorder phase transitions with multi-stability and hysteresis effects. Moreover, by analytically exploring their memory-retrieval capacity using the replica trick near ferromagnetic and spin-glass phase boundaries, we demonstrate that these networks can enhance memory capacity and robustness of retrieval over classical associative-memory networks. Overall, the proposed framework provides parsimonious models amenable to analytical study, revealing novel higher-order phenomena in complex networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.07463</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.07463</id><created>2024-08-14</created><updated>2025-02-04</updated><authors><author><keyname>Costa</keyname><forenames>Efthymios</forenames></author><author><keyname>Papatsouma</keyname><forenames>Ioanna</forenames></author></authors><title>A novel framework for quantifying nominal outlyingness</title><categories>stat.ME</categories><comments>24 pages</comments><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Outlier detection is an important data mining tool that becomes particularly challenging when dealing with nominal data. First and foremost, flagging observations as outlying requires a well-defined notion of nominal outlyingness. This paper presents a definition of nominal outlyingness and introduces a general framework for quantifying outlyingness of nominal data. The proposed framework makes use of ideas from the association rule mining literature and can be used for calculating scores that indicate how outlying a nominal observation is. Methods for determining the involved hyperparameter values are presented and the concepts of variable contributions and outlyingness depth are introduced, in an attempt to enhance interpretability of the results. The proposed framework is evaluated on both synthetic and real-world data sets, demonstrating comparable performance to state-of-the-art frequent pattern mining algorithms and even outperforming them in certain cases. The ideas presented can serve as a tool for assessing the degree to which an observation differs from the rest of the data, under the assumption of sequences of nominal levels having been generated from a Multinomial distribution with varying event probabilities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.08062</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.08062</id><created>2024-08-15</created><updated>2025-02-04</updated><authors><author><keyname>Champneys</keyname><forenames>Max D.</forenames></author><author><keyname>Rogers</keyname><forenames>Timothy J.</forenames></author></authors><title>BINDy -- Bayesian identification of nonlinear dynamics with   reversible-jump Markov-chain Monte-Carlo</title><categories>stat.ML cs.LG math.DS</categories><doi>10.1098/rspa.2024.0620</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Model parsimony is an important \emph{cognitive bias} in data-driven modelling that aids interpretability and helps to prevent over-fitting. Sparse identification of nonlinear dynamics (SINDy) methods are able to learn sparse representations of complex dynamics directly from data, given a basis of library functions. In this work, a novel Bayesian treatment of dictionary learning system identification, as an alternative to SINDy, is envisaged. The proposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is distinct from previous approaches in that it targets the full joint posterior distribution over both the terms in the library and their parameterisation in the model. This formulation confers the advantage that an arbitrary prior may be placed over the model structure to produce models that are sparse in the model space rather than in parameter space. Because this posterior is defined over parameter vectors that can change in dimension, the inference cannot be performed by standard techniques. Instead, a Gibbs sampler based on reversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare favourably to ensemble SINDy in three benchmark case-studies. In particular, it is seen that the proposed method is better able to assign high probability to correct model terms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.12482</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.12482</id><created>2024-08-22</created><updated>2025-02-04</updated><authors><author><keyname>Rodríguez</keyname><forenames>Ignacio Echave-Sustaeta</forenames></author><author><keyname>Röttger</keyname><forenames>Frank</forenames></author></authors><title>Latent Gaussian and H\"usler--Reiss Graphical Models with Golazo Penalty</title><categories>stat.ME math.ST stat.TH</categories><comments>20 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of latent variables in practical problems is common, for example when some variables are difficult or expensive to measure, or simply unknown. When latent variables are unaccounted for, structure learning for Gaussian graphical models can be blurred by additional correlation between the observed variables that is incurred by the latent variables. A standard approach for this problem is a latent version of the graphical lasso that splits the inverse covariance matrix into a sparse and a low-rank part that are penalized separately. This approach has recently been extended successfully to H\"usler--Reiss graphical models, which can be considered as an analogue of Gaussian graphical models in extreme value statistics. In this paper we propose a generalization of structure learning for Gaussian and H\"usler--Reiss graphical models via the flexible Golazo penalty. This allows us to introduce latent versions of for example the adaptive lasso, positive dependence constraints or predetermined sparsity patterns, and combinations of those. We develop algorithms for both latent graphical models with the Golazo penalty and demonstrate them on simulated and real data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.12830</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.12830</id><created>2024-08-23</created><updated>2025-02-05</updated><authors><author><keyname>Luo</keyname><forenames>Wang</forenames></author><author><keyname>Li</keyname><forenames>Haoran</forenames></author><author><keyname>Zhang</keyname><forenames>Zicheng</forenames></author><author><keyname>Han</keyname><forenames>Congying</forenames></author><author><keyname>Lv</keyname><forenames>Jiayu</forenames></author><author><keyname>Guo</keyname><forenames>Tiande</forenames></author></authors><title>SAMBO-RL: Shifts-aware Model-based Offline Reinforcement Learning</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based offline reinforcement learning trains policies using pre-collected datasets and learned environment models, eliminating the need for direct real-world environment interaction. However, this paradigm is inherently challenged by distribution shift (DS). Existing methods address this issue by leveraging off-policy mechanisms and estimating model uncertainty, but they often result in inconsistent objectives and lack a unified theoretical foundation. This paper offers a comprehensive analysis that disentangles the problem into two fundamental components: model bias and policy shift. Our theoretical and empirical investigations reveal how these factors distort value estimation and restrict policy optimization. To tackle these challenges, we derive a novel Shifts-aware Reward (SAR) through a unified probabilistic inference framework, which modifies the vanilla reward to refine value learning and facilitate policy training. Building on this, we introduce Shifts-aware Model-based Offline Reinforcement Learning (SAMBO-RL), a practical framework that efficiently trains classifiers to approximate SAR for policy optimization. Empirical experiments show that SAR effectively mitigates DS, and SAMBO-RL achieves superior or comparable performance across various benchmarks, underscoring its effectiveness and validating our theoretical analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.03845</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.03845</id><created>2024-09-05</created><updated>2025-02-05</updated><authors><author><keyname>Cheng</keyname><forenames>Sheng</forenames></author><author><keyname>Kong</keyname><forenames>Deqian</forenames></author><author><keyname>Xie</keyname><forenames>Jianwen</forenames></author><author><keyname>Lee</keyname><forenames>Kookjin</forenames></author><author><keyname>Wu</keyname><forenames>Ying Nian</forenames></author><author><keyname>Yang</keyname><forenames>Yezhou</forenames></author></authors><title>Latent Space Energy-based Neural ODEs</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces novel deep dynamical models designed to represent continuous-time sequences. Our approach employs a neural emission model to generate each data point in the time series through a non-linear transformation of a latent state vector. The evolution of these latent states is implicitly defined by a neural ordinary differential equation (ODE), with the initial state drawn from an informative prior distribution parameterized by an Energy-based model (EBM). This framework is extended to disentangle dynamic states from underlying static factors of variation, represented as time-invariant variables in the latent space. We train the model using maximum likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end manner. Experimental results on oscillating systems, videos and real-world state sequences (MuJoCo) demonstrate that our model with the learnable energy-based prior outperforms existing counterparts, and can generalize to new dynamic parameterization, enabling long-horizon predictions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.14557</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.14557</id><created>2024-09-22</created><updated>2025-02-05</updated><authors><author><keyname>Wan</keyname><forenames>Jia</forenames></author><author><keyname>Sinclair</keyname><forenames>Sean R.</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Exploiting Exogenous Structure for Sample-Efficient Reinforcement   Learning</title><categories>stat.ML cs.LG math.OC</categories><comments>43 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Exo-MDPs, a structured class of Markov Decision Processes (MDPs) where the state space is partitioned into exogenous and endogenous components. Exogenous states evolve stochastically, independent of the agent's actions, while endogenous states evolve deterministically based on both state components and actions. Exo-MDPs are useful for applications including inventory control, portfolio management, and ride-sharing. Our first result is structural, establishing a representational equivalence between the classes of discrete MDPs, Exo-MDPs, and discrete linear mixture MDPs. Specifically, any discrete MDP can be represented as an Exo-MDP, and the transition and reward dynamics can be written as linear functions of the exogenous state distribution, showing that Exo-MDPs are instances of linear mixture MDPs. For unobserved exogenous states, we prove a regret upper bound of $O(H^{3/2}d\sqrt{K})$ over $K$ trajectories of horizon $H$, with $d$ as the size of the exogenous state space, and establish nearly-matching lower bounds. Our findings demonstrate how Exo-MDPs decouple sample complexity from action and endogenous state sizes, and we validate our theoretical insights with experiments on inventory control. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.19546</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.19546</id><created>2024-09-29</created><updated>2025-02-03</updated><authors><author><keyname>Blaser</keyname><forenames>Ethan</forenames></author><author><keyname>Zhang</keyname><forenames>Shangtong</forenames></author></authors><title>Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic   Approximations with Markovian Noise</title><categories>cs.LG cs.AI math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Stochastic approximation is an important class of algorithms, and a large body of previous analysis focuses on stochastic approximations driven by contractive operators, which is not applicable in some important reinforcement learning settings. This work instead investigates stochastic approximations with merely nonexpansive operators. In particular, we study nonexpansive stochastic approximations with Markovian noise, providing both asymptotic and finite sample analysis. Key to our analysis are a few novel bounds of noise terms resulting from the Poisson equation. As an application, we prove, for the first time, that the classical tabular average reward temporal difference learning converges to a sample path dependent fixed point. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.12538</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.12538</id><created>2024-10-16</created><updated>2025-02-03</updated><authors><author><keyname>Rahmani</keyname><forenames>Saeed</forenames></author><author><keyname>Xu</keyname><forenames>Zhenlin</forenames></author><author><keyname>Calvert</keyname><forenames>Simeon C.</forenames></author><author><keyname>van Arem</keyname><forenames>Bart</forenames></author></authors><title>Automated Vehicles at Unsignalized Intersections: Safety and Efficiency   Implications of Mixed-Human-Automated Traffic</title><categories>cs.RO cs.AI stat.AP</categories><comments>This work has been submitted to Transportation Research Record for   potential publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of automated vehicles (AVs) into transportation systems presents an unprecedented opportunity to enhance road safety and efficiency. However, understanding the interactions between AVs and human-driven vehicles (HVs) at intersections remains an open research question. This study aims to bridge this gap by examining behavioral differences and adaptations of AVs and HVs at unsignalized intersections by utilizing two large-scale AV datasets from Waymo and Lyft. By using a systematic methodology, the research identifies and analyzes merging and crossing conflicts by calculating key safety and efficiency metrics, including time to collision (TTC), post-encroachment time (PET), maximum required deceleration (MRD), time advantage (TA), and speed and acceleration profiles. The findings reveal a paradox in mixed traffic flow: while AVs maintain larger safety margins, their conservative behavior can lead to unexpected situations for human drivers, potentially causing unsafe conditions. From a performance point of view, human drivers exhibit more consistent behavior when interacting with AVs versus other HVs, suggesting AVs may contribute to harmonizing traffic flow patterns. Moreover, notable differences were observed between Waymo and Lyft vehicles, which highlights the importance of considering manufacturer-specific AV behaviors in traffic modeling and management strategies for the safe integration of AVs. The processed dataset utilized in this study is openly published to foster the research on AV-HV interactions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.18959</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.18959</id><created>2024-10-24</created><updated>2025-02-04</updated><authors><author><keyname>Williams</keyname><forenames>Andrew Robert</forenames></author><author><keyname>Ashok</keyname><forenames>Arjun</forenames></author><author><keyname>Marcotte</keyname><forenames>Étienne</forenames></author><author><keyname>Zantedeschi</keyname><forenames>Valentina</forenames></author><author><keyname>Subramanian</keyname><forenames>Jithendaraa</forenames></author><author><keyname>Riachi</keyname><forenames>Roland</forenames></author><author><keyname>Requeima</keyname><forenames>James</forenames></author><author><keyname>Lacoste</keyname><forenames>Alexandre</forenames></author><author><keyname>Rish</keyname><forenames>Irina</forenames></author><author><keyname>Chapados</keyname><forenames>Nicolas</forenames></author><author><keyname>Drouin</keyname><forenames>Alexandre</forenames></author></authors><title>Context is Key: A Benchmark for Forecasting with Essential Textual   Information</title><categories>cs.LG cs.AI stat.ML</categories><comments>Preprint; under review. First two authors contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Forecasting is a critical task in decision-making across numerous domains. While historical numerical data provide a start, they fail to convey the complete context for reliable and accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge and constraints, which can efficiently be communicated through natural language. However, in spite of recent progress with LLM-based forecasters, their ability to effectively integrate this textual information remains an open question. To address this, we introduce "Context is Key" (CiK), a time-series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities; crucially, every task in CiK requires understanding textual context to be solved successfully. We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. This benchmark aims to advance multimodal forecasting by promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://anon-forecast.github.io/benchmark_report_dev/. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.21154</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.21154</id><created>2024-10-28</created><updated>2025-02-04</updated><authors><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Pu</keyname><forenames>Yuan</forenames></author><author><keyname>Kawamura</keyname><forenames>Yuki</forenames></author><author><keyname>Loza</keyname><forenames>Andrew</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Shung</keyname><forenames>Dennis L.</forenames></author><author><keyname>Tong</keyname><forenames>Alexander</forenames></author></authors><title>Trajectory Flow Matching with Applications to Clinical Time Series   Modeling</title><categories>cs.LG cs.AI stat.ML</categories><comments>NeurIPS 2024 Spotlight</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling stochastic and irregularly sampled time series is a challenging problem found in a wide range of applications, especially in medicine. Neural stochastic differential equations (Neural SDEs) are an attractive modeling technique for this problem, which parameterize the drift and diffusion terms of an SDE with neural networks. However, current algorithms for training Neural SDEs require backpropagation through the SDE dynamics, greatly limiting their scalability and stability. To address this, we propose Trajectory Flow Matching (TFM), which trains a Neural SDE in a simulation-free manner, bypassing backpropagation through the dynamics. TFM leverages the flow matching technique from generative modeling to model time series. In this work we first establish necessary conditions for TFM to learn time series data. Next, we present a reparameterization trick which improves training stability. Finally, we adapt TFM to the clinical time series setting, demonstrating improved performance on three clinical time series datasets both in terms of absolute performance and uncertainty prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.22333</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.22333</id><created>2024-10-29</created><updated>2025-02-05</updated><authors><author><keyname>Koch</keyname><forenames>Lukas</forenames></author></authors><title>Hypothesis tests and model parameter estimation on data sets with   missing correlation information</title><categories>stat.ME hep-ph stat.AP</categories><comments>19 pages, 10 figures; follow-up of arxiv.org:2102.06172; Fixed some   typos, made tables prettier, added funding</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ideally, all analyses of normally distributed data should include the full covariance information between all data points. In practice, the full covariance matrix between all data points is not always available. Either because a result was published without a covariance matrix, or because one tries to combine multiple results from separate publications. For simple hypothesis tests, it is possible to define robust test statistics that will behave conservatively in the presence on unknown correlations. For model parameter fits, one can inflate the variance by a factor to ensure that things remain conservative at least up to a chosen confidence level. This paper describes a class of robust test statistics for simple hypothesis tests, as well as an algorithm to determine the necessary inflation factor for model parameter fits and Goodness of Fit tests and composite hypothesis tests. It then presents some example applications of the methods to real neutrino interaction data and model comparisons. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.01694</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.01694</id><created>2024-11-03</created><updated>2025-02-03</updated><authors><author><keyname>Bayisa</keyname><forenames>Fekadu L.</forenames></author><author><keyname>Seals</keyname><forenames>Christopher L.</forenames></author><author><keyname>Leeper</keyname><forenames>Hannah J.</forenames></author><author><keyname>Steury</keyname><forenames>Todd D.</forenames></author><author><keyname>Ceyhan</keyname><forenames>Elvan</forenames></author></authors><title>Modeling Home Range and Intra-Specific Spatial Interaction in Wild   Animal Populations</title><categories>stat.AP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions among individuals from the same-species of wild animals are an important component of population dynamics. An interaction can be either static (based on overlap of space use) or dynamic (based on movement). The goal of this work is to determine the level of static interactions between individuals from the same-species of wild animals using 95\% and 50\% home ranges, as well as to model their movement interactions, which could include attraction, avoidance (or repulsion), or lack of interaction, in order to gain new insights and improve our understanding of ecological processes. Home range estimation methods (minimum convex polygon, kernel density estimator, and autocorrelated kernel density estimator), inhomogeneous multitype (or cross-type) summary statistics, and envelope testing methods (pointwise and global envelope tests) were proposed to study the nature of the same-species wild-animal spatial interactions. This study provides comprehensive, self-contained methodological details for investigating spatial interactions between individuals of the same species in wildlife populations. Using GPS collar data, we applied the methods to quantify both static and dynamic interactions between black bears in southern Alabama, USA. In general, our findings suggest that the black bears in our dataset showed no significant preference to live together or apart, i.e., there was no significant deviation from independence toward association or avoidance (i.e., segregation) between the bears. This can be loosely interpreted to mean that a black bear is generally indifferent to the presence of other black bears living or wandering nearby. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.06568</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.06568</id><created>2024-11-10</created><updated>2025-02-04</updated><authors><author><keyname>Alfano</keyname><forenames>Carlo</forenames></author><author><keyname>Sapora</keyname><forenames>Silvia</forenames></author><author><keyname>Foerster</keyname><forenames>Jakob Nicolaus</forenames></author><author><keyname>Rebeschini</keyname><forenames>Patrick</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Meta-Learning Objectives for Preference Optimization</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluating preference optimization (PO) algorithms on LLM alignment is a challenging task that presents prohibitive costs, noise, and several variables like model size and hyper-parameters. In this work, we show that it is possible to gain insights on the efficacy of PO algorithm on much simpler benchmarks. We design a diagnostic suite of MuJoCo tasks and datasets, which we use to systematically evaluate PO algorithms, establishing a more controlled and cheaper benchmark. We then propose a novel family of PO algorithms based on mirror descent, which we call Mirror Preference Optimization (MPO). Through evolutionary strategies, we search this class to discover algorithms specialized to specific properties of preference datasets, such as mixed-quality or noisy data. We demonstrate that our discovered PO algorithms outperform all known algorithms in the targeted MuJoCo settings. Finally, based on the insights gained from our MuJoCo experiments, we design a novel PO algorithm that significantly outperforms existing baselines in an LLM alignment task. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.16303</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.16303</id><created>2024-11-25</created><updated>2025-02-05</updated><authors><author><keyname>Zeng</keyname><forenames>Dun</forenames></author><author><keyname>Wu</keyname><forenames>Zheshun</forenames></author><author><keyname>Liu</keyname><forenames>Shiyu</forenames></author><author><keyname>Pan</keyname><forenames>Yu</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoying</forenames></author><author><keyname>Xu</keyname><forenames>Zenglin</forenames></author></authors><title>Understanding Generalization of Federated Learning: the Trade-off   between Model Stability and Optimization</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Federated Learning (FL) is a distributed learning approach that trains machine learning models across multiple devices while keeping their local data private. However, FL often faces challenges due to data heterogeneity, leading to inconsistent local optima among clients. These inconsistencies can cause unfavorable convergence behavior and generalization performance degradation. Existing studies mainly describe this issue through \textit{convergence analysis}, focusing on how well a model fits training data, or through \textit{algorithmic stability}, which examines the generalization gap. However, neither approach precisely captures the generalization performance of FL algorithms, especially for neural networks. This paper introduces an innovative generalization dynamics analysis framework, named as Libra, for algorithm-dependent excess risk minimization, highlighting the trade-offs between model stability and optimization. Through this framework, we show how the generalization of FL algorithms is affected by the interplay of algorithmic stability and optimization. This framework applies to standard federated optimization and its advanced variants, such as server momentum. Our findings suggest that larger local steps or momentum accelerate convergence but enlarge stability, while yielding a better minimum excess risk. These insights can guide the design of future algorithms to achieve stronger generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.16715</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.16715</id><created>2024-11-22</created><updated>2025-02-04</updated><authors><author><keyname>Pohland</keyname><forenames>Sara</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire</forenames></author></authors><title>PaRCE: Probabilistic and Reconstruction-based Competency Estimation for   CNN-based Image Classification</title><categories>cs.CV cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:2409.06111</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNNs) are extremely popular and effective for image classification tasks but tend to be overly confident in their predictions. Various works have sought to quantify uncertainty associated with these models, detect out-of-distribution (OOD) inputs, or identify anomalous regions in an image, but limited work has sought to develop a holistic approach that can accurately estimate perception model confidence across various sources of uncertainty. We develop a probabilistic and reconstruction-based competency estimation (PaRCE) method and compare it to existing approaches for uncertainty quantification and OOD detection. We find that our method can best distinguish between correctly classified, misclassified, and OOD samples with anomalous regions, as well as between samples with visual image modifications resulting in high, medium, and low prediction accuracy. We describe how to extend our approach for anomaly localization tasks and demonstrate the ability of our approach to distinguish between regions in an image that are familiar to the perception model from those that are unfamiliar. We find that our method generates interpretable scores that most reliably capture a holistic notion of perception model confidence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.02529</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.02529</id><created>2024-12-03</created><updated>2025-02-04</updated><authors><author><keyname>Wagenmaker</keyname><forenames>Andrew</forenames></author><author><keyname>Mi</keyname><forenames>Lu</forenames></author><author><keyname>Rozsa</keyname><forenames>Marton</forenames></author><author><keyname>Bull</keyname><forenames>Matthew S.</forenames></author><author><keyname>Svoboda</keyname><forenames>Karel</forenames></author><author><keyname>Daie</keyname><forenames>Kayvon</forenames></author><author><keyname>Golub</keyname><forenames>Matthew D.</forenames></author><author><keyname>Jamieson</keyname><forenames>Kevin</forenames></author></authors><title>Active learning of neural population dynamics using two-photon   holographic optogenetics</title><categories>q-bio.NC cs.LG stat.ML</categories><comments>NeurIPS 2024</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in techniques for monitoring and perturbing neural populations have greatly enhanced our ability to study circuits in the brain. In particular, two-photon holographic optogenetics now enables precise photostimulation of experimenter-specified groups of individual neurons, while simultaneous two-photon calcium imaging enables the measurement of ongoing and induced activity across the neural population. Despite the enormous space of potential photostimulation patterns and the time-consuming nature of photostimulation experiments, very little algorithmic work has been done to determine the most effective photostimulation patterns for identifying the neural population dynamics. Here, we develop methods to efficiently select which neurons to stimulate such that the resulting neural responses will best inform a dynamical model of the neural population activity. Using neural population responses to photostimulation in mouse motor cortex, we demonstrate the efficacy of a low-rank linear dynamical systems model, and develop an active learning procedure which takes advantage of low-rank structure to determine informative photostimulation patterns. We demonstrate our approach on both real and synthetic data, obtaining in some cases as much as a two-fold reduction in the amount of data required to reach a given predictive power. Our active stimulation design method is based on a novel active learning procedure for low-rank regression, which may be of independent interest. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.05906</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.05906</id><created>2024-12-08</created><updated>2025-02-04</updated><authors><author><keyname>Li</keyname><forenames>Lucky</forenames></author></authors><title>Reinforcement Learning for a Discrete-Time Linear-Quadratic Control   Problem with an Application</title><categories>stat.ML cs.LG math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the discrete-time linear-quadratic (LQ) control model using reinforcement learning (RL). Using entropy to measure the cost of exploration, we prove that the optimal feedback policy for the problem must be Gaussian type. Then, we apply the results of the discrete-time LQ model to solve the discrete-time mean-variance asset-liability management problem and prove our RL algorithm's policy improvement and convergence. Finally, a numerical example sheds light on the theoretical results established using simulations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.06540</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.06540</id><created>2024-12-09</created><updated>2025-02-04</updated><authors><author><keyname>Polo</keyname><forenames>Felipe Maia</forenames></author><author><keyname>Somerstep</keyname><forenames>Seamus</forenames></author><author><keyname>Choshen</keyname><forenames>Leshem</forenames></author><author><keyname>Sun</keyname><forenames>Yuekai</forenames></author><author><keyname>Yurochkin</keyname><forenames>Mikhail</forenames></author></authors><title>Sloth: scaling laws for LLM skills to predict multi-benchmark   performance across families</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scaling laws for large language models (LLMs) predict model performance based on parameters like size and training data. However, differences in training configurations and data processing across model families lead to significant variations in benchmark performance, making it difficult for a single scaling law to generalize across all LLMs. On the other hand, training family-specific scaling laws requires training models of varying sizes for every family. In this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a novel scaling law that leverages publicly available benchmark data and assumes LLM performance is driven by low-dimensional latent skills, such as reasoning and instruction following. These latent skills are influenced by computational resources like model size and training tokens but with varying efficiencies across model families. Sloth exploits correlations across benchmarks to provide more accurate and interpretable predictions while alleviating the need to train multiple LLMs per family. We present both theoretical results on parameter identification and empirical evaluations on 12 prominent benchmarks, from Open LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance efficiently and offers insights into scaling behaviors for complex downstream tasks and increased test-time compute. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.10038</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.10038</id><created>2024-12-13</created><updated>2025-02-05</updated><authors><author><keyname>Callegher</keyname><forenames>Gianmarco</forenames></author><author><keyname>Kneib</keyname><forenames>Thomas</forenames></author><author><keyname>Söding</keyname><forenames>Johannes</forenames></author><author><keyname>Wiemann</keyname><forenames>Paul</forenames></author></authors><title>Stochastic Variational Inference for Structured Additive Distributional   Regression</title><categories>stat.CO</categories><msc-class>62</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In structured additive distributional regression, the conditional distribution of the response variables given the covariate information and the vector of model parameters is modelled using a P-parametric probability density function where each parameter is modelled through a linear predictor and a bijective response function that maps the domain of the predictor into the domain of the parameter. We present a method to perform inference in structured additive distributional regression using stochastic variational inference. We propose two strategies for constructing a multivariate Gaussian variational distribution to estimate the posterior distribution of the regression coefficients. The first strategy leverages covariate information and hyperparameters to learn both the location vector and the precision matrix. The second strategy tackles the complexity challenges of the first by initially assuming independence among all smooth terms and then introducing correlations through an additional set of variational parameters. Furthermore, we present two approaches for estimating the smoothing parameters. The first treats them as free parameters and provides point estimates, while the second accounts for uncertainty by applying a variational approximation to the posterior distribution. Our model was benchmarked against state-of-the-art competitors in logistic and gamma regression simulation studies. Finally, we validated our approach by comparing its posterior estimates to those obtained using Markov Chain Monte Carlo on a dataset of patents from the biotechnology/pharmaceutics and semiconductor/computer sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20553</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20553</id><created>2024-12-29</created><updated>2025-02-04</updated><authors><author><keyname>Andreyev</keyname><forenames>Arseniy</forenames></author><author><keyname>Beneventano</keyname><forenames>Pierfrancesco</forenames></author></authors><title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title><categories>cs.LG math.OC stat.ML</categories><comments>35 pages, 26 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent findings by Cohen et al., 2021, demonstrate that when training neural networks with full-batch gradient descent with a step size of $\eta$, the largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently stabilizes at $\lambda_{\max} = 2/\eta$. These results have significant implications for convergence and generalization. This, however, is not the case of mini-batch stochastic gradient descent (SGD), limiting the broader applicability of its consequences. We show that SGD trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/\eta$ is *Batch Sharpness*: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $\lambda_{\max}$--which is generally smaller than Batch Sharpness--is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20824</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20824</id><created>2024-12-30</created><updated>2025-02-05</updated><authors><author><keyname>Jorge</keyname><forenames>Emilio</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Basu</keyname><forenames>Debabrota</forenames></author></authors><title>Isoperimetry is All We Need: Langevin Posterior Sampling for RL with   Sublinear Regret</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common assumptions, like linear or RKHS models, and Gaussian or log-concave posteriors over the models, do not explain practical success of RL across a wider range of distributions and models. Thus, we study how to design RL algorithms with sublinear regret for isoperimetric distributions, specifically the ones satisfying the Log-Sobolev Inequality (LSI). LSI distributions include the standard setups of RL theory, and others, such as many non-log-concave and perturbed distributions. First, we show that the Posterior Sampling-based RL (PSRL) algorithm yields sublinear regret if the data distributions satisfy LSI and some mild additional assumptions. Also, when we cannot compute or sample from an exact posterior, we propose a Langevin sampling-based algorithm design: LaPSRL. We show that LaPSRL achieves order-optimal regret and subquadratic complexity per episode. Finally, we deploy LaPSRL with a Langevin sampler -- SARAH-LD, and test it for different bandit and MDP environments. Experimental results validate the generality of LaPSRL across environments and its competitive performance with respect to the baselines. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.04871</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.04871</id><created>2025-01-08</created><updated>2025-02-04</updated><authors><author><keyname>Lee</keyname><forenames>Kaitlyn J.</forenames></author><author><keyname>Schuler</keyname><forenames>Alejandro</forenames></author></authors><title>RieszBoost: Gradient Boosting for Riesz Regression</title><categories>stat.ML cs.LG stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Answering causal questions often involves estimating linear functionals of conditional expectations, such as the average treatment effect or the effect of a longitudinal modified treatment policy. By the Riesz representation theorem, these functionals can be expressed as the expected product of the conditional expectation of the outcome and the Riesz representer, a key component in doubly robust estimation methods. Traditionally, the Riesz representer is estimated indirectly by deriving its explicit analytical form, estimating its components, and substituting these estimates into the known form (e.g., the inverse propensity score). However, deriving or estimating the analytical form can be challenging, and substitution methods are often sensitive to practical positivity violations, leading to higher variance and wider confidence intervals. In this paper, we propose a novel gradient boosting algorithm to directly estimate the Riesz representer without requiring its explicit analytical form. This method is particularly suited for tabular data, offering a flexible, nonparametric, and computationally efficient alternative to existing methods for Riesz regression. Through simulation studies, we demonstrate that our algorithm performs on par with or better than indirect estimation techniques across a range of functionals, providing a user-friendly and robust solution for estimating causal quantities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06653</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06653</id><created>2025-01-11</created><authors><author><keyname>Zhao</keyname><forenames>Mengyu</forenames></author><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author></authors><title>Theoretical Characterization of Effect of Masks in Snapshot Compressive   Imaging</title><categories>cs.IT eess.IV math.IT stat.AP</categories><comments>27 pages. arXiv admin note: substantial text overlap with   arXiv:2307.07796</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Snapshot compressive imaging (SCI) refers to the recovery of three-dimensional data cubes-such as videos or hyperspectral images-from their two-dimensional projections, which are generated by a special encoding of the data with a mask. SCI systems commonly use binary-valued masks that follow certain physical constraints. Optimizing these masks subject to these constraints is expected to improve system performance. However, prior theoretical work on SCI systems focuses solely on independently and identically distributed (i.i.d.) Gaussian masks, which do not permit such optimization. On the other hand, existing practical mask optimizations rely on computationally intensive joint optimizations that provide limited insight into the role of masks and are expected to be sub-optimal due to the non-convexity and complexity of the optimization. In this paper, we analytically characterize the performance of SCI systems employing binary masks and leverage our analysis to optimize hardware parameters. Our findings provide a comprehensive and fundamental understanding of the role of binary masks - with both independent and dependent elements - and their optimization. We also present simulation results that confirm our theoretical findings and further illuminate different aspects of mask design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08270</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08270</id><created>2025-01-14</created><updated>2025-02-04</updated><authors><author><keyname>Fowler</keyname><forenames>Charlotte R.</forenames></author><author><keyname>Cai</keyname><forenames>Xiaoxuan</forenames></author><author><keyname>Rahimi-Eichi</keyname><forenames>Habiballah</forenames></author><author><keyname>Dixon</keyname><forenames>Lisa</forenames></author><author><keyname>Baker</keyname><forenames>Justin T.</forenames></author><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author><author><keyname>Valeri</keyname><forenames>Linda</forenames></author></authors><title>Individual causal effect estimation accounting for latent disease state   modification among bipolar participants in mobile health studies</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Individuals with bipolar disorder tend to cycle through disease states such as depression and mania. The heterogeneous nature of disease across states complicates the evaluation of interventions for bipolar disorder patients, as varied interventional success is observed within and across individuals. In fact, we hypothesize that disease state acts as an effect modifier for the causal effect of a given intervention on health outcomes. To address this dilemma, we propose an N-of-1 approach using an adapted autoregressive hidden Markov model, applied to longitudinal mobile health data collected from individuals with bipolar disorder. This method allows us to identify a latent variable from mobile health data to be treated as an effect modifier between the exposure and outcome of interest while allowing for missing data in the outcome. A counterfactual approach is employed for causal inference and to obtain a g-formula estimator to recover said effect. The performance of the proposed method is compared with a naive approach across extensive simulations and application to a multi-year smartphone study of bipolar patients, evaluating the individual effect of digital social activity on sleep duration across different latent disease states. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08945</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08945</id><created>2025-01-15</created><updated>2025-02-04</updated><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>Zhu</keyname><forenames>Ke</forenames></author><author><keyname>Han</keyname><forenames>Larry</forenames></author><author><keyname>Yang</keyname><forenames>Shu</forenames></author></authors><title>COADVISE: Covariate Adjustment with Variable Selection and Missing Data   Imputation in Randomized Controlled Trials</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adjusting for covariates in randomized controlled trials can enhance the credibility and efficiency of treatment effect estimation. However, handling numerous covariates and their non-linear transformations is challenging, particularly when outcomes and covariates have missing data. In this tutorial, we propose a principled Covariate Adjustment with Variable Selection and Missing Data Imputation (COADVISE) framework that enables (i) variable selection for covariates most relevant to the outcome, (ii) nonlinear adjustments, and (iii) robust imputation of missing data for both outcomes and covariates. This framework ensures consistent estimates with improved efficiency over unadjusted estimators and provides robust variance estimation, even under outcome model misspecification. We demonstrate efficiency gains through theoretical analysis and conduct extensive simulations to compare alternative variable selection strategies, offering cautionary recommendations. We showcase the practical utility of COADVISE by applying it to the Best Apnea Interventions for Research trial data from the National Sleep Research Resource. A user-friendly R package, Coadvise, facilitates implementation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.09683</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.09683</id><created>2025-01-16</created><updated>2025-02-05</updated><authors><author><keyname>Cirone</keyname><forenames>Nicola Muca</forenames></author><author><keyname>Salvi</keyname><forenames>Cristopher</forenames></author></authors><title>Rough kernel hedging</title><categories>math.FA cs.LG stat.ML</categories><comments>v2. minor corrections to presentation</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Building on the functional-analytic framework of operator-valued kernels and un-truncated signature kernels, we propose a scalable, provably convergent signature-based algorithm for a broad class of high-dimensional, path-dependent hedging problems. We make minimal assumptions about market dynamics by modelling them as general geometric rough paths, yielding a fully model-free approach. Furthermore, through a representer theorem, we provide theoretical guarantees on the existence and uniqueness of a global minimum for the resulting optimization problem and derive an analytic solution under highly general loss functions. Similar to the popular deep hedging approach, but in a more rigorous fashion, our method can also incorporate additional features via the underlying operator-valued kernel, such as trading signals, news analytics, and past hedging decisions, closely aligning with true machine-learning practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10910</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10910</id><created>2025-01-18</created><updated>2025-02-05</updated><authors><author><keyname>Kowsar</keyname><forenames>Ibna</forenames></author><author><keyname>Rabbani</keyname><forenames>Shourav B.</forenames></author><author><keyname>Hou</keyname><forenames>Yina</forenames></author><author><keyname>Samad</keyname><forenames>Manar D.</forenames></author></authors><title>DeepIFSAC: Deep Imputation of Missing Values Using Feature and Sample   Attention within Contrastive Framework</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Missing values of varying patterns and rates in real-world tabular data pose a significant challenge in developing reliable data-driven models. Existing missing value imputation methods use statistical and traditional machine learning and are ineffective when the missing rate is high and not at random. This paper explores row and column attention in tabular data as between-feature and between-sample attention in a novel framework to reconstruct missing values. The proposed method uses the CutMix data augmentation within a contrastive learning framework to improve the uncertainty of missing value estimation. The performance and generalizability of trained imputation models are evaluated on set-aside test data folds with missing values. The proposed framework outperforms nine state-of-the-art imputation methods across several missing value types and rates (10\%-50\%) on a diverse selection of twelve tabular data sets. We evaluate the quality of imputed data using real-world electronic health records with missing values, demonstrating our proposed framework's superiority to state-of-the-art statistical, machine learning, and deep imputation methods. This paper highlights the heterogeneity of tabular data sets to recommend imputation methods based on missing value types and data characteristics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11280</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11280</id><created>2025-01-20</created><updated>2025-02-04</updated><authors><author><keyname>Yoshida</keyname><forenames>Tsukasa</forenames></author><author><keyname>Watanabe</keyname><forenames>Kazuho</forenames></author></authors><title>Empirical Bayes Estimation for Lasso-Type Regularizers: Analysis of   Automatic Relevance Determination</title><categories>math.ST cs.IT cs.LG math.IT stat.TH</categories><comments>8 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper focuses on linear regression models with non-conjugate sparsity-inducing regularizers such as lasso and group lasso. Although empirical Bayes approach enables us to estimate the regularization parameter, little is known on the properties of the estimators. In particular, there are many unexplained aspects regarding the specific conditions under which the mechanism of automatic relevance determination (ARD) occurs. In this paper, we derive the empirical Bayes estimators for the group lasso regularized linear regression models with a limited number of parameters. It is shown that the estimators diverge under a certain condition, giving rise to the ARD mechanism. We also prove that empirical Bayes methods can produce ARD mechanism in general regularized linear regression models and clarify the conditions under which models such as ridge, lasso, and group lasso can produce ARD mechanism. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11650</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11650</id><created>2025-01-20</created><updated>2025-02-05</updated><authors><author><keyname>Leach</keyname><forenames>Callum</forenames></author><author><keyname>Ewans</keyname><forenames>Kevin</forenames></author><author><keyname>Jonathan</keyname><forenames>Philip</forenames></author></authors><title>Changes over time in the 100-year return value of climate model   variables</title><categories>stat.AP physics.ao-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We assess evidence for changes in tail characteristics of wind, solar irradiance and temperature variables output from CMIP6 global climate models (GCMs) due to climate forcing. We estimate global and climate zone annual maximum and annual means for period (2015, 2100) from daily output of seven GCMs for daily wind speed, maximum wind speed, solar irradiance and near-surface temperature. We calculate corresponding annualised data for individual locations within neighbourhoods of the North Atlantic and Celtic Sea region. We consider output for three climate scenarios and multiple climate ensembles. We estimate non-stationary extreme value models for annual extremes, and non-homogeneous Gaussian regressions for annual means, using Bayesian inference. We use estimated statistical models to quantify the distribution of (i) the change in 100-year return value for annual extremes, and (2) the change in annual mean, over the period (2025, 2125). To summarise results, we estimate linear mixed effects models for observed variation of (i) and (ii). Evidence for changes in the 100-year return value for annual maxima of solar irradiance and temperature is much stronger than for wind variables over time and with climate scenario. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11689</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11689</id><created>2025-01-20</created><updated>2025-02-05</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Randomness, exchangeability, and conformal prediction</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>24 pages, 1 figure; v2 includes several new results about the   optimality of results in v1</comments><msc-class>68Q32 (Primary) 62G15, 68T05, 03D32 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper continues development of the functional theory of randomness, a modification of the algorithmic theory of randomness getting rid of unspecified additive constants. It introduces new kinds of confidence predictors, including randomness predictors (the most general confidence predictors based on the assumption of IID observations) and exchangeability predictors (the most general confidence predictors based on the assumption of exchangeable observations). The main result implies that both are close to conformal predictors and quantifies the difference between randomness prediction and conformal prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12737</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12737</id><created>2025-01-22</created><updated>2025-02-04</updated><authors><author><keyname>Yang</keyname><forenames>Jiaqi</forenames></author><author><keyname>Xie</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Xiaohua</forenames></author></authors><title>Stability and Generalization of Quantum Neural Networks</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum neural networks (QNNs) play an important role as an emerging technology in the rapidly growing field of quantum machine learning. While their empirical success is evident, the theoretical explorations of QNNs, particularly their generalization properties, are less developed and primarily focus on the uniform convergence approach. In this paper, we exploit an advanced tool in classical learning theory, i.e., algorithmic stability, to study the generalization of QNNs. We first establish high-probability generalization bounds for QNNs via uniform stability. Our bounds shed light on the key factors influencing the generalization performance of QNNs and provide practical insights into both the design and training processes. We next explore the generalization of QNNs on near-term noisy intermediate-scale quantum (NISQ) devices, highlighting the potential benefits of quantum noise. Moreover, we argue that our previous analysis characterizes worst-case generalization guarantees, and we establish a refined optimization-dependent generalization bound for QNNs via on-average stability. Numerical experiments on various real-world datasets support our theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.15194</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.15194</id><created>2025-01-25</created><updated>2025-02-04</updated><authors><author><keyname>Yao</keyname><forenames>Zhihao</forenames></author><author><keyname>Yin</keyname><forenames>Jixuan</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author></authors><title>Reliable Pseudo-labeling via Optimal Transport with Attention for Short   Text Clustering</title><categories>cs.LG stat.CO stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Short text clustering has gained significant attention in the data mining community. However, the limited valuable information contained in short texts often leads to low-discriminative representations, increasing the difficulty of clustering. This paper proposes a novel short text clustering framework, called Reliable \textbf{P}seudo-labeling via \textbf{O}ptimal \textbf{T}ransport with \textbf{A}ttention for Short Text Clustering (\textbf{POTA}), that generate reliable pseudo-labels to aid discriminative representation learning for clustering. Specially, \textbf{POTA} first implements an instance-level attention mechanism to capture the semantic relationships among samples, which are then incorporated as a semantic consistency regularization term into an optimal transport problem. By solving this OT problem, we can yield reliable pseudo-labels that simultaneously account for sample-to-sample semantic consistency and sample-to-cluster global structure information. Additionally, the proposed OT can adaptively estimate cluster distributions, making \textbf{POTA} well-suited for varying degrees of imbalanced datasets. Then, we utilize the pseudo-labels to guide contrastive learning to generate discriminative representations and achieve efficient clustering. Extensive experiments demonstrate \textbf{POTA} outperforms state-of-the-art methods. The code is available at: \href{https://github.com/YZH0905/POTA-STC/tree/main}{https://github.com/YZH0905/POTA-STC/tree/main}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.15753</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.15753</id><created>2025-01-26</created><updated>2025-02-05</updated><authors><author><keyname>Fallahgoul</keyname><forenames>Hasan</forenames></author></authors><title>Scale-Insensitive Neural Network Significance Tests</title><categories>stat.ML cs.LG econ.EM</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper develops a scale-insensitive framework for neural network significance testing, substantially generalizing existing approaches through three key innovations. First, we replace metric entropy calculations with Rademacher complexity bounds, enabling the analysis of neural networks without requiring bounded weights or specific architectural constraints. Second, we weaken the regularity conditions on the target function to require only Sobolev space membership $H^s([-1,1]^d)$ with $s &gt; d/2$, significantly relaxing previous smoothness assumptions while maintaining optimal approximation rates. Third, we introduce a modified sieve space construction based on moment bounds rather than weight constraints, providing a more natural theoretical framework for modern deep learning practices. Our approach achieves these generalizations while preserving optimal convergence rates and establishing valid asymptotic distributions for test statistics. The technical foundation combines localization theory, sharp concentration inequalities, and scale-insensitive complexity measures to handle unbounded weights and general Lipschitz activation functions. This framework better aligns theoretical guarantees with contemporary deep learning practice while maintaining mathematical rigor. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.16489</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.16489</id><created>2025-01-27</created><updated>2025-02-04</updated><authors><author><keyname>Hou</keyname><forenames>Boya</forenames></author><author><keyname>Sanjari</keyname><forenames>Sina</forenames></author><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author></authors><title>Nonparametric Sparse Online Learning of the Koopman Operator</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>This work was intended as a replacement of arXiv:2405.07432 and any   subsequent updates will appear there</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.16730</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.16730</id><created>2025-01-28</created><updated>2025-02-04</updated><authors><author><keyname>Cong</keyname><forenames>Lin William</forenames></author><author><keyname>Feng</keyname><forenames>Guanhao</forenames></author><author><keyname>He</keyname><forenames>Jingyu</forenames></author><author><keyname>He</keyname><forenames>Xin</forenames></author></authors><title>Growing the Efficient Frontier on Panel Trees</title><categories>cs.LG q-fin.PR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of tree-based models, P-Trees, for analyzing (unbalanced) panel of individual asset returns, generalizing high-dimensional sorting with economic guidance and interpretability. Under the mean-variance efficient framework, P-Trees construct test assets that significantly advance the efficient frontier compared to commonly used test assets, with alphas unexplained by benchmark pricing models. P-Tree tangency portfolios also constitute traded factors, recovering the pricing kernel and outperforming popular observable and latent factor models for investments and cross-sectional pricing. Finally, P-Trees capture the complexity of asset returns with sparsity, achieving out-of-sample Sharpe ratios close to those attained only by over-parameterized large models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.17446</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.17446</id><created>2025-01-29</created><updated>2025-02-03</updated><authors><author><keyname>Satoh</keyname><forenames>Kenichi</forenames></author></authors><title>Applying non-negative matrix factorization with covariates to   multivariate time series data as a vector autoregression model</title><categories>stat.ME</categories><comments>8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative matrix factorization (NMF) is a powerful technique for dimensionality reduction, but its application to time series data remains limited. This paper proposes a novel framework that integrates NMF with a vector autoregression (VAR) model to capture both latent structure and temporal dependencies in multivariate time series data. By representing the NMF coefficient matrix as a VAR model, the framework leverages the interpretability of NMF while incorporating the dynamic characteristics of time series data. This approach allows for the extraction of meaningful features and accurate predictions in time series data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.18095</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.18095</id><created>2025-01-29</created><updated>2025-02-04</updated><authors><author><keyname>Han</keyname><forenames>Barron</forenames></author><author><keyname>Akhtiamov</keyname><forenames>Danil</forenames></author><author><keyname>Ghane</keyname><forenames>Reza</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Robust Mean Estimation With Auxiliary Samples</title><categories>math.ST stat.TH</categories><comments>Submitted to International Symposium on Information Theory 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In data-driven learning and inference tasks, the high cost of acquiring samples from the target distribution often limits performance. A common strategy to mitigate this challenge is to augment the limited target samples with data from a more accessible "auxiliary" distribution. This paper establishes fundamental limits of this approach by analyzing the improvement in the mean square error (MSE) when estimating the mean of the target distribution. Using the Wasserstein-2 metric to quantify the distance between distributions, we derive expressions for the worst-case MSE when samples are drawn (with labels) from both a target distribution and an auxiliary distribution within a specified Wasserstein-2 distance from the target distribution. We explicitly characterize the achievable MSE and the optimal estimator in terms of the problem dimension, the number of samples from the target and auxiliary distributions, the Wasserstein-2 distance, and the covariance of the target distribution. We note that utilizing samples from the auxiliary distribution effectively improves the MSE when the squared radius of the Wasserstein-2 uncertainty ball is small compared to the variance of the true distribution and the number of samples from the true distribution is limited. Numerical simulations in the Gaussian location model illustrate the theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.18184</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.18184</id><created>2025-01-30</created><updated>2025-02-05</updated><authors><author><keyname>Lyu</keyname><forenames>Qingchuan</forenames></author></authors><title>Genetic Algorithm with Border Trades (GAB)</title><categories>cs.LG cs.NE stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel approach to improving Genetic Algorithms (GA) in large or complex problem spaces by incorporating new chromosome patterns in the breeding process through border trade activities. These strategies increase chromosome diversity, preventing premature convergence and enhancing the GA's ability to explore the solution space more effectively. Empirical evidence demonstrates significant improvements in convergence behavior. This approach offers a promising pathway to addressing challenges in optimizing large or complex problem domains. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.00298</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.00298</id><created>2025-01-31</created><updated>2025-02-03</updated><authors><author><keyname>Moreno</keyname><forenames>Alexander</forenames></author><author><keyname>Xiao</keyname><forenames>Justin</forenames></author><author><keyname>Mei</keyname><forenames>Jonathan</forenames></author></authors><title>The Price of Linear Time: Error Analysis of Structured Kernel   Interpolation</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Structured Kernel Interpolation (SKI) (Wilson et al. 2015) helps scale Gaussian Processes (GPs) by approximating the kernel matrix via interpolation at inducing points, achieving linear computational complexity. However, it lacks rigorous theoretical error analysis. This paper bridges the gap: we prove error bounds for the SKI Gram matrix and examine the error's effect on hyperparameter estimation and posterior inference. We further provide a practical guide to selecting the number of inducing points under convolutional cubic interpolation: they should grow as $n^{d/3}$ for error control. Crucially, we identify two dimensionality regimes governing the trade-off between SKI Gram matrix spectral norm error and computational complexity. For $d \leq 3$, any error tolerance can achieve linear time for sufficiently large sample size. For $d &gt; 3$, the error must increase with sample size to maintain linear time. Our analysis provides key insights into SKI's scalability-accuracy trade-offs, establishing precise conditions for achieving linear-time GP inference with controlled approximation error. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01627</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01627</id><created>2025-02-03</created><updated>2025-02-04</updated><authors><author><keyname>Song</keyname><forenames>Yanke</forenames></author><author><keyname>Villar</keyname><forenames>Victoria Ashley</forenames></author><author><keyname>Martinez-Galarza</keyname><forenames>Juan Rafael</forenames></author><author><keyname>Dillmann</keyname><forenames>Steven</forenames></author></authors><title>A Poisson Process AutoDecoder for X-ray Sources</title><categories>astro-ph.IM astro-ph.HE cs.LG stat.AP</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray observing facilities, such as the Chandra X-ray Observatory and the eROSITA, have detected millions of astronomical sources associated with high-energy phenomena. The arrival of photons as a function of time follows a Poisson process and can vary by orders-of-magnitude, presenting obstacles for common tasks such as source classification, physical property derivation, and anomaly detection. Previous work has either failed to directly capture the Poisson nature of the data or only focuses on Poisson rate function reconstruction. In this work, we present Poisson Process AutoDecoder (PPAD). PPAD is a neural field decoder that maps fixed-length latent features to continuous Poisson rate functions across energy band and time via unsupervised learning. PPAD reconstructs the rate function and yields a representation at the same time. We demonstrate the efficacy of PPAD via reconstruction, regression, classification and anomaly detection experiments using the Chandra Source Catalog. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01672</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01672</id><created>2025-02-01</created><authors><author><keyname>Liu</keyname><forenames>Manqing</forenames></author><author><keyname>Beam</keyname><forenames>Andrew L.</forenames></author></authors><title>Doubly Robust Monte Carlo Tree Search</title><categories>stat.ML cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present Doubly Robust Monte Carlo Tree Search (DR-MCTS), a novel algorithm that integrates Doubly Robust (DR) off-policy estimation into Monte Carlo Tree Search (MCTS) to enhance sample efficiency and decision quality in complex environments. Our approach introduces a hybrid estimator that combines MCTS rollouts with DR estimation, offering theoretical guarantees of unbiasedness and variance reduction under specified conditions. Empirical evaluations in Tic-Tac-Toe and the partially observable VirtualHome environment demonstrate DR-MCTS's superior performance over standard MCTS. In Tic-Tac-Toe, DR-MCTS achieves an 88% win rate compared to a 10% win rate for standard MCTS. In compound VirtualHome tasks, DR-MCTS attains a 20.7% success rate versus 10.3% for standard MCTS. Our scaling analysis reveals that DR-MCTS exhibits better sample efficiency, notably outperforming standard MCTS with larger language models while using a smaller model. These results underscore DR-MCTS's potential for efficient decision-making in complex, real-world scenarios where sample efficiency is paramount. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01694</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01694</id><created>2025-02-02</created><authors><author><keyname>Kim</keyname><forenames>Juno</forenames></author><author><keyname>Wu</keyname><forenames>Denny</forenames></author><author><keyname>Lee</keyname><forenames>Jason</forenames></author><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author></authors><title>Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of   Search, RL and Distillation</title><categories>cs.AI cs.LG stat.ML</categories><comments>55 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A key paradigm to improve the reasoning capabilities of large language models (LLMs) is to allocate more inference-time compute to search against a verifier or reward model. This process can then be utilized to refine the pretrained model or distill its reasoning patterns into more efficient models. In this paper, we study inference-time compute by viewing chain-of-thought (CoT) generation as a metastable Markov process: easy reasoning steps (e.g., algebraic manipulations) form densely connected clusters, while hard reasoning steps (e.g., applying a relevant theorem) create sparse, low-probability edges between clusters, leading to phase transitions at longer timescales. Under this framework, we prove that implementing a search protocol that rewards sparse edges improves CoT by decreasing the expected number of steps to reach different clusters. In contrast, we establish a limit on reasoning capability when the model is restricted to local information of the pretrained graph. We also show that the information gained by search can be utilized to obtain a better reasoning model: (1) the pretrained model can be directly finetuned to favor sparse edges via policy gradient methods, and moreover (2) a compressed metastable representation of the reasoning dynamics can be distilled into a smaller, more efficient model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01701</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01701</id><created>2025-02-03</created><authors><author><keyname>Lalanne</keyname><forenames>Clément</forenames><affiliation>IMT, ANITI</affiliation></author><author><keyname>Loubes</keyname><forenames>Jean-Michel</forenames><affiliation>IMT, ANITI</affiliation></author><author><keyname>Rodríguez-Vítores</keyname><forenames>David</forenames><affiliation>UVa, IMUVA</affiliation></author></authors><title>Learning with Differentially Private (Sliced) Wasserstein Gradients</title><categories>cs.LG math.ST stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce a novel framework for privately optimizing objectives that rely on Wasserstein distances between data-dependent empirical measures. Our main theoretical contribution is, based on an explicit formulation of the Wasserstein gradient in a fully discrete setting, a control on the sensitivity of this gradient to individual data points, allowing strong privacy guarantees at minimal utility cost. Building on these insights, we develop a deep learning approach that incorporates gradient and activations clipping, originally designed for DP training of problems with a finite-sum structure. We further demonstrate that privacy accounting methods extend to Wasserstein-based objectives, facilitating large-scale private training. Empirical results confirm that our framework effectively balances accuracy and privacy, offering a theoretically sound solution for privacy-preserving machine learning tasks relying on optimal transport distances such as Wasserstein distance or sliced-Wasserstein distance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01763</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01763</id><created>2025-02-03</created><authors><author><keyname>Zhang</keyname><forenames>Thomas T.</forenames></author><author><keyname>Moniri</keyname><forenames>Behrad</forenames></author><author><keyname>Nagwekar</keyname><forenames>Ansh</forenames></author><author><keyname>Rahman</keyname><forenames>Faraz</forenames></author><author><keyname>Xue</keyname><forenames>Anton</forenames></author><author><keyname>Hassani</keyname><forenames>Hamed</forenames></author><author><keyname>Matni</keyname><forenames>Nikolai</forenames></author></authors><title>On The Concurrence of Layer-wise Preconditioning Methods and Provable   Feature Learning</title><categories>cs.LG math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Layer-wise preconditioning methods are a family of memory-efficient optimization algorithms that introduce preconditioners per axis of each layer's weight tensors. These methods have seen a recent resurgence, demonstrating impressive performance relative to entry-wise ("diagonal") preconditioning methods such as Adam(W) on a wide range of neural network optimization tasks. Complementary to their practical performance, we demonstrate that layer-wise preconditioning methods are provably necessary from a statistical perspective. To showcase this, we consider two prototypical models, linear representation learning and single-index learning, which are widely used to study how typical algorithms efficiently learn useful features to enable generalization. In these problems, we show SGD is a suboptimal feature learner when extending beyond ideal isotropic inputs $\mathbf{x} \sim \mathsf{N}(\mathbf{0}, \mathbf{I})$ and well-conditioned settings typically assumed in prior work. We demonstrate theoretically and numerically that this suboptimality is fundamental, and that layer-wise preconditioning emerges naturally as the solution. We further show that standard tools like Adam preconditioning and batch-norm only mildly mitigate these issues, supporting the unique benefits of layer-wise preconditioning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01780</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01780</id><created>2025-02-03</created><authors><author><keyname>Park</keyname><forenames>Hongju</forenames></author><author><keyname>Bai</keyname><forenames>Shuyang</forenames></author><author><keyname>Ye</keyname><forenames>Zhenyao</forenames></author><author><keyname>Lee</keyname><forenames>Hwiyoung</forenames></author><author><keyname>Ma</keyname><forenames>Tianzhou</forenames></author><author><keyname>Chen</keyname><forenames>Shuo</forenames></author></authors><title>Graph Canonical Correlation Analysis</title><categories>stat.ML cs.LG</categories><comments>40 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Canonical correlation analysis (CCA) is a widely used technique for estimating associations between two sets of multi-dimensional variables. Recent advancements in CCA methods have expanded their application to decipher the interactions of multiomics datasets, imaging-omics datasets, and more. However, conventional CCA methods are limited in their ability to incorporate structured patterns in the cross-correlation matrix, potentially leading to suboptimal estimations. To address this limitation, we propose the graph Canonical Correlation Analysis (gCCA) approach, which calculates canonical correlations based on the graph structure of the cross-correlation matrix between the two sets of variables. We develop computationally efficient algorithms for gCCA, and provide theoretical results for finite sample analysis of best subset selection and canonical correlation estimation by introducing concentration inequalities and stopping time rule based on martingale theories. Extensive simulations demonstrate that gCCA outperforms competing CCA methods. Additionally, we apply gCCA to a multiomics dataset of DNA methylation and RNA-seq transcriptomics, identifying both positively and negatively regulated gene expression pathways by DNA methylation pathways. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01810</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01810</id><created>2025-02-03</created><authors><author><keyname>Mele</keyname><forenames>Angelo</forenames></author></authors><title>Estimating Network Models using Neural Networks</title><categories>cs.SI econ.EM stat.CO stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Exponential random graph models (ERGMs) are very flexible for modeling network formation but pose difficult estimation challenges due to their intractable normalizing constant. Existing methods, such as MCMC-MLE, rely on sequential simulation at every optimization step. We propose a neural network approach that trains on a single, large set of parameter-simulation pairs to learn the mapping from parameters to average network statistics. Once trained, this map can be inverted, yielding a fast and parallelizable estimation method. The procedure also accommodates extra network statistics to mitigate model misspecification. Some simple illustrative examples show that the method performs well in practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01861</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01861</id><created>2025-02-03</created><authors><author><keyname>Harvey</keyname><forenames>Ethan</forenames></author><author><keyname>Petrov</keyname><forenames>Mikhail</forenames></author><author><keyname>Hughes</keyname><forenames>Michael C.</forenames></author></authors><title>Learning Hyperparameters via a Data-Emphasized Variational Objective</title><categories>cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:2410.19675</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When training large flexible models, practitioners often rely on grid search to select hyperparameters that control over-fitting. This grid search has several disadvantages: the search is computationally expensive, requires carving out a validation set that reduces the available data for training, and requires users to specify candidate values. In this paper, we propose an alternative: directly learning regularization hyperparameters on the full training set via the evidence lower bound ("ELBo") objective from variational methods. For deep neural networks with millions of parameters, we recommend a modified ELBo that upweights the influence of the data likelihood relative to the prior. Our proposed technique overcomes all three disadvantages of grid search. In a case study on transfer learning of image classifiers, we show how our method reduces the 88+ hour grid search of past work to under 3 hours while delivering comparable accuracy. We further demonstrate how our approach enables efficient yet accurate approximations of Gaussian processes with learnable length-scale kernels. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01886</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01886</id><created>2025-02-03</created><authors><author><keyname>Díaz</keyname><forenames>Mateo</forenames></author><author><keyname>Drusvyatskiy</keyname><forenames>Dmitriy</forenames></author><author><keyname>Kendrick</keyname><forenames>Jack</forenames></author><author><keyname>Thomas</keyname><forenames>Rekha R.</forenames></author></authors><title>Invariant Kernels: Rank Stabilization and Generalization Across   Dimensions</title><categories>math.OC math.RT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry arises often when learning from high dimensional data. For example, data sets consisting of point clouds, graphs, and unordered sets appear routinely in contemporary applications, and exhibit rich underlying symmetries. Understanding the benefits of symmetry on the statistical and numerical efficiency of learning algorithms is an active area of research. In this work, we show that symmetry has a pronounced impact on the rank of kernel matrices. Specifically, we compute the rank of a polynomial kernel of fixed degree that is invariant under various groups acting independently on its two arguments. In concrete circumstances, including the three aforementioned examples, symmetry dramatically decreases the rank making it independent of the data dimension. In such settings, we show that a simple regression procedure is minimax optimal for estimating an invariant polynomial from finitely many samples drawn across different dimensions. We complete the paper with numerical experiments that illustrate our findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01892</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01892</id><created>2025-02-03</created><authors><author><keyname>Stivala</keyname><forenames>Alex</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Lomi</keyname><forenames>Alessandro</forenames></author></authors><title>Improving exponential-family random graph models for bipartite networks</title><categories>stat.ME stat.AP</categories><comments>54 pages including appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bipartite graphs, representing two-mode networks, arise in many research fields. These networks have two disjoint node sets representing distinct entity types, for example persons and groups, with edges representing associations between the two entity types. In bipartite graphs, the smallest possible cycle is a cycle of length four, and hence four-cycles are the smallest structure to model closure in such networks. Exponential-family random graph models (ERGMs) are a widely used model for social, and other, networks, including specifically bipartite networks. Existing ERGM terms to model four-cycles in bipartite networks, however, are relatively rarely used. In this work we demonstrate some problems with these existing terms to model four-cycles, and define new ERGM terms to help overcome these problems. The position of the new terms in the ERGM dependence hierarchy, and their interpretation, is discussed. The new terms are demonstrated in simulation experiments, and their application illustrated with ERGM models of empirical networks ranging in size from hundreds of nodes to hundreds of thousands of nodes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01919</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01919</id><created>2025-02-03</created><authors><author><keyname>James</keyname><forenames>Lancelot F.</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Pandey</keyname><forenames>Abhinav</forenames></author></authors><title>Poisson Hierarchical Indian Buffet Processes for Within and Across Group   Sharing of Latent Features-With Indications for Microbiome Species Sampling   Models</title><categories>stat.ML cs.LG math.PR math.ST stat.TH</categories><comments>experiments to be added</comments><msc-class>60C05, 60G09 (Primary), 60G57, 60E99 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we present a comprehensive Bayesian posterior analysis of what we term Poisson Hierarchical Indian Buffet Processes, designed for complex random sparse count species sampling models that allow for the sharing of information across and within groups. This analysis covers a potentially infinite number of species and unknown parameters, which, within a Bayesian machine learning context, we are able to learn from as more information is sampled. To achieve our refined results, we employ a range of methodologies drawn from Bayesian latent feature models, random occupancy models, and excursion theory. Despite this complexity, our goal is to make our findings accessible to practitioners, including those who may not be familiar with these areas. To facilitate understanding, we adopt a pseudo-expository style that emphasizes clarity and practical utility. We aim to express our findings in a language that resonates with experts in microbiome and ecological studies, addressing gaps in modeling capabilities while acknowledging that we are not experts ourselves in these fields. This approach encourages the use of our models as basic components of more sophisticated frameworks employed by domain experts, embodying the spirit of the seminal work on the Dirichlet Process. Ultimately, our refined posterior analysis not only yields tractable computational procedures but also enables practical statistical implementation and provides a clear mapping to relevant quantities in microbiome analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01947</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01947</id><created>2025-02-03</created><authors><author><keyname>Zheng</keyname><forenames>Runbing</forenames></author></authors><title>Detection and estimation of vertex-wise latent position shifts across   networks</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pairwise network comparison is essential for various applications, including neuroscience, disease research, and dynamic network analysis. While existing literature primarily focuses on comparing entire network structures, we address a vertex-wise comparison problem where two random networks share the same set of vertices but allow for structural variations in some vertices, enabling a more detailed and flexible analysis of network differences. In our framework, some vertices retain their latent positions between networks, while others undergo shifts. To identify the shifted and unshifted vertices and estimate their latent position shifts, we propose a method that first derives vertex embeddings in a low-rank Euclidean space for each network, then aligns these estimated vertex latent positions into a common space to resolve potential non-identifiability, and finally tests whether each vertex is shifted or not and estimates the vertex shifts. Our theoretical results establish the test statistic for the algorithms, guide parameter selection, and provide performance guarantees. Simulation studies and real data applications, including a case-control study in disease research and dynamic network analysis, demonstrate that the proposed algorithms are both computationally efficient and effective in extracting meaningful insights from network comparisons. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01953</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01953</id><created>2025-02-03</created><authors><author><keyname>Asgari</keyname><forenames>Kiana</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Saeed</keyname><forenames>Basil</forenames></author></authors><title>Local minima of the empirical risk in high dimension: General theorems   and convex examples</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>95 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general model for high-dimensional empirical risk minimization whereby the data $\mathbf{x}_i$ are $d$-dimensional isotropic Gaussian vectors, the model is parametrized by $\mathbf{\Theta}\in\mathbb{R}^{d\times k}$, and the loss depends on the data via the projection $\mathbf{\Theta}^\mathsf{T}\mathbf{x}_i$. This setting covers as special cases classical statistics methods (e.g. multinomial regression and other generalized linear models), but also two-layer fully connected neural networks with $k$ hidden neurons. We use the Kac-Rice formula from Gaussian process theory to derive a bound on the expected number of local minima of this empirical risk, under the proportional asymptotics in which $n,d\to\infty$, with $n\asymp d$. Via Markov's inequality, this bound allows to determine the positions of these minimizers (with exponential deviation bounds) and hence derive sharp asymptotics on the estimation and prediction error. In this paper, we apply our characterization to convex losses, where high-dimensional asymptotics were not (in general) rigorously established for $k\ge 2$. We show that our approach is tight and allows to prove previously conjectured results. In addition, we characterize the spectrum of the Hessian at the minimizer. A companion paper applies our general result to non-convex examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01995</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01995</id><created>2025-02-03</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author><author><keyname>Bondell</keyname><forenames>Howard</forenames></author></authors><title>Theoretical and Practical Analysis of Fr\'echet Regression via   Comparison Geometry</title><categories>stat.ML cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fr\'echet regression extends classical regression methods to non-Euclidean metric spaces, enabling the analysis of data relationships on complex structures such as manifolds and graphs. This work establishes a rigorous theoretical analysis for Fr\'echet regression through the lens of comparison geometry which leads to important considerations for its use in practice. The analysis provides key results on the existence, uniqueness, and stability of the Fr\'echet mean, along with statistical guarantees for nonparametric regression, including exponential concentration bounds and convergence rates. Additionally, insights into angle stability reveal the interplay between curvature of the manifold and the behavior of the regression estimator in these non-Euclidean contexts. Empirical experiments validate the theoretical findings, demonstrating the effectiveness of proposed hyperbolic mappings, particularly for data with heteroscedasticity, and highlighting the practical usefulness of these results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02000</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02000</id><created>2025-02-03</created><authors><author><keyname>Lu</keyname><forenames>Yuchen</forenames></author><author><keyname>Lee</keyname><forenames>Ben Seiyon</forenames></author><author><keyname>Doss-Gollin</keyname><forenames>James</forenames></author></authors><title>Bayesian Spatiotemporal Nonstationary Model Quantifies Robust Increases   in Daily Extreme Rainfall Across the Western Gulf Coast</title><categories>stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precipitation exceedance probabilities are widely used in engineering design, risk assessment, and floodplain management. While common approaches like NOAA Atlas 14 assume that extreme precipitation characteristics are stationary over time, this assumption may underestimate current and future hazards due to anthropogenic climate change. However, the incorporation of nonstationarity in the statistical modeling of extreme precipitation has faced practical challenges that have restricted its applications. In particular, random sampling variability challenges the reliable estimation of trends and parameters, especially when observational records are limited. To address this methodological gap, we propose the Spatially Varying Covariates Model, a hierarchical Bayesian spatial framework that integrates nonstationarity and regionalization for robust frequency analysis of extreme precipitation. This model draws from extreme value theory, spatial statistics, and Bayesian statistics, and is validated through cross-validation and multiple performance metrics. Applying this framework to a case study of daily rainfall in the Western Gulf Coast, we identify robustly increasing trends in extreme precipitation intensity and variability throughout the study area, with notable spatial heterogeneity. This flexible model accommodates stations with varying observation records, yields smooth return level estimates, and can be straightforwardly adapted to the analysis of precipitation frequencies at different durations and for other regions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02002</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02002</id><created>2025-02-03</created><authors><author><keyname>Gruntkowska</keyname><forenames>Kaja</forenames></author><author><keyname>Li</keyname><forenames>Hanmin</forenames></author><author><keyname>Rane</keyname><forenames>Aadi</forenames></author><author><keyname>Richtárik</keyname><forenames>Peter</forenames></author></authors><title>The Ball-Proximal (="Broximal") Point Method: a New Algorithm,   Convergence Theory, and Applications</title><categories>math.OC cs.LG stat.ML</categories><comments>44 pages, 3 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Non-smooth and non-convex global optimization poses significant challenges across various applications, where standard gradient-based methods often struggle. We propose the Ball-Proximal Point Method, Broximal Point Method, or Ball Point Method (BPM) for short - a novel algorithmic framework inspired by the classical Proximal Point Method (PPM) (Rockafellar, 1976), which, as we show, sheds new light on several foundational optimization paradigms and phenomena, including non-convex and non-smooth optimization, acceleration, smoothing, adaptive stepsize selection, and trust-region methods. At the core of BPM lies the ball-proximal ("broximal") operator, which arises from the classical proximal operator by replacing the quadratic distance penalty by a ball constraint. Surprisingly, and in sharp contrast with the sublinear rate of PPM in the nonsmooth convex regime, we prove that BPM converges linearly and in a finite number of steps in the same regime. Furthermore, by introducing the concept of ball-convexity, we prove that BPM retains the same global convergence guarantees under weaker assumptions, making it a powerful tool for a broader class of potentially non-convex optimization problems. Just like PPM plays the role of a conceptual method inspiring the development of practically efficient algorithms and algorithmic elements, e.g., gradient descent, adaptive step sizes, acceleration (Ahn &amp; Sra, 2020), and "W" in AdamW (Zhuang et al., 2022), we believe that BPM should be understood in the same manner: as a blueprint and inspiration for further development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02006</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02006</id><created>2025-02-03</created><authors><author><keyname>Robinson</keyname><forenames>Benjamin D.</forenames></author><author><keyname>Latimer</keyname><forenames>Van</forenames></author></authors><title>Nonlinear Covariance Shrinkage for Hotelling's $T^2$ in High Dimension</title><categories>math.ST math.PR stat.ME stat.TH</categories><comments>41 pages, 9 figures</comments><msc-class>62H15</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we study the problem of comparing the means of a single observation and a reference sample in the presence of a common data covariance matrix, where the data dimension $p$ grows linearly with the number of samples $n$ and $p/n$ converges to a number between 0 and 1. The approach we take is to replace the sample covariance matrix with a nonlinear shrinkage estimator -- i.e., a matrix with the same eigenvectors -- in Hotelling's $T^2$ test. Current approaches of this sort typically assume that the data covariance matrix has a condition number or spiked rank that increases slowly with dimension. However, this assumption is ill-suited to data sets containing many strongly correlated background covariates, as often found in finance, genetics, and remote sensing. To address this problem we construct, using variational methods and new local random-matrix laws, a nonlinear covariance shrinkage method tailored to optimize detection performance across a broad range of spiked ranks and condition numbers. We then demonstrate, via both simulated and real-world data, that our method outperforms existing approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02020</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02020</id><created>2025-02-04</created><authors><author><keyname>Zhao</keyname><forenames>Yijia</forenames></author><author><keyname>Zhou</keyname><forenames>Qing</forenames></author></authors><title>Causal bandits with backdoor adjustment on unknown Gaussian DAGs</title><categories>cs.LG stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The causal bandit problem aims to sequentially learn the intervention that maximizes the expectation of a reward variable within a system governed by a causal graph. Most existing approaches assume prior knowledge of the graph structure, or impose unrealistically restrictive conditions on the graph. In this paper, we assume a Gaussian linear directed acyclic graph (DAG) over arms and the reward variable, and study the causal bandit problem when the graph structure is unknown. We identify backdoor adjustment sets for each arm using sequentially generated experimental and observational data during the decision process, which allows us to estimate causal effects and construct upper confidence bounds. By integrating estimates from both data sources, we develop a novel bandit algorithm, based on modified upper confidence bounds, to sequentially determine the optimal intervention. We establish both case-dependent and case-independent upper bounds on the cumulative regret for our algorithm, which improve upon the bounds of the standard multi-armed bandit algorithms. Our empirical study demonstrates its advantage over existing methods with respect to cumulative regret and computation time. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02032</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02032</id><created>2025-02-04</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author></authors><title>Heteroscedastic Double Bayesian Elastic Net</title><categories>stat.ME cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In many practical applications, regression models are employed to uncover relationships between predictors and a response variable, yet the common assumption of constant error variance is frequently violated. This issue is further compounded in high-dimensional settings where the number of predictors exceeds the sample size, necessitating regularization for effective estimation and variable selection. To address this problem, we propose the Heteroscedastic Double Bayesian Elastic Net (HDBEN), a novel framework that jointly models the mean and log-variance using hierarchical Bayesian priors incorporating both $\ell_1$ and $\ell_2$ penalties. Our approach simultaneously induces sparsity and grouping in the regression coefficients and variance parameters, capturing complex variance structures in the data. Theoretical results demonstrate that proposed HDBEN achieves posterior concentration, variable selection consistency, and asymptotic normality under mild conditions which justifying its behavior. Simulation studies further illustrate that HDBEN outperforms existing methods, particularly in scenarios characterized by heteroscedasticity and high dimensionality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02103</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02103</id><created>2025-02-04</created><authors><author><keyname>Oursland</keyname><forenames>Alan</forenames></author></authors><title>Neural Networks Learn Distance Metrics</title><categories>cs.LG cs.AI stat.ML</categories><comments>14 pages, 1 figures. Code and additional resources available at   https://github.com/alanoursland/neural_networks_learn_distance_metrics</comments><msc-class>68T07 (Primary) 62H12 (Secondary)</msc-class><acm-class>I.5.1; G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural networks may naturally favor distance-based representations, where smaller activations indicate closer proximity to learned prototypes. This contrasts with intensity-based approaches, which rely on activation magnitudes. To test this hypothesis, we conducted experiments with six MNIST architectural variants constrained to learn either distance or intensity representations. Our results reveal that the underlying representation affects model performance. We develop a novel geometric framework that explains these findings and introduce OffsetL2, a new architecture based on Mahalanobis distance equations, to further validate this framework. This work highlights the importance of considering distance-based learning in neural network design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02110</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02110</id><created>2025-02-04</created><authors><author><keyname>Venkatasubramaniam</keyname><forenames>Ashwini</forenames></author><author><keyname>Wolfson</keyname><forenames>Julian</forenames></author></authors><title>Multi-Study Causal Forest (MCF): A flexible framework for data borrowing   in the presence of varying treatment effect heterogeneity</title><categories>stat.ME</categories><comments>5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tailoring treatment assignment to specific individuals can improve the health outcomes, but a single study may offer inadequate information for this purpose. The ability to leverage information from an auxiliary data source deemed to be `most similar' to a primary data source has been shown to improve estimates of treatment effects. In this paper, we introduce a framework, the Multi-Study Causal Forest (MCF), to borrow individual patient-level data from an auxiliary data source in the presence of `varying sources' of treatment effect heterogeneity. We utilise a simulation study to demonstrate the superiority of the MCF in the presence of varying treatment allocation models (between-study heterogeneity) in addition to being able to account for the presence of within-study heterogeneity. This approach can combine data from randomised controlled trials, observational studies or a combination of both. We illustrate using Breast cancer data that the MCF performs favourably compared to an existing methodology in the presence of varying sources of (both between and within) heterogeneity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02121</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02121</id><created>2025-02-04</created><authors><author><keyname>Chew</keyname><forenames>Ruth Wan Theng</forenames></author><author><keyname>Nguyen</keyname><forenames>Quoc Phong</forenames></author><author><keyname>Low</keyname><forenames>Bryan Kian Hsiang</forenames></author></authors><title>BILBO: BILevel Bayesian Optimization</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bilevel optimization is characterized by a two-level optimization structure, where the upper-level problem is constrained by optimal lower-level solutions, and such structures are prevalent in real-world problems. The constraint by optimal lower-level solutions poses significant challenges, especially in noisy, constrained, and derivative-free settings, as repeating lower-level optimizations is sample inefficient and predicted lower-level solutions may be suboptimal. We present BILevel Bayesian Optimization (BILBO), a novel Bayesian optimization algorithm for general bilevel problems with blackbox functions, which optimizes both upper- and lower-level problems simultaneously, without the repeated lower-level optimization required by existing methods. BILBO samples from confidence-bounds based trusted sets, which bounds the suboptimality on the lower level. Moreover, BILBO selects only one function query per iteration, where the function query selection strategy incorporates the uncertainty of estimated lower-level solutions and includes a conditional reassignment of the query to encourage exploration of the lower-level objective. The performance of BILBO is theoretically guaranteed with a sublinear regret bound for commonly used kernels and is empirically evaluated on several synthetic and real-world problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02132</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02132</id><created>2025-02-04</created><authors><author><keyname>Cattaneo</keyname><forenames>Matias D.</forenames></author><author><keyname>Shigida</keyname><forenames>Boris</forenames></author></authors><title>How Memory in Optimization Algorithms Implicitly Modifies the Loss</title><categories>cs.LG cs.AI math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In modern optimization methods used in deep learning, each update depends on the history of previous iterations, often referred to as memory, and this dependence decays fast as the iterates go further into the past. For example, gradient descent with momentum has exponentially decaying memory through exponentially averaged past gradients. We introduce a general technique for identifying a memoryless algorithm that approximates an optimization algorithm with memory. It is obtained by replacing all past iterates in the update by the current one, and then adding a correction term arising from memory (also a function of the current iterate). This correction term can be interpreted as a perturbation of the loss, and the nature of this perturbation can inform how memory implicitly (anti-)regularizes the optimization dynamics. As an application of our theory, we find that Lion does not have the kind of implicit anti-regularization induced by memory that AdamW does, providing a theory-based explanation for Lion's better generalization performance recently documented. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02140</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02140</id><created>2025-02-04</created><authors><author><keyname>Gouverneur</keyname><forenames>Amaury</forenames></author><author><keyname>Gálvez</keyname><forenames>Borja Rodriguez</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>An Information-Theoretic Analysis of Thompson Sampling with Infinite   Action Spaces</title><categories>stat.ML cs.LG</categories><comments>5 pages, accepted to ICASSP</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the Bayesian regret of the Thompson Sampling algorithm for bandit problems, building on the information-theoretic framework introduced by Russo and Van Roy (2015). Specifically, it extends the rate-distortion analysis of Dong and Van Roy (2018), which provides near-optimal bounds for linear bandits. A limitation of these results is the assumption of a finite action space. We address this by extending the analysis to settings with infinite and continuous action spaces. Additionally, we specialize our results to bandit problems with expected rewards that are Lipschitz continuous with respect to the action space, deriving a regret bound that explicitly accounts for the complexity of the action space. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02148</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02148</id><created>2025-02-04</created><authors><author><keyname>Hemmens</keyname><forenames>Christopher</forenames></author><author><keyname>Robert-Nicoud</keyname><forenames>Stephan</forenames></author></authors><title>Can linear algebra create perfect knockoffs?</title><categories>stat.ME</categories><comments>11 pages</comments><journal-ref>Big Data and Internet of Things. BDIoT 2024. Lecture Notes in   Networks and Systems, vol 887. Springer, Cham</journal-ref><doi>10.1007/978-3-031-74491-4_81</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As new Model-X knockoff construction techniques are developed, primarily concerned with determining the correct conditional distribution from which to sample, we focus less on deriving the correct multivariate distribution and instead ask if ``perfect'' knockoffs can be constructed using linear algebra. Using mean absolute correlation between knockoffs and features as a measure of quality, we do produce knockoffs that are pseudo-perfect, however, the optimization algorithm is computationally very expensive. We outline a series of methods to significantly reduce the computation time of the algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02160</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02160</id><created>2025-02-04</created><authors><author><keyname>Pistone</keyname><forenames>Giovanni</forenames></author></authors><title>Information geometry of Bayes computations</title><categories>math.ST stat.TH</categories><comments>First version of a submitted conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Amari's Information Geometry is a dually affine formalism for parametric probability models. The literature proposes various nonparametric functional versions. Our approach uses classical Weyl's axioms so that the affine velocity of a one-parameter statistical model equals the classical Fisher's score. In the present note, we first offer a concise review of the notion of a statistical bundle as a set of couples of probability densities and Fisher's scores. Then, we show how the nonparametric dually affine setup deals with the basic Bayes and Kullback-Leibler divergence computations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02177</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02177</id><created>2025-02-04</created><authors><author><keyname>Pistone</keyname><forenames>Giovanni</forenames></author></authors><title>Affine calculus for constrained minima of the Kullback-Leibler   divergence</title><categories>math.ST stat.TH</categories><comments>First version of a submitted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper showcases general computations derived from our version of Amari's dually affine Information Geometry. We especially focus on statistics and machine learning algorithms involving the constrained minimization of the Kullback-Liebler divergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02206</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02206</id><created>2025-02-04</created><authors><author><keyname>Llorente</keyname><forenames>F.</forenames></author><author><keyname>Martino</keyname><forenames>L.</forenames></author><author><keyname>Delgado</keyname><forenames>D.</forenames></author></authors><title>Target-aware Bayesian inference via generalized thermodynamic   integration</title><categories>stat.CO cs.CE stat.ME</categories><journal-ref>Computational Statistics, Volume 38, Pages 2097-2119, year 2023</journal-ref><doi>10.1007/s00180-023-01358-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian inference, we are usually interested in the numerical approximation of integrals that are posterior expectations or marginal likelihoods (a.k.a., Bayesian evidence). In this paper, we focus on the computation of the posterior expectation of a function $f(\x)$. We consider a \emph{target-aware} scenario where $f(\x)$ is known in advance and can be exploited in order to improve the estimation of the posterior expectation. In this scenario, this task can be reduced to perform several independent marginal likelihood estimation tasks. The idea of using a path of tempered posterior distributions has been widely applied in the literature for the computation of marginal likelihoods. Thermodynamic integration, path sampling and annealing importance sampling are well-known examples of algorithms belonging to this family of methods. In this work, we introduce a generalized thermodynamic integration (GTI) scheme which is able to perform a target-aware Bayesian inference, i.e., GTI can approximate the posterior expectation of a given function. Several scenarios of application of GTI are discussed and different numerical simulations are provided. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02213</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02213</id><created>2025-02-04</created><authors><author><keyname>Rasines</keyname><forenames>Daniel García</forenames></author><author><keyname>Young</keyname><forenames>G. Alastair</forenames></author></authors><title>Sampling models for selective inference</title><categories>math.ST stat.TH</categories><comments>16 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper explores the challenges of constructing suitable inferential models in scenarios where the parameter of interest is determined in light of the data, such as regression after variable selection. Two compelling arguments for conditioning converge in this context, whose interplay can introduce ambiguity in the choice of conditioning strategy: the Conditionality Principle, from classical statistics, and the `condition on selection' paradigm, central to selective inference. We discuss two general principles that can be employed to resolve this ambiguity in some recurrent contexts. The first one refers to the consideration of how information is processed at the selection stage. The second one concerns an exploration of ancillarity in the presence of selection. We demonstrate that certain notions of ancillarity are preserved after conditioning on the selection event, supporting the application of the Conditionality Principle. We illustrate these concepts through examples and provide guidance on the adequate inferential approach in some common scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02216</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02216</id><created>2025-02-04</created><authors><author><keyname>Chen</keyname><forenames>Dexiong</forenames></author><author><keyname>Krimmel</keyname><forenames>Markus</forenames></author><author><keyname>Borgwardt</keyname><forenames>Karsten</forenames></author></authors><title>Flatten Graphs as Sequences: Transformers are Scalable Graph Generators</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce AutoGraph, a novel autoregressive framework for generating large attributed graphs using decoder-only transformers. At the core of our approach is a reversible "flattening" process that transforms graphs into random sequences. By sampling and learning from these sequences, AutoGraph enables transformers to model and generate complex graph structures in a manner akin to natural language. In contrast to diffusion models that rely on computationally intensive node features, our approach operates exclusively on these sequences. The sampling complexity and sequence length scale linearly with the number of edges, making AutoGraph highly scalable for generating large sparse graphs. Empirically, AutoGraph achieves state-of-the-art performance across diverse synthetic and molecular graph generation benchmarks, while delivering a 100-fold generation and a 3-fold training speedup compared to leading diffusion models. Additionally, it demonstrates promising transfer capabilities and supports substructure-conditioned generation without additional fine-tuning. By extending language modeling techniques to graph generation, this work paves the way for developing graph foundation models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02221</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02221</id><created>2025-02-04</created><authors><author><keyname>Němeček</keyname><forenames>Jiří</forenames></author><author><keyname>Kozdoba</keyname><forenames>Mark</forenames></author><author><keyname>Kryvoviaz</keyname><forenames>Illia</forenames></author><author><keyname>Pevný</keyname><forenames>Tomáš</forenames></author><author><keyname>Mareček</keyname><forenames>Jakub</forenames></author></authors><title>Bias Detection via Maximum Subgroup Discrepancy</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bias evaluation is fundamental to trustworthy AI, both in terms of checking data quality and in terms of checking the outputs of AI systems. In testing data quality, for example, one may study a distance of a given dataset, viewed as a distribution, to a given ground-truth reference dataset. However, classical metrics, such as the Total Variation and the Wasserstein distances, are known to have high sample complexities and, therefore, may fail to provide meaningful distinction in many practical scenarios.   In this paper, we propose a new notion of distance, the Maximum Subgroup Discrepancy (MSD). In this metric, two distributions are close if, roughly, discrepancies are low for all feature subgroups. While the number of subgroups may be exponential, we show that the sample complexity is linear in the number of features, thus making it feasible for practical applications. Moreover, we provide a practical algorithm for the evaluation of the distance, based on Mixed-integer optimization (MIO). We also note that the proposed distance is easily interpretable, thus providing clearer paths to fixing the biases once they have been identified. It also provides guarantees for all subgroups. Finally, we empirically evaluate, compare with other metrics, and demonstrate the above properties of MSD on real-world datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02233</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02233</id><created>2025-02-04</created><authors><author><keyname>Sahoo</keyname><forenames>Satyajeet</forenames></author><author><keyname>Maiti</keyname><forenames>Jhareswar</forenames></author></authors><title>Variance-Adjusted Cosine Distance as Similarity Metric</title><categories>stat.ML cs.LG</categories><comments>6 Pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Cosine similarity is a popular distance measure that measures the similarity between two vectors in the inner product space. It is widely used in many data classification algorithms like K-Nearest Neighbors, Clustering etc. This study demonstrates limitations of application of cosine similarity. Particularly, this study demonstrates that traditional cosine similarity metric is valid only in the Euclidean space, whereas the original data resides in a random variable space. When there is variance and correlation in the data, then cosine distance is not a completely accurate measure of similarity. While new similarity and distance metrics have been developed to make up for the limitations of cosine similarity, these metrics are used as substitutes to cosine distance, and do not make modifications to cosine distance to overcome its limitations. Subsequently, we propose a modified cosine similarity metric, where cosine distance is adjusted by variance-covariance of the data. Application of variance-adjusted cosine distance gives better similarity performance compared to traditional cosine distance. KNN modelling on the Wisconsin Breast Cancer Dataset is performed using both traditional and modified cosine similarity measures and compared. The modified formula shows 100% test accuracy on the data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02270</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02270</id><created>2025-02-04</created><authors><author><keyname>Alcalde</keyname><forenames>Albert</forenames></author><author><keyname>Fantuzzi</keyname><forenames>Giovanni</forenames></author><author><keyname>Zuazua</keyname><forenames>Enrique</forenames></author></authors><title>Exact Sequence Classification with Hardmax Transformers</title><categories>cs.LG math.OC stat.ML</categories><comments>14 pages, 5 figures. Funded by the European Union (Horizon Europe   MSCA project ModConFlex, grant number 101073558)</comments><msc-class>68T07, 68T50</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We prove that hardmax attention transformers perfectly classify datasets of $N$ labeled sequences in $\mathbb{R}^d$, $d\geq 2$. Specifically, given $N$ sequences with an arbitrary but finite length in $\mathbb{R}^d$, we construct a transformer with $\mathcal{O}(N)$ blocks and $\mathcal{O}(Nd)$ parameters perfectly classifying this dataset. Our construction achieves the best complexity estimate to date, independent of the length of the sequences, by innovatively alternating feed-forward and self-attention layers and by capitalizing on the clustering effect inherent to the latter. Our novel constructive method also uses low-rank parameter matrices within the attention mechanism, a common practice in real-life transformer implementations. Consequently, our analysis holds twofold significance: it substantially advances the mathematical theory of transformers and it rigorously justifies their exceptional real-world performance in sequence classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02296</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02296</id><created>2025-02-04</created><authors><author><keyname>Rakitzis</keyname><forenames>Athanasios C.</forenames></author></authors><title>On The Performance of a Two-Sided Shewhart Chart for Continuous   Proportions with Estimated Parameters</title><categories>stat.ME stat.AP</categories><comments>33 pages, 13 figures</comments><msc-class>62P30</msc-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  During the recent years there was an increased interest in studying the performance of different types of control charts, under various distributional models for continuous proportions, such as percentages and rates. In this work we consider the Kumaraswamy distribution, a popular and flexible distributional model for data in the unit interval (0,1) and investigate further the properties of a two-sided chart for individual observations for monitoring these types of processes, when the process parameters are unknown. Specifically, using Monte Carlo simulation, we evaluate the performance of the chart under a conditional perspective and provide empirical rules on how to select the appropriate size for the Phase I sample. In addition, we explore possible adjustments on the control limits of the chart, which take into account the available Phase I sample. The performance of the chart is also investigated for several out-of-control situations. The results show that for small and moderate size Phase I samples, practitioners have to choose whether they prefer a guaranteed in-control performance or an improved out-of-control performance. The implementation of the considered methods in practice is discussed via two numerical examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02305</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02305</id><created>2025-02-04</created><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Information-Theoretic Proofs for Diffusion Sampling</title><categories>stat.ML cs.IT cs.LG math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper provides an elementary, self-contained analysis of diffusion-based sampling methods for generative modeling. In contrast to existing approaches that rely on continuous-time processes and then discretize, our treatment works directly with discrete-time stochastic processes and yields precise non-asymptotic convergence guarantees under broad assumptions. The key insight is to couple the sampling process of interest with an idealized comparison process that has an explicit Gaussian-convolution structure. We then leverage simple identities from information theory, including the I-MMSE relationship, to bound the discrepancy (in terms of the Kullback-Leibler divergence) between these two discrete-time processes. In particular, we show that, if the diffusion step sizes are chosen sufficiently small and one can approximate certain conditional mean estimators well, then the sampling distribution is provably close to the target distribution. Our results also provide a transparent view on how to accelerate convergence by introducing additional randomness in each step to match higher order moments in the comparison process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02331</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02331</id><created>2025-02-04</created><authors><author><keyname>Tsoy</keyname><forenames>Nikita</forenames></author><author><keyname>Kirev</keyname><forenames>Ivan</forenames></author><author><keyname>Rahimiyazdi</keyname><forenames>Negin</forenames></author><author><keyname>Konstantinov</keyname><forenames>Nikola</forenames></author></authors><title>On the Impact of Performative Risk Minimization for Binary Random   Variables</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Performativity, the phenomenon where outcomes are influenced by predictions, is particularly prevalent in social contexts where individuals strategically respond to a deployed model. In order to preserve the high accuracy of machine learning models under distribution shifts caused by performativity, Perdomo et al. (2020) introduced the concept of performative risk minimization (PRM). While this framework ensures model accuracy, it overlooks the impact of the PRM on the underlying distributions and the predictions of the model. In this paper, we initiate the analysis of the impact of PRM, by studying performativity for a sequential performative risk minimization problem with binary random variables and linear performative shifts. We formulate two natural measures of impact. In the case of full information, where the distribution dynamics are known, we derive explicit formulas for the PRM solution and our impact measures. In the case of partial information, we provide performative-aware statistical estimators, as well as simulations. Our analysis contrasts PRM to alternatives that do not model data shift and indicates that PRM can have amplified side effects compared to such methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02363</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02363</id><created>2025-02-04</created><authors><author><keyname>Cortinovis</keyname><forenames>Stefano</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>FAB-PPI: Frequentist, Assisted by Bayes, Prediction-Powered Inference</title><categories>stat.ML cs.LG</categories><comments>28 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction-powered inference (PPI) enables valid statistical inference by combining experimental data with machine learning predictions. When a sufficient number of high-quality predictions is available, PPI results in more accurate estimates and tighter confidence intervals than traditional methods. In this paper, we propose to inform the PPI framework with prior knowledge on the quality of the predictions. The resulting method, which we call frequentist, assisted by Bayes, PPI (FAB-PPI), improves over PPI when the observed prediction quality is likely under the prior, while maintaining its frequentist guarantees. Furthermore, when using heavy-tailed priors, FAB-PPI adaptively reverts to standard PPI in low prior probability regions. We demonstrate the benefits of FAB-PPI in real and synthetic examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02364</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02364</id><created>2025-02-04</created><authors><author><keyname>Baillie</keyname><forenames>Nils</forenames></author><author><keyname>Van Biesbroeck</keyname><forenames>Antoine</forenames></author><author><keyname>Gauchy</keyname><forenames>Clément</forenames></author></authors><title>Variational inference for approximate reference priors using neural   networks</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian statistics, the choice of the prior can have an important influence on the posterior and the parameter estimation, especially when few data samples are available. To limit the added subjectivity from a priori information, one can use the framework of reference priors. However, computing such priors is a difficult task in general. We develop in this paper a flexible algorithm based on variational inference which computes approximations of reference priors from a set of parametric distributions using neural networks. We also show that our algorithm can retrieve reference priors when constraints are specified in the optimization problem to ensure the solution is proper. We propose a simple method to recover a relevant approximation of the parametric posterior distribution using Markov Chain Monte Carlo (MCMC) methods even if the density function of the parametric prior is not known in general. Numerical experiments on several statistical models of increasing complexity are presented. We show the usefulness of this approach by recovering the target distribution. The performance of the algorithm is evaluated on the prior distributions as well as the posterior distributions, jointly using variational inference and MCMC sampling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02369</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02369</id><created>2025-02-04</created><authors><author><keyname>Brinks</keyname><forenames>Ralph</forenames></author></authors><title>Estimation of the incidence rate and mortality rate ratio for chronic   conditions based on aggregated current status data</title><categories>stat.AP q-bio.PE</categories><comments>10 pages, 3 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that the transition rates of the illness-death model (IDM) for chronic conditions are related to the percentages of people in the states by a three-dimensional system of differential equations [Bri24]. The aim of this article is to introduce a method to estimate the age-specific incidence rate together with the mortality rate ratio from aggregated current status (ACS) data. By ACS data we mean counts of (non-necessarily different) people in the three states of the IDM at different points in time. ACS data stem from epidemiological studies where only current disease status and vital status data need to be collected without following-up people (as, for example, in cohort studies). As an application, we use the theory in a simulation study about diabetes in Germany with 600 study subjects at eleven repeated cross-sections each of which with 50% participation quote. Special focus is given to stochastic dependency of the sampled participants. We find a good agreement between the estimates and the input parameters used for the simulation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02379</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02379</id><created>2025-02-04</created><authors><author><keyname>Coupette</keyname><forenames>Corinna</forenames></author><author><keyname>Wayland</keyname><forenames>Jeremy</forenames></author><author><keyname>Simons</keyname><forenames>Emily</forenames></author><author><keyname>Rieck</keyname><forenames>Bastian</forenames></author></authors><title>No Metric to Rule Them All: Toward Principled Evaluations of   Graph-Learning Datasets</title><categories>cs.LG cs.SI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Benchmark datasets have proved pivotal to the success of graph learning, and good benchmark datasets are crucial to guide the development of the field. Recent research has highlighted problems with graph-learning datasets and benchmarking practices -- revealing, for example, that methods which ignore the graph structure can outperform graph-based approaches on popular benchmark datasets. Such findings raise two questions: (1) What makes a good graph-learning dataset, and (2) how can we evaluate dataset quality in graph learning? Our work addresses these questions. As the classic evaluation setup uses datasets to evaluate models, it does not apply to dataset evaluation. Hence, we start from first principles. Observing that graph-learning datasets uniquely combine two modes -- the graph structure and the node features -- , we introduce RINGS, a flexible and extensible mode-perturbation framework to assess the quality of graph-learning datasets based on dataset ablations -- i.e., by quantifying differences between the original dataset and its perturbed representations. Within this framework, we propose two measures -- performance separability and mode complementarity -- as evaluation tools, each assessing, from a distinct angle, the capacity of a graph dataset to benchmark the power and efficacy of graph-learning methods. We demonstrate the utility of our framework for graph-learning dataset evaluation in an extensive set of experiments and derive actionable recommendations for improving the evaluation of graph-learning methods. Our work opens new research directions in data-centric graph learning, and it constitutes a first step toward the systematic evaluation of evaluations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02392</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02392</id><created>2025-02-04</created><authors><author><keyname>Aloni</keyname><forenames>Ofek</forenames></author><author><keyname>Perelman</keyname><forenames>Gal</forenames></author><author><keyname>Fishbain</keyname><forenames>Barak</forenames></author></authors><title>Synthetic Random Environmental Time Series Generation with Similarity   Control, Preserving Original Signal's Statistical Characteristics</title><categories>stat.ME</categories><comments>Accepted for publication 27 November 2024. Code available at   https://github.com/Al-Ofek/stsg.git</comments><journal-ref>Environmental Modelling &amp; Software, Volume 185, February 2025,   106283</journal-ref><doi>10.1016/j.envsoft.2024.106283</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Synthetic datasets are widely used in many applications, such as missing data imputation, examining non-stationary scenarios, in simulations, training data-driven models, and analyzing system robustness. Typically, synthetic data are based on historical data obtained from the observed system. The data needs to represent a specific behavior of the system, yet be new and diverse enough so that the system is challenged with a broad range of inputs. This paper presents a method, based on discrete Fourier transform, for generating synthetic time series with similar statistical moments for any given signal. The suggested method makes it possible to control the level of similarity between the given signal and the generated synthetic signals. Proof shows analytically that this method preserves the first two statistical moments of the input signal, and its autocorrelation function. The method is compared to known methods, ARMA, GAN, and CoSMoS. A large variety of environmental datasets with different temporal resolutions, and from different domains are used, testing the generality and flexibility of the method. A Python library implementing this method is made available as open-source software. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02397</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02397</id><created>2025-02-04</created><authors><author><keyname>Calvi</keyname><forenames>Annalisa</forenames></author><author><keyname>Laa</keyname><forenames>Ursula</forenames></author><author><keyname>Cook</keyname><forenames>Dianne</forenames></author></authors><title>Is this normal? A new projection pursuit index to assess a sample   against a multivariate null distribution</title><categories>stat.ME stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many data problems contain some reference or normal conditions, upon which to compare newly collected data. This scenario occurs in data collected as part of clinical trials to detect adverse events, or for measuring climate change against historical norms. The data is typically multivariate, and often the normal ranges are specified by a multivariate normal distribution. The work presented in this paper develops methods to compare the new sample against the reference distribution with high-dimensional visualisation. It uses a projection pursuit guided tour to produce a sequence of low-dimensional projections steered towards those where the new sample is most different from the reference. A new projection pursuit index is defined for this purpose. The tour visualisation also includes drawing of the projected ellipse, which is computed analytically, corresponding to the reference distribution. The methods are implemented in the R package, tourr. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02407</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02407</id><created>2025-02-04</created><authors><author><keyname>Singh</keyname><forenames>Sidak Pal</forenames></author><author><keyname>Mobahi</keyname><forenames>Hossein</forenames></author><author><keyname>Agarwala</keyname><forenames>Atish</forenames></author><author><keyname>Dauphin</keyname><forenames>Yann</forenames></author></authors><title>Avoiding spurious sharpness minimization broadens applicability of SAM</title><categories>cs.LG cs.CL stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Curvature regularization techniques like Sharpness Aware Minimization (SAM) have shown great promise in improving generalization on vision tasks. However, we find that SAM performs poorly in domains like natural language processing (NLP), often degrading performance -- even with twice the compute budget. We investigate the discrepancy across domains and find that in the NLP setting, SAM is dominated by regularization of the logit statistics -- instead of improving the geometry of the function itself. We use this observation to develop an alternative algorithm we call Functional-SAM, which regularizes curvature only through modification of the statistics of the overall function implemented by the neural network, and avoids spurious minimization through logit manipulation. Furthermore, we argue that preconditioning the SAM perturbation also prevents spurious minimization, and when combined with Functional-SAM, it gives further improvements. Our proposed algorithms show improved performance over AdamW and SAM baselines when trained for an equal number of steps, in both fixed-length and Chinchilla-style training settings, at various model scales (including billion-parameter scale). On the whole, our work highlights the importance of more precise characterizations of sharpness in broadening the applicability of curvature regularization to large language models (LLMs). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02410</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02410</id><created>2025-02-04</created><authors><author><keyname>Schuchardt</keyname><forenames>Jan</forenames></author><author><keyname>Dalirrooyfard</keyname><forenames>Mina</forenames></author><author><keyname>Guzelkabaagac</keyname><forenames>Jed</forenames></author><author><keyname>Schneider</keyname><forenames>Anderson</forenames></author><author><keyname>Nevmyvaka</keyname><forenames>Yuriy</forenames></author><author><keyname>Günnemann</keyname><forenames>Stephan</forenames></author></authors><title>Privacy Amplification by Structured Subsampling for Deep Differentially   Private Time Series Forecasting</title><categories>cs.LG cs.CR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with timeseries-specific tasks like forecasting, since they rely on the privacy amplification attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this structured subsampling to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02430</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02430</id><created>2025-02-04</created><authors><author><keyname>Busa-Fekete</keyname><forenames>Róbert</forenames></author><author><keyname>Zimmert</keyname><forenames>Julian</forenames></author><author><keyname>György</keyname><forenames>András</forenames></author><author><keyname>Qiu</keyname><forenames>Linhai</forenames></author><author><keyname>Sung</keyname><forenames>Tzu-Wei</forenames></author><author><keyname>Shen</keyname><forenames>Hao</forenames></author><author><keyname>Choi</keyname><forenames>Hyomin</forenames></author><author><keyname>Subramaniam</keyname><forenames>Sharmila</forenames></author><author><keyname>Xiao</keyname><forenames>Li</forenames></author></authors><title>A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals</title><categories>stat.ML cs.IR cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Web refresh crawling is the problem of keeping a cache of web pages fresh, that is, having the most recent copy available when a page is requested, given a limited bandwidth available to the crawler. Under the assumption that the change and request events, resp., to each web page follow independent Poisson processes, the optimal scheduling policy was derived by Azar et al. 2018. In this paper, we study an extension of this problem where side information indicating content changes, such as various types of web pings, for example, signals from sitemaps, content delivery networks, etc., is available. Incorporating such side information into the crawling policy is challenging, because (i) the signals can be noisy with false positive events and with missing change events; and (ii) the crawler should achieve a fair performance over web pages regardless of the quality of the side information, which might differ from web page to web page. We propose a scalable crawling algorithm which (i) uses the noisy side information in an optimal way under mild assumptions; (ii) can be deployed without heavy centralized computation; (iii) is able to crawl web pages at a constant total rate without spikes in the total bandwidth usage over any time interval, and automatically adapt to the new optimal solution when the total bandwidth changes without centralized computation. Experiments clearly demonstrate the versatility of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02450</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02450</id><created>2025-02-04</created><authors><author><keyname>Laplante</keyname><forenames>William</forenames></author><author><keyname>Altamirano</keyname><forenames>Matias</forenames></author><author><keyname>Duncan</keyname><forenames>Andrew</forenames></author><author><keyname>Knoblauch</keyname><forenames>Jeremias</forenames></author><author><keyname>Briol</keyname><forenames>François-Xavier</forenames></author></authors><title>Robust and Conjugate Spatio-Temporal Gaussian Processes</title><categories>stat.CO stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  State-space formulations allow for Gaussian process (GP) regression with linear-in-time computational cost in spatio-temporal settings, but performance typically suffers in the presence of outliers. In this paper, we adapt and specialise the robust and conjugate GP (RCGP) framework of Altamirano et al. (2024) to the spatio-temporal setting. In doing so, we obtain an outlier-robust spatio-temporal GP with a computational cost comparable to classical spatio-temporal GPs. We also overcome the three main drawbacks of RCGPs: their unreliable performance when the prior mean is chosen poorly, their lack of reliable uncertainty quantification, and the need to carefully select a hyperparameter by hand. We study our method extensively in finance and weather forecasting applications, demonstrating that it provides a reliable approach to spatio-temporal modelling in the presence of outliers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02463</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02463</id><created>2025-02-04</created><authors><author><keyname>Whittle</keyname><forenames>George</forenames></author><author><keyname>Ziomek</keyname><forenames>Juliusz</forenames></author><author><keyname>Rawling</keyname><forenames>Jacob</forenames></author><author><keyname>Osborne</keyname><forenames>Michael A</forenames></author></authors><title>Distribution Transformers: Fast Approximate Bayesian Inference With   On-The-Fly Prior Adaptation</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  While Bayesian inference provides a principled framework for reasoning under uncertainty, its widespread adoption is limited by the intractability of exact posterior computation, necessitating the use of approximate inference. However, existing methods are often computationally expensive, or demand costly retraining when priors change, limiting their utility, particularly in sequential inference problems such as real-time sensor fusion. To address these challenges, we introduce the Distribution Transformer -- a novel architecture that can learn arbitrary distribution-to-distribution mappings. Our method can be trained to map a prior to the corresponding posterior, conditioned on some dataset -- thus performing approximate Bayesian inference. Our novel architecture represents a prior distribution as a (universally-approximating) Gaussian Mixture Model (GMM), and transforms it into a GMM representation of the posterior. The components of the GMM attend to each other via self-attention, and to the datapoints via cross-attention. We demonstrate that Distribution Transformers both maintain flexibility to vary the prior, and significantly reduces computation times-from minutes to milliseconds-while achieving log-likelihood performance on par with or superior to existing approximate inference methods across tasks such as sequential inference, quantum system parameter inference, and Gaussian Process predictive posterior inference with hyperpriors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02472</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02472</id><created>2025-02-04</created><authors><author><keyname>Bartosh</keyname><forenames>Grigory</forenames></author><author><keyname>Vetrov</keyname><forenames>Dmitry</forenames></author><author><keyname>Naesseth</keyname><forenames>Christian A.</forenames></author></authors><title>SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic   Differential Equations</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Latent Stochastic Differential Equation (SDE) is a powerful tool for time series and sequence modeling. However, training Latent SDEs typically relies on adjoint sensitivity methods, which depend on simulation and backpropagation through approximate SDE solutions, which limit scalability. In this work, we propose SDE Matching, a new simulation-free method for training Latent SDEs. Inspired by modern Score- and Flow Matching algorithms for learning generative dynamics, we extend these ideas to the domain of stochastic dynamics for time series and sequence modeling, eliminating the need for costly numerical simulations. Our results demonstrate that SDE Matching achieves performance comparable to adjoint sensitivity methods while drastically reducing computational complexity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02483</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02483</id><created>2025-02-04</created><authors><author><keyname>De Bortoli</keyname><forenames>Valentin</forenames></author><author><keyname>Galashov</keyname><forenames>Alexandre</forenames></author><author><keyname>Guntupalli</keyname><forenames>J. Swaroop</forenames></author><author><keyname>Zhou</keyname><forenames>Guangyao</forenames></author><author><keyname>Murphy</keyname><forenames>Kevin</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Doucet</keyname><forenames>Arnaud</forenames></author></authors><title>Distributional Diffusion Models with Scoring Rules</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion models generate high-quality synthetic data. They operate by defining a continuous-time forward process which gradually adds Gaussian noise to data until fully corrupted. The corresponding reverse process progressively "denoises" a Gaussian sample into a sample from the data distribution. However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process. This is expensive and has motivated the development of many acceleration methods. We propose to accomplish sample generation by learning the posterior {\em distribution} of clean data samples given their noisy versions, instead of only the mean of this distribution. This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output. This is accomplished by replacing the standard regression loss used to estimate conditional means with a scoring rule. We validate our method on image and robot trajectory generation, where we consistently outperform standard diffusion models at few discretization steps. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02486</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02486</id><created>2025-02-04</created><authors><author><keyname>Ye</keyname><forenames>Chenlu</forenames></author><author><keyname>Jin</keyname><forenames>Yujia</forenames></author><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Catoni Contextual Bandits are Robust to Heavy-tailed Rewards</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Typical contextual bandit algorithms assume that the rewards at each round lie in some fixed range $[0, R]$, and their regret scales polynomially with this reward range $R$. However, many practical scenarios naturally involve heavy-tailed rewards or rewards where the worst-case range can be substantially larger than the variance. In this paper, we develop an algorithmic approach building on Catoni's estimator from robust statistics, and apply it to contextual bandits with general function approximation. When the variance of the reward at each round is known, we use a variance-weighted regression approach and establish a regret bound that depends only on the cumulative reward variance and logarithmically on the reward range $R$ as well as the number of rounds $T$. For the unknown-variance case, we further propose a careful peeling-based algorithm and remove the need for cumbersome variance estimation. With additional dependence on the fourth moment, our algorithm also enjoys a variance-based bound with logarithmic reward-range dependence. Moreover, we demonstrate the optimality of the leading-order term in our regret bound through a matching lower bound. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02496</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02496</id><created>2025-02-04</created><authors><author><keyname>Kolb</keyname><forenames>Chris</forenames></author><author><keyname>Weber</keyname><forenames>Tobias</forenames></author><author><keyname>Bischl</keyname><forenames>Bernd</forenames></author><author><keyname>Rügamer</keyname><forenames>David</forenames></author></authors><title>Deep Weight Factorization: Sparse Learning Through the Lens of   Artificial Symmetries</title><categories>cs.LG stat.ML</categories><comments>accepted at ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse regularization techniques are well-established in machine learning, yet their application in neural networks remains challenging due to the non-differentiability of penalties like the $L_1$ norm, which is incompatible with stochastic gradient descent. A promising alternative is shallow weight factorization, where weights are decomposed into two factors, allowing for smooth optimization of $L_1$-penalized neural networks by adding differentiable $L_2$ regularization to the factors. In this work, we introduce deep weight factorization, extending previous shallow approaches to more than two factors. We theoretically establish equivalence of our deep factorization with non-convex sparse regularization and analyze its impact on training dynamics and optimization. Due to the limitations posed by standard training practices, we propose a tailored initialization scheme and identify important learning rate requirements necessary for training factorized networks. We demonstrate the effectiveness of our deep weight factorization through experiments on various architectures and datasets, consistently outperforming its shallow counterpart and widely used pruning methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02516</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02516</id><created>2025-02-04</created><authors><author><keyname>Russo</keyname><forenames>Alessio</forenames></author><author><keyname>Pacchiano</keyname><forenames>Aldo</forenames></author></authors><title>Adaptive Exploration for Multi-Reward Multi-Policy Evaluation</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the policy evaluation problem in an online multi-reward multi-policy discounted setting, where multiple reward functions must be evaluated simultaneously for different policies. We adopt an $(\epsilon,\delta)$-PAC perspective to achieve $\epsilon$-accurate estimates with high confidence across finite or convex sets of rewards, a setting that has not been investigated in the literature. Building on prior work on Multi-Reward Best Policy Identification, we adapt the MR-NaS exploration scheme to jointly minimize sample complexity for evaluating different policies across different reward sets. Our approach leverages an instance-specific lower bound revealing how the sample complexity scales with a measure of value deviation, guiding the design of an efficient exploration policy. Although computing this bound entails a hard non-convex optimization, we propose an efficient convex approximation that holds for both finite and convex reward sets. Experiments in tabular domains demonstrate the effectiveness of this adaptive exploration scheme. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02529</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02529</id><created>2025-02-04</created><authors><author><keyname>Hult</keyname><forenames>Henrik</forenames></author><author><keyname>Lindhe</keyname><forenames>Adam</forenames></author><author><keyname>Nyquist</keyname><forenames>Pierre</forenames></author><author><keyname>Wu</keyname><forenames>Guo-Jhen</forenames></author></authors><title>A weak convergence approach to large deviations for stochastic   approximations</title><categories>math.PR math.OC stat.ML</categories><comments>60 p</comments><msc-class>60F10, 62L20, 60J20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of stochastic approximations form the theoretical foundation for studying convergence properties of many popular recursive learning algorithms in statistics, machine learning and statistical physics. Large deviations for stochastic approximations provide asymptotic estimates of the probability that the learning algorithm deviates from its expected path, given by a limit ODE, and the large deviation rate function gives insights to the most likely way that such deviations occur.   In this paper we prove a large deviation principle for general stochastic approximations with state-dependent Markovian noise and decreasing step size. Using the weak convergence approach to large deviations, we generalize previous results for stochastic approximations and identify the appropriate scaling sequence for the large deviation principle. We also give a new representation for the rate function, in which the rate function is expressed as an action functional involving the family of Markov transition kernels. Examples of learning algorithms that are covered by the large deviation principle include stochastic gradient descent, persistent contrastive divergence and the Wang-Landau algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02531</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02531</id><created>2025-02-04</created><updated>2025-02-05</updated><authors><author><keyname>Bordelon</keyname><forenames>Blake</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Deep Linear Network Training Dynamics from Random Initialization: Data,   Width, Depth, and Hyperparameter Transfer</title><categories>cs.LG cond-mat.dis-nn stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data. Our theory captures the ``wider is better" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width. We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\sqrt{\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration. Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02552</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02552</id><created>2025-02-04</created><authors><author><keyname>Zhu</keyname><forenames>Haonan</forenames></author><author><keyname>Goncalves</keyname><forenames>Andre R.</forenames></author><author><keyname>Valdes</keyname><forenames>Camilo</forenames></author><author><keyname>Ranganathan</keyname><forenames>Hiranmayi</forenames></author><author><keyname>Zhang</keyname><forenames>Boya</forenames></author><author><keyname>Martí</keyname><forenames>Jose Manuel</forenames></author><author><keyname>Kok</keyname><forenames>Car Reen</forenames></author><author><keyname>Borucki</keyname><forenames>Monica K.</forenames></author><author><keyname>Mulakken</keyname><forenames>Nisha J.</forenames></author><author><keyname>Thissen</keyname><forenames>James B.</forenames></author><author><keyname>Jaing</keyname><forenames>Crystal</forenames></author><author><keyname>Hero</keyname><forenames>Alfred</forenames></author><author><keyname>Be</keyname><forenames>Nicholas A.</forenames></author></authors><title>Hierarchical Sparse Bayesian Multitask Model with Scalable Inference for   Microbiome Analysis</title><categories>cs.LG q-bio.BM stat.AP stat.CO stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a hierarchical Bayesian multitask learning model that is applicable to the general multi-task binary classification learning problem where the model assumes a shared sparsity structure across different tasks. We derive a computationally efficient inference algorithm based on variational inference to approximate the posterior distribution. We demonstrate the potential of the new approach on various synthetic datasets and for predicting human health status based on microbiome profile. Our analysis incorporates data pooled from multiple microbiome studies, along with a comprehensive comparison with other benchmark methods. Results in synthetic datasets show that the proposed approach has superior support recovery property when the underlying regression coefficients share a common sparsity structure across different tasks. Our experiments on microbiome classification demonstrate the utility of the method in extracting informative taxa while providing well-calibrated predictions with uncertainty quantification and achieving competitive performance in terms of prediction metrics. Notably, despite the heterogeneity of the pooled datasets (e.g., different experimental objectives, laboratory setups, sequencing equipment, patient demographics), our method delivers robust results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02561</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02561</id><created>2025-02-04</created><authors><author><keyname>Kiyani</keyname><forenames>Shayan</forenames></author><author><keyname>Pappas</keyname><forenames>George</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Hassani</keyname><forenames>Hamed</forenames></author></authors><title>Decision Theoretic Foundations for Conformal Prediction: Optimal   Uncertainty Quantification for Risk-Averse Agents</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions in ways that can usefully inform downstream action. This interface between prediction uncertainty and decision-making is especially important in risk-sensitive domains, such as medicine. In this paper, we develop decision-theoretic foundations that connect uncertainty quantification using prediction sets with risk-averse decision-making. Specifically, we answer three fundamental questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. Answering these questions naturally leads to an algorithm, Risk-Averse Calibration (RAC), which follows a provably optimal design for deriving action policies from predictions. RAC is designed to be both practical-capable of leveraging the quality of predictions in a black-box manner to enhance downstream utility-and safe-adhering to a user-defined risk threshold and optimizing the corresponding risk quantile of the user's downstream utility. Finally, we experimentally demonstrate the significant advantages of RAC in applications such as medical diagnosis and recommendation systems. Specifically, we show that RAC achieves a substantially improved trade-off between safety and utility, offering higher utility compared to existing methods while maintaining the safety guarantee. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02562</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02562</id><created>2025-02-04</created><authors><author><keyname>Schenck</keyname><forenames>Connor</forenames></author><author><keyname>Reid</keyname><forenames>Isaac</forenames></author><author><keyname>Jacob</keyname><forenames>Mithun George</forenames></author><author><keyname>Bewley</keyname><forenames>Alex</forenames></author><author><keyname>Ainslie</keyname><forenames>Joshua</forenames></author><author><keyname>Rendleman</keyname><forenames>David</forenames></author><author><keyname>Jain</keyname><forenames>Deepali</forenames></author><author><keyname>Sharma</keyname><forenames>Mohit</forenames></author><author><keyname>Dubey</keyname><forenames>Avinava</forenames></author><author><keyname>Wahid</keyname><forenames>Ayzaan</forenames></author><author><keyname>Singh</keyname><forenames>Sumeet</forenames></author><author><keyname>Wagner</keyname><forenames>Rene</forenames></author><author><keyname>Ding</keyname><forenames>Tianli</forenames></author><author><keyname>Fu</keyname><forenames>Chuyuan</forenames></author><author><keyname>Byravan</keyname><forenames>Arunkumar</forenames></author><author><keyname>Varley</keyname><forenames>Jake</forenames></author><author><keyname>Gritsenko</keyname><forenames>Alexey</forenames></author><author><keyname>Minderer</keyname><forenames>Matthias</forenames></author><author><keyname>Kalashnikov</keyname><forenames>Dmitry</forenames></author><author><keyname>Tompson</keyname><forenames>Jonathan</forenames></author><author><keyname>Sindhwani</keyname><forenames>Vikas</forenames></author><author><keyname>Choromanski</keyname><forenames>Krzysztof</forenames></author></authors><title>Learning the RoPEs: Better 2D and 3D Position Encodings with STRING</title><categories>cs.LG cs.AI cs.CV cs.RO stat.ML</categories><comments>Videos of STRING-based robotics controllers can be found here:   https://sites.google.com/view/string-robotics</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce STRING: Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers. We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02580</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02580</id><created>2025-02-04</created><updated>2025-02-04</updated><authors><author><keyname>Huang</keyname><forenames>Chengzhu</forenames></author><author><keyname>Gu</keyname><forenames>Yuqi</forenames></author></authors><title>Minimax-Optimal Dimension-Reduced Clustering for High-Dimensional   Nonspherical Mixtures</title><categories>math.ST stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mixture models, nonspherical (anisotropic) noise within each cluster is widely present in real-world data. We study both the minimax rate and optimal statistical procedure for clustering under high-dimensional nonspherical mixture models. In high-dimensional settings, we first establish the information-theoretic limits for clustering under Gaussian mixtures. The minimax lower bound unveils an intriguing informational dimension-reduction phenomenon: there exists a substantial gap between the minimax rate and the oracle clustering risk, with the former determined solely by the projected centers and projected covariance matrices in a low-dimensional space. Motivated by the lower bound, we propose a novel computationally efficient clustering method: Covariance Projected Spectral Clustering (COPO). Its key step is to project the high-dimensional data onto the low-dimensional space spanned by the cluster centers and then use the projected covariance matrices in this space to enhance clustering. We establish tight algorithmic upper bounds for COPO, both for Gaussian noise with flexible covariance and general noise with local dependence. Our theory indicates the minimax-optimality of COPO in the Gaussian case and highlights its adaptivity to a broad spectrum of dependent noise. Extensive simulation studies under various noise structures and real data analysis demonstrate our method's superior performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02623</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02623</id><created>2025-02-04</created><authors><author><keyname>Matilla</keyname><forenames>German Martinez</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author></authors><title>Sample Complexity of Bias Detection with Subsampled Point-to-Subspace   Distances</title><categories>cs.LG cs.AI math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sample complexity of bias estimation is a lower bound on the runtime of any bias detection method. Many regulatory frameworks require the bias to be tested for all subgroups, whose number grows exponentially with the number of protected attributes. Unless one wishes to run a bias detection with a doubly-exponential run-time, one should like to have polynomial complexity of bias detection for a single subgroup. At the same time, the reference data may be based on surveys, and thus come with non-trivial uncertainty.   Here, we reformulate bias detection as a point-to-subspace problem on the space of measures and show that, for supremum norm, it can be subsampled efficiently. In particular, our probabilistically approximately correct (PAC) results are corroborated by tests on well-known instances. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02671</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02671</id><created>2025-02-04</created><authors><author><keyname>Tiapkin</keyname><forenames>Daniil</forenames></author><author><keyname>Calandriello</keyname><forenames>Daniele</forenames></author><author><keyname>Ferret</keyname><forenames>Johan</forenames></author><author><keyname>Perrin</keyname><forenames>Sarah</forenames></author><author><keyname>Vieillard</keyname><forenames>Nino</forenames></author><author><keyname>Ramé</keyname><forenames>Alexandre</forenames></author><author><keyname>Blondel</keyname><forenames>Mathieu</forenames></author></authors><title>On Teacher Hacking in Language Model Distillation</title><categories>cs.LG cs.AI cs.CL stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Post-training of language models (LMs) increasingly relies on the following two stages: (i) knowledge distillation, where the LM is trained to imitate a larger teacher LM, and (ii) reinforcement learning from human feedback (RLHF), where the LM is aligned by optimizing a reward model. In the second RLHF stage, a well-known challenge is reward hacking, where the LM over-optimizes the reward model. Such phenomenon is in line with Goodhart's law and can lead to degraded performance on the true objective. In this paper, we investigate whether a similar phenomenon, that we call teacher hacking, can occur during knowledge distillation. This could arise because the teacher LM is itself an imperfect approximation of the true distribution. To study this, we propose a controlled experimental setup involving: (i) an oracle LM representing the ground-truth distribution, (ii) a teacher LM distilled from the oracle, and (iii) a student LM distilled from the teacher. Our experiments reveal the following insights. When using a fixed offline dataset for distillation, teacher hacking occurs; moreover, we can detect it by observing when the optimization process deviates from polynomial convergence laws. In contrast, employing online data generation techniques effectively mitigates teacher hacking. More precisely, we identify data diversity as the key factor in preventing hacking. Overall, our findings provide a deeper understanding of the benefits and limitations of distillation for building robust and efficient LMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02674</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02674</id><created>2025-02-04</created><authors><author><keyname>Stanley</keyname><forenames>Michael</forenames></author><author><keyname>Batlle</keyname><forenames>Pau</forenames></author><author><keyname>Patil</keyname><forenames>Pratik</forenames></author><author><keyname>Owhadi</keyname><forenames>Houman</forenames></author><author><keyname>Kuusela</keyname><forenames>Mikael</forenames></author></authors><title>Confidence intervals for functionals in constrained inverse problems via   data-adaptive sampling-based calibration</title><categories>stat.ME stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address functional uncertainty quantification for ill-posed inverse problems where it is possible to evaluate a possibly rank-deficient forward model, the observation noise distribution is known, and there are known parameter constraints. We present four constraint-aware confidence intervals extending the work of Batlle et al. (2023) by making the intervals both computationally feasible and less conservative. Our approach first shrinks the potentially unbounded constraint set compact in a data-adaptive way, obtains samples of the relevant test statistic inside this set to estimate a quantile function, and then uses these computed quantities to produce the intervals. Our data-adaptive bounding approach is based on the approach by Berger and Boos (1994), and involves defining a subset of the constraint set where the true parameter exists with high probability. This probabilistic guarantee is then incorporated into the final coverage guarantee in the form of an uncertainty budget. We then propose custom sampling algorithms to efficiently sample from this subset, even when the parameter space is high-dimensional. Optimization-based interval methods formulate confidence interval computation as two endpoint optimizations, where the optimization constraints can be set to achieve different types of interval calibration while seamlessly incorporating parameter constraints. However, choosing valid optimization constraints has been elusive. We show that all four proposed intervals achieve nominal coverage for a particular functional both theoretically and in practice, with numerical examples demonstrating superior performance of our intervals over the OSB interval in terms of both coverage and expected length. In particular, we show the superior performance in a realistic unfolding simulation from high-energy physics that is severely ill-posed and involves a rank-deficient forward model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02679</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02679</id><created>2025-02-04</created><authors><author><keyname>Kurkova</keyname><forenames>Vera</forenames></author><author><keyname>Sanguineti</keyname><forenames>Marcello</forenames></author></authors><title>Networks with Finite VC Dimension: Pro and Contra</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Approximation and learning of classifiers of large data sets by neural networks in terms of high-dimensional geometry and statistical learning theory are investigated. The influence of the VC dimension of sets of input-output functions of networks on approximation capabilities is compared with its influence on consistency in learning from samples of data. It is shown that, whereas finite VC dimension is desirable for uniform convergence of empirical errors, it may not be desirable for approximation of functions drawn from a probability distribution modeling the likelihood that they occur in a given type of application. Based on the concentration-of-measure properties of high dimensional geometry, it is proven that both errors in approximation and empirical errors behave almost deterministically for networks implementing sets of input-output functions with finite VC dimensions in processing large data sets. Practical limitations of the universal approximation property, the trade-offs between the accuracy of approximation and consistency in learning from data, and the influence of depth of networks with ReLU units on their accuracy and consistency are discussed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02701</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02701</id><created>2025-02-04</created><authors><author><keyname>Noda</keyname><forenames>Atsushi</forenames></author><author><keyname>Isozaki</keyname><forenames>Takashi</forenames></author></authors><title>Practically Effective Adjustment Variable Selection in Causal Inference</title><categories>cs.LG cs.AI physics.data-an stat.ME</categories><comments>20 pages, 8 figures</comments><journal-ref>Journal of Physics: Complexity 6, 015001 (2025)</journal-ref><doi>10.1088/2632-072X/ada861</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the estimation of causal effects, one common method for removing the influence of confounders is to adjust the variables that satisfy the back-door criterion. However, it is not always possible to uniquely determine sets of such variables. Moreover, real-world data is almost always limited, which means it may be insufficient for statistical estimation. Therefore, we propose criteria for selecting variables from a list of candidate adjustment variables along with an algorithm to prevent accuracy degradation in causal effect estimation. We initially focus on directed acyclic graphs (DAGs) and then outlines specific steps for applying this method to completed partially directed acyclic graphs (CPDAGs). We also present and prove a theorem on causal effect computation possibility in CPDAGs. Finally, we demonstrate the practical utility of our method using both existing and artificial data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02710</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02710</id><created>2025-02-04</created><authors><author><keyname>Kostin</keyname><forenames>Julia</forenames></author><author><keyname>Gnecco</keyname><forenames>Nicola</forenames></author><author><keyname>Yang</keyname><forenames>Fanny</forenames></author></authors><title>Achievable distributional robustness when the robust risk is only   partially identified</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In safety-critical applications, machine learning models should generalize well under worst-case distribution shifts, that is, have a small robust risk. Invariance-based algorithms can provably take advantage of structural assumptions on the shifts when the training distributions are heterogeneous enough to identify the robust risk. However, in practice, such identifiability conditions are rarely satisfied -- a scenario so far underexplored in the theoretical literature. In this paper, we aim to fill the gap and propose to study the more general setting when the robust risk is only partially identifiable. In particular, we introduce the worst-case robust risk as a new measure of robustness that is always well-defined regardless of identifiability. Its minimum corresponds to an algorithm-independent (population) minimax quantity that measures the best achievable robustness under partial identifiability. While these concepts can be defined more broadly, in this paper we introduce and derive them explicitly for a linear model for concreteness of the presentation. First, we show that existing robustness methods are provably suboptimal in the partially identifiable case. We then evaluate these methods and the minimizer of the (empirical) worst-case robust risk on real-world gene expression data and find a similar trend: the test error of existing robustness methods grows increasingly suboptimal as the fraction of data from unseen environments increases, whereas accounting for partial identifiability allows for better generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02726</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02726</id><created>2025-02-04</created><authors><author><keyname>Li</keyname><forenames>Pengtao</forenames></author><author><keyname>Chen</keyname><forenames>Xiaohui</forenames></author></authors><title>Multimarginal Schr\"{o}dinger Barycenter</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Wasserstein barycenter plays a fundamental role in averaging measure-valued data under the framework of optimal transport. However, there are tremendous challenges in computing and estimating the Wasserstein barycenter for high-dimensional distributions. In this paper, we introduce the multimarginal Schr\"{o}dinger barycenter (MSB) based on the entropy regularized multimarginal optimal transport problem that admits general-purpose fast algorithms for computation. By recognizing a proper dual geometry, we derive non-asymptotic rates of convergence for estimating several key MSB quantities from point clouds randomly sampled from the input marginal distributions. Specifically, we show that our obtained sample complexity is statistically optimal for estimating the cost functional, Schr\"{o}dinger coupling and barycenter. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02736</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02736</id><created>2025-02-04</created><authors><author><keyname>Dong</keyname><forenames>Larry</forenames></author><author><keyname>Pullenayegum</keyname><forenames>Eleanor</forenames></author><author><keyname>Thiébaut</keyname><forenames>Rodolphe</forenames></author><author><keyname>Saarela</keyname><forenames>Olli</forenames></author></authors><title>Estimating Optimal Dynamic Treatment Regimes Using Irregularly Observed   Data: A Target Trial Emulation and Bayesian Joint Modeling Approach</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimal dynamic treatment regime (DTR) is a sequence of decision rules aimed at providing the best course of treatments individualized to patients. While conventional DTR estimation uses longitudinal data, such data can also be irregular, where patient-level variables can affect visit times, treatment assignments and outcomes. In this work, we first extend the target trial framework - a paradigm to estimate statistical estimands specified under hypothetical randomized trials using observational data - to the DTR context; this extension allows treatment regimes to be defined with intervenable visit times. We propose an adapted version of G-computation marginalizing over random effects for rewards that encapsulate a treatment strategy's value. To estimate components of the G-computation formula, we then articulate a Bayesian joint model to handle correlated random effects between the outcome, visit and treatment processes. We show via simulation studies that, in the estimation of regime rewards, failure to account for the observational treatment and visit processes produces bias which can be removed through joint modeling. We also apply our proposed method on data from INSPIRE 2 and 3 studies to estimate optimal injection cycles of Interleukin 7 to treat HIV-infected individuals. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02771</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02771</id><created>2025-02-04</created><authors><author><keyname>Cheung</keyname><forenames>Matt Y.</forenames></author><author><keyname>Zorek</keyname><forenames>Sophia</forenames></author><author><keyname>Netherton</keyname><forenames>Tucker J.</forenames></author><author><keyname>Court</keyname><forenames>Laurence E.</forenames></author><author><keyname>Al-Kindi</keyname><forenames>Sadeer</forenames></author><author><keyname>Veeraraghavan</keyname><forenames>Ashok</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Guha</forenames></author></authors><title>When are Diffusion Priors Helpful in Sparse Reconstruction? A Study with   Sparse-view CT</title><categories>physics.med-ph cs.CV cs.LG eess.IV stat.AP</categories><comments>Accepted at IEEE ISBI 2025, 5 pages, 2 figures, 1 table</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion models demonstrate state-of-the-art performance on image generation, and are gaining traction for sparse medical image reconstruction tasks. However, compared to classical reconstruction algorithms relying on simple analytical priors, diffusion models have the dangerous property of producing realistic looking results \emph{even when incorrect}, particularly with few observations. We investigate the utility of diffusion models as priors for image reconstruction by varying the number of observations and comparing their performance to classical priors (sparse and Tikhonov regularization) using pixel-based, structural, and downstream metrics. We make comparisons on low-dose chest wall computed tomography (CT) for fat mass quantification. First, we find that classical priors are superior to diffusion priors when the number of projections is ``sufficient''. Second, we find that diffusion priors can capture a large amount of detail with very few observations, significantly outperforming classical priors. However, they fall short of capturing all details, even with many observations. Finally, we find that the performance of diffusion priors plateau after extremely few ($\approx$10-15) projections. Ultimately, our work highlights potential issues with diffusion-based sparse reconstruction and underscores the importance of further investigation, particularly in high-stakes clinical settings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02781</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02781</id><created>2025-02-04</created><authors><author><keyname>Forzani</keyname><forenames>Liliana</forenames></author><author><keyname>Arancibia</keyname><forenames>Rodrigo García</forenames></author><author><keyname>Gieco</keyname><forenames>Antonella</forenames></author><author><keyname>Llop</keyname><forenames>Pamela</forenames></author><author><keyname>Yao</keyname><forenames>Anne</forenames></author></authors><title>Sufficient dimension reduction for regression with spatially correlated   errors: application to prediction</title><categories>stat.ME math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this paper, we address the problem of predicting a response variable in the context of both, spatially correlated and high-dimensional data. To reduce the dimensionality of the predictor variables, we apply the sufficient dimension reduction (SDR) paradigm, which reduces the predictor space while retaining relevant information about the response. To achieve this, we impose two different spatial models on the inverse regression: the separable spatial covariance model (SSCM) and the spatial autoregressive error model (SEM). For these models, we derive maximum likelihood estimators for the reduction and use them to predict the response via nonparametric rules for forward regression. Through simulations and real data applications, we demonstrate the effectiveness of our approach for spatial data prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02793</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02793</id><created>2025-02-04</created><authors><author><keyname>Cui</keyname><forenames>Zihan</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Early Stopping in Contextual Bandits and Inferences</title><categories>math.ST math.OC math.PR stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandit algorithms sequentially accumulate data using adaptive sampling policies, offering flexibility for real-world applications. However, excessive sampling can be costly, motivating the devolopment of early stopping methods and reliable post-experiment conditional inferences. This paper studies early stopping methods in linear contextual bandits, including both pre-determined and online stopping rules, to minimize in-experiment regrets while accounting for sampling costs. We propose stopping rules based on the Opportunity Cost and Threshold Method, utilizing the variances of unbiased or consistent online estimators to quantify the upper regret bounds of learned optimal policy. The study focuses on batched settings for stability, selecting a weighed combination of batched estimators as the online estimator and deriving its asymptotic distribution. Online statistical inferences are performed based on the selected estimator, conditional on the realized stopping time. Our proposed method provides a systematic approach to minimize in-experiment regret and conduct robust post-experiment inferences, facilitating decision-making in future applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02797</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02797</id><created>2025-02-04</created><authors><author><keyname>Sanyal</keyname><forenames>Sunny</forenames></author><author><keyname>Prairie</keyname><forenames>Hayden</forenames></author><author><keyname>Das</keyname><forenames>Rudrajit</forenames></author><author><keyname>Kavis</keyname><forenames>Ali</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting</title><categories>cs.LG cs.AI stat.ML</categories><comments>49 pages, 4 figures, 12 tables. Code available at   https://github.com/sanyalsunny111/FLOW_finetuning</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as "catastrophic forgetting". This is especially an issue when one does not have access to the data and recipe used to develop the pre-trained model. Under this constraint, most existing methods for mitigating forgetting are inapplicable. To address this challenge, we propose a sample weighting scheme for the fine-tuning data solely based on the pre-trained model's losses. Specifically, we upweight the easy samples on which the pre-trained model's loss is low and vice versa to limit the drift from the pre-trained model. Our approach is orthogonal and yet complementary to existing methods; while such methods mostly operate on parameter or gradient space, we concentrate on the sample space. We theoretically analyze the impact of fine-tuning with our method in a linear setting, showing that it stalls learning in a certain subspace which inhibits overfitting to the target task. We empirically demonstrate the efficacy of our method on both language and vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our method results in only a $0.8\%$ drop in accuracy on GSM8K (another math dataset) compared to standard fine-tuning, while preserving $5.4\%$ more accuracy on the pre-training datasets. Our code is publicly available at https://github.com/sanyalsunny111/FLOW_finetuning . </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02812</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02812</id><created>2025-02-04</created><authors><author><keyname>Propp</keyname><forenames>Adrienne M.</forenames></author><author><keyname>Vardavas</keyname><forenames>Raffaele</forenames></author><author><keyname>Price</keyname><forenames>Carter C.</forenames></author><author><keyname>Kapinos</keyname><forenames>Kandice A.</forenames></author></authors><title>LHIEM: the Longitudinal Health, Income, and Employment Model</title><categories>stat.AP</categories><comments>To appear in Journal of Artificial Societies and Social Simulation,   2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic microsimulation has long been recognized as a powerful tool for policy analysis, but in fact most major health policy simulations lack path dependency, a critical feature for evaluating policies that depend on accumulated outcomes such as retirement savings, wealth, or debt. We propose LHIEM (the Longitudinal Health, Income and Employment Model), a path-dependent discrete-time microsimulation that predicts annual health care expenditures, family income, and health status for the U.S. population over a multi-year period. LHIEM advances the population from year to year as a Markov chain with modules capturing the particular dynamics of each predictive attribute. LHIEM was designed to assess a health care financing proposal that would allow individuals to borrow from the U.S. government to cover health care costs, requiring careful tracking of medical expenditures and medical debt over time. However, LHIEM is flexible enough to be used for a range of modeling needs related to predicting health care spending and income over time. In this paper, we present the details of the model and all dynamic modules, and include a case study to demonstrate how LHIEM can be used to evaluate proposed policy changes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02846</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02846</id><created>2025-02-04</created><authors><author><keyname>Sun</keyname><forenames>Siqi</forenames></author><author><keyname>Schmidt</keyname><forenames>Karen M.</forenames></author><author><keyname>Henry</keyname><forenames>Teague R.</forenames></author></authors><title>Don't Let Your Likert Scales Grow Up To Be Visual Analog Scales:   Understanding the Relationship Between Number of Response Categories and   Measurement Error</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of Visual Analog Scales (VAS), which can be broadly conceptualized as items where the response scale is 0-100, has surged recently due to the convenience of digital assessments. However, there is no consensus as to whether the use of VAS scales is optimal in a measurement sense. Put differently, in the 90+ years since Likert introduced his eponymous scale, the field does not know how to determine the optimal number of response options for a given item. In the current work, we investigate the optimal number of response categories using a series of simulations. We find that when the measurement error of an item is not dependent on the number of response categories, there is no true optimum; rather, reliability increases with number of response options and then plateaus. However, under the more realistic assumption that the measurement error of an item increases with the number of response categories, we find a clear optimum that depends on the rate of that increase. If measurement error increases with the number of response categories, then conversion of any Likert scale item to VAS will result in a drastic decrease in reliability. Finally, if researchers do want to change the response scale of a validated measure, they must re-validate the new measure as the measurement error of the scale is likely to change. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02848</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02848</id><created>2025-02-04</created><authors><author><keyname>Zhou</keyname><forenames>Shuheng</forenames></author><author><keyname>Park</keyname><forenames>Seyoung</forenames></author><author><keyname>Shedden</keyname><forenames>Kerby</forenames></author></authors><title>Kronecker sum covariance models for spatio-temporal data</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we study the subgaussian matrix variate model, where we observe the matrix variate data $X$ which consists of a signal matrix $X_0$ and a noise matrix $W$. More specifically, we study a subgaussian model using the Kronecker sum covariance as in Rudelson and Zhou (2017). Let $Z_1, Z_2$ be independent copies of a subgaussian random matrix $Z =(Z_{ij})$, where $Z_{ij}, \forall i, j$ are independent mean 0, unit variance, subgaussian random variables with bounded $\psi_2$ norm. We use $X \sim \mathcal{M}_{n,m}(0, A \oplus B)$ to denote the subgaussian random matrix $X_{n \times m}$ which is generated using: $$ X = Z_1 A^{1/2} + B^{1/2} Z_2. $$ In this covariance model, the first component $A \otimes I_n$ describes the covariance of the signal $X_0 = Z_1 A^{1/2}$, which is an ${n \times m}$ random design matrix with independent subgaussian row vectors, and the other component $I_m \otimes B$ describes the covariance for the noise matrix $W =B^{1/2} Z_2$, which contains independent subgaussian column vectors $w^1, \ldots, w^m$, independent of $X_0$. This leads to a non-separable class of models for the observation $X$, which we denote by $X \sim \mathcal{M}_{n,m}(0, A \oplus B)$ throughout this paper. Our method on inverse covariance estimation corresponds to the proposal in Yuan (2010) and Loh and Wainwright (2012), only now dropping the i.i.d. or Gaussian assumptions. We present the statistical rates of convergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02859</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02859</id><created>2025-02-04</created><authors><author><keyname>Zhang</keyname><forenames>Haochen</forenames></author><author><keyname>Zheng</keyname><forenames>Zhong</forenames></author><author><keyname>Xue</keyname><forenames>Lingzhou</forenames></author></authors><title>Gap-Dependent Bounds for Federated $Q$-learning</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present the first gap-dependent analysis of regret and communication cost for on-policy federated $Q$-Learning in tabular episodic finite-horizon Markov decision processes (MDPs). Existing FRL methods focus on worst-case scenarios, leading to $\sqrt{T}$-type regret bounds and communication cost bounds with a $\log T$ term scaling with the number of agents $M$, states $S$, and actions $A$, where $T$ is the average total number of steps per agent. In contrast, our novel framework leverages the benign structures of MDPs, such as a strictly positive suboptimality gap, to achieve a $\log T$-type regret bound and a refined communication cost bound that disentangles exploration and exploitation. Our gap-dependent regret bound reveals a distinct multi-agent speedup pattern, and our gap-dependent communication cost bound removes the dependence on $MSA$ from the $\log T$ term. Notably, our gap-dependent communication cost bound also yields a better global switching cost when $M=1$, removing $SA$ from the $\log T$ term. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02861</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02861</id><created>2025-02-04</created><authors><author><keyname>Shen</keyname><forenames>Judy</forenames></author><author><keyname>Vitercik</keyname><forenames>Ellen</forenames></author><author><keyname>Wikum</keyname><forenames>Anders</forenames></author></authors><title>Algorithms with Calibrated Machine Learning Predictions</title><categories>stat.ML cs.DS cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The field of algorithms with predictions incorporates machine learning advice in the design of online algorithms to improve real-world performance. While this theoretical framework often assumes uniform reliability across all predictions, modern machine learning models can now provide instance-level uncertainty estimates. In this paper, we propose calibration as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the ski rental and online job scheduling problems. For ski rental, we design an algorithm that achieves optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02870</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02870</id><created>2025-02-04</created><authors><author><keyname>Wilson</keyname><forenames>Joseph</forenames></author><author><keyname>van der Heide</keyname><forenames>Chris</forenames></author><author><keyname>Hodgkinson</keyname><forenames>Liam</forenames></author><author><keyname>Roosta</keyname><forenames>Fred</forenames></author></authors><title>Uncertainty Quantification with the Empirical Neural Tangent Kernel</title><categories>stat.ML cs.LG</categories><comments>24 pages, 5 figures, 9 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While neural networks have demonstrated impressive performance across various tasks, accurately quantifying uncertainty in their predictions is essential to ensure their trustworthiness and enable widespread adoption in critical systems. Several Bayesian uncertainty quantification (UQ) methods exist that are either cheap or reliable, but not both. We propose a post-hoc, sampling-based UQ method for over-parameterized networks at the end of training. Our approach constructs efficient and meaningful deep ensembles by employing a (stochastic) gradient-descent sampling process on appropriately linearized networks. We demonstrate that our method effectively approximates the posterior of a Gaussian process using the empirical Neural Tangent Kernel. Through a series of numerical experiments, we show that our method not only outperforms competing approaches in computational efficiency (often reducing costs by multiple factors) but also maintains state-of-the-art performance across a variety of UQ metrics for both regression and classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02887</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02887</id><created>2025-02-04</created><authors><author><keyname>Perlaza</keyname><forenames>Samir M.</forenames></author><author><keyname>Bisson</keyname><forenames>Gaetan</forenames></author></authors><title>Variations on the Expectation Due to Changes in the Probability Measure</title><categories>cs.IT cs.LG math.IT math.PR math.ST stat.TH</categories><comments>Submitted to the IEEE International Symposium on Information Theory   (ISIT2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Closed-form expressions are presented for the variation of the expectation of a given function due to changes in the probability measure used for the expectation. They unveil interesting connections with Gibbs probability measures, the mutual information, and the lautum information. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02892</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02892</id><created>2025-02-05</created><authors><author><keyname>Nguyen</keyname><forenames>Cattram D</forenames></author><author><keyname>Lee</keyname><forenames>Katherine J</forenames></author><author><keyname>White</keyname><forenames>Ian R</forenames></author><author><keyname>van Buuren</keyname><forenames>Stef</forenames></author><author><keyname>Moreno-Betancur</keyname><forenames>Margarita</forenames></author></authors><title>Sensitivity analysis for multivariable missing data using multiple   imputation: a tutorial</title><categories>stat.ME</categories><comments>24 pages, 3 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multiple imputation is a popular method for handling missing data, with fully conditional specification (FCS) being one of the predominant imputation approaches for multivariable missingness. Unbiased estimation with standard implementations of multiple imputation depends on assumptions concerning the missingness mechanism (e.g. that data are "missing at random"). The plausibility of these assumptions can only be assessed using subject-matter knowledge, and not data alone. It is therefore important to perform sensitivity analyses to explore the robustness of results to violations of these assumptions (e.g. if the data are in fact "missing not at random"). In this tutorial, we provide a roadmap for conducting sensitivity analysis using the Not at Random Fully Conditional Specification (NARFCS) procedure for multivariate imputation. Using a case study from the Longitudinal Study of Australian Children, we work through the steps involved, from assessing the need to perform the sensitivity analysis, and specifying the NARFCS models and sensitivity parameters, through to implementing NARFCS using FCS procedures in R and Stata. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02914</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02914</id><created>2025-02-05</created><authors><author><keyname>Kelter</keyname><forenames>Riko</forenames></author><author><keyname>Pawel</keyname><forenames>Samuel</forenames></author></authors><title>Bayesian Power and Sample Size Calculations for Bayes Factors in the   Binomial Setting</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Bayesian design of experiments and sample size calculations usually rely on complex Monte Carlo simulations in practice. Obtaining bounds on Bayesian notions of the false-positive rate and power therefore often lack closed-form or approximate numerical solutions. In this paper, we focus on the sample size calculation in the binomial setting via Bayes factors, the predictive updating factor from prior to posterior odds. We discuss the drawbacks of sample size calculations via Monte Carlo simulations and propose a numerical root-finding approach which allows to determine the necessary sample size to obtain prespecified bounds of Bayesian power and type-I-error rate almost instantaneously. Real-world examples and applications in clinical trials illustrate the advantage of the proposed method. We focus on point-null versus composite and directional hypothesis tests, derive the corresponding Bayes factors, and discuss relevant aspects to consider when pursuing Bayesian design of experiments with the introduced approach. In summary, our approach allows for a Bayes-frequentist compromise by providing a Bayesian analogue to a frequentist power analysis for the Bayes factor in binomial settings. A case study from a Phase II trial illustrates the utility of our approach. The methods are implemented in our R package bfpwr. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02925</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02925</id><created>2025-02-05</created><authors><author><keyname>Hiew</keyname><forenames>Joshua Zoen-Git</forenames></author><author><keyname>Lim</keyname><forenames>Tongseok</forenames></author><author><keyname>Pass</keyname><forenames>Brendan</forenames></author><author><keyname>de Souza</keyname><forenames>Marcelo Cruz</forenames></author></authors><title>Data denoising with self consistency, variance maximization, and the   Kantorovich dominance</title><categories>stat.ME cs.LG math.PR math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a new framework for data denoising, partially inspired by martingale optimal transport. For a given noisy distribution (the data), our approach involves finding the closest distribution to it among all distributions which 1) have a particular prescribed structure (expressed by requiring they lie in a particular domain), and 2) are self-consistent with the data. We show that this amounts to maximizing the variance among measures in the domain which are dominated in convex order by the data. For particular choices of the domain, this problem and a relaxed version of it, in which the self-consistency condition is removed, are intimately related to various classical approaches to denoising. We prove that our general problem has certain desirable features: solutions exist under mild assumptions, have certain robustness properties, and, for very simple domains, coincide with solutions to the relaxed problem.   We also introduce a novel relationship between distributions, termed Kantorovich dominance, which retains certain aspects of the convex order while being a weaker, more robust, and easier-to-verify condition. Building on this, we propose and analyze a new denoising problem by substituting the convex order in the previously described framework with Kantorovich dominance. We demonstrate that this revised problem shares some characteristics with the full convex order problem but offers enhanced stability, greater computational efficiency, and, in specific domains, more meaningful solutions. Finally, we present simple numerical examples illustrating solutions for both the full convex order problem and the Kantorovich dominance problem. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02927</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02927</id><created>2025-02-05</created><authors><author><keyname>Azhad</keyname><forenames>Qazi J.</forenames></author><author><keyname>Khan</keyname><forenames>Abdul Nasir</forenames></author><author><keyname>Devi</keyname><forenames>Bhagwati</forenames></author><author><keyname>Khan</keyname><forenames>Jahangir Sabbir</forenames></author><author><keyname>Tripathi</keyname><forenames>Ayush</forenames></author></authors><title>Bayesian estimation of Unit-Weibull distribution based on dual   generalized order statistics with application to the Cotton Production Data</title><categories>stat.ME math.ST stat.OT stat.TH</categories><comments>19 Pages, 1 figure, 12 tables, preprint</comments><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Unit Weibull distribution with parameters $\alpha$ and $\beta$ is considered to study in the context of dual generalized order statistics. For the analysis purpose, Bayes estimators based on symmetric and asymmetric loss functions are obtained. The methods which are utilized for Bayesian estimation are approximation and simulation tools such as Lindley, Tierney-Kadane and Markov chain Monte Carlo methods. The authors have considered squared error loss function as symmetric and LINEX and general entropy loss function as asymmetric loss functions. After presenting the mathematical results, a simulation study is conducted to exhibit the performances of various derived estimators. As this study is considered for the dual generalized order statistics that is unification of models based distinct ordered random variable such as order statistics, record values, etc. This provides flexibility in our results and in continuation of this, the cotton production data of USA is analyzed for both submodels of ordered random variables: order statistics and record values. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02986</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02986</id><created>2025-02-05</created><authors><author><keyname>Sturma</keyname><forenames>Nils</forenames></author><author><keyname>Kranzlmueller</keyname><forenames>Miriam</forenames></author><author><keyname>Portakal</keyname><forenames>Irem</forenames></author><author><keyname>Drton</keyname><forenames>Mathias</forenames></author></authors><title>Matching Criterion for Identifiability in Sparse Factor Analysis</title><categories>math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Factor analysis models explain dependence among observed variables by a smaller number of unobserved factors. A main challenge in confirmatory factor analysis is determining whether the factor loading matrix is identifiable from the observed covariance matrix. The factor loading matrix captures the linear effects of the factors and, if unrestricted, can only be identified up to an orthogonal transformation of the factors. However, in many applications the factor loadings exhibit an interesting sparsity pattern that may lead to identifiability up to column signs. We study this phenomenon by connecting sparse factor models to bipartite graphs and providing sufficient graphical conditions for identifiability of the factor loading matrix up to column signs. In contrast to previous work, our main contribution, the matching criterion, exploits sparsity by operating locally on the graph structure, thereby improving existing conditions. Our criterion is efficiently decidable in time that is polynomial in the size of the graph, when restricting the search steps to sets of bounded size. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02996</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02996</id><created>2025-02-05</created><authors><author><keyname>Stewart</keyname><forenames>Lawrence</forenames><affiliation>DI-ENS, LIENS, Inria</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, SIERRA</affiliation></author><author><keyname>Berthet</keyname><forenames>Quentin</forenames></author></authors><title>Building Bridges between Regression, Clustering, and Classification</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regression, the task of predicting a continuous scalar target y based on some features x is one of the most fundamental tasks in machine learning and statistics. It has been observed and theoretically analyzed that the classical approach, meansquared error minimization, can lead to suboptimal results when training neural networks. In this work, we propose a new method to improve the training of these models on regression tasks, with continuous scalar targets. Our method is based on casting this task in a different fashion, using a target encoder, and a prediction decoder, inspired by approaches in classification and clustering. We showcase the performance of our method on a wide range of real-world datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03023</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03023</id><created>2025-02-05</created><authors><author><keyname>Zeng</keyname><forenames>Hao</forenames></author><author><keyname>Liu</keyname><forenames>Kangdao</forenames></author><author><keyname>Jing</keyname><forenames>Bingyi</forenames></author><author><keyname>Wei</keyname><forenames>Hongxin</forenames></author></authors><title>Parametric Scaling Law of Tuning Bias in Conformal Prediction</title><categories>cs.LG math.ST stat.ME stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional holdout set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03030</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03030</id><created>2025-02-05</created><authors><author><keyname>Hughes</keyname><forenames>Arthur</forenames></author><author><keyname>Parast</keyname><forenames>Layla</forenames></author><author><keyname>Thiébaut</keyname><forenames>Rodolphe</forenames></author><author><keyname>Hejblum</keyname><forenames>Boris P.</forenames></author></authors><title>Rank-Based Identification of High-dimensional Surrogate Markers:   Application to Vaccinology</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In vaccine trials with long-term participant follow-up, it is of great importance to identify surrogate markers that accurately infer long-term immune responses. These markers offer practical advantages such as providing early, indirect evidence of vaccine efficacy, and can accelerate vaccine development while identifying potential biomarkers. High-throughput technologies like RNA-sequencing have emerged as promising tools for understanding complex biological systems and informing new treatment strategies. However, these data are high-dimensional, presenting unique statistical challenges for existing surrogate marker identification methods. We introduce Rank-based Identification of high-dimensional SurrogatE Markers (RISE), a novel approach designed for small sample, high-dimensional settings typical in modern vaccine experiments. RISE employs a non-parametric univariate test to screen variables for promising candidates, followed by surrogate evaluation on independent data. Our simulation studies demonstrate RISE's desirable properties, including type one error rate control and empirical power under various conditions. Applying RISE to a clinical trial for inactivated influenza vaccination, we sought to identify genes whose post-vaccination expression could serve as a surrogate for the induced immune response. This analysis revealed a signature of genes whose combined expression at 1 day post-injection appears to be a reasonable surrogate for the neutralising antibody titres at 28 days after vaccination. Pathways related to innate antiviral signalling and interferon stimulation were strongly represented in this derived surrogate, providing a clear immunological interpretation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03048</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03048</id><created>2025-02-05</created><authors><author><keyname>MacKinlay</keyname><forenames>Dan</forenames></author></authors><title>The Ensemble Kalman Update is an Empirical Matheron Update</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Ensemble Kalman Filter (EnKF) is a widely used method for data assimilation in high-dimensional systems. In this paper, we show that the ensemble update step of the EnKF is equivalent to an empirical version of the Matheron update popular in the study of Gaussian process regression.   While this connection is simple, it seems not to be widely known, the literature about each technique seems distinct, and connections between the methods are not exploited. This paper exists to provide an informal introduction to the connection, with the necessary definitions so that it is intelligible to as broad an audience as possible. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03062</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03062</id><created>2025-02-05</created><authors><author><keyname>Yamada</keyname><forenames>Akifumi</forenames></author><author><keyname>Shiraishi</keyname><forenames>Tomohiro</forenames></author><author><keyname>Nishino</keyname><forenames>Shuichi</forenames></author><author><keyname>Katsuoka</keyname><forenames>Teruyuki</forenames></author><author><keyname>Taji</keyname><forenames>Kouichi</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Time Series Anomaly Detection in the Frequency Domain with Statistical   Reliability</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Effective anomaly detection in complex systems requires identifying change points (CPs) in the frequency domain, as abnormalities often arise across multiple frequencies. This paper extends recent advancements in statistically significant CP detection, based on Selective Inference (SI), to the frequency domain. The proposed SI method quantifies the statistical significance of detected CPs in the frequency domain using $p$-values, ensuring that the detected changes reflect genuine structural shifts in the target system. We address two major technical challenges to achieve this. First, we extend the existing SI framework to the frequency domain by appropriately utilizing the properties of discrete Fourier transform (DFT). Second, we develop an SI method that provides valid $p$-values for CPs where changes occur across multiple frequencies. Experimental results demonstrate that the proposed method reliably identifies genuine CPs with strong statistical guarantees, enabling more accurate root-cause analysis in the frequency domain of complex systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03090</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03090</id><created>2025-02-05</created><authors><author><keyname>Li</keyname><forenames>Jinglai</forenames></author><author><keyname>Wang</keyname><forenames>Hongqiao</forenames></author></authors><title>Gaussian Processes Regression for Uncertainty Quantification: An   Introductory Tutorial</title><categories>stat.CO cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian Process Regression (GPR) is a powerful method widely used in Uncertainty Quantification (UQ). This tutorial serves as an introductory guide for beginners, aiming to offer a structured and accessible overview of GPR's applications in UQ. We begin with an introduction to UQ and outline its key tasks, including uncertainty propagation, risk estimation, optimization under uncertainty, parameter estimation, and sensitivity analysis. We then introduce Gaussian Processes (GPs) as a surrogate modeling technique, detailing their formulation, choice of covariance kernels, hyperparameter estimation, and active learning strategies for efficient data acquisition. The tutorial further explores how GPR can be applied to different UQ tasks, including Bayesian quadrature for uncertainty propagation, active learning-based risk estimation, Bayesian optimization for optimization under uncertainty, and surrogate-based sensitivity analysis. Throughout, we emphasize how to leverage the unique formulation of GP for these UQ tasks, rather than simply using it as a standard surrogate model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03099</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03099</id><created>2025-02-05</created><authors><author><keyname>Betken</keyname><forenames>Annika</forenames></author><author><keyname>Micali</keyname><forenames>Giorgio</forenames></author><author><keyname>Schmidt-Hieber</keyname><forenames>Johannes</forenames></author></authors><title>Ordinal Patterns Based Change Points Detection</title><categories>math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ordinal patterns of a fixed number of consecutive values in a time series is the spatial ordering of these values. Counting how often a specific ordinal pattern occurs in a time series provides important insights into the properties of the time series. In this work, we prove the asymptotic normality of the relative frequency of ordinal patterns for time series with linear increments. Moreover, we apply ordinal patterns to detect changes in the distribution of a time series. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03119</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03119</id><created>2025-02-05</created><authors><author><keyname>Graf</keyname><forenames>Ricarda</forenames></author><author><keyname>Todd</keyname><forenames>Susan</forenames></author><author><keyname>Baksh</keyname><forenames>M. Fazil</forenames></author></authors><title>Comparison of the Cox proportional hazards model and Random Survival   Forest algorithm for predicting patient-specific survival probabilities in   clinical trial data</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Cox proportional hazards model is often used for model development in data from randomized controlled trials (RCT) with time-to-event outcomes. Random survival forests (RSF) is a machine-learning algorithm known for its high predictive performance. We conduct a comprehensive neutral comparison study to compare the predictive performance of Cox regression and RSF in real-world as well as simulated data. Performance is compared using multiple performance measures according to recommendations for the comparison of prognostic prediction models. We found that while the RSF usually outperforms the Cox model when using the $C$ index, Cox model predictions may be better calibrated. With respect to overall performance, the Cox model often exceeds the RSF in nonproportional hazards settings, while otherwise the RSF typically performs better especially for smaller sample sizes. Overall performance of the RSF is more affected by higher censoring rates, while overall performance of the Cox model suffers more from smaller sample sizes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03156</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03156</id><created>2025-02-05</created><authors><author><keyname>Jonzon</keyname><forenames>Gustav</forenames></author><author><keyname>Gabriel</keyname><forenames>Erin E</forenames></author><author><keyname>Sjölander</keyname><forenames>Arvid</forenames></author><author><keyname>Sachs</keyname><forenames>Michael C</forenames></author></authors><title>Adding covariates to bounds: What is the question?</title><categories>stat.ME</categories><msc-class>62D20</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Symbolic nonparametric bounds for partial identification of causal effects now have a long history in the causal literature. Sharp bounds, bounds that use all available information to make the range of values as narrow as possible, are often the goal. For this reason, many publications have focused on deriving sharp bounds, but the concept of sharp bounds is nuanced and can be misleading. In settings with ancillary covariates, the situation becomes more complex. We provide clear definitions for pointwise and uniform sharpness of covariate-conditional bounds, that we then use to prove some general and some specific to the IV setting results about the relationship between these two concepts. As we demonstrate, general conditions are much more difficult to determine and thus, we urge authors to be clear when including ancillary covariates in bounds via conditioning about the setting of interest and the assumptions made. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03163</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03163</id><created>2025-02-05</created><authors><author><keyname>Glückstad</keyname><forenames>Mie</forenames></author><author><keyname>Cirone</keyname><forenames>Nicola Muca</forenames></author><author><keyname>Teichmann</keyname><forenames>Josef</forenames></author></authors><title>Signature Reconstruction from Randomized Signatures</title><categories>math.CA cs.LG math.PR stat.ML</categories><comments>37 pages, 7 figures</comments><msc-class>60L10 (Primary) 60L70, 60L90, 68T07 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Controlled ordinary differential equations driven by continuous bounded variation curves can be considered a continuous time analogue of recurrent neural networks for the construction of expressive features of the input curves. We ask up to which extent well known signature features of such curves can be reconstructed from controlled ordinary differential equations with (untrained) random vector fields. The answer turns out to be algebraically involved, but essentially the number of signature features, which can be reconstructed from the non-linear flow of the controlled ordinary differential equation, is exponential in its hidden dimension, when the vector fields are chosen to be neural with depth two. Moreover, we characterize a general linear independence condition on arbitrary vector fields, under which the signature features up to some fixed order can always be reconstructed. Algebraically speaking this complements in a quantitative manner several well known results from the theory of Lie algebras of vector fields and puts them in a context of machine learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03174</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03174</id><created>2025-02-05</created><authors><author><keyname>Lecestre</keyname><forenames>Alexandre</forenames></author></authors><title>Robust Label Shift Quantification</title><categories>math.ST stat.ML stat.TH</categories><msc-class>62F35</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the label shift quantification problem. We propose robust estimators of the label distribution which turn out to coincide with the Maximum Likelihood Estimator. We analyze the theoretical aspects and derive deviation bounds for the proposed method, providing optimal guarantees in the well-specified case, along with notable robustness properties against outliers and contamination. Our results provide theoretical validation for empirical observations on the robustness of Maximum Likelihood Label Shift. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03208</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03208</id><created>2025-02-05</created><authors><author><keyname>Sziklai</keyname><forenames>Balázs R.</forenames></author><author><keyname>Gere</keyname><forenames>Attila</forenames></author><author><keyname>Héberger</keyname><forenames>Károly</forenames></author><author><keyname>Staudacher</keyname><forenames>Jochen</forenames></author></authors><title>rSRD: An R package for the Sum of Ranking Differences statistical   procedure</title><categories>math.ST stat.TH</categories><msc-class>62-04</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Sum of Ranking Differences (SRD) is a relatively novel, non-para-metric statistical procedure that has become increasingly popular recently. SRD compares solutions via a reference by applying a rank transformation on the input and calculating the distance from the reference in $L_1$ norm. Although the computation of the test statistics is simple, validating the results is cumbersome -- at least by hand. There are two validation steps involved. Comparison of Ranks with Random Numbers, which is a permutation-test, and cross-validation combined with statistical testing. Both options impose computational difficulties albeit different ones. The rSRD package was devised to simplify the validation process by reducing both validation steps into single function calls. In addition, the package provides various useful tools including data preprocessing and plotting. The package makes SRD accessible to a wide audience as there are currently no other software options with such a comprehensive toolkit. This paper aims to serve as a guide for practitioners by offering a detailed presentation of the features. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03210</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03210</id><created>2025-02-05</created><authors><author><keyname>Rubin</keyname><forenames>Noa</forenames></author><author><keyname>Fischer</keyname><forenames>Kirsten</forenames></author><author><keyname>Lindner</keyname><forenames>Javed</forenames></author><author><keyname>Dahmen</keyname><forenames>David</forenames></author><author><keyname>Seroussi</keyname><forenames>Inbar</forenames></author><author><keyname>Ringel</keyname><forenames>Zohar</forenames></author><author><keyname>Krämer</keyname><forenames>Michael</forenames></author><author><keyname>Helias</keyname><forenames>Moritz</forenames></author></authors><title>From Kernels to Features: A Multi-Scale Adaptive Theory of Feature   Learning</title><categories>cond-mat.dis-nn cs.LG stat.ML</categories><comments>24 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Theoretically describing feature learning in neural networks is crucial for understanding their expressive power and inductive biases, motivating various approaches. Some approaches describe network behavior after training through a simple change in kernel scale from initialization, resulting in a generalization power comparable to a Gaussian process. Conversely, in other approaches training results in the adaptation of the kernel to the data, involving complex directional changes to the kernel. While these approaches capture different facets of network behavior, their relationship and respective strengths across scaling regimes remains an open question. This work presents a theoretical framework of multi-scale adaptive feature learning bridging these approaches. Using methods from statistical mechanics, we derive analytical expressions for network output statistics which are valid across scaling regimes and in the continuum between them. A systematic expansion of the network's probability distribution reveals that mean-field scaling requires only a saddle-point approximation, while standard scaling necessitates additional correction terms. Remarkably, we find across regimes that kernel adaptation can be reduced to an effective kernel rescaling when predicting the mean network output of a linear network. However, even in this case, the multi-scale adaptive approach captures directional feature learning effects, providing richer insights than what could be recovered from a rescaling of the kernel alone. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03217</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03217</id><created>2025-02-05</created><authors><author><keyname>Cuellar</keyname><forenames>Maria</forenames></author></authors><title>The Prosecutor's Fallacy and Expert Testimony: A Modern Take Using   Likelihood Ratios</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Forensic examiners and attorneys need to know how to express evidence in favor or against a prosecutor's hypothesis in a way that avoids the prosecutor's fallacy and follows the modern reporting standards for forensic evidence. This article delves into the inherent conflict between legal and scientific principles, exacerbated by the prevalence of alternative facts in contemporary discourse. Courts grapple with contradictory expert testimonies, leading to a surge in erroneous rulings based on flawed amicus briefs and testimonies, notably the persistent prosecutor's fallacy. The piece underscores the necessity for legal practitioners to navigate this fallacy within the modern forensic science framework, emphasizing the importance of reporting likelihood ratios (LRs) over posterior probabilities. Recognizing the challenge of lay comprehension of LRs, the article calls for updated recommendations to mitigate the prosecutor's fallacy. Its contribution lies in providing a detailed analysis of the fallacy using LRs and advocating for a sound interpretation of evidence. Illustrated through a modified real case, this article serves as a valuable guide for legal professionals, offering insights into avoiding fallacious reasoning in forensic evidence assessment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03237</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03237</id><created>2025-02-05</created><authors><author><keyname>Mane</keyname><forenames>S. R.</forenames></author></authors><title>New technique for parameter estimation and improved fits to experimental   data for a set of compound Poisson distributions</title><categories>stat.ME math.PR</categories><comments>43 pages, 18 figures</comments><report-no>CC25-2</report-no><msc-class>62F30, 60-06, 05-08</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Compound Poisson distributions have been employed by many authors to fit experimental data, typically via the method of moments or maximum likelihood estimation. We propose a new technique and apply it to several sets of published data. It yields better fits than those obtained by the original authors for a set of widely employed compound Poisson distributions (in some cases, significantly better). The technique employs the power spectrum (the absolute square of the characteristic function). The new idea is suggested as a useful addition to the tools for parameter estimation of compound Poisson distributions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03241</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03241</id><created>2025-02-05</created><authors><author><keyname>Wang</keyname><forenames>Yaping</forenames></author><author><keyname>Liu</keyname><forenames>Sixu</forenames></author><author><keyname>Xiao</keyname><forenames>Qian</forenames></author></authors><title>Optimal design of experiments with quantitative-sequence factors</title><categories>stat.ME</categories><comments>This is the English version of the published paper in Chinese by   SCIENCE CHINA Mathematics</comments><msc-class>62K20, 62K99</msc-class><journal-ref>SCIENCE CHINA Mathematics, 2025, 55: 1-24 (in Chinese)</journal-ref><doi>10.1360/SCM-2024-0039</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A new type of experiment with joint considerations of quantitative and sequence factors is recently drawing much attention in medical science, bio-engineering, and many other disciplines. The input spaces of such experiments are semi-discrete and often very large. Thus, efficient and economical experimental designs are required. Based on the transformations and aggregations of good lattice point sets, we construct a new class of optimal quantitative-sequence (QS) designs that are marginally coupled, pair-balanced, space-filling, and asymptotically orthogonal. The proposed QS designs have a certain flexibility in run and factor sizes and are especially appealing for high-dimensional cases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03254</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03254</id><created>2025-02-05</created><authors><author><keyname>Młynarczyk</keyname><forenames>Dorota</forenames></author><author><keyname>Calvo</keyname><forenames>Gabriel</forenames></author><author><keyname>Palmi-Perales</keyname><forenames>Francisco</forenames></author><author><keyname>Armero</keyname><forenames>Carmen</forenames></author><author><keyname>Gómez-Rubio</keyname><forenames>Virgilio</forenames></author><author><keyname>Martinez-Iranzo</keyname><forenames>Ursula</forenames></author></authors><title>Bayesian network approach to building an affective module for a driver   behavioural model</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper focuses on the affective component of a Driver Behavioural Model (DBM), specifically modelling some driver's mental states, such as mental load and active fatigue, which may affect driving performance. We used Bayesian networks (BNs) to explore the dependencies between various relevant variables and estimate the probability that a driver was in a particular mental state based on their physiological and demographic conditions. Through this approach, our goal is to improve our understanding of driver behaviour in dynamic environments, with potential applications in traffic safety and autonomous vehicle technologies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03261</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03261</id><created>2025-02-05</created><authors><author><keyname>Somerstep</keyname><forenames>Seamus</forenames></author><author><keyname>Polo</keyname><forenames>Felipe Maia</forenames></author><author><keyname>de Oliveira</keyname><forenames>Allysson Flavio Melo</forenames></author><author><keyname>Mangal</keyname><forenames>Prattyush</forenames></author><author><keyname>Silva</keyname><forenames>Mírian</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Onkar</forenames></author><author><keyname>Yurochkin</keyname><forenames>Mikhail</forenames></author><author><keyname>Maity</keyname><forenames>Subha</forenames></author></authors><title>CARROT: A Cost Aware Rate Optimal Router</title><categories>stat.ML cs.LG cs.NI math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in LLM routing, or directing queries to the cheapest LLM that can deliver a suitable response. Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware Routing (SPROUT) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03273</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03273</id><created>2025-02-05</created><authors><author><keyname>Hadj-Amar</keyname><forenames>Beniamino</forenames></author><author><keyname>Krishnan</keyname><forenames>Vaishnav</forenames></author><author><keyname>Vannucci</keyname><forenames>Marina</forenames></author></authors><title>Bayesian Covariate-Dependent Circadian Modeling of Rest-Activity Rhythms</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a Bayesian covariate-dependent anti-logistic circadian model for analyzing activity data collected via wrist-worn wearable devices. The proposed approach integrates covariates into the modeling of the amplitude and phase parameters, facilitating cohort-level analysis with enhanced flexibility and interpretability. To promote model sparsity, we employ an l_1-ball projection prior, enabling precise control over complexity while identifying significant predictors. We assess performances on simulated data and then apply the method to real-world actigraphy data from people with epilepsy. Our results demonstrate the model's effectiveness in uncovering complex relationships among demographic, psychological, and medical factors influencing rest-activity rhythms, offering insights for personalized clinical assessments and healthcare interventions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03279</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03279</id><created>2025-02-05</created><authors><author><keyname>Säilynoja</keyname><forenames>Teemu</forenames></author><author><keyname>Schmitt</keyname><forenames>Marvin</forenames></author><author><keyname>Bürkner</keyname><forenames>Paul</forenames></author><author><keyname>Vehtari</keyname><forenames>Aki</forenames></author></authors><title>Posterior SBC: Simulation-Based Calibration Checking Conditional on Data</title><categories>stat.ME stat.CO stat.ML</categories><comments>22 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Simulation-based calibration checking (SBC) refers to the validation of an inference algorithm and model implementation through repeated inference on data simulated from a generative model. In the original and commonly used approach, the generative model uses parameters drawn from the prior, and thus the approach is testing whether the inference works for simulated data generated with parameter values plausible under that prior. This approach is natural and desirable when we want to test whether the inference works for a wide range of datasets we might observe. However, after observing data, we are interested in answering whether the inference works conditional on that particular data. In this paper, we propose posterior SBC and demonstrate how it can be used to validate the inference conditionally on observed data. We illustrate the utility of posterior SBC in three case studies: (1) A simple multilevel model; (2) a model that is governed by differential equations; and (3) a joint integrative neuroscience model which is approximated via amortized Bayesian inference with neural networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03327</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03327</id><created>2025-02-05</created><authors><author><keyname>Kratsios</keyname><forenames>Anastasis</forenames></author><author><keyname>Furuya</keyname><forenames>Takashi</forenames></author></authors><title>Is In-Context Universality Enough? MLPs are Also Universal In-Context</title><categories>stat.ML cs.LG cs.NA cs.NE math.NA math.PR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The success of transformers is often linked to their ability to perform in-context learning. Recent work shows that transformers are universal in context, capable of approximating any real-valued continuous function of a context (a probability measure over $\mathcal{X}\subseteq \mathbb{R}^d$) and a query $x\in \mathcal{X}$. This raises the question: Does in-context universality explain their advantage over classical models? We answer this in the negative by proving that MLPs with trainable activation functions are also universal in-context. This suggests the transformer's success is likely due to other factors like inductive bias or training stability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03329</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03329</id><created>2025-02-05</created><authors><author><keyname>Parra</keyname><forenames>Camila Olarte</forenames></author><author><keyname>Daniel</keyname><forenames>Rhian M.</forenames></author><author><keyname>Bartlett</keyname><forenames>Jonathan W.</forenames></author></authors><title>Dealing with multiple intercurrent events using hypothetical and   treatment policy strategies simultaneously</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To precisely define the treatment effect of interest in a clinical trial, the ICH E9 estimand addendum describes that relevant so-called intercurrent events should be identified and strategies specified to deal with them. Handling intercurrent events with different strategies leads to different estimands. In this paper, we focus on estimands that involve addressing one intercurrent event with the treatment policy strategy and another with the hypothetical strategy. We define these estimands using potential outcomes and causal diagrams, considering the possible causal relationships between the two intercurrent events and other variables. We show that there are different causal estimand definitions and assumptions one could adopt, each having different implications for estimation, which is demonstrated in a simulation study. The different considerations are illustrated conceptually using a diabetes trial as an example. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03332</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03332</id><created>2025-02-05</created><authors><author><keyname>Janati</keyname><forenames>Yazid</forenames></author><author><keyname>Moufad</keyname><forenames>Badr</forenames></author><author><keyname>Qassime</keyname><forenames>Mehdi Abou El</forenames></author><author><keyname>Durmus</keyname><forenames>Alain</forenames></author><author><keyname>Moulines</keyname><forenames>Eric</forenames></author><author><keyname>Olsson</keyname><forenames>Jimmy</forenames></author></authors><title>A Mixture-Based Framework for Guiding Diffusion Models</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Denoising diffusion models have driven significant progress in the field of Bayesian inverse problems. Recent approaches use pre-trained diffusion models as priors to solve a wide range of such problems, only leveraging inference-time compute and thereby eliminating the need to retrain task-specific models on the same dataset. To approximate the posterior of a Bayesian inverse problem, a diffusion model samples from a sequence of intermediate posterior distributions, each with an intractable likelihood function. This work proposes a novel mixture approximation of these intermediate distributions. Since direct gradient-based sampling of these mixtures is infeasible due to intractable terms, we propose a practical method based on Gibbs sampling. We validate our approach through extensive experiments on image inverse problems, utilizing both pixel- and latent-space diffusion priors, as well as on source separation with an audio diffusion model. The code is available at https://www.github.com/badr-moufad/mgdm </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03341</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03341</id><created>2025-02-05</created><authors><author><keyname>Leisenberger</keyname><forenames>Harald</forenames></author><author><keyname>Pernkopf</keyname><forenames>Franz</forenames></author></authors><title>Adaptive Variational Inference in Probabilistic Graphical Models: Beyond   Bethe, Tree-Reweighted, and Convex Free Energies</title><categories>stat.ML cs.AI cs.LG</categories><comments>This work has been submitted to the Conference on Uncertainty in   Artificial Intelligence (UAI) 2025 for possible publication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Variational inference in probabilistic graphical models aims to approximate fundamental quantities such as marginal distributions and the partition function. Popular approaches are the Bethe approximation, tree-reweighted, and other types of convex free energies. These approximations are efficient but can fail if the model is complex and highly interactive. In this work, we analyze two classes of approximations that include the above methods as special cases: first, if the model parameters are changed; and second, if the entropy approximation is changed. We discuss benefits and drawbacks of either approach, and deduce from this analysis how a free energy approximation should ideally be constructed. Based on our observations, we propose approximations that automatically adapt to a given model and demonstrate their effectiveness for a range of difficult problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03342</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03342</id><created>2025-02-05</created><authors><author><keyname>Baouan</keyname><forenames>Ali</forenames></author></authors><title>Statistical analysis of team formation and player roles in football</title><categories>stat.AP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The availability of tracking data in football presents unique opportunities for analyzing team shape and player roles, but leveraging it effectively remains challenging. This difficulty arises from the significant overlap in player positions, which complicates the identification of distinct roles and team formations. In this work, we propose a novel model that incorporates a hidden permutation matrix to simultaneously estimate team formations and assign roles to players at the frame level. To address the cardinality of permutation sets, we develop a statistical procedure to parsimoniously select relevant matrices prior to parameter estimation. Additionally, to capture formation changes during a match, we introduce a latent regime variable, enabling the modeling of dynamic tactical adjustments. This framework disentangles player locations from role-specific positions, providing a clear representation of team structure. We demonstrate the applicability of our approach using player tracking data, showcasing its potential for detailed team and player analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03350</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03350</id><created>2025-02-05</created><authors><author><keyname>Li</keyname><forenames>Ziyan</forenames></author><author><keyname>Hiratani</keyname><forenames>Naoki</forenames></author></authors><title>Optimal Task Order for Continual Learning of Multiple Tasks</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continual learning of multiple tasks remains a major challenge for neural networks. Here, we investigate how task order influences continual learning and propose a strategy for optimizing it. Leveraging a linear teacher-student model with latent factors, we derive an analytical expression relating task similarity and ordering to learning performance. Our analysis reveals two principles that hold under a wide parameter range: (1) tasks should be arranged from the least representative to the most typical, and (2) adjacent tasks should be dissimilar. We validate these rules on both synthetic data and real-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100), demonstrating consistent performance improvements in both multilayer perceptrons and convolutional neural networks. Our work thus presents a generalizable framework for task-order optimization in task-incremental continual learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03366</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03366</id><created>2025-02-05</created><authors><author><keyname>Mucsányi</keyname><forenames>Bálint</forenames></author><author><keyname>Da Costa</keyname><forenames>Nathaël</forenames></author><author><keyname>Hennig</keyname><forenames>Philipp</forenames></author></authors><title>Rethinking Approximate Gaussian Inference in Classification</title><categories>cs.LG stat.ML</categories><comments>29 pages, 15 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In classification tasks, softmax functions are ubiquitously used as output activations to produce predictive probabilities. Such outputs only capture aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian inference methods have been proposed, which output Gaussian distributions over the logit space. Predictives are then obtained as the expectations of the Gaussian distributions pushed forward through the softmax. However, such softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC) approximations can be costly and noisy. We propose a simple change in the learning objective which allows the exact computation of predictives and enjoys improved training dynamics, with no runtime or memory overhead. This framework is compatible with a family of output activation functions that includes the softmax, as well as element-wise normCDF and sigmoid. Moreover, it allows for approximating the Gaussian pushforwards with Dirichlet distributions by analytic moment matching. We evaluate our approach combined with several approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and small-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertainty quantification capabilities compared to softmax MC sampling. Code is available at https://github.com/bmucsanyi/probit. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03414</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03414</id><created>2025-02-05</created><authors><author><keyname>Jetsupphasuk</keyname><forenames>Michael</forenames></author><author><keyname>Li</keyname><forenames>Didong</forenames></author><author><keyname>Hudgens</keyname><forenames>Michael G.</forenames></author></authors><title>Estimating causal effects using difference-in-differences under network   dependency and interference</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differences-in-differences (DiD) is a causal inference method for observational longitudinal data that assumes parallel expected outcome trajectories between treatment groups under the (possible) counterfactual of receiving a specific treatment. In this paper DiD is extended to allow for (i) network dependency where outcomes, treatments, and covariates may exhibit between-unit latent correlation, and (ii) interference, where treatments can affect outcomes in neighboring units. In this setting, the causal estimand of interest is the average exposure effect among units with a specific exposure level, where the exposure is a function of treatments from potentially many units. Under a conditional parallel trends assumption and suitable network dependency conditions, a doubly robust estimator allowing for data-adaptive nuisance function estimation is proposed and shown to be consistent and asymptotically normal with variance reaching the semiparametric efficiency bound. The proposed methods are evaluated in simulations and applied to study the effects of adopting emission control technologies in coal power plants on county-level mortality due to cardiovascular disease. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03435</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03435</id><created>2025-02-05</created><authors><author><keyname>Wu</keyname><forenames>Yu-Han</forenames></author><author><keyname>Marion</keyname><forenames>Pierre</forenames></author><author><keyname>Biau</keyname><forenames>Gérard</forenames></author><author><keyname>Boyer</keyname><forenames>Claire</forenames></author></authors><title>Taking a Big Step: Large Learning Rates in Denoising Score Matching   Prevent Memorization</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Denoising score matching plays a pivotal role in the performance of diffusion-based generative models. However, the empirical optimal score--the exact solution to the denoising score matching--leads to memorization, where generated samples replicate the training data. Yet, in practice, only a moderate degree of memorization is observed, even without explicit regularization. In this paper, we investigate this phenomenon by uncovering an implicit regularization mechanism driven by large learning rates. Specifically, we show that in the small-noise regime, the empirical optimal score exhibits high irregularity. We then prove that, when trained by stochastic gradient descent with a large enough learning rate, neural networks cannot stably converge to a local minimum with arbitrarily small excess risk. Consequently, the learned score cannot be arbitrarily close to the empirical optimal score, thereby mitigating memorization. To make the analysis tractable, we consider one-dimensional data and two-layer neural networks. Experiments validate the crucial role of the learning rate in preventing memorization, even beyond the one-dimensional setting. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03439</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03439</id><created>2025-02-05</created><authors><author><keyname>Linwu</keyname><forenames>Jun</forenames></author><author><keyname>Khurana</keyname><forenames>Varun</forenames></author><author><keyname>Karris</keyname><forenames>Nicholas</forenames></author><author><keyname>Cloninger</keyname><forenames>Alexander</forenames></author></authors><title>Linearized Optimal Transport pyLOT Library: A Toolkit for Machine   Learning on Point Clouds</title><categories>stat.ML cs.LG cs.MS stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pyLOT library offers a Python implementation of linearized optimal transport (LOT) techniques and methods to use in downstream tasks. The pipeline embeds probability distributions into a Hilbert space via the Optimal Transport maps from a fixed reference distribution, and this linearization allows downstream tasks to be completed using off the shelf (linear) machine learning algorithms. We provide a case study of performing ML on 3D scans of lemur teeth, where the original questions of classification, clustering, dimension reduction, and data generation reduce to simple linear operations performed on the LOT embedded representations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03458</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03458</id><created>2025-02-05</created><authors><author><keyname>Johnston</keyname><forenames>Tim</forenames></author><author><keyname>Lytras</keyname><forenames>Iosif</forenames></author><author><keyname>Makras</keyname><forenames>Nikolaos</forenames></author><author><keyname>Sabanis</keyname><forenames>Sotirios</forenames></author></authors><title>The Performance Of The Unadjusted Langevin Algorithm Without Smoothness   Assumptions</title><categories>stat.ML math.OC math.PR stat.CO</categories><comments>26pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this article, we study the problem of sampling from distributions whose densities are not necessarily smooth nor log-concave. We propose a simple Langevin-based algorithm that does not rely on popular but computationally challenging techniques, such as the Moreau Yosida envelope or Gaussian smoothing. We derive non-asymptotic guarantees for the convergence of the algorithm to the target distribution in Wasserstein distances. Non asymptotic bounds are also provided for the performance of the algorithm as an optimizer, specifically for the solution of associated excess risk optimization problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1401.1137</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1401.1137</id><created>2014-01-06</created><updated>2015-03-27</updated><authors><author><keyname>Caron</keyname><forenames>François</forenames></author><author><keyname>Fox</keyname><forenames>Emily B.</forenames></author></authors><title>Sparse graphs using exchangeable random measures</title><categories>stat.ME cs.SI math.ST stat.ML stat.TH</categories><comments>New title. Extended version</comments><journal-ref>Journal of the Royal Statistical Society Series B: Statistical   Methodology, Volume 79, Issue 5, November 2017, Pages 1295-1366</journal-ref><doi>10.1111/rssb.12233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical network modeling has focused on representing the graph as a discrete structure, namely the adjacency matrix, and considering the exchangeability of this array. In such cases, the Aldous-Hoover representation theorem (Aldous, 1981;Hoover, 1979} applies and informs us that the graph is necessarily either dense or empty. In this paper, we instead consider representing the graph as a measure on $\mathbb{R}_+^2$. For the associated definition of exchangeability in this continuous space, we rely on the Kallenberg representation theorem (Kallenberg, 2005). We show that for certain choices of such exchangeable random measures underlying our graph construction, our network process is sparse with power-law degree distribution. In particular, we build on the framework of completely random measures (CRMs) and use the theory associated with such processes to derive important network properties, such as an urn representation for our analysis and network simulation. Our theoretical results are explored empirically and compared to common network models. We then present a Hamiltonian Monte Carlo algorithm for efficient exploration of the posterior distribution and demonstrate that we are able to recover graphs ranging from dense to sparse--and perform associated tests--based on our flexible CRM-based formulation. We explore network properties in a range of real datasets, including Facebook social circles, a political blogosphere, protein networks, citation networks, and world wide web networks, including networks with hundreds of thousands of nodes and millions of edges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1602.02114</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1602.02114</id><created>2016-02-05</created><updated>2017-08-23</updated><authors><author><keyname>Todeschini</keyname><forenames>Adrien</forenames></author><author><keyname>Miscouridou</keyname><forenames>Xenia</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Exchangeable Random Measures for Sparse and Modular Graphs with   Overlapping Communities</title><categories>stat.ME cs.SI physics.soc-ph stat.ML</categories><journal-ref>Journal of the Royal Statistical Society Series B: Statistical   Methodology, Volume 82, Issue 2, April 2020, Pages 487-520</journal-ref><doi>10.1111/rssb.12363</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel statistical model for sparse networks with overlapping community structure. The model is based on representing the graph as an exchangeable point process, and naturally generalizes existing probabilistic models with overlapping block-structure to the sparse regime. Our construction builds on vectors of completely random measures, and has interpretable parameters, each node being assigned a vector representing its level of affiliation to some latent communities. We develop methods for simulating this class of random graphs, as well as to perform posterior inference. We show that the proposed approach can recover interpretable structure from two real-world networks and can handle graphs with thousands of nodes and tens of thousands of edges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1708.03120</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1708.03120</id><created>2017-08-10</created><updated>2022-11-01</updated><authors><author><keyname>Caron</keyname><forenames>François</forenames></author><author><keyname>Panero</keyname><forenames>Francesca</forenames></author><author><keyname>Rousseau</keyname><forenames>Judith</forenames></author></authors><title>On sparsity, power-law and clustering properties of graphex processes</title><categories>math.ST math.PR stat.TH</categories><journal-ref>Advances in Applied Probability, Volume 55, Issue 4, December   2023, pp. 1211 - 1253</journal-ref><doi>10.1017/apr.2022.75</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates properties of the class of graphs based on exchangeable point processes. We provide asymptotic expressions for the number of edges, number of nodes and degree distributions, identifying four regimes: (i) a dense regime, (ii) a sparse almost dense regime, (iii) a sparse regime with power-law behaviour, and (iv) an almost extremely sparse regime. We show that under mild assumptions, both the global and local clustering coefficients converge to constants which may or may not be the same. We also derive a central limit theorem for the number of nodes. Finally, we propose a class of models within this framework where one can separately control the latent structure and the global sparsity/power-law properties of the graph. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1902.04714</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1902.04714</id><created>2019-02-12</created><updated>2019-07-09</updated><authors><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Beyond the Chinese Restaurant and Pitman-Yor processes: Statistical   Models with Double Power-law Behavior</title><categories>stat.ML cs.LG</categories><journal-ref>Proceedings of the 36th International Conference on Machine   Learning, PMLR 97:395-404, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian nonparametric approaches, in particular the Pitman-Yor process and the associated two-parameter Chinese Restaurant process, have been successfully used in applications where the data exhibit a power-law behavior. Examples include natural language processing, natural images or networks. There is also growing empirical evidence that some datasets exhibit a two-regime power-law behavior: one regime for small frequencies, and a second regime, with a different exponent, for high frequencies. In this paper, we introduce a class of completely random measures which are doubly regularly-varying. Contrary to the Pitman-Yor process, we show that when completely random measures in this class are normalized to obtain random probability measures and associated random partitions, such partitions exhibit a double power-law behavior. We discuss in particular three models within this class: the beta prime process (Broderick et al. (2015, 2018), a novel process called generalized BFRY process, and a mixture construction. We derive efficient Markov chain Monte Carlo algorithms to estimate the parameters of these models. Finally, we show that the proposed models provide a better fit than the Pitman-Yor process on various datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1905.09059</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1905.09059</id><created>2019-05-22</created><authors><author><keyname>Rathasamuth</keyname><forenames>Wanthanee</forenames></author><author><keyname>Pasupa</keyname><forenames>Kitsuchart</forenames></author><author><keyname>Tongsima</keyname><forenames>Sissades</forenames></author></authors><title>Selection of a Minimal Number of Significant Porcine SNPs by an   Information Gain and Genetic Algorithm Hybrid Model</title><categories>q-bio.QM cs.NE stat.AP</categories><comments>16 pages, 9 figures, preprint submitted to Malaysian Journal of   Computer Science</comments><journal-ref>Malaysian Journal of Computer Science, SI2, 79--95 (2019)</journal-ref><doi>10.22452/mjcs.sp2019no2.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A panel of large number of common Single Nucleotide Polymorphisms (SNPs) distributed across an entire porcine genome has been widely used to represent genetic variability of pig. With the advent of SNP-array technology, a genome-wide genetic profile of a specimen can be easily observed. Among the large number of such variations, there exist a much smaller subset of the SNP panel that could equally be used to correctly identify the corresponding breed. This work presents a SNP selection heuristic that can still be used effectively in the breed classification process. The proposed feature selection was done by the approach of combining a filter method and a wrapper method--information gain method and genetic algorithm--plus a feature frequency selection step, while classification was done by support vector machine. The approach was able to reduce the number of significant SNPs to 0.86 % of the total number of SNPs in a swine dataset and provided a high classification accuracy of 94.80 %. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1905.10733</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1905.10733</id><created>2019-05-26</created><authors><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Miscouridou</keyname><forenames>Xenia</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>A unified construction for series representations and finite   approximations of completely random measures</title><categories>math.ST cs.LG stat.ML stat.TH</categories><journal-ref>Bernoulli 29(3): 2142-2166, 2023</journal-ref><doi>10.3150/22-BEJ1536</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infinite-activity completely random measures (CRMs) have become important building blocks of complex Bayesian nonparametric models. They have been successfully used in various applications such as clustering, density estimation, latent feature models, survival analysis or network science. Popular infinite-activity CRMs include the (generalized) gamma process and the (stable) beta process. However, except in some specific cases, exact simulation or scalable inference with these models is challenging and finite-dimensional approximations are often considered. In this work, we propose a general and unified framework to derive both series representations and finite-dimensional approximations of CRMs. Our framework can be seen as an extension of constructions based on size-biased sampling of Poisson point process [Perman1992]. It includes as special cases several known series representations as well as novel ones. In particular, we show that one can get novel series representations for the generalized gamma process and the stable beta process. We also provide some analysis of the truncation error. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1911.06869</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1911.06869</id><created>2019-11-15</created><updated>2025-02-05</updated><authors><author><keyname>Bhadra</keyname><forenames>Somnath</forenames></author><author><keyname>Chakraborty</keyname><forenames>Kaustav</forenames></author><author><keyname>Sengupta</keyname><forenames>Srijan</forenames></author><author><keyname>Lahiri</keyname><forenames>Soumendra</forenames></author></authors><title>A Bootstrap-based Method for Testing Network Similarity</title><categories>stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the matched network inference problem, where the goal is to determine if two networks, defined on a common set of nodes, exhibit a specific form of stochastic similarity. Two notions of similarity are considered: (i) equality, i.e., testing whether the networks arise from the same random graph model, and (ii) scaling, i.e., testing whether their probability matrices are proportional for some unknown scaling constant. We develop a testing framework based on a parametric bootstrap approach and a Frobenius norm-based test statistic. The proposed approach is highly versatile as it covers both the equality and scaling problems, and ensures adaptability under various model settings, including stochastic blockmodels, Chung-Lu models, and random dot product graph models. We establish theoretical consistency of the proposed tests and demonstrate their empirical performance through extensive simulations under a wide range of model classes. Our results establish the flexibility and computational efficiency of the proposed method compared to existing approaches. We also report a real-world application involving the Aarhus network dataset, which reveals meaningful sociological patterns across different communication layers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2006.10968</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2006.10968</id><created>2020-06-19</created><updated>2022-11-28</updated><authors><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>The Normal-Generalised Gamma-Pareto process: A novel pure-jump L\'evy   process with flexible tail and jump-activity properties</title><categories>stat.ME math.ST stat.TH</categories><journal-ref>Bayesian Anal. 19(1): 123-152, 2024</journal-ref><doi>10.1214/22-BA1343</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pure-jump L\'evy processes are popular classes of stochastic processes which have found many applications in finance, statistics or machine learning. In this paper, we propose a novel family of self-decomposable L\'evy processes where one can control separately the tail behavior and the jump activity of the process, via two different parameters. Crucially, we show that one can sample exactly increments of this process, at any time scale; this allows the implementation of likelihood-free Markov chain Monte Carlo algorithms for (asymptotically) exact posterior inference. We use this novel process in L\'evy-based stochastic volatility models to predict the returns of stock market data, and show that the proposed class of models leads to superior predictive performances compared to classical alternatives. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2007.14717</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2007.14717</id><created>2020-07-29</created><updated>2024-06-05</updated><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames></author><author><keyname>Dreveton</keyname><forenames>Maximilien</forenames></author></authors><title>Almost exact recovery in noisy semi-supervised learning</title><categories>cs.LG math.ST stat.ML stat.TH</categories><msc-class>62F12, 62H30, 68T10</msc-class><journal-ref>Prob. Eng. Inf. Sci. 39 (2025) 1-22</journal-ref><doi>10.1017/S0269964824000135</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graph-based semi-supervised learning methods combine the graph structure and labeled data to classify unlabeled data. In this work, we study the effect of a noisy oracle on classification. In particular, we derive the Maximum A Posteriori (MAP) estimator for clustering a Degree Corrected Stochastic Block Model (DC-SBM) when a noisy oracle reveals a fraction of the labels. We then propose an algorithm derived from a continuous relaxation of the MAP, and we establish its consistency. Numerical experiments show that our approach achieves promising performance on synthetic and real data sets, even in the case of very noisy labeled data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2010.08891</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2010.08891</id><created>2020-10-17</created><updated>2025-02-04</updated><authors><author><keyname>Shrestha</keyname><forenames>Aayam</forenames></author><author><keyname>Lee</keyname><forenames>Stefan</forenames></author><author><keyname>Tadepalli</keyname><forenames>Prasad</forenames></author><author><keyname>Fern</keyname><forenames>Alan</forenames></author></authors><title>DeepAveragers: Offline Reinforcement Learning by Solving Derived   Non-Parametric MDPs</title><categories>cs.LG cs.AI stat.ML</categories><comments>Camera Ready ICLR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an approach to offline reinforcement learning (RL) based on optimally solving finitely-represented MDPs derived from a static dataset of experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals. Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL. DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model. In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2011.01591</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2011.01591</id><created>2020-11-03</created><updated>2025-02-05</updated><authors><author><keyname>Hermann</keyname><forenames>Philipp</forenames></author><author><keyname>Holzmann</keyname><forenames>Hajo</forenames></author></authors><title>Support estimation in high-dimensional heteroscedastic mean regression</title><categories>math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A current strand of research in high-dimensional statistics deals with robustifying the available methodology with respect to deviations from the pervasive light-tail assumptions. In this paper we consider a linear mean regression model with random design and potentially heteroscedastic, heavy-tailed errors, and investigate support estimation in this framework. We use a strictly convex, smooth variant of the Huber loss function with tuning parameter depending on the parameters of the problem, as well as the adaptive LASSO penalty for computational efficiency. For the resulting estimator we show sign-consistency and optimal rates of convergence in the $\ell_\infty$ norm as in the homoscedastic, light-tailed setting. In our analysis, we have to deal with the issue that the support of the target parameter in the linear mean regression model and its robustified version may differ substantially even for small values of the tuning parameter of the Huber loss function. Simulations illustrate the favorable numerical performance of the proposed methodology. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2101.07718</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2101.07718</id><created>2021-01-19</created><updated>2025-02-04</updated><authors><author><keyname>Wang</keyname><forenames>Zhu</forenames></author></authors><title>Unified Robust Boosting</title><categories>stat.CO</categories><msc-class>62H30, 62G35, 68Q32</msc-class><journal-ref>Journal of Data Science, 2025, 23(1): 90-108</journal-ref><doi>10.6339/24-JDS1138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting is a popular algorithm in supervised machine learning with wide applications in regression and classification problems. It combines weak learners, such as regression trees, to obtain accurate predictions. However, in the presence of outliers, traditional boosting may yield inferior results since the algorithm optimizes a convex loss function. Recent literature has proposed boosting algorithms that optimize robust nonconvex loss functions. Nevertheless, there is a lack of weighted estimation to indicate the outlier status of observations. This article introduces the iteratively reweighted boosting (IRBoost) algorithm, which combines robust loss optimization and weighted estimation. It can be conveniently constructed with existing software. The output includes weights as valuable diagnostics for the outlier status of observations. For practitioners interested in the boosting algorithm, the new method can be interpreted as a way to tune robust observation weights. IRBoost is implemented in the R package irboost and is demonstrated using publicly available data in generalized linear models, classification, and survival data analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2107.00587</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2107.00587</id><created>2021-07-01</created><authors><author><keyname>Lecestre</keyname><forenames>Alexandre</forenames></author></authors><title>Robust Estimation in Finite Mixture Models</title><categories>math.ST stat.TH</categories><msc-class>62G05, 62G35, 62F35 (Primary) 62G07 (Secondary)</msc-class><journal-ref>ESAIM:PS, 27(2023), 402--460</journal-ref><doi>10.1051/ps/2023004</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We observe a $n$-sample, the distribution of which is assumed to belong, or at least to be close enough, to a given mixture model. We propose an estimator of this distribution that belongs to our model and possesses some robustness properties with respect to a possible misspecification of it. We establish a non-asymptotic deviation bound for the Hellinger distance between the target distribution and its estimator when the model consists of a mixture of densities that belong to VC-subgraph classes. Under suitable assumptions and when the mixture model is well-specified, we derive risk bounds for the parameters of the mixture. Finally, we design a statistical procedure that allows us to select from the data the number of components as well as suitable models for each of the densities that are involved in the mixture. These models are chosen among a collection of candidate ones and we show that our selection rule combined with our estimation strategy result in an estimator which satisfies an oracle-type inequality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2107.01120</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2107.01120</id><created>2021-07-02</created><updated>2022-05-25</updated><authors><author><keyname>Naulet</keyname><forenames>Zacharie</forenames></author><author><keyname>Rousseau</keyname><forenames>Judith</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Asymptotic Analysis of Statistical Estimators related to MultiGraphex   Processes under Misspecification</title><categories>math.ST stat.TH</categories><journal-ref>Bernoulli 30(4): 2644-2675, 2024</journal-ref><doi>10.3150/23-BEJ1689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the asymptotic properties of Bayesian or frequentist estimators of a vector of parameters related to structural properties of sequences of graphs. The estimators studied originate from a particular class of graphex model introduced by Caron and Fox. The analysis is however performed here under very weak assumptions on the underlying data generating process, which may be different from the model of Caron and Fox or from a graphex model. In particular, we consider generic sparse graph models, with unbounded degree, whose degree distribution satisfies some assumptions. We show that one can relate the limit of the estimator of one of the parameters to the sparsity constant of the true graph generating process. When taking a Bayesian approach, we also show that the posterior distribution is asymptotically normal. We discuss situations where classical random graphs models such as configuration models, sparse graphon models, edge exchangeable models or graphon processes satisfy our assumptions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2109.00375</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2109.00375</id><created>2021-09-01</created><updated>2025-02-04</updated><authors><author><keyname>Tan</keyname><forenames>Linda S. L.</forenames></author></authors><title>Analytic natural gradient updates for Cholesky factor in Gaussian   variational approximation</title><categories>stat.CO</categories><doi>10.1093/jrsssb/qkaf001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural gradients can improve convergence in stochastic variational inference significantly but inverting the Fisher information matrix is daunting in high dimensions. Moreover, in Gaussian variational approximation, natural gradient updates of the precision matrix do not ensure positive definiteness. To tackle this issue, we derive analytic natural gradient updates of the Cholesky factor of the covariance or precision matrix, and consider sparsity constraints representing different posterior correlation structures. Stochastic normalized natural gradient ascent with momentum is proposed for implementation in generalized linear mixed models and deep neural networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2110.06250</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2110.06250</id><created>2021-10-12</created><updated>2025-02-05</updated><authors><author><keyname>Weinstein</keyname><forenames>Asaf</forenames></author></authors><title>On the Minimum Attainable Risk in Permutation Invariant Problems</title><categories>math.ST stat.TH</categories><comments>1 figure</comments><msc-class>62C05, 62C12, 62C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a broad class of permutation invariant statistical problems by extending the standard decision theoretic definition to allow also selective inference tasks, where the target is specified only after seeing the data. For any such problem we show that, among all permutation invariant procedures, the minimizer of the risk at $\boldsymbol{\theta}$ is precisely the rule that minimizes the Bayes risk under a (postulated) discrete prior assigning equal probability to every permutation of $\boldsymbol{\theta}$. This gives an explicit characterization of the greatest lower bound on the risk of every sensible procedure in a wide range of problems. Furthermore, in a permutation invariant problem of estimating the parameter of a selected population under squared loss, we prove that this lower bound coincides asymptotically with a simpler lower bound, attained by the Bayes solution that replaces the aforementioned uniform prior on all permutations of $\boldsymbol{\theta}$ by the i.i.d. prior with the same marginals. This has important algorithmic implications because it suggests that our greatest lower bound is asymptotically attainable uniformly in $\boldsymbol{\theta}$ by an empirical Bayes procedure. Altogether, the above extends theory that has been established in the existing literature only for the very special case of compound decision problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.03513</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.03513</id><created>2022-02-07</created><updated>2025-02-05</updated><authors><author><keyname>Díaz</keyname><forenames>Iván</forenames></author><author><keyname>Hoffman</keyname><forenames>Katherine L</forenames></author><author><keyname>Hejazi</keyname><forenames>Nima S.</forenames></author></authors><title>Causal survival analysis under competing risks using longitudinal   modified treatment policies</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Longitudinal modified treatment policies (LMTP) have been recently developed as a novel method to define and estimate causal parameters that depend on the natural value of treatment. LMTPs represent an important advancement in causal inference for longitudinal studies as they allow the non-parametric definition and estimation of the joint effect of multiple categorical, numerical, or continuous exposures measured at several time points. We extend the LMTP methodology to problems in which the outcome is a time-to-event variable subject to right-censoring and competing risks. We present identification results and non-parametric locally efficient estimators that use flexible data-adaptive regression techniques to alleviate model misspecification bias, while retaining important asymptotic properties such as $\sqrt{n}$-consistency. We present an application to the estimation of the effect of the time-to-intubation on acute kidney injury amongst COVID-19 hospitalized patients, where death by other causes is taken to be the competing event. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.11886</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.11886</id><created>2022-02-23</created><updated>2025-02-04</updated><authors><author><keyname>Jeong</keyname><forenames>Yujin</forenames></author><author><keyname>Rothenhäusler</keyname><forenames>Dominik</forenames></author></authors><title>Calibrated inference: statistical inference that accounts for both   sampling uncertainty and distributional uncertainty</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  How can we draw trustworthy scientific conclusions? One criterion is that a study can be replicated by independent teams. While replication is critically important, it is arguably insufficient. If a study is biased for some reason and other studies recapitulate the approach then findings might be consistently incorrect. It has been argued that trustworthy scientific conclusions require disparate sources of evidence. However, different methods might have shared biases, making it difficult to judge the trustworthiness of a result. We formalize this issue by introducing a "distributional uncertainty model", wherein dense distributional shifts emerge as the superposition of numerous small random changes. The distributional perturbation model arises under a symmetry assumption on distributional shifts and is strictly weaker than assuming that the data is i.i.d. from the target distribution. We show that a stability analysis on a single data set allows us to construct confidence intervals that account for both sampling uncertainty and distributional uncertainty. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2205.08187</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2205.08187</id><created>2022-05-17</created><updated>2023-09-11</updated><authors><author><keyname>Lee</keyname><forenames>Hoil</forenames></author><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Jung</keyname><forenames>Paul</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Yang</keyname><forenames>Hongseok</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Deep neural networks with dependent weights: Gaussian Process mixture   limit, heavy tails, sparsity and compressibility</title><categories>stat.ML cs.LG math.PR math.ST stat.TH</categories><comments>96 pages, 15 figures, 9 tables</comments><msc-class>68T07 (Primary), 62M45, 60F99 (Secondary)</msc-class><journal-ref>Journal Of Machine Learning Research, 24(289):1-78, 2023</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the infinite-width limit of deep feedforward neural networks whose weights are dependent, and modelled via a mixture of Gaussian distributions. Each hidden node of the network is assigned a nonnegative random variable that controls the variance of the outgoing weights of that node. We make minimal assumptions on these per-node random variables: they are iid and their sum, in each layer, converges to some finite random variable in the infinite-width limit. Under this model, we show that each layer of the infinite-width neural network can be characterised by two simple quantities: a non-negative scalar parameter and a L\'evy measure on the positive reals. If the scalar parameters are strictly positive and the L\'evy measures are trivial at all hidden layers, then one recovers the classical Gaussian process (GP) limit, obtained with iid Gaussian weights. More interestingly, if the L\'evy measure of at least one layer is non-trivial, we obtain a mixture of Gaussian processes (MoGP) in the large-width limit. The behaviour of the neural network in this regime is very different from the GP regime. One obtains correlated outputs, with non-Gaussian distributions, possibly with heavy tails. Additionally, we show that, in this regime, the weights are compressible, and some nodes have asymptotically non-negligible contributions, therefore representing important hidden features. Many sparsity-promoting neural network models can be recast as special cases of our approach, and we discuss their infinite-width limits; we also present an asymptotic analysis of the pruning error. We illustrate some of the benefits of the MoGP regime over the GP regime in terms of representation learning and compressibility on simulated, MNIST and Fashion MNIST datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2206.02204</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2206.02204</id><created>2022-06-05</created><updated>2025-02-05</updated><authors><author><keyname>Lu</keyname><forenames>Jun</forenames></author><author><keyname>Mao</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Li</keyname><forenames>Mengyao</forenames></author><author><keyname>Hou</keyname><forenames>Chenping</forenames></author></authors><title>Adaptive weighted approach for high-dimensional statistical learning and   inference</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We propose a new weighted average estimator for the high dimensional parameters under the distributed learning system, in which the weight assigned to each coordinate is precisely proportional to the inverse of the variance of the local estimates for that coordinate. This strategy empowers the new estimator to achieve a minimal mean squared error, comparable to the current state-of-the-art one-shot distributed learning methods. While at the same time, the new weighting approach maintains remarkably low communication costs, as each agent is required to transmit only two vectors to the central server. As a result, the newly proposed method achieves optimal statistical efficiency while significantly reducing communication overhead. We further demonstrate the effectiveness of the new estimator by investigating the error bound and the asymptotic properties of the estimation, as well as the numerical performance on some simulated examples and a real data analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2208.07853</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2208.07853</id><created>2022-08-16</created><updated>2025-02-05</updated><authors><author><keyname>Neto</keyname><forenames>Jeova Farias Sales Rocha</forenames></author></authors><title>Estimating Appearance Models for Image Segmentation via Tensor   Factorization</title><categories>cs.CV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Image Segmentation is one of the core tasks in Computer Vision and solving it often depends on modeling the image appearance data via the color distributions of each it its constituent regions. Whereas many segmentation algorithms handle the appearance models dependence using alternation or implicit methods, we propose here a new approach to directly estimate them from the image without prior information on the underlying segmentation. Our method uses local high order color statistics from the image as an input to tensor factorization-based estimator for latent variable models. This approach is able to estimate models in multiregion images and automatically output the regions proportions without prior user interaction, overcoming the drawbacks from a prior attempt to this problem. We also demonstrate the performance of our proposed method in many challenging synthetic and real imaging scenarios and show that it leads to an efficient segmentation algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2208.10790</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2208.10790</id><created>2022-08-23</created><updated>2025-02-04</updated><authors><author><keyname>Brunzema</keyname><forenames>Paul</forenames></author><author><keyname>von Rohr</keyname><forenames>Alexander</forenames></author><author><keyname>Solowjow</keyname><forenames>Friedrich</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Event-Triggered Time-Varying Bayesian Optimization</title><categories>cs.LG stat.ML</categories><comments>Published in Transactions on Machine Learning Research (TMLR)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Current approaches to TVBO require prior knowledge of a constant rate of change to cope with stale data arising from time variations. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function and then resets the dataset. This allows the algorithm to adapt online to realized temporal changes without the need for exact prior knowledge. The event trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We derive regret bounds for adaptive resets without exact prior knowledge of the temporal changes and show in numerical experiments that ET-GP-UCB outperforms competing GP-UCB algorithms on both synthetic and real-world data. The results demonstrate that ET-GP-UCB is readily applicable without extensive hyperparameter tuning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2211.02609</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2211.02609</id><created>2022-11-04</created><updated>2025-02-05</updated><authors><author><keyname>Costello</keyname><forenames>Fintan</forenames></author><author><keyname>Watts</keyname><forenames>Paul</forenames></author></authors><title>How to Tell When a Result Will Replicate: Significance and Replication   in Distributional Null Hypothesis Tests</title><categories>stat.ME math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  There is a well-known problem in Null Hypothesis Significance Testing: many statistically significant results fail to replicate in subsequent experiments. We show that this problem arises because standard `point-form null' significance tests consider only within-experiment but ignore between-experiment variation, and so systematically underestimate the degree of random variation in results. We give an extension to standard significance testing that addresses this problem by analysing both within- and between-experiment variation. This `distributional null' approach does not underestimate experimental variability and so is not overconfident in identifying significance; because this approach addresses between-experiment variation, it gives mathematically coherent estimates for the probability of replication of significant results. Using a large-scale replication dataset (the first `Many Labs' project), we show that many experimental results that appear statistically significant in standard tests are in fact consistent with random variation when both within- and between-experiment variation are taken into account in this approach. Further, grouping experiments in this dataset into `predictor-target' pairs we show that the predicted replication probabilities for target experiments produced in this approach (given predictor experiment results and the sample sizes of the two experiments) are strongly correlated with observed replication rates. Distributional null hypothesis testing thus gives researchers a statistical tool for identifying statistically significant and reliably replicable results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2303.11293</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2303.11293</id><created>2023-03-13</created><updated>2025-02-05</updated><authors><author><keyname>Pran</keyname><forenames>Rakib Hassan</forenames></author></authors><title>Advancing Network Securing Strategies with Network Algorithms for   Integrated Air Defense System (IADS) Missile Batteries</title><categories>cs.SI stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently, the Integrated Air Defense System (IADS) has become vital for the defense system as the military defense system is vital for national security. Placing Integrated Air Defense System batteries among locations to protect locations assets is a crucial problem because optimal solutions are needed for interceptor missiles to intercept attacker missiles for maximizing protection of assets across locations or places. In this research, the procedures of using network algorithms along with developing several network algorithms are going to be demonstrated to develop a model for sequential development of seven network securing strategies of placing Surface to Air Missile (SAM) batteries to maximize the protection of assets across locations (based on given asset values) by generating optimal solutions through computation to destroy maximum attacker missiles by using minimum interceptor missiles with given intercept probability. This network securing strategies can be implemented not only for Integrated Air Defense System (IADS) planning but also Counter Air (CA) planning as Integrated Air Defense System (IADS) is conducted with defensive counter air supported by attack operations in offensive counter air. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.05242</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.05242</id><created>2023-04-11</created><updated>2025-02-05</updated><authors><author><keyname>Baouan</keyname><forenames>Ali</forenames></author><author><keyname>Coustou</keyname><forenames>Sébastien</forenames></author><author><keyname>Lacome</keyname><forenames>Mathieu</forenames></author><author><keyname>Pulido</keyname><forenames>Sergio</forenames></author><author><keyname>Rosenbaum</keyname><forenames>Mathieu</forenames></author></authors><title>Generation of Threat: Crediting football players for creating dangerous   actions in an unbiased way</title><categories>stat.AP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We introduce an innovative methodology to identify football players at the origin of threatening actions in a team. In our framework, a threat is defined as entering the opposing team's danger area. We investigate the timing of threat events and ball touches of players, and capture their correlation using Hawkes processes. Our model-based approach allows us to evaluate a player's ability to create danger both directly and through interactions with teammates. We define a new index, called Generation of Threat (GoT), that measures in an unbiased way the contribution of a player to threat generation. For illustration, we present a detailed analysis of Chelsea's 2016-2017 season, with a standout performance from Eden Hazard. We are able to credit each player for his involvement in danger creation and determine the main circuits leading to threat. In the same spirit, we investigate the danger generation process of Stade Rennais in the 2021-2022 season. Furthermore, we establish a comprehensive ranking of Ligue 1 players based on their generated threat in the 2021-2022 season. Our analysis reveals surprising results, with players such as Jason Berthomier, Moses Simon and Frederic Guilbert among the top performers in the GoT rankings. We also present a ranking of Ligue 1 central defenders in terms of generation of threat and confirm the great performance of some center-back pairs, such as Nayef Aguerd and Warmed Omari. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.12218</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.12218</id><created>2023-04-24</created><updated>2025-02-05</updated><authors><author><keyname>Clarke</keyname><forenames>Bertrand</forenames></author><author><keyname>Yao</keyname><forenames>Yuling</forenames></author></authors><title>A Cheat Sheet for Bayesian Prediction</title><categories>stat.ME</categories><comments>23 pages</comments><msc-class>62-02</msc-class><journal-ref>Statist. Sci. 2025, Vol. 40, 3-24</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper reviews the growing field of Bayesian prediction. Bayes point and interval prediction are defined and exemplified and situated in statistical prediction more generally. Then, four general approaches to Bayes prediction are defined and we turn to predictor selection. This can be done predictively or non-predictively and predictors can be based on single models or multiple models. We call these latter cases unitary predictors and model average predictors, respectively. Then we turn to the most recent aspect of prediction to emerge, namely prediction in the context of large observational data sets and discuss three further classes of techniques. We conclude with a summary and statement of several current open problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2305.06116</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2305.06116</id><created>2023-05-10</created><updated>2025-02-04</updated><authors><author><keyname>Catalano</keyname><forenames>Marta</forenames></author><author><keyname>Lavenant</keyname><forenames>Hugo</forenames></author></authors><title>Merging Rate of Opinions via Optimal Transport on Random Measures</title><categories>math.ST math.PR stat.TH</categories><comments>Substantial modifications compared to v1 of this preprint</comments><msc-class>60G55, 60G57, 49Q22, 62C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random measures provide flexible parameters for Bayesian nonparametric models. Given two different priors for a random measure, we develop a natural framework to investigate the rate at which the corresponding posteriors merge, as the sample size increases. We define a new distance between the laws of random measures that is built as a Wasserstein distance on the ground space of unbalanced measures, endowed with the bounded Lipschitz metric. We develop tight analytical bounds for its specification to completely random measures, including the special case of Poisson and gamma random measures. The bounds are interpreted in terms of an adapted extended Wasserstein distance between the L\'evy measures and are used to investigate the merging between the posteriors of normalized gamma and generalized gamma priors. After a careful study on the identifiability of the law of the random measure, interesting asymptotic and finite-sample insights are derived without putting \emph{any} assumption on the true data generating process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2306.01727</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2306.01727</id><created>2023-06-02</created><updated>2025-02-04</updated><authors><author><keyname>Briend</keyname><forenames>Simon</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Lugosi</keyname><forenames>Gabor</forenames></author></authors><title>Broadcasting in random recursive dags</title><categories>stat.ML cs.LG cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A uniform $k$-{\sc dag} generalizes the uniform random recursive tree by picking $k$ parents uniformly at random from the existing nodes. It starts with $k$ ''roots''. Each of the $k$ roots is assigned a bit. These bits are propagated by a noisy channel. The parents' bits are flipped with probability $p$, and a majority vote is taken. When all nodes have received their bits, the $k$-{\sc dag} is shown without identifying the roots. The goal is to estimate the majority bit among the roots. We identify the threshold for $p$ as a function of $k$ below which the majority rule among all nodes yields an error $c+o(1)$ with $c&lt;1/2$. Above the threshold the majority rule errs with probability $1/2+o(1)$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2306.02813</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2306.02813</id><created>2023-06-05</created><updated>2024-07-16</updated><authors><author><keyname>Tan</keyname><forenames>Linda S. L.</forenames></author><author><keyname>Chen</keyname><forenames>Aoxiang</forenames></author></authors><title>Variational inference based on a subclass of closed skew normals</title><categories>stat.ME</categories><comments>keywords: Closed skew normal; Gaussian variational approximation;   natural gradient; centered parametrization; LU decomposition</comments><doi>10.1080/10618600.2024.2402278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian distributions are widely used in Bayesian variational inference to approximate intractable posterior densities, but the ability to accommodate skewness can improve approximation accuracy significantly, when data or prior information is scarce. We study the properties of a subclass of closed skew normals constructed using affine transformation of independent standardized univariate skew normals as the variational density, and illustrate how it provides increased flexibility and accuracy in approximating the joint posterior in various applications, by overcoming limitations in existing skew normal variational approximations. The evidence lower bound is optimized using stochastic gradient ascent, where analytic natural gradient updates are derived. We also demonstrate how problems in maximum likelihood estimation of skew normal parameters occur similarly in stochastic variational inference, and can be resolved using the centered parametrization. Supplemental materials are available online. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.09766</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.09766</id><created>2023-10-15</created><updated>2025-02-03</updated><authors><author><keyname>Chen</keyname><forenames>Haoxian</forenames></author><author><keyname>Lam</keyname><forenames>Henry</forenames></author></authors><title>Pseudo-Bayesian Optimization</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-based methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a suitable "randomized prior" construction to quantify uncertainty, not only guarantees convergence but also consistently outperforms state-of-the-art benchmarks in examples ranging from high-dimensional synthetic experiments to realistic hyperparameter tuning and robotic applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.05153</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.05153</id><created>2023-12-08</created><updated>2025-02-05</updated><authors><author><keyname>Reiser</keyname><forenames>Philipp</forenames></author><author><keyname>Aguilar</keyname><forenames>Javier Enrique</forenames></author><author><keyname>Guthke</keyname><forenames>Anneli</forenames></author><author><keyname>Bürkner</keyname><forenames>Paul-Christian</forenames></author></authors><title>Uncertainty Quantification and Propagation in Surrogate-based Bayesian   Inference</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Surrogate models are statistical or conceptual approximations for more complex simulation models. In this context, it is crucial to propagate the uncertainty induced by limited simulation budget and surrogate approximation error to predictions, inference, and subsequent decision-relevant quantities. However, quantifying and then propagating the uncertainty of surrogates is usually limited to special analytic cases or is otherwise computationally very expensive. In this paper, we propose a framework enabling a scalable, Bayesian approach to surrogate modeling with thorough uncertainty quantification, propagation, and validation. Specifically, we present three methods for Bayesian inference with surrogate models given measurement data. This is a task where the propagation of surrogate uncertainty is especially relevant, because failing to account for it may lead to biased and/or overconfident estimates of the parameters of interest. We showcase our approach in three detailed case studies for linear and nonlinear real-world modeling scenarios. Uncertainty propagation in surrogate models enables more reliable and safe approximation of expensive simulators and will therefore be useful in various fields of applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.14531</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.14531</id><created>2024-01-25</created><updated>2025-02-03</updated><authors><author><keyname>Mandjes</keyname><forenames>Michel</forenames></author><author><keyname>Wang</keyname><forenames>Jiesen</forenames></author></authors><title>Estimation of on- and off-time distributions in a dynamic   Erd\H{o}s-R\'enyi random graph</title><categories>math.ST math.PR stat.TH</categories><msc-class>05C80, 62M09, 62F12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a dynamic Erd\H{o}s-R\'enyi graph in which edges, according to an alternating renewal process, change from present to absent and vice versa. The objective is to estimate the on- and off-time distributions while only observing the aggregate number of edges. This inverse problem is dealt with, in a parametric context, by setting up an estimator based on the method of moments. We provide conditions under which the estimator is asymptotically normal, and we point out how the corresponding covariance matrix can be identified. It is also demonstrated how to adapt the estimation procedure if alternative subgraph counts are observed, such as the number of wedges or triangles. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.04933</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.04933</id><created>2024-02-07</created><updated>2025-02-05</updated><authors><author><keyname>Liang</keyname><forenames>Biyonka</forenames></author><author><keyname>Xu</keyname><forenames>Lily</forenames></author><author><keyname>Taneja</keyname><forenames>Aparna</forenames></author><author><keyname>Tambe</keyname><forenames>Milind</forenames></author><author><keyname>Janson</keyname><forenames>Lucas</forenames></author></authors><title>Context in Public Health for Underserved Communities: A Bayesian   Approach to Online Restless Bandits</title><categories>cs.LG stat.AP</categories><comments>29 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public health programs often provide interventions to encourage program adherence, and effectively allocating interventions is vital for producing the greatest overall health outcomes, especially in underserved communities where resources are limited. Such resource allocation problems are often modeled as restless multi-armed bandits (RMABs) with unknown underlying transition dynamics, hence requiring online reinforcement learning (RL). We present Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs that novelly combines techniques in Bayesian modeling with Thompson sampling to flexibly model the complex RMAB settings present in public health program adherence problems, namely context and non-stationarity. BCoR's key strength is the ability to leverage shared information within and between arms to learn the unknown RMAB transition dynamics quickly in intervention-scarce settings with relatively short time horizons, which is common in public health applications. Empirically, BCoR achieves substantially higher finite-sample performance over a range of experimental settings, including a setting using real-world adherence data that was developed in collaboration with ARMMAN, an NGO in India which runs a large-scale maternal mHealth program, showcasing BCoR practical utility and potential for real-world deployment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.08283</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.08283</id><created>2024-02-13</created><updated>2024-10-24</updated><authors><author><keyname>Ghosh</keyname><forenames>Annesha</forenames></author><author><keyname>Ghosh</keyname><forenames>Anil K.</forenames></author><author><keyname>SahaRay</keyname><forenames>Rita</forenames></author><author><keyname>Sarkar</keyname><forenames>Soham</forenames></author></authors><title>Classification Using Global and Local Mahalanobis Distances</title><categories>stat.ME stat.ML</categories><doi>10.1016/j.jmva.2025.105417</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel semiparametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric modeling assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose another classifier based on a generalized additive model that uses the local Mahalanobis distances as features. This nonparametric classifier usually performs like the Mahalanobis distance based semiparametric classifier when the underlying distributions are elliptic, but outperforms it for several non-elliptic and multimodal distributions. We also investigate the behaviour of these two classifiers in high dimension, low sample size situations. A thorough numerical study involving several simulated and real datasets demonstrate the usefulness of the proposed classifiers in comparison to many state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.10018</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.10018</id><created>2024-02-15</created><updated>2025-02-04</updated><authors><author><keyname>Portnoy</keyname><forenames>Ayelet C.</forenames></author><author><keyname>Solomon</keyname><forenames>Amit</forenames></author><author><keyname>Cohen</keyname><forenames>Alejandro</forenames></author></authors><title>Non-Adaptive Multi-Stage Algorithm and Bounds for Group Testing with   Prior Statistics</title><categories>cs.IT math.IT q-bio.QM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient multi-stage algorithm for non-adaptive Group Testing (GT) with general correlated prior statistics. The proposed solution can be applied to any correlated statistical prior represented in trellis, e.g., finite state machines and Markov processes. We introduce a variation of List Viterbi Algorithm (LVA) to enable accurate recovery using much fewer tests than objectives, which efficiently gains from the correlated prior statistics structure. We also provide a sufficiency bound to the number of pooled tests required by any Maximum A Posteriori (MAP) decoder with an arbitrary correlation between infected items. Our numerical results demonstrate that the proposed Multi-Stage GT (MSGT) algorithm can obtain the optimal MAP performance with feasible complexity in practical regimes, such as with COVID-19 and sparse signal recovery applications, and reduce in the scenarios tested the number of pooled tests by at least 25% compared to existing classical low complexity GT algorithms. Moreover, we analytically characterize the complexity of the proposed MSGT algorithm that guarantees its efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.14645</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.14645</id><created>2024-02-22</created><updated>2025-02-04</updated><authors><author><keyname>Gupte</keyname><forenames>Aparna</forenames></author><author><keyname>Vafa</keyname><forenames>Neekon</forenames></author><author><keyname>Vaikuntanathan</keyname><forenames>Vinod</forenames></author></authors><title>Sparse Linear Regression and Lattice Problems</title><categories>cs.LG stat.ML</categories><comments>TCC 2024; minor edits</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse linear regression (SLR) is a well-studied problem in statistics where one is given a design matrix $X\in\mathbb{R}^{m\times n}$ and a response vector $y=X\theta^*+w$ for a $k$-sparse vector $\theta^*$ (that is, $\|\theta^*\|_0\leq k$) and small, arbitrary noise $w$, and the goal is to find a $k$-sparse $\widehat{\theta} \in \mathbb{R}^n$ that minimizes the mean squared prediction error $\frac{1}{m}\|X\widehat{\theta}-X\theta^*\|^2_2$. While $\ell_1$-relaxation methods such as basis pursuit, Lasso, and the Dantzig selector solve SLR when the design matrix is well-conditioned, no general algorithm is known, nor is there any formal evidence of hardness in an average-case setting with respect to all efficient algorithms.   We give evidence of average-case hardness of SLR w.r.t. all efficient algorithms assuming the worst-case hardness of lattice problems. Specifically, we give an instance-by-instance reduction from a variant of the bounded distance decoding (BDD) problem on lattices to SLR, where the condition number of the lattice basis that defines the BDD instance is directly related to the restricted eigenvalue condition of the design matrix, which characterizes some of the classical statistical-computational gaps for sparse linear regression. Also, by appealing to worst-case to average-case reductions from the world of lattices, this shows hardness for a distribution of SLR instances; while the design matrices are ill-conditioned, the resulting SLR instances are in the identifiable regime.   Furthermore, for well-conditioned (essentially) isotropic Gaussian design matrices, where Lasso is known to behave well in the identifiable regime, we show hardness of outputting any good solution in the unidentifiable regime where there are many solutions, assuming the worst-case hardness of standard and well-studied lattice problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.18213</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.18213</id><created>2024-02-28</created><updated>2025-02-04</updated><authors><author><keyname>Sukthanker</keyname><forenames>Rhea Sanjay</forenames></author><author><keyname>Zela</keyname><forenames>Arber</forenames></author><author><keyname>Staffler</keyname><forenames>Benedikt</forenames></author><author><keyname>Dooley</keyname><forenames>Samuel</forenames></author><author><keyname>Grabocka</keyname><forenames>Josif</forenames></author><author><keyname>Hutter</keyname><forenames>Frank</forenames></author></authors><title>Multi-objective Differentiable Neural Architecture Search</title><categories>cs.LG cs.CV stat.ML</categories><comments>44 pages, 34 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Pareto front profiling in multi-objective optimization (MOO), i.e., finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives that require training a neural network. Typically, in MOO for neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a computationally expensive search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences to trade-off performance and hardware metrics, yielding representative and diverse architectures across multiple devices in just a single search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot transferability to new devices. Extensive experiments involving up to 19 hardware devices and 3 different objectives demonstrate the effectiveness and scalability of our method. Finally, we show that, without any additional costs, our method outperforms existing MOO NAS methods across a broad range of qualitatively different search spaces and datasets, including MobileNetV3 on ImageNet-1k, an encoder-decoder transformer space for machine translation and a decoder-only space for language modelling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.02233</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.02233</id><created>2024-03-04</created><updated>2025-02-05</updated><authors><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Wen</keyname><forenames>Zixin</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author></authors><title>A Theoretical Analysis of Self-Supervised Learning for Vision   Transformers</title><categories>cs.LG math.OC stat.ML</categories><comments>Accepted by ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-supervised learning has become a cornerstone in computer vision, primarily divided into reconstruction-based methods like masked autoencoders (MAE) and discriminative methods such as contrastive learning (CL). Recent empirical observations reveal that MAE and CL capture different types of representations: CL tends to focus on global patterns, while MAE adeptly captures both global and subtle local information simultaneously. Despite a flurry of recent empirical investigations to shed light on this difference, theoretical understanding remains limited, especially on the dominant architecture vision transformers (ViTs). In this paper, to provide rigorous insights, we model the visual data distribution by considering two types of spatial features: dominant global features and comparatively minuscule local features, and study the impact of imbalance among these features. We analyze the training dynamics of one-layer softmax-based ViTs on both MAE and CL objectives using gradient descent. Our analysis shows that as the degree of feature imbalance varies, ViTs trained with the MAE objective effectively learn both global and local features to achieve near-optimal reconstruction, while the CL-trained ViTs favor predominantly global features, even under mild imbalance. These results provide a theoretical explanation for distinct behaviors of MAE and CL observed in empirical studies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.05038</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.05038</id><created>2024-03-07</created><updated>2025-02-04</updated><authors><author><keyname>Krantz</keyname><forenames>Sebastian</forenames></author></authors><title>collapse: Advanced and Fast Statistical Computing and Data   Transformation in R</title><categories>stat.CO</categories><comments>32 pages, 0 figures. Submitted to the Journal of Statistical Software</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  collapse is a large C/C++-based infrastructure package facilitating complex statistical computing, data transformation, and exploration tasks in R - at outstanding levels of performance and memory efficiency. It also implements a class-agnostic approach to R programming, supporting vector, matrix and data frame-like objects and their popular extensions (units, integer64, xts, tibble, data.table, sf, pdata.frame), enabling its seamless integration with large parts of the R ecosystem. This article introduces the package's key components and design principles in a structured way, supported by a rich set of examples. A small benchmark demonstrates its computational performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.07628</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.07628</id><created>2024-03-12</created><updated>2025-02-04</updated><authors><author><keyname>Bornemann</keyname><forenames>Folkmar</forenames></author></authors><title>Asymptotic Expansions of the Limit Laws of Gaussian and Laguerre   (Wishart) Ensembles at the Soft Edge</title><categories>math.PR math-ph math.MP math.ST stat.TH</categories><comments>V5: using an alternative expression for the parameter tau that better   fits the style of the other parameters in the Laguerre/Wishart cases, more   remarks on the rationale of the scaling in the symplectic cases; 70 pages, 8   figures</comments><msc-class>60B20, 15B52, 62E20, 41A60, 33C15, 33C45, 33E17, 34E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The large-matrix limit laws of the rescaled largest eigenvalue of the orthogonal, unitary, and symplectic $n$-dimensional Gaussian ensembles -- and of the corresponding Laguerre ensembles (Wishart distributions) for various regimes of the parameter $\alpha$ (degrees of freedom $p$) -- are known to be the Tracy-Widom distributions $F_\beta$ ($\beta=1,2,4$). We establish (paying particular attention to large or small ratios $p/n$) that, with careful choices of the rescaling constants and of the expansion parameter $h$, the limit laws embed into asymptotic expansions in powers of $h$, where $h \asymp n^{-2/3}$ resp. $h \asymp (n\,\wedge\,p)^{-2/3}$. We find explicit analytic expressions of the first few expansion terms as linear combinations of higher-order derivatives of the limit law $F_\beta$ with rational polynomial coefficients. The parametrizations are fine-tuned so that the expansion coefficients in the Gaussian cases are, for given $n$, the limits $p\to\infty$ of those of the Laguerre cases. Whereas the results for $\beta=2$ are presented with proof, the discussion of the cases $\beta=1,4$ is based on some hypotheses, focusing on the algebraic aspects of actually computing the polynomial coefficients. For the purposes of illustration and validation, the various results are checked against simulation data with large sample sizes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.19448</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.19448</id><created>2024-03-28</created><updated>2025-02-03</updated><authors><author><keyname>Müller</keyname><forenames>Johannes</forenames></author><author><keyname>Çaycı</keyname><forenames>Semih</forenames></author><author><keyname>Montúfar</keyname><forenames>Guido</forenames></author></authors><title>Fisher-Rao Gradient Flows of Linear Programs and State-Action Natural   Policy Gradients</title><categories>math.OC cs.LG cs.NA cs.SY eess.SY math.NA stat.ML</categories><comments>25 pages, 4 figures, to appear at SIAM Journal on Optimization</comments><msc-class>65K05, 90C05, 90C08, 90C40, 90C53</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kakade's natural policy gradient method has been studied extensively in recent years, showing linear convergence with and without regularization. We study another natural gradient method based on the Fisher information matrix of the state-action distributions which has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher-Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher-Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher-Rao gradient flows and natural gradient flows up to an approximation error. In particular, these general results cover the case of state-action natural policy gradients. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.00820</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.00820</id><created>2024-03-31</created><updated>2025-02-03</updated><authors><author><keyname>Erdely</keyname><forenames>Arturo</forenames></author><author><keyname>Rubio-Sanchez</keyname><forenames>Manuel</forenames></author></authors><title>Visual analysis of bivariate dependence between continuous random   variables</title><categories>stat.ME</categories><comments>10 pages, 11 figures, 1 table</comments><msc-class>62P99</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scatter plots are widely recognized as fundamental tools for illustrating the relationship between two numerical variables. Despite this, based on solid theoretical foundations, scatter plots generated from pairs of continuous random variables may not serve as reliable tools for assessing dependence. Sklar's Theorem implies that scatter plots created from ranked data are preferable for such analysis as they exclusively convey information pertinent to dependence. This is in stark contrast to conventional scatter plots, which also encapsulate information about the variables' marginal distributions. Such additional information is extraneous to dependence analysis and can obscure the visual interpretation of the variables' relationship. In this article, we delve into the theoretical underpinnings of these ranked data scatter plots, hereafter referred to as rank plots. We offer insights into interpreting the information they reveal and examine their connections with various association measures, including Pearson's and Spearman's correlation coefficients, as well as Schweizer-Wolff's measure of dependence. Furthermore, we introduce a novel graphical combination for dependence analysis, termed a dplot, and demonstrate its efficacy through real data examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.14337</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.14337</id><created>2024-04-22</created><updated>2025-02-05</updated><authors><author><keyname>Sadeghi</keyname><forenames>Agathe</forenames></author><author><keyname>Feinstein</keyname><forenames>Zachary</forenames></author></authors><title>Statistical Validation of Contagion Centrality in Financial Networks</title><categories>q-fin.MF q-fin.RM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an impact centrality measure to evaluate shock propagation on financial networks capturing a notion of contagion and systemic risk contributions, permitting comparisons of these risks over time. In addition, we provide a statistical validation method when the network is estimated from data, as is done in practice. This statistical test allows us to reliably assess the computed centrality values. We validate our methodology on simulated data and conduct empirical case studies using financial data. We find that our proposed centrality measure increases significantly during times of financial distress and is able to provide insights into the (market implied) risk-levels of different firms and sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.02140</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.02140</id><created>2024-05-03</created><updated>2024-06-26</updated><authors><author><keyname>Correia</keyname><forenames>Alvaro H. C.</forenames></author><author><keyname>Massoli</keyname><forenames>Fabio Valerio</forenames></author><author><keyname>Louizos</keyname><forenames>Christos</forenames></author><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author></authors><title>An Information Theoretic Perspective on Conformal Prediction</title><categories>cs.LG cs.IT math.IT stat.ML</categories><journal-ref>Advances in Neural Information Processing Systems 37 (NeurIPS   2024)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conformal Prediction (CP) is a distribution-free uncertainty estimation framework that constructs prediction sets guaranteed to contain the true answer with a user-specified probability. Intuitively, the size of the prediction set encodes a general notion of uncertainty, with larger sets associated with higher degrees of uncertainty. In this work, we leverage information theory to connect conformal prediction to other notions of uncertainty. More precisely, we prove three different ways to upper bound the intrinsic uncertainty, as described by the conditional entropy of the target variable given the inputs, by combining CP with information theoretical inequalities. Moreover, we demonstrate two direct and useful applications of such connection between conformal prediction and information theory: (i) more principled and effective conformal training objectives that generalize previous approaches and enable end-to-end training of machine learning models from scratch, and (ii) a natural mechanism to incorporate side information into conformal prediction. We empirically validate both applications in centralized and federated learning settings, showing our theoretical results translate to lower inefficiency (average prediction set size) for popular CP methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.03096</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.03096</id><created>2024-05-05</created><updated>2025-02-03</updated><authors><author><keyname>Tam</keyname><forenames>Edric</forenames></author><author><keyname>Dunson</keyname><forenames>David B.</forenames></author><author><keyname>Duan</keyname><forenames>Leo L.</forenames></author></authors><title>Exact Sampling of Spanning Trees via Fast-forwarded Random Walks</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tree graphs are routinely used in statistics. When estimating a Bayesian model with a tree component, sampling the posterior remains a core difficulty. Existing Markov chain Monte Carlo methods tend to rely on local moves, often leading to poor mixing. A promising approach is to instead directly sample spanning trees on an auxiliary graph. Current spanning tree samplers, such as the celebrated Aldous--Broder algorithm, predominantly rely on simulating random walks that are required to visit all the nodes of the graph. Such algorithms are prone to getting stuck in certain sub-graphs. We formalize this phenomenon using the bottlenecks in the random walk's transition probability matrix. We then propose a novel fast-forwarded cover algorithm that can break free from bottlenecks. The core idea is a marginalization argument that leads to a closed-form expression which allows for fast-forwarding to the event of visiting a new node. Unlike many existing approximation algorithms, our algorithm yields exact samples. We demonstrate the enhanced efficiency of the fast-forwarded cover algorithm, and illustrate its application in fitting a Bayesian dendrogram model on a Massachusetts crimes and communities dataset. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.05238</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.05238</id><created>2024-05-08</created><updated>2025-02-04</updated><authors><author><keyname>Glazer</keyname><forenames>Amanda K.</forenames></author><author><keyname>Stark</keyname><forenames>Philip B.</forenames></author></authors><title>Fast Conservative Monte Carlo Confidence Intervals</title><categories>stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Extant "fast" algorithms for Monte Carlo confidence sets are limited to univariate shift parameters for the one-sample and two-sample problems using the sample mean as the test statistic; moreover, some do not converge reliably and most do not produce conservative confidence sets. We outline general methods for constructing confidence sets for real-valued and multidimensional parameters by inverting Monte Carlo tests using any test statistic and a broad range of randomization schemes. The method exploits two facts that, to our knowledge, had not been combined: (i) there are Monte Carlo tests that are conservative despite relying on simulation, and (ii) since the coverage probability of confidence sets depends only on the significance level of the test of the true null, every null can be tested using the same Monte Carlo sample. The Monte Carlo sample can be arbitrarily small, although the highest nontrivial attainable confidence level generally increases as the number $N$ of Monte Carlo replicates increases. We present open-source Python and R implementations of new algorithms to compute conservative confidence sets for real-valued and multidimensional parameters from Monte Carlo tests, for test statistics and randomization schemes that yield $P$-values that are monotone or weakly unimodal in the parameter, with the data and Monte Carlo sample held fixed. In this case, the new method finds conservative confidence sets for real-valued parameters in $O(n)$ time, where $n$ is the number of data. The values of some test statistics for different simulations and parameter values have a simple relationship that makes more savings possible. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.07432</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.07432</id><created>2024-05-12</created><updated>2025-02-04</updated><authors><author><keyname>Hou</keyname><forenames>Boya</forenames></author><author><keyname>Sanjari</keyname><forenames>Sina</forenames></author><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author></authors><title>Nonparametric Sparse Online Learning of the Koopman Operator</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>49 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.07482</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.07482</id><created>2024-05-13</created><updated>2025-02-03</updated><authors><author><keyname>Nguyen</keyname><forenames>Khai</forenames></author><author><keyname>Nguyen</keyname><forenames>Hai</forenames></author><author><keyname>Ho</keyname><forenames>Nhat</forenames></author></authors><title>Towards Marginal Fairness Sliced Wasserstein Barycenter</title><categories>stat.ML cs.GR cs.LG</categories><comments>Accepted to ICLR 2025, 29 pages, 15 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sliced Wasserstein barycenter (SWB) is a widely acknowledged method for efficiently generalizing the averaging operation within probability measure spaces. However, achieving marginal fairness SWB, ensuring approximately equal distances from the barycenter to marginals, remains unexplored. The uniform weighted SWB is not necessarily the optimal choice to obtain the desired marginal fairness barycenter due to the heterogeneous structure of marginals and the non-optimality of the optimization. As the first attempt to tackle the problem, we define the marginal fairness sliced Wasserstein barycenter (MFSWB) as a constrained SWB problem. Due to the computational disadvantages of the formal definition, we propose two hyperparameter-free and computationally tractable surrogate MFSWB problems that implicitly minimize the distances to marginals and encourage marginal fairness at the same time. To further improve the efficiency, we perform slicing distribution selection and obtain the third surrogate definition by introducing a new slicing distribution that focuses more on marginally unfair projecting directions. We discuss the relationship of the three proposed problems and their relationship to sliced multi-marginal Wasserstein distance. Finally, we conduct experiments on finding 3D point-clouds averaging, color harmonization, and training of sliced Wasserstein autoencoder with class-fairness representation to show the favorable performance of the proposed surrogate MFSWB problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.08203</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.08203</id><created>2024-05-13</created><updated>2025-01-27</updated><authors><author><keyname>Candellone</keyname><forenames>Elena</forenames></author><author><keyname>van Kesteren</keyname><forenames>Erik-Jan</forenames></author><author><keyname>Chelmi</keyname><forenames>Sofia</forenames></author><author><keyname>Garcia-Bernardo</keyname><forenames>Javier</forenames></author></authors><title>Community detection in bipartite signed networks is highly dependent on   parameter choice</title><categories>physics.soc-ph cs.SI stat.ME</categories><doi>10.1142/S0219525925400028</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decision-making processes often involve voting. Human interactions with exogenous entities such as legislations or products can be effectively modeled as two-mode (bipartite) signed networks-where people can either vote positively, negatively, or abstain from voting on the entities. Detecting communities in such networks could help us understand underlying properties: for example ideological camps or consumer preferences. While community detection is an established practice separately for bipartite and signed networks, it remains largely unexplored in the case of bipartite signed networks. In this paper, we systematically evaluate the efficacy of community detection methods on projected bipartite signed networks using a synthetic benchmark and real-world datasets. Our findings reveal that when no communities are present in the data, these methods often recover spurious user communities. When communities are present, the algorithms exhibit promising performance, although their performance is highly susceptible to parameter choice. This indicates that researchers using community detection methods in the context of bipartite signed networks should not take the communities found at face value: it is essential to assess the robustness of parameter choices or perform domain-specific external validation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.11751</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.11751</id><created>2024-05-19</created><updated>2025-02-04</updated><authors><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author><author><keyname>Letey</keyname><forenames>Mary I.</forenames></author><author><keyname>Zavatone-Veth</keyname><forenames>Jacob A.</forenames></author><author><keyname>Maiti</keyname><forenames>Anindita</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Asymptotic theory of in-context learning by linear attention</title><categories>stat.ML cond-mat.dis-nn cs.LG</categories><comments>17 pages (main doc), 6 figures, and supplementary information (23   pages)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transformers have a remarkable ability to learn and execute tasks based on examples provided within the input itself, without explicit prior training. It has been argued that this capability, known as in-context learning (ICL), is a cornerstone of Transformers' success, yet questions about the necessary sample complexity, pretraining task diversity, and context length for successful ICL remain unresolved. Here, we provide a precise answer to these questions in an exactly solvable model of ICL of a linear regression task by linear attention. We derive sharp asymptotics for the learning curve in a phenomenologically-rich scaling regime where the token dimension is taken to infinity; the context length and pretraining task diversity scale proportionally with the token dimension; and the number of pretraining examples scales quadratically. We demonstrate a double-descent learning curve with increasing pretraining examples, and uncover a phase transition in the model's behavior between low and high task diversity regimes: In the low diversity regime, the model tends toward memorization of training tasks, whereas in the high diversity regime, it achieves genuine in-context learning and generalization beyond the scope of pretrained tasks. These theoretical insights are empirically validated through experiments with both linear attention and full nonlinear Transformer architectures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.13690</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.13690</id><created>2024-05-22</created><updated>2025-02-05</updated><authors><author><keyname>Massa</keyname><forenames>Emanuele</forenames></author><author><keyname>Coolen</keyname><forenames>Anthony</forenames></author></authors><title>Observable asymptotics of regularized Cox regression models with   standard Gaussian designs: a statistical mechanics approach</title><categories>math.ST cond-mat.dis-nn stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic behaviour of the Regularized Maximum Partial Likelihood Estimator (RMPLE) in the proportional limit, considering an arbitrary convex regularizer and assuming that the covariates $\mathbf{X}_i\in\mathbb{R}^{p}$ follow a multivariate Gaussian law with covariance $\mathbf{I}_p/p$ for each $i=1, \dots, n$. In order to efficiently compute the estimator under investigation, we propose a modified Approximate Message Passing (AMP) algorithm, that we name COX-AMP, and compare its performance with the Coordinate-wise Descent (CD) algorithm, which is taken as reference. By means of the Replica method, we derive a set of six Replica Symmetric (RS) equations that we show to correctly describe the average behaviour of the estimators when the sample size and the number of covariates is large and commensurate. These equations cannot be solved in practice, as the data generating process (that we are trying to estimate) is not known. However, the update equations of COX-AMP suggest the construction of a local field that can in turn be used to accurately estimate all the RS order parameters of the theory \emph{solely from the data}, \emph{without} actually solving the RS equations. We emphasize that this approach can be applied when the estimator is computed via any method and is not restricted to COX-AMP. Once the RS order parameters are estimated, we have access to the amount of signal and noise in the RMPLE, but also its generalization error, directly from the data. Although we focus on the Partial Likelihood objective, we envisage broader application of the methodology proposed here, for instance to GLMs with nuisance parameters, which include some non-proportional hazards models, e.g. Accelerated Failure Time models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.15885</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.15885</id><created>2024-05-24</created><updated>2025-02-05</updated><authors><author><keyname>Zheng</keyname><forenames>Kaiwen</forenames></author><author><keyname>He</keyname><forenames>Guande</forenames></author><author><keyname>Chen</keyname><forenames>Jianfei</forenames></author><author><keyname>Bao</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>Jun</forenames></author></authors><title>Diffusion Bridge Implicit Models</title><categories>cs.LG stat.ML</categories><comments>Accepted at ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at https://github.com/thu-ml/DiffusionBridge. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.15887</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.15887</id><created>2024-05-24</created><updated>2025-02-04</updated><authors><author><keyname>Thiyageswaran</keyname><forenames>Vydhourie</forenames></author><author><keyname>McCormick</keyname><forenames>Tyler</forenames></author><author><keyname>Brennan</keyname><forenames>Jennifer</forenames></author></authors><title>Data-adaptive exposure thresholds for the Horvitz-Thompson estimator of   the Average Treatment Effect in experiments with network interference</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Randomized controlled trials often suffer from interference, a violation of the Stable Unit Treatment Values Assumption (SUTVA) in which a unit's treatment assignment affects the outcomes of its neighbors. This interference causes bias in naive estimators of the average treatment effect (ATE). A popular method to achieve unbiasedness is to pair the Horvitz-Thompson estimator of the ATE with a known exposure mapping: a function that identifies which units in a given randomization are not subject to interference. For example, an exposure mapping can specify that any unit with at least $h$-fraction of its neighbors having the same treatment status does not experience interference. However, this threshold $h$ is difficult to elicit from domain experts, and a misspecified threshold can induce bias. In this work, we propose a data-adaptive method to select the "$h$"-fraction threshold that minimizes the mean squared error of the Hortvitz-Thompson estimator. Our method estimates the bias and variance of the Horvitz-Thompson estimator under different thresholds using a linear dose-response model of the potential outcomes. We present simulations illustrating that our method improves upon non-adaptive choices of the threshold. We further illustrate the performance of our estimator by running experiments on a publicly-available Amazon product similarity graph. Furthermore, we demonstrate that our method is robust to deviations from the linear potential outcomes model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.16351</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.16351</id><created>2024-05-25</created><updated>2025-02-04</updated><authors><author><keyname>Malik</keyname><forenames>Zachariah</forenames></author><author><keyname>Huang</keyname><forenames>Yu-Jui</forenames></author></authors><title>A Differential Equation Approach for Wasserstein GANs and Beyond</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new theoretical lens to view Wasserstein generative adversarial networks (WGANs). To minimize the Wasserstein-1 distance between the true data distribution and our estimate of it, we derive a distribution-dependent ordinary differential equation (ODE) which represents the gradient flow of the Wasserstein-1 loss, and show that a forward Euler discretization of the ODE converges. This inspires a new class of generative models that naturally integrates persistent training (which we call W1-FE). When persistent training is turned off, we prove that W1-FE reduces to WGAN. When we intensify persistent training, W1-FE is shown to outperform WGAN in training experiments from low to high dimensions, in terms of both convergence speed and training results. Intriguingly, one can reap the benefits only when persistent training is carefully integrated through our ODE perspective. As demonstrated numerically, a naive inclusion of persistent training in WGAN (without relying on our ODE framework) can significantly worsen training results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.17508</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.17508</id><created>2024-05-26</created><updated>2025-02-03</updated><authors><author><keyname>Qian</keyname><forenames>Linglong</forenames></author><author><keyname>Yang</keyname><forenames>Yiyuan</forenames></author><author><keyname>Du</keyname><forenames>Wenjie</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Dobsoni</keyname><forenames>Richard</forenames></author><author><keyname>Ibrahim</keyname><forenames>Zina</forenames></author></authors><title>Beyond Random Missingness: Clinically Rethinking for Healthcare Time   Series Imputation</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study investigates the impact of masking strategies on time series imputation models in healthcare settings. While current approaches predominantly rely on random masking for model evaluation, this practice fails to capture the structured nature of missing patterns in clinical data. Using the PhysioNet Challenge 2012 dataset, we analyse how different masking implementations affect both imputation accuracy and downstream clinical predictions across eleven imputation methods. Our results demonstrate that masking choices significantly influence model performance, while recurrent architectures show more consistent performance across strategies. Analysis of downstream mortality prediction reveals that imputation accuracy doesn't necessarily translate to optimal clinical prediction capabilities. Our findings emphasise the need for clinically-informed masking strategies that better reflect real-world missing patterns in healthcare data, suggesting current evaluation frameworks may need reconsideration for reliable clinical deployment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.19466</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.19466</id><created>2024-05-29</created><updated>2025-02-05</updated><authors><author><keyname>Cai</keyname><forenames>Tiffany Tianhui</forenames></author><author><keyname>Namkoong</keyname><forenames>Hongseok</forenames></author><author><keyname>Russo</keyname><forenames>Daniel</forenames></author><author><keyname>Zhang</keyname><forenames>Kelly W</forenames></author></authors><title>Active Exploration via Autoregressive Generation of Missing Data</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We pose uncertainty quantification and exploration in online decision-making as a problem of training and generation from an autoregressive sequence model, an area experiencing rapid innovation. Our approach rests on viewing uncertainty as arising from missing future outcomes that would be revealed through appropriate action choices, rather than from unobservable latent parameters of the environment. This reformulation aligns naturally with modern machine learning capabilities: we can i) train generative models through next-outcome prediction rather than fit explicit priors, ii) assess uncertainty through autoregressive generation rather than parameter sampling, and iii) adapt to new information through in-context learning rather than explicit posterior updating. To showcase these ideas, we formulate a challenging meta-bandit problem where effective performance requires leveraging unstructured prior information (like text features) while exploring judiciously to resolve key remaining uncertainties. We validate our approach through both theory and experiments. Our theory establishes a reduction, showing success at offline next-outcome prediction translates to reliable online uncertainty quantification and decision-making, even with strategically collected data. Semi-synthetic experiments show our insights bear out in a news-article recommendation task, where article text can be leveraged to minimize exploration. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.01793</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.01793</id><created>2024-06-03</created><updated>2025-02-03</updated><authors><author><keyname>Schlaginhaufen</keyname><forenames>Andreas</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author></authors><title>Towards the Transferability of Rewards Recovered via Regularized Inverse   Reinforcement Learning</title><categories>cs.LG cs.AI stat.ML</categories><comments>The Thirty-Eighth Annual Conference on Neural Information Processing   Systems (NeurIPS 2024)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inverse reinforcement learning (IRL) aims to infer a reward from expert demonstrations, motivated by the idea that the reward, rather than the policy, is the most succinct and transferable description of a task [Ng et al., 2000]. However, the reward corresponding to an optimal policy is not unique, making it unclear if an IRL-learned reward is transferable to new transition laws in the sense that its optimal policy aligns with the optimal policy corresponding to the expert's true reward. Past work has addressed this problem only under the assumption of full access to the expert's policy, guaranteeing transferability when learning from two experts with the same reward but different transition laws that satisfy a specific rank condition [Rolland et al., 2022]. In this work, we show that the conditions developed under full access to the expert's policy cannot guarantee transferability in the more practical scenario where we have access only to demonstrations of the expert. Instead of a binary rank condition, we propose principal angles as a more refined measure of similarity and dissimilarity between transition laws. Based on this, we then establish two key results: 1) a sufficient condition for transferability to any transition laws when learning from at least two experts with sufficiently different transition laws, and 2) a sufficient condition for transferability to local changes in the transition law when learning from a single expert. Furthermore, we also provide a probably approximately correct (PAC) algorithm and an end-to-end analysis for learning transferable rewards from demonstrations of multiple experts. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.03696</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.03696</id><created>2024-06-05</created><updated>2025-02-03</updated><authors><author><keyname>Lok</keyname><forenames>Jackie</forenames></author><author><keyname>Sonthalia</keyname><forenames>Rishi</forenames></author><author><keyname>Rebrova</keyname><forenames>Elizaveta</forenames></author></authors><title>Error dynamics of mini-batch gradient descent with random reshuffling   for least squares regression</title><categories>stat.ML cs.LG math.OC</categories><comments>33 pages. Accepted at ALT 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the discrete dynamics of mini-batch gradient descent with random reshuffling for least squares regression. We show that the training and generalization errors depend on a sample cross-covariance matrix $Z$ between the original features $X$ and a set of new features $\widetilde{X}$ in which each feature is modified by the mini-batches that appear before it during the learning process in an averaged way. Using this representation, we establish that the dynamics of mini-batch and full-batch gradient descent agree up to leading order with respect to the step size using the linear scaling rule. However, mini-batch gradient descent with random reshuffling exhibits a subtle dependence on the step size that a gradient flow analysis cannot detect, such as converging to a limit that depends on the step size. By comparing $Z$, a non-commutative polynomial of random matrices, with the sample covariance matrix of $X$ asymptotically, we demonstrate that batching affects the dynamics by resulting in a form of shrinkage on the spectrum. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.05242</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.05242</id><created>2024-06-07</created><updated>2025-02-05</updated><authors><author><keyname>Yuan</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Guanyang</forenames></author></authors><title>Markov chain Monte Carlo without evaluating the target: an auxiliary   variable approach</title><categories>stat.CO stat.ME stat.ML</categories><comments>62 pages, 13 figures, 3 tables. Add additional illustrations and   experiments. Codes available at https://github.com/ywwes26/MCMC-Auxiliary</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sampling tasks, it is common for target distributions to be known up to a normalizing constant. However, in many situations, even evaluating the unnormalized distribution can be costly or infeasible. This issue arises in scenarios such as sampling from the Bayesian posterior for tall datasets and the 'doubly-intractable' distributions. In this paper, we begin by observing that seemingly different Markov chain Monte Carlo (MCMC) algorithms, such as the exchange algorithm, PoissonMH, and TunaMH, can be unified under a simple common procedure. We then extend this procedure into a novel framework that allows the use of auxiliary variables in both the proposal and the acceptance-rejection step. Several new MCMC algorithms emerge from this framework that utilize estimated gradients to guide the proposal moves. They have demonstrated significantly better performance than existing methods on both synthetic and real datasets. Additionally, we develop the theory of the new framework and apply it to existing algorithms to simplify and extend their results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.05911</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.05911</id><created>2024-06-09</created><updated>2025-02-03</updated><authors><author><keyname>Prasadan</keyname><forenames>Akshay</forenames></author><author><keyname>Neykov</keyname><forenames>Matey</forenames></author></authors><title>Some facts about the optimality of the LSE in the Gaussian sequence   model with convex constraint</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider a convex constrained Gaussian sequence model and characterize necessary and sufficient conditions for the least squares estimator (LSE) to be minimax optimal. For a closed convex set $K\subset \mathbb{R}^n$ we observe $Y=\mu+\xi$ for $\xi\sim \mathcal{N}(0,\sigma^2\mathbb{I}_n)$ and $\mu\in K$ and aim to estimate $\mu$. We characterize the worst case risk of the LSE in multiple ways by analyzing the behavior of the local Gaussian width on $K$. We demonstrate that optimality is equivalent to a Lipschitz property of the local Gaussian width mapping. We also provide theoretical algorithms that search for the worst case risk. We then provide examples showing optimality or suboptimality of the LSE on various sets, including $\ell_p$ balls for $p\in[1,2]$, pyramids, solids of revolution, and multivariate isotonic regression, among others. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.09521</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.09521</id><created>2024-06-13</created><updated>2025-02-04</updated><authors><author><keyname>Ritzwoller</keyname><forenames>David M.</forenames></author><author><keyname>Romano</keyname><forenames>Joseph P.</forenames></author><author><keyname>Shaikh</keyname><forenames>Azeem M.</forenames></author></authors><title>Randomization Inference: Theory and Applications</title><categories>econ.EM stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We review approaches to statistical inference based on randomization. Permutation tests are treated as an important special case. Under a certain group invariance property, referred to as the ``randomization hypothesis,'' randomization tests achieve exact control of the Type I error rate in finite samples. Although this unequivocal precision is very appealing, the range of problems that satisfy the randomization hypothesis is somewhat limited. We show that randomization tests are often asymptotically, or approximately, valid and efficient in settings that deviate from the conditions required for finite-sample error control. When randomization tests fail to offer even asymptotic Type 1 error control, their asymptotic validity may be restored by constructing an asymptotically pivotal test statistic. Randomization tests can then provide exact error control for tests of highly structured hypotheses with good performance in a wider class of problems. We give a detailed overview of several prominent applications of randomization tests, including two-sample permutation tests, regression, and conformal inference. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.14026</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.14026</id><created>2024-06-20</created><updated>2025-02-03</updated><authors><author><keyname>Jin</keyname><forenames>Xisen</forenames></author><author><keyname>Ren</keyname><forenames>Xiang</forenames></author></authors><title>Demystifying Language Model Forgetting with Low-rank Example   Associations</title><categories>cs.LG cs.CL stat.ML</categories><comments>8 pages; preprint</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Large Language models (LLMs) suffer from forgetting of upstream data when fine-tuned. Despite efforts on mitigating forgetting, few have investigated whether, and how forgotten upstream examples are dependent on newly learned tasks. Insights on such dependencies enable efficient and targeted mitigation of forgetting. In this paper, we empirically analyze forgetting that occurs in $N$ upstream examples of language modeling or instruction-tuning after fine-tuning LLMs on one of $M$ new tasks, visualized in $M\times N$ matrices. We show that the matrices are often well-approximated with low-rank matrices, indicating the dominance of simple associations between the learned tasks and forgotten upstream examples. Leveraging the analysis, we predict forgetting of upstream examples when fine-tuning on unseen tasks with matrix completion over the empirical associations. This enables fast identification of most forgotten examples without expensive inference on the entire upstream data. The approach, despite simplicity, outperforms prior approaches that learn semantic relationships of learned tasks and upstream examples with LMs for predicting forgetting. We demonstrate the practical utility of our analysis by showing statistically significantly reduced forgetting as we upweight predicted examples for replay at fine-tuning. Project page: https://inklab.usc.edu/lm-forgetting-prediction/ </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.02700</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.02700</id><created>2024-07-02</created><updated>2025-02-04</updated><authors><author><keyname>Rojas</keyname><forenames>Helder</forenames></author><author><keyname>Rojas</keyname><forenames>Nilton</forenames></author><author><keyname>B.</keyname><forenames>Espinoza J.</forenames></author><author><keyname>Huamanchumo</keyname><forenames>Luis</forenames></author></authors><title>A simple algorithm for output range analysis for deep neural networks</title><categories>cs.LG math.PR stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a novel approach for the output range estimation problem in Deep Neural Networks (DNNs) by integrating a Simulated Annealing (SA) algorithm tailored to operate within constrained domains and ensure convergence towards global optima. The method effectively addresses the challenges posed by the lack of local geometric information and the high non-linearity inherent to DNNs, making it applicable to a wide variety of architectures, with a special focus on Residual Networks (ResNets) due to their practical importance. Unlike existing methods, our algorithm imposes minimal assumptions on the internal architecture of neural networks, thereby extending its usability to complex models. Theoretical analysis guarantees convergence, while extensive empirical evaluations-including optimization tests involving functions with multiple local minima-demonstrate the robustness of our algorithm in navigating non-convex response surfaces. The experimental results highlight the algorithm's efficiency in accurately estimating DNN output ranges, even in scenarios characterized by high non-linearity and complex constraints. For reproducibility, Python codes and datasets used in the experiments are publicly available through our GitHub repository. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.03389</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.03389</id><created>2024-07-03</created><updated>2025-02-04</updated><authors><author><keyname>Costa</keyname><forenames>Efthymios</forenames></author><author><keyname>Papatsouma</keyname><forenames>Ioanna</forenames></author><author><keyname>Markos</keyname><forenames>Angelos</forenames></author></authors><title>A Deterministic Information Bottleneck Method for Clustering Mixed-Type   Data</title><categories>stat.ME cs.LG stat.ML</categories><comments>30 pages</comments><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we present an information-theoretic method for clustering mixed-type data, that is, data consisting of both continuous and categorical variables. The proposed approach is built on the deterministic variant of the Information Bottleneck algorithm, designed to optimally compress data while preserving its relevant structural information. We evaluate the performance of our method against four well-established clustering techniques for mixed-type data -- KAMILA, K-Prototypes, Factor Analysis for Mixed Data with K-Means, and Partitioning Around Medoids using Gower's dissimilarity -- using both simulated and real-world datasets. The results highlight that the proposed approach offers a competitive alternative to traditional clustering techniques, particularly under specific conditions where heterogeneity in data poses significant challenges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.15532</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.15532</id><created>2024-07-22</created><updated>2025-02-03</updated><authors><author><keyname>Korangi</keyname><forenames>Kamesh</forenames></author><author><keyname>Mues</keyname><forenames>Christophe</forenames></author><author><keyname>Bravo</keyname><forenames>Cristián</forenames></author></authors><title>Large-scale Time-Varying Portfolio Optimisation using Graph Attention   Networks</title><categories>q-fin.PM cs.AI cs.SI q-fin.RM stat.ML</categories><comments>39 pages, 10 figures, v2</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Apart from assessing individual asset performance, investors in financial markets also need to consider how a set of firms performs collectively as a portfolio. Whereas traditional Markowitz-based mean-variance portfolios are widespread, network-based optimisation techniques offer a more flexible tool to capture complex interdependencies between asset values. However, most of the existing studies do not contain firms at risk of default and remove any firms that drop off indices over a certain time. This is the first study to also incorporate such firms in portfolio optimisation on a large scale. We propose and empirically test a novel method that leverages Graph Attention networks (GATs), a subclass of Graph Neural Networks (GNNs). GNNs, as deep learning-based models, can exploit network data to uncover nonlinear relationships. Their ability to handle high-dimensional data and accommodate customised layers for specific purposes makes them appealing for large-scale problems such as mid- and small-cap portfolio optimisation. This study utilises 30 years of data on mid-cap firms, creating graphs of firms using distance correlation and the Triangulated Maximally Filtered Graph approach. These graphs are the inputs to a GAT model incorporating weight and allocation constraints and a loss function derived from the Sharpe ratio, thus focusing on maximising portfolio risk-adjusted returns. This new model is benchmarked against a network characteristic-based portfolio, a mean variance-based portfolio, and an equal-weighted portfolio. The results show that the portfolio produced by the GAT-based model outperforms all benchmarks and is consistently superior to other strategies over a long period, while also being informative of market dynamics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.16134</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.16134</id><created>2024-07-22</created><updated>2025-02-04</updated><authors><author><keyname>Fu</keyname><forenames>Hengyu</forenames></author><author><keyname>Dou</keyname><forenames>Zehao</forenames></author><author><keyname>Guo</keyname><forenames>Jiawei</forenames></author><author><keyname>Wang</keyname><forenames>Mengdi</forenames></author><author><keyname>Chen</keyname><forenames>Minshuo</forenames></author></authors><title>Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory   for Gaussian Process Data</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>56 pages, 13 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation. Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies. These dependencies represent the underlying dynamic model and are critical to validate the generated data. In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies. Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns. We highlight how the spatial-temporal dependencies are captured and affect learning efficiency. Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm. We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.02326</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.02326</id><created>2024-08-05</created><updated>2025-02-04</updated><authors><author><keyname>Aguilera</keyname><forenames>Miguel</forenames></author><author><keyname>Morales</keyname><forenames>Pablo A.</forenames></author><author><keyname>Rosas</keyname><forenames>Fernando E.</forenames></author><author><keyname>Shimazaki</keyname><forenames>Hideaki</forenames></author></authors><title>Explosive neural networks via higher-order interactions in curved   statistical manifolds</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT nlin.AO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order interactions underlie complex phenomena in systems such as biological and artificial neural networks, but their study is challenging due to the scarcity of tractable models. By leveraging a generalisation of the maximum entropy principle, here we introduce curved neural networks as a class of prototypical models with a limited number of parameters that are particularly well-suited for studying higher-order phenomena. Through exact mean-field descriptions, we show that these curved neural networks implement a self-regulating annealing process that can accelerate memory retrieval, leading to explosive order-disorder phase transitions with multi-stability and hysteresis effects. Moreover, by analytically exploring their memory-retrieval capacity using the replica trick near ferromagnetic and spin-glass phase boundaries, we demonstrate that these networks can enhance memory capacity and robustness of retrieval over classical associative-memory networks. Overall, the proposed framework provides parsimonious models amenable to analytical study, revealing novel higher-order phenomena in complex networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.07463</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.07463</id><created>2024-08-14</created><updated>2025-02-04</updated><authors><author><keyname>Costa</keyname><forenames>Efthymios</forenames></author><author><keyname>Papatsouma</keyname><forenames>Ioanna</forenames></author></authors><title>A novel framework for quantifying nominal outlyingness</title><categories>stat.ME</categories><comments>24 pages</comments><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Outlier detection is an important data mining tool that becomes particularly challenging when dealing with nominal data. First and foremost, flagging observations as outlying requires a well-defined notion of nominal outlyingness. This paper presents a definition of nominal outlyingness and introduces a general framework for quantifying outlyingness of nominal data. The proposed framework makes use of ideas from the association rule mining literature and can be used for calculating scores that indicate how outlying a nominal observation is. Methods for determining the involved hyperparameter values are presented and the concepts of variable contributions and outlyingness depth are introduced, in an attempt to enhance interpretability of the results. The proposed framework is evaluated on both synthetic and real-world data sets, demonstrating comparable performance to state-of-the-art frequent pattern mining algorithms and even outperforming them in certain cases. The ideas presented can serve as a tool for assessing the degree to which an observation differs from the rest of the data, under the assumption of sequences of nominal levels having been generated from a Multinomial distribution with varying event probabilities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.08062</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.08062</id><created>2024-08-15</created><updated>2025-02-04</updated><authors><author><keyname>Champneys</keyname><forenames>Max D.</forenames></author><author><keyname>Rogers</keyname><forenames>Timothy J.</forenames></author></authors><title>BINDy -- Bayesian identification of nonlinear dynamics with   reversible-jump Markov-chain Monte-Carlo</title><categories>stat.ML cs.LG math.DS</categories><doi>10.1098/rspa.2024.0620</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Model parsimony is an important \emph{cognitive bias} in data-driven modelling that aids interpretability and helps to prevent over-fitting. Sparse identification of nonlinear dynamics (SINDy) methods are able to learn sparse representations of complex dynamics directly from data, given a basis of library functions. In this work, a novel Bayesian treatment of dictionary learning system identification, as an alternative to SINDy, is envisaged. The proposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is distinct from previous approaches in that it targets the full joint posterior distribution over both the terms in the library and their parameterisation in the model. This formulation confers the advantage that an arbitrary prior may be placed over the model structure to produce models that are sparse in the model space rather than in parameter space. Because this posterior is defined over parameter vectors that can change in dimension, the inference cannot be performed by standard techniques. Instead, a Gibbs sampler based on reversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare favourably to ensemble SINDy in three benchmark case-studies. In particular, it is seen that the proposed method is better able to assign high probability to correct model terms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.12482</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.12482</id><created>2024-08-22</created><updated>2025-02-04</updated><authors><author><keyname>Rodríguez</keyname><forenames>Ignacio Echave-Sustaeta</forenames></author><author><keyname>Röttger</keyname><forenames>Frank</forenames></author></authors><title>Latent Gaussian and H\"usler--Reiss Graphical Models with Golazo Penalty</title><categories>stat.ME math.ST stat.TH</categories><comments>20 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of latent variables in practical problems is common, for example when some variables are difficult or expensive to measure, or simply unknown. When latent variables are unaccounted for, structure learning for Gaussian graphical models can be blurred by additional correlation between the observed variables that is incurred by the latent variables. A standard approach for this problem is a latent version of the graphical lasso that splits the inverse covariance matrix into a sparse and a low-rank part that are penalized separately. This approach has recently been extended successfully to H\"usler--Reiss graphical models, which can be considered as an analogue of Gaussian graphical models in extreme value statistics. In this paper we propose a generalization of structure learning for Gaussian and H\"usler--Reiss graphical models via the flexible Golazo penalty. This allows us to introduce latent versions of for example the adaptive lasso, positive dependence constraints or predetermined sparsity patterns, and combinations of those. We develop algorithms for both latent graphical models with the Golazo penalty and demonstrate them on simulated and real data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.12830</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.12830</id><created>2024-08-23</created><updated>2025-02-05</updated><authors><author><keyname>Luo</keyname><forenames>Wang</forenames></author><author><keyname>Li</keyname><forenames>Haoran</forenames></author><author><keyname>Zhang</keyname><forenames>Zicheng</forenames></author><author><keyname>Han</keyname><forenames>Congying</forenames></author><author><keyname>Lv</keyname><forenames>Jiayu</forenames></author><author><keyname>Guo</keyname><forenames>Tiande</forenames></author></authors><title>SAMBO-RL: Shifts-aware Model-based Offline Reinforcement Learning</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based offline reinforcement learning trains policies using pre-collected datasets and learned environment models, eliminating the need for direct real-world environment interaction. However, this paradigm is inherently challenged by distribution shift (DS). Existing methods address this issue by leveraging off-policy mechanisms and estimating model uncertainty, but they often result in inconsistent objectives and lack a unified theoretical foundation. This paper offers a comprehensive analysis that disentangles the problem into two fundamental components: model bias and policy shift. Our theoretical and empirical investigations reveal how these factors distort value estimation and restrict policy optimization. To tackle these challenges, we derive a novel Shifts-aware Reward (SAR) through a unified probabilistic inference framework, which modifies the vanilla reward to refine value learning and facilitate policy training. Building on this, we introduce Shifts-aware Model-based Offline Reinforcement Learning (SAMBO-RL), a practical framework that efficiently trains classifiers to approximate SAR for policy optimization. Empirical experiments show that SAR effectively mitigates DS, and SAMBO-RL achieves superior or comparable performance across various benchmarks, underscoring its effectiveness and validating our theoretical analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.03845</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.03845</id><created>2024-09-05</created><updated>2025-02-05</updated><authors><author><keyname>Cheng</keyname><forenames>Sheng</forenames></author><author><keyname>Kong</keyname><forenames>Deqian</forenames></author><author><keyname>Xie</keyname><forenames>Jianwen</forenames></author><author><keyname>Lee</keyname><forenames>Kookjin</forenames></author><author><keyname>Wu</keyname><forenames>Ying Nian</forenames></author><author><keyname>Yang</keyname><forenames>Yezhou</forenames></author></authors><title>Latent Space Energy-based Neural ODEs</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces novel deep dynamical models designed to represent continuous-time sequences. Our approach employs a neural emission model to generate each data point in the time series through a non-linear transformation of a latent state vector. The evolution of these latent states is implicitly defined by a neural ordinary differential equation (ODE), with the initial state drawn from an informative prior distribution parameterized by an Energy-based model (EBM). This framework is extended to disentangle dynamic states from underlying static factors of variation, represented as time-invariant variables in the latent space. We train the model using maximum likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end manner. Experimental results on oscillating systems, videos and real-world state sequences (MuJoCo) demonstrate that our model with the learnable energy-based prior outperforms existing counterparts, and can generalize to new dynamic parameterization, enabling long-horizon predictions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.14557</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.14557</id><created>2024-09-22</created><updated>2025-02-05</updated><authors><author><keyname>Wan</keyname><forenames>Jia</forenames></author><author><keyname>Sinclair</keyname><forenames>Sean R.</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Exploiting Exogenous Structure for Sample-Efficient Reinforcement   Learning</title><categories>stat.ML cs.LG math.OC</categories><comments>43 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Exo-MDPs, a structured class of Markov Decision Processes (MDPs) where the state space is partitioned into exogenous and endogenous components. Exogenous states evolve stochastically, independent of the agent's actions, while endogenous states evolve deterministically based on both state components and actions. Exo-MDPs are useful for applications including inventory control, portfolio management, and ride-sharing. Our first result is structural, establishing a representational equivalence between the classes of discrete MDPs, Exo-MDPs, and discrete linear mixture MDPs. Specifically, any discrete MDP can be represented as an Exo-MDP, and the transition and reward dynamics can be written as linear functions of the exogenous state distribution, showing that Exo-MDPs are instances of linear mixture MDPs. For unobserved exogenous states, we prove a regret upper bound of $O(H^{3/2}d\sqrt{K})$ over $K$ trajectories of horizon $H$, with $d$ as the size of the exogenous state space, and establish nearly-matching lower bounds. Our findings demonstrate how Exo-MDPs decouple sample complexity from action and endogenous state sizes, and we validate our theoretical insights with experiments on inventory control. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.19546</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.19546</id><created>2024-09-29</created><updated>2025-02-03</updated><authors><author><keyname>Blaser</keyname><forenames>Ethan</forenames></author><author><keyname>Zhang</keyname><forenames>Shangtong</forenames></author></authors><title>Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic   Approximations with Markovian Noise</title><categories>cs.LG cs.AI math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Stochastic approximation is an important class of algorithms, and a large body of previous analysis focuses on stochastic approximations driven by contractive operators, which is not applicable in some important reinforcement learning settings. This work instead investigates stochastic approximations with merely nonexpansive operators. In particular, we study nonexpansive stochastic approximations with Markovian noise, providing both asymptotic and finite sample analysis. Key to our analysis are a few novel bounds of noise terms resulting from the Poisson equation. As an application, we prove, for the first time, that the classical tabular average reward temporal difference learning converges to a sample path dependent fixed point. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.12538</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.12538</id><created>2024-10-16</created><updated>2025-02-03</updated><authors><author><keyname>Rahmani</keyname><forenames>Saeed</forenames></author><author><keyname>Xu</keyname><forenames>Zhenlin</forenames></author><author><keyname>Calvert</keyname><forenames>Simeon C.</forenames></author><author><keyname>van Arem</keyname><forenames>Bart</forenames></author></authors><title>Automated Vehicles at Unsignalized Intersections: Safety and Efficiency   Implications of Mixed-Human-Automated Traffic</title><categories>cs.RO cs.AI stat.AP</categories><comments>This work has been submitted to Transportation Research Record for   potential publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of automated vehicles (AVs) into transportation systems presents an unprecedented opportunity to enhance road safety and efficiency. However, understanding the interactions between AVs and human-driven vehicles (HVs) at intersections remains an open research question. This study aims to bridge this gap by examining behavioral differences and adaptations of AVs and HVs at unsignalized intersections by utilizing two large-scale AV datasets from Waymo and Lyft. By using a systematic methodology, the research identifies and analyzes merging and crossing conflicts by calculating key safety and efficiency metrics, including time to collision (TTC), post-encroachment time (PET), maximum required deceleration (MRD), time advantage (TA), and speed and acceleration profiles. The findings reveal a paradox in mixed traffic flow: while AVs maintain larger safety margins, their conservative behavior can lead to unexpected situations for human drivers, potentially causing unsafe conditions. From a performance point of view, human drivers exhibit more consistent behavior when interacting with AVs versus other HVs, suggesting AVs may contribute to harmonizing traffic flow patterns. Moreover, notable differences were observed between Waymo and Lyft vehicles, which highlights the importance of considering manufacturer-specific AV behaviors in traffic modeling and management strategies for the safe integration of AVs. The processed dataset utilized in this study is openly published to foster the research on AV-HV interactions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.18959</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.18959</id><created>2024-10-24</created><updated>2025-02-04</updated><authors><author><keyname>Williams</keyname><forenames>Andrew Robert</forenames></author><author><keyname>Ashok</keyname><forenames>Arjun</forenames></author><author><keyname>Marcotte</keyname><forenames>Étienne</forenames></author><author><keyname>Zantedeschi</keyname><forenames>Valentina</forenames></author><author><keyname>Subramanian</keyname><forenames>Jithendaraa</forenames></author><author><keyname>Riachi</keyname><forenames>Roland</forenames></author><author><keyname>Requeima</keyname><forenames>James</forenames></author><author><keyname>Lacoste</keyname><forenames>Alexandre</forenames></author><author><keyname>Rish</keyname><forenames>Irina</forenames></author><author><keyname>Chapados</keyname><forenames>Nicolas</forenames></author><author><keyname>Drouin</keyname><forenames>Alexandre</forenames></author></authors><title>Context is Key: A Benchmark for Forecasting with Essential Textual   Information</title><categories>cs.LG cs.AI stat.ML</categories><comments>Preprint; under review. First two authors contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Forecasting is a critical task in decision-making across numerous domains. While historical numerical data provide a start, they fail to convey the complete context for reliable and accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge and constraints, which can efficiently be communicated through natural language. However, in spite of recent progress with LLM-based forecasters, their ability to effectively integrate this textual information remains an open question. To address this, we introduce "Context is Key" (CiK), a time-series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities; crucially, every task in CiK requires understanding textual context to be solved successfully. We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. This benchmark aims to advance multimodal forecasting by promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://anon-forecast.github.io/benchmark_report_dev/. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.21154</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.21154</id><created>2024-10-28</created><updated>2025-02-04</updated><authors><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Pu</keyname><forenames>Yuan</forenames></author><author><keyname>Kawamura</keyname><forenames>Yuki</forenames></author><author><keyname>Loza</keyname><forenames>Andrew</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Shung</keyname><forenames>Dennis L.</forenames></author><author><keyname>Tong</keyname><forenames>Alexander</forenames></author></authors><title>Trajectory Flow Matching with Applications to Clinical Time Series   Modeling</title><categories>cs.LG cs.AI stat.ML</categories><comments>NeurIPS 2024 Spotlight</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling stochastic and irregularly sampled time series is a challenging problem found in a wide range of applications, especially in medicine. Neural stochastic differential equations (Neural SDEs) are an attractive modeling technique for this problem, which parameterize the drift and diffusion terms of an SDE with neural networks. However, current algorithms for training Neural SDEs require backpropagation through the SDE dynamics, greatly limiting their scalability and stability. To address this, we propose Trajectory Flow Matching (TFM), which trains a Neural SDE in a simulation-free manner, bypassing backpropagation through the dynamics. TFM leverages the flow matching technique from generative modeling to model time series. In this work we first establish necessary conditions for TFM to learn time series data. Next, we present a reparameterization trick which improves training stability. Finally, we adapt TFM to the clinical time series setting, demonstrating improved performance on three clinical time series datasets both in terms of absolute performance and uncertainty prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.22333</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.22333</id><created>2024-10-29</created><updated>2025-02-05</updated><authors><author><keyname>Koch</keyname><forenames>Lukas</forenames></author></authors><title>Hypothesis tests and model parameter estimation on data sets with   missing correlation information</title><categories>stat.ME hep-ph stat.AP</categories><comments>19 pages, 10 figures; follow-up of arxiv.org:2102.06172; Fixed some   typos, made tables prettier, added funding</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ideally, all analyses of normally distributed data should include the full covariance information between all data points. In practice, the full covariance matrix between all data points is not always available. Either because a result was published without a covariance matrix, or because one tries to combine multiple results from separate publications. For simple hypothesis tests, it is possible to define robust test statistics that will behave conservatively in the presence on unknown correlations. For model parameter fits, one can inflate the variance by a factor to ensure that things remain conservative at least up to a chosen confidence level. This paper describes a class of robust test statistics for simple hypothesis tests, as well as an algorithm to determine the necessary inflation factor for model parameter fits and Goodness of Fit tests and composite hypothesis tests. It then presents some example applications of the methods to real neutrino interaction data and model comparisons. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.01694</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.01694</id><created>2024-11-03</created><updated>2025-02-03</updated><authors><author><keyname>Bayisa</keyname><forenames>Fekadu L.</forenames></author><author><keyname>Seals</keyname><forenames>Christopher L.</forenames></author><author><keyname>Leeper</keyname><forenames>Hannah J.</forenames></author><author><keyname>Steury</keyname><forenames>Todd D.</forenames></author><author><keyname>Ceyhan</keyname><forenames>Elvan</forenames></author></authors><title>Modeling Home Range and Intra-Specific Spatial Interaction in Wild   Animal Populations</title><categories>stat.AP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions among individuals from the same-species of wild animals are an important component of population dynamics. An interaction can be either static (based on overlap of space use) or dynamic (based on movement). The goal of this work is to determine the level of static interactions between individuals from the same-species of wild animals using 95\% and 50\% home ranges, as well as to model their movement interactions, which could include attraction, avoidance (or repulsion), or lack of interaction, in order to gain new insights and improve our understanding of ecological processes. Home range estimation methods (minimum convex polygon, kernel density estimator, and autocorrelated kernel density estimator), inhomogeneous multitype (or cross-type) summary statistics, and envelope testing methods (pointwise and global envelope tests) were proposed to study the nature of the same-species wild-animal spatial interactions. This study provides comprehensive, self-contained methodological details for investigating spatial interactions between individuals of the same species in wildlife populations. Using GPS collar data, we applied the methods to quantify both static and dynamic interactions between black bears in southern Alabama, USA. In general, our findings suggest that the black bears in our dataset showed no significant preference to live together or apart, i.e., there was no significant deviation from independence toward association or avoidance (i.e., segregation) between the bears. This can be loosely interpreted to mean that a black bear is generally indifferent to the presence of other black bears living or wandering nearby. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.06568</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.06568</id><created>2024-11-10</created><updated>2025-02-04</updated><authors><author><keyname>Alfano</keyname><forenames>Carlo</forenames></author><author><keyname>Sapora</keyname><forenames>Silvia</forenames></author><author><keyname>Foerster</keyname><forenames>Jakob Nicolaus</forenames></author><author><keyname>Rebeschini</keyname><forenames>Patrick</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Meta-Learning Objectives for Preference Optimization</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluating preference optimization (PO) algorithms on LLM alignment is a challenging task that presents prohibitive costs, noise, and several variables like model size and hyper-parameters. In this work, we show that it is possible to gain insights on the efficacy of PO algorithm on much simpler benchmarks. We design a diagnostic suite of MuJoCo tasks and datasets, which we use to systematically evaluate PO algorithms, establishing a more controlled and cheaper benchmark. We then propose a novel family of PO algorithms based on mirror descent, which we call Mirror Preference Optimization (MPO). Through evolutionary strategies, we search this class to discover algorithms specialized to specific properties of preference datasets, such as mixed-quality or noisy data. We demonstrate that our discovered PO algorithms outperform all known algorithms in the targeted MuJoCo settings. Finally, based on the insights gained from our MuJoCo experiments, we design a novel PO algorithm that significantly outperforms existing baselines in an LLM alignment task. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.16303</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.16303</id><created>2024-11-25</created><updated>2025-02-05</updated><authors><author><keyname>Zeng</keyname><forenames>Dun</forenames></author><author><keyname>Wu</keyname><forenames>Zheshun</forenames></author><author><keyname>Liu</keyname><forenames>Shiyu</forenames></author><author><keyname>Pan</keyname><forenames>Yu</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoying</forenames></author><author><keyname>Xu</keyname><forenames>Zenglin</forenames></author></authors><title>Understanding Generalization of Federated Learning: the Trade-off   between Model Stability and Optimization</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Federated Learning (FL) is a distributed learning approach that trains machine learning models across multiple devices while keeping their local data private. However, FL often faces challenges due to data heterogeneity, leading to inconsistent local optima among clients. These inconsistencies can cause unfavorable convergence behavior and generalization performance degradation. Existing studies mainly describe this issue through \textit{convergence analysis}, focusing on how well a model fits training data, or through \textit{algorithmic stability}, which examines the generalization gap. However, neither approach precisely captures the generalization performance of FL algorithms, especially for neural networks. This paper introduces an innovative generalization dynamics analysis framework, named as Libra, for algorithm-dependent excess risk minimization, highlighting the trade-offs between model stability and optimization. Through this framework, we show how the generalization of FL algorithms is affected by the interplay of algorithmic stability and optimization. This framework applies to standard federated optimization and its advanced variants, such as server momentum. Our findings suggest that larger local steps or momentum accelerate convergence but enlarge stability, while yielding a better minimum excess risk. These insights can guide the design of future algorithms to achieve stronger generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.16715</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.16715</id><created>2024-11-22</created><updated>2025-02-04</updated><authors><author><keyname>Pohland</keyname><forenames>Sara</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire</forenames></author></authors><title>PaRCE: Probabilistic and Reconstruction-based Competency Estimation for   CNN-based Image Classification</title><categories>cs.CV cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:2409.06111</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNNs) are extremely popular and effective for image classification tasks but tend to be overly confident in their predictions. Various works have sought to quantify uncertainty associated with these models, detect out-of-distribution (OOD) inputs, or identify anomalous regions in an image, but limited work has sought to develop a holistic approach that can accurately estimate perception model confidence across various sources of uncertainty. We develop a probabilistic and reconstruction-based competency estimation (PaRCE) method and compare it to existing approaches for uncertainty quantification and OOD detection. We find that our method can best distinguish between correctly classified, misclassified, and OOD samples with anomalous regions, as well as between samples with visual image modifications resulting in high, medium, and low prediction accuracy. We describe how to extend our approach for anomaly localization tasks and demonstrate the ability of our approach to distinguish between regions in an image that are familiar to the perception model from those that are unfamiliar. We find that our method generates interpretable scores that most reliably capture a holistic notion of perception model confidence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.02529</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.02529</id><created>2024-12-03</created><updated>2025-02-04</updated><authors><author><keyname>Wagenmaker</keyname><forenames>Andrew</forenames></author><author><keyname>Mi</keyname><forenames>Lu</forenames></author><author><keyname>Rozsa</keyname><forenames>Marton</forenames></author><author><keyname>Bull</keyname><forenames>Matthew S.</forenames></author><author><keyname>Svoboda</keyname><forenames>Karel</forenames></author><author><keyname>Daie</keyname><forenames>Kayvon</forenames></author><author><keyname>Golub</keyname><forenames>Matthew D.</forenames></author><author><keyname>Jamieson</keyname><forenames>Kevin</forenames></author></authors><title>Active learning of neural population dynamics using two-photon   holographic optogenetics</title><categories>q-bio.NC cs.LG stat.ML</categories><comments>NeurIPS 2024</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in techniques for monitoring and perturbing neural populations have greatly enhanced our ability to study circuits in the brain. In particular, two-photon holographic optogenetics now enables precise photostimulation of experimenter-specified groups of individual neurons, while simultaneous two-photon calcium imaging enables the measurement of ongoing and induced activity across the neural population. Despite the enormous space of potential photostimulation patterns and the time-consuming nature of photostimulation experiments, very little algorithmic work has been done to determine the most effective photostimulation patterns for identifying the neural population dynamics. Here, we develop methods to efficiently select which neurons to stimulate such that the resulting neural responses will best inform a dynamical model of the neural population activity. Using neural population responses to photostimulation in mouse motor cortex, we demonstrate the efficacy of a low-rank linear dynamical systems model, and develop an active learning procedure which takes advantage of low-rank structure to determine informative photostimulation patterns. We demonstrate our approach on both real and synthetic data, obtaining in some cases as much as a two-fold reduction in the amount of data required to reach a given predictive power. Our active stimulation design method is based on a novel active learning procedure for low-rank regression, which may be of independent interest. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.05906</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.05906</id><created>2024-12-08</created><updated>2025-02-04</updated><authors><author><keyname>Li</keyname><forenames>Lucky</forenames></author></authors><title>Reinforcement Learning for a Discrete-Time Linear-Quadratic Control   Problem with an Application</title><categories>stat.ML cs.LG math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the discrete-time linear-quadratic (LQ) control model using reinforcement learning (RL). Using entropy to measure the cost of exploration, we prove that the optimal feedback policy for the problem must be Gaussian type. Then, we apply the results of the discrete-time LQ model to solve the discrete-time mean-variance asset-liability management problem and prove our RL algorithm's policy improvement and convergence. Finally, a numerical example sheds light on the theoretical results established using simulations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.06540</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.06540</id><created>2024-12-09</created><updated>2025-02-04</updated><authors><author><keyname>Polo</keyname><forenames>Felipe Maia</forenames></author><author><keyname>Somerstep</keyname><forenames>Seamus</forenames></author><author><keyname>Choshen</keyname><forenames>Leshem</forenames></author><author><keyname>Sun</keyname><forenames>Yuekai</forenames></author><author><keyname>Yurochkin</keyname><forenames>Mikhail</forenames></author></authors><title>Sloth: scaling laws for LLM skills to predict multi-benchmark   performance across families</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scaling laws for large language models (LLMs) predict model performance based on parameters like size and training data. However, differences in training configurations and data processing across model families lead to significant variations in benchmark performance, making it difficult for a single scaling law to generalize across all LLMs. On the other hand, training family-specific scaling laws requires training models of varying sizes for every family. In this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a novel scaling law that leverages publicly available benchmark data and assumes LLM performance is driven by low-dimensional latent skills, such as reasoning and instruction following. These latent skills are influenced by computational resources like model size and training tokens but with varying efficiencies across model families. Sloth exploits correlations across benchmarks to provide more accurate and interpretable predictions while alleviating the need to train multiple LLMs per family. We present both theoretical results on parameter identification and empirical evaluations on 12 prominent benchmarks, from Open LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance efficiently and offers insights into scaling behaviors for complex downstream tasks and increased test-time compute. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.10038</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.10038</id><created>2024-12-13</created><updated>2025-02-05</updated><authors><author><keyname>Callegher</keyname><forenames>Gianmarco</forenames></author><author><keyname>Kneib</keyname><forenames>Thomas</forenames></author><author><keyname>Söding</keyname><forenames>Johannes</forenames></author><author><keyname>Wiemann</keyname><forenames>Paul</forenames></author></authors><title>Stochastic Variational Inference for Structured Additive Distributional   Regression</title><categories>stat.CO</categories><msc-class>62</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In structured additive distributional regression, the conditional distribution of the response variables given the covariate information and the vector of model parameters is modelled using a P-parametric probability density function where each parameter is modelled through a linear predictor and a bijective response function that maps the domain of the predictor into the domain of the parameter. We present a method to perform inference in structured additive distributional regression using stochastic variational inference. We propose two strategies for constructing a multivariate Gaussian variational distribution to estimate the posterior distribution of the regression coefficients. The first strategy leverages covariate information and hyperparameters to learn both the location vector and the precision matrix. The second strategy tackles the complexity challenges of the first by initially assuming independence among all smooth terms and then introducing correlations through an additional set of variational parameters. Furthermore, we present two approaches for estimating the smoothing parameters. The first treats them as free parameters and provides point estimates, while the second accounts for uncertainty by applying a variational approximation to the posterior distribution. Our model was benchmarked against state-of-the-art competitors in logistic and gamma regression simulation studies. Finally, we validated our approach by comparing its posterior estimates to those obtained using Markov Chain Monte Carlo on a dataset of patents from the biotechnology/pharmaceutics and semiconductor/computer sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20553</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20553</id><created>2024-12-29</created><updated>2025-02-04</updated><authors><author><keyname>Andreyev</keyname><forenames>Arseniy</forenames></author><author><keyname>Beneventano</keyname><forenames>Pierfrancesco</forenames></author></authors><title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title><categories>cs.LG math.OC stat.ML</categories><comments>35 pages, 26 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent findings by Cohen et al., 2021, demonstrate that when training neural networks with full-batch gradient descent with a step size of $\eta$, the largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently stabilizes at $\lambda_{\max} = 2/\eta$. These results have significant implications for convergence and generalization. This, however, is not the case of mini-batch stochastic gradient descent (SGD), limiting the broader applicability of its consequences. We show that SGD trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/\eta$ is *Batch Sharpness*: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $\lambda_{\max}$--which is generally smaller than Batch Sharpness--is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20824</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20824</id><created>2024-12-30</created><updated>2025-02-05</updated><authors><author><keyname>Jorge</keyname><forenames>Emilio</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Basu</keyname><forenames>Debabrota</forenames></author></authors><title>Isoperimetry is All We Need: Langevin Posterior Sampling for RL with   Sublinear Regret</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common assumptions, like linear or RKHS models, and Gaussian or log-concave posteriors over the models, do not explain practical success of RL across a wider range of distributions and models. Thus, we study how to design RL algorithms with sublinear regret for isoperimetric distributions, specifically the ones satisfying the Log-Sobolev Inequality (LSI). LSI distributions include the standard setups of RL theory, and others, such as many non-log-concave and perturbed distributions. First, we show that the Posterior Sampling-based RL (PSRL) algorithm yields sublinear regret if the data distributions satisfy LSI and some mild additional assumptions. Also, when we cannot compute or sample from an exact posterior, we propose a Langevin sampling-based algorithm design: LaPSRL. We show that LaPSRL achieves order-optimal regret and subquadratic complexity per episode. Finally, we deploy LaPSRL with a Langevin sampler -- SARAH-LD, and test it for different bandit and MDP environments. Experimental results validate the generality of LaPSRL across environments and its competitive performance with respect to the baselines. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.04871</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.04871</id><created>2025-01-08</created><updated>2025-02-04</updated><authors><author><keyname>Lee</keyname><forenames>Kaitlyn J.</forenames></author><author><keyname>Schuler</keyname><forenames>Alejandro</forenames></author></authors><title>RieszBoost: Gradient Boosting for Riesz Regression</title><categories>stat.ML cs.LG stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Answering causal questions often involves estimating linear functionals of conditional expectations, such as the average treatment effect or the effect of a longitudinal modified treatment policy. By the Riesz representation theorem, these functionals can be expressed as the expected product of the conditional expectation of the outcome and the Riesz representer, a key component in doubly robust estimation methods. Traditionally, the Riesz representer is estimated indirectly by deriving its explicit analytical form, estimating its components, and substituting these estimates into the known form (e.g., the inverse propensity score). However, deriving or estimating the analytical form can be challenging, and substitution methods are often sensitive to practical positivity violations, leading to higher variance and wider confidence intervals. In this paper, we propose a novel gradient boosting algorithm to directly estimate the Riesz representer without requiring its explicit analytical form. This method is particularly suited for tabular data, offering a flexible, nonparametric, and computationally efficient alternative to existing methods for Riesz regression. Through simulation studies, we demonstrate that our algorithm performs on par with or better than indirect estimation techniques across a range of functionals, providing a user-friendly and robust solution for estimating causal quantities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06653</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06653</id><created>2025-01-11</created><authors><author><keyname>Zhao</keyname><forenames>Mengyu</forenames></author><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author></authors><title>Theoretical Characterization of Effect of Masks in Snapshot Compressive   Imaging</title><categories>cs.IT eess.IV math.IT stat.AP</categories><comments>27 pages. arXiv admin note: substantial text overlap with   arXiv:2307.07796</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Snapshot compressive imaging (SCI) refers to the recovery of three-dimensional data cubes-such as videos or hyperspectral images-from their two-dimensional projections, which are generated by a special encoding of the data with a mask. SCI systems commonly use binary-valued masks that follow certain physical constraints. Optimizing these masks subject to these constraints is expected to improve system performance. However, prior theoretical work on SCI systems focuses solely on independently and identically distributed (i.i.d.) Gaussian masks, which do not permit such optimization. On the other hand, existing practical mask optimizations rely on computationally intensive joint optimizations that provide limited insight into the role of masks and are expected to be sub-optimal due to the non-convexity and complexity of the optimization. In this paper, we analytically characterize the performance of SCI systems employing binary masks and leverage our analysis to optimize hardware parameters. Our findings provide a comprehensive and fundamental understanding of the role of binary masks - with both independent and dependent elements - and their optimization. We also present simulation results that confirm our theoretical findings and further illuminate different aspects of mask design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08270</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08270</id><created>2025-01-14</created><updated>2025-02-04</updated><authors><author><keyname>Fowler</keyname><forenames>Charlotte R.</forenames></author><author><keyname>Cai</keyname><forenames>Xiaoxuan</forenames></author><author><keyname>Rahimi-Eichi</keyname><forenames>Habiballah</forenames></author><author><keyname>Dixon</keyname><forenames>Lisa</forenames></author><author><keyname>Baker</keyname><forenames>Justin T.</forenames></author><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author><author><keyname>Valeri</keyname><forenames>Linda</forenames></author></authors><title>Individual causal effect estimation accounting for latent disease state   modification among bipolar participants in mobile health studies</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Individuals with bipolar disorder tend to cycle through disease states such as depression and mania. The heterogeneous nature of disease across states complicates the evaluation of interventions for bipolar disorder patients, as varied interventional success is observed within and across individuals. In fact, we hypothesize that disease state acts as an effect modifier for the causal effect of a given intervention on health outcomes. To address this dilemma, we propose an N-of-1 approach using an adapted autoregressive hidden Markov model, applied to longitudinal mobile health data collected from individuals with bipolar disorder. This method allows us to identify a latent variable from mobile health data to be treated as an effect modifier between the exposure and outcome of interest while allowing for missing data in the outcome. A counterfactual approach is employed for causal inference and to obtain a g-formula estimator to recover said effect. The performance of the proposed method is compared with a naive approach across extensive simulations and application to a multi-year smartphone study of bipolar patients, evaluating the individual effect of digital social activity on sleep duration across different latent disease states. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08945</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08945</id><created>2025-01-15</created><updated>2025-02-04</updated><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>Zhu</keyname><forenames>Ke</forenames></author><author><keyname>Han</keyname><forenames>Larry</forenames></author><author><keyname>Yang</keyname><forenames>Shu</forenames></author></authors><title>COADVISE: Covariate Adjustment with Variable Selection and Missing Data   Imputation in Randomized Controlled Trials</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adjusting for covariates in randomized controlled trials can enhance the credibility and efficiency of treatment effect estimation. However, handling numerous covariates and their non-linear transformations is challenging, particularly when outcomes and covariates have missing data. In this tutorial, we propose a principled Covariate Adjustment with Variable Selection and Missing Data Imputation (COADVISE) framework that enables (i) variable selection for covariates most relevant to the outcome, (ii) nonlinear adjustments, and (iii) robust imputation of missing data for both outcomes and covariates. This framework ensures consistent estimates with improved efficiency over unadjusted estimators and provides robust variance estimation, even under outcome model misspecification. We demonstrate efficiency gains through theoretical analysis and conduct extensive simulations to compare alternative variable selection strategies, offering cautionary recommendations. We showcase the practical utility of COADVISE by applying it to the Best Apnea Interventions for Research trial data from the National Sleep Research Resource. A user-friendly R package, Coadvise, facilitates implementation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.09683</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.09683</id><created>2025-01-16</created><updated>2025-02-05</updated><authors><author><keyname>Cirone</keyname><forenames>Nicola Muca</forenames></author><author><keyname>Salvi</keyname><forenames>Cristopher</forenames></author></authors><title>Rough kernel hedging</title><categories>math.FA cs.LG stat.ML</categories><comments>v2. minor corrections to presentation</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Building on the functional-analytic framework of operator-valued kernels and un-truncated signature kernels, we propose a scalable, provably convergent signature-based algorithm for a broad class of high-dimensional, path-dependent hedging problems. We make minimal assumptions about market dynamics by modelling them as general geometric rough paths, yielding a fully model-free approach. Furthermore, through a representer theorem, we provide theoretical guarantees on the existence and uniqueness of a global minimum for the resulting optimization problem and derive an analytic solution under highly general loss functions. Similar to the popular deep hedging approach, but in a more rigorous fashion, our method can also incorporate additional features via the underlying operator-valued kernel, such as trading signals, news analytics, and past hedging decisions, closely aligning with true machine-learning practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10910</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10910</id><created>2025-01-18</created><updated>2025-02-05</updated><authors><author><keyname>Kowsar</keyname><forenames>Ibna</forenames></author><author><keyname>Rabbani</keyname><forenames>Shourav B.</forenames></author><author><keyname>Hou</keyname><forenames>Yina</forenames></author><author><keyname>Samad</keyname><forenames>Manar D.</forenames></author></authors><title>DeepIFSAC: Deep Imputation of Missing Values Using Feature and Sample   Attention within Contrastive Framework</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Missing values of varying patterns and rates in real-world tabular data pose a significant challenge in developing reliable data-driven models. Existing missing value imputation methods use statistical and traditional machine learning and are ineffective when the missing rate is high and not at random. This paper explores row and column attention in tabular data as between-feature and between-sample attention in a novel framework to reconstruct missing values. The proposed method uses the CutMix data augmentation within a contrastive learning framework to improve the uncertainty of missing value estimation. The performance and generalizability of trained imputation models are evaluated on set-aside test data folds with missing values. The proposed framework outperforms nine state-of-the-art imputation methods across several missing value types and rates (10\%-50\%) on a diverse selection of twelve tabular data sets. We evaluate the quality of imputed data using real-world electronic health records with missing values, demonstrating our proposed framework's superiority to state-of-the-art statistical, machine learning, and deep imputation methods. This paper highlights the heterogeneity of tabular data sets to recommend imputation methods based on missing value types and data characteristics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11280</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11280</id><created>2025-01-20</created><updated>2025-02-04</updated><authors><author><keyname>Yoshida</keyname><forenames>Tsukasa</forenames></author><author><keyname>Watanabe</keyname><forenames>Kazuho</forenames></author></authors><title>Empirical Bayes Estimation for Lasso-Type Regularizers: Analysis of   Automatic Relevance Determination</title><categories>math.ST cs.IT cs.LG math.IT stat.TH</categories><comments>8 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper focuses on linear regression models with non-conjugate sparsity-inducing regularizers such as lasso and group lasso. Although empirical Bayes approach enables us to estimate the regularization parameter, little is known on the properties of the estimators. In particular, there are many unexplained aspects regarding the specific conditions under which the mechanism of automatic relevance determination (ARD) occurs. In this paper, we derive the empirical Bayes estimators for the group lasso regularized linear regression models with a limited number of parameters. It is shown that the estimators diverge under a certain condition, giving rise to the ARD mechanism. We also prove that empirical Bayes methods can produce ARD mechanism in general regularized linear regression models and clarify the conditions under which models such as ridge, lasso, and group lasso can produce ARD mechanism. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11650</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11650</id><created>2025-01-20</created><updated>2025-02-05</updated><authors><author><keyname>Leach</keyname><forenames>Callum</forenames></author><author><keyname>Ewans</keyname><forenames>Kevin</forenames></author><author><keyname>Jonathan</keyname><forenames>Philip</forenames></author></authors><title>Changes over time in the 100-year return value of climate model   variables</title><categories>stat.AP physics.ao-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We assess evidence for changes in tail characteristics of wind, solar irradiance and temperature variables output from CMIP6 global climate models (GCMs) due to climate forcing. We estimate global and climate zone annual maximum and annual means for period (2015, 2100) from daily output of seven GCMs for daily wind speed, maximum wind speed, solar irradiance and near-surface temperature. We calculate corresponding annualised data for individual locations within neighbourhoods of the North Atlantic and Celtic Sea region. We consider output for three climate scenarios and multiple climate ensembles. We estimate non-stationary extreme value models for annual extremes, and non-homogeneous Gaussian regressions for annual means, using Bayesian inference. We use estimated statistical models to quantify the distribution of (i) the change in 100-year return value for annual extremes, and (2) the change in annual mean, over the period (2025, 2125). To summarise results, we estimate linear mixed effects models for observed variation of (i) and (ii). Evidence for changes in the 100-year return value for annual maxima of solar irradiance and temperature is much stronger than for wind variables over time and with climate scenario. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11689</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11689</id><created>2025-01-20</created><updated>2025-02-05</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Randomness, exchangeability, and conformal prediction</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>24 pages, 1 figure; v2 includes several new results about the   optimality of results in v1</comments><msc-class>68Q32 (Primary) 62G15, 68T05, 03D32 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper continues development of the functional theory of randomness, a modification of the algorithmic theory of randomness getting rid of unspecified additive constants. It introduces new kinds of confidence predictors, including randomness predictors (the most general confidence predictors based on the assumption of IID observations) and exchangeability predictors (the most general confidence predictors based on the assumption of exchangeable observations). The main result implies that both are close to conformal predictors and quantifies the difference between randomness prediction and conformal prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12737</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12737</id><created>2025-01-22</created><updated>2025-02-04</updated><authors><author><keyname>Yang</keyname><forenames>Jiaqi</forenames></author><author><keyname>Xie</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Xiaohua</forenames></author></authors><title>Stability and Generalization of Quantum Neural Networks</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum neural networks (QNNs) play an important role as an emerging technology in the rapidly growing field of quantum machine learning. While their empirical success is evident, the theoretical explorations of QNNs, particularly their generalization properties, are less developed and primarily focus on the uniform convergence approach. In this paper, we exploit an advanced tool in classical learning theory, i.e., algorithmic stability, to study the generalization of QNNs. We first establish high-probability generalization bounds for QNNs via uniform stability. Our bounds shed light on the key factors influencing the generalization performance of QNNs and provide practical insights into both the design and training processes. We next explore the generalization of QNNs on near-term noisy intermediate-scale quantum (NISQ) devices, highlighting the potential benefits of quantum noise. Moreover, we argue that our previous analysis characterizes worst-case generalization guarantees, and we establish a refined optimization-dependent generalization bound for QNNs via on-average stability. Numerical experiments on various real-world datasets support our theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.15194</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.15194</id><created>2025-01-25</created><updated>2025-02-04</updated><authors><author><keyname>Yao</keyname><forenames>Zhihao</forenames></author><author><keyname>Yin</keyname><forenames>Jixuan</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author></authors><title>Reliable Pseudo-labeling via Optimal Transport with Attention for Short   Text Clustering</title><categories>cs.LG stat.CO stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Short text clustering has gained significant attention in the data mining community. However, the limited valuable information contained in short texts often leads to low-discriminative representations, increasing the difficulty of clustering. This paper proposes a novel short text clustering framework, called Reliable \textbf{P}seudo-labeling via \textbf{O}ptimal \textbf{T}ransport with \textbf{A}ttention for Short Text Clustering (\textbf{POTA}), that generate reliable pseudo-labels to aid discriminative representation learning for clustering. Specially, \textbf{POTA} first implements an instance-level attention mechanism to capture the semantic relationships among samples, which are then incorporated as a semantic consistency regularization term into an optimal transport problem. By solving this OT problem, we can yield reliable pseudo-labels that simultaneously account for sample-to-sample semantic consistency and sample-to-cluster global structure information. Additionally, the proposed OT can adaptively estimate cluster distributions, making \textbf{POTA} well-suited for varying degrees of imbalanced datasets. Then, we utilize the pseudo-labels to guide contrastive learning to generate discriminative representations and achieve efficient clustering. Extensive experiments demonstrate \textbf{POTA} outperforms state-of-the-art methods. The code is available at: \href{https://github.com/YZH0905/POTA-STC/tree/main}{https://github.com/YZH0905/POTA-STC/tree/main}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.15753</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.15753</id><created>2025-01-26</created><updated>2025-02-05</updated><authors><author><keyname>Fallahgoul</keyname><forenames>Hasan</forenames></author></authors><title>Scale-Insensitive Neural Network Significance Tests</title><categories>stat.ML cs.LG econ.EM</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper develops a scale-insensitive framework for neural network significance testing, substantially generalizing existing approaches through three key innovations. First, we replace metric entropy calculations with Rademacher complexity bounds, enabling the analysis of neural networks without requiring bounded weights or specific architectural constraints. Second, we weaken the regularity conditions on the target function to require only Sobolev space membership $H^s([-1,1]^d)$ with $s &gt; d/2$, significantly relaxing previous smoothness assumptions while maintaining optimal approximation rates. Third, we introduce a modified sieve space construction based on moment bounds rather than weight constraints, providing a more natural theoretical framework for modern deep learning practices. Our approach achieves these generalizations while preserving optimal convergence rates and establishing valid asymptotic distributions for test statistics. The technical foundation combines localization theory, sharp concentration inequalities, and scale-insensitive complexity measures to handle unbounded weights and general Lipschitz activation functions. This framework better aligns theoretical guarantees with contemporary deep learning practice while maintaining mathematical rigor. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.16489</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.16489</id><created>2025-01-27</created><updated>2025-02-04</updated><authors><author><keyname>Hou</keyname><forenames>Boya</forenames></author><author><keyname>Sanjari</keyname><forenames>Sina</forenames></author><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author></authors><title>Nonparametric Sparse Online Learning of the Koopman Operator</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>This work was intended as a replacement of arXiv:2405.07432 and any   subsequent updates will appear there</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.16730</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.16730</id><created>2025-01-28</created><updated>2025-02-04</updated><authors><author><keyname>Cong</keyname><forenames>Lin William</forenames></author><author><keyname>Feng</keyname><forenames>Guanhao</forenames></author><author><keyname>He</keyname><forenames>Jingyu</forenames></author><author><keyname>He</keyname><forenames>Xin</forenames></author></authors><title>Growing the Efficient Frontier on Panel Trees</title><categories>cs.LG q-fin.PR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of tree-based models, P-Trees, for analyzing (unbalanced) panel of individual asset returns, generalizing high-dimensional sorting with economic guidance and interpretability. Under the mean-variance efficient framework, P-Trees construct test assets that significantly advance the efficient frontier compared to commonly used test assets, with alphas unexplained by benchmark pricing models. P-Tree tangency portfolios also constitute traded factors, recovering the pricing kernel and outperforming popular observable and latent factor models for investments and cross-sectional pricing. Finally, P-Trees capture the complexity of asset returns with sparsity, achieving out-of-sample Sharpe ratios close to those attained only by over-parameterized large models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.17446</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.17446</id><created>2025-01-29</created><updated>2025-02-03</updated><authors><author><keyname>Satoh</keyname><forenames>Kenichi</forenames></author></authors><title>Applying non-negative matrix factorization with covariates to   multivariate time series data as a vector autoregression model</title><categories>stat.ME</categories><comments>8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative matrix factorization (NMF) is a powerful technique for dimensionality reduction, but its application to time series data remains limited. This paper proposes a novel framework that integrates NMF with a vector autoregression (VAR) model to capture both latent structure and temporal dependencies in multivariate time series data. By representing the NMF coefficient matrix as a VAR model, the framework leverages the interpretability of NMF while incorporating the dynamic characteristics of time series data. This approach allows for the extraction of meaningful features and accurate predictions in time series data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.18095</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.18095</id><created>2025-01-29</created><updated>2025-02-04</updated><authors><author><keyname>Han</keyname><forenames>Barron</forenames></author><author><keyname>Akhtiamov</keyname><forenames>Danil</forenames></author><author><keyname>Ghane</keyname><forenames>Reza</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Robust Mean Estimation With Auxiliary Samples</title><categories>math.ST stat.TH</categories><comments>Submitted to International Symposium on Information Theory 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In data-driven learning and inference tasks, the high cost of acquiring samples from the target distribution often limits performance. A common strategy to mitigate this challenge is to augment the limited target samples with data from a more accessible "auxiliary" distribution. This paper establishes fundamental limits of this approach by analyzing the improvement in the mean square error (MSE) when estimating the mean of the target distribution. Using the Wasserstein-2 metric to quantify the distance between distributions, we derive expressions for the worst-case MSE when samples are drawn (with labels) from both a target distribution and an auxiliary distribution within a specified Wasserstein-2 distance from the target distribution. We explicitly characterize the achievable MSE and the optimal estimator in terms of the problem dimension, the number of samples from the target and auxiliary distributions, the Wasserstein-2 distance, and the covariance of the target distribution. We note that utilizing samples from the auxiliary distribution effectively improves the MSE when the squared radius of the Wasserstein-2 uncertainty ball is small compared to the variance of the true distribution and the number of samples from the true distribution is limited. Numerical simulations in the Gaussian location model illustrate the theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.18184</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.18184</id><created>2025-01-30</created><updated>2025-02-05</updated><authors><author><keyname>Lyu</keyname><forenames>Qingchuan</forenames></author></authors><title>Genetic Algorithm with Border Trades (GAB)</title><categories>cs.LG cs.NE stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel approach to improving Genetic Algorithms (GA) in large or complex problem spaces by incorporating new chromosome patterns in the breeding process through border trade activities. These strategies increase chromosome diversity, preventing premature convergence and enhancing the GA's ability to explore the solution space more effectively. Empirical evidence demonstrates significant improvements in convergence behavior. This approach offers a promising pathway to addressing challenges in optimizing large or complex problem domains. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.00298</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.00298</id><created>2025-01-31</created><updated>2025-02-03</updated><authors><author><keyname>Moreno</keyname><forenames>Alexander</forenames></author><author><keyname>Xiao</keyname><forenames>Justin</forenames></author><author><keyname>Mei</keyname><forenames>Jonathan</forenames></author></authors><title>The Price of Linear Time: Error Analysis of Structured Kernel   Interpolation</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Structured Kernel Interpolation (SKI) (Wilson et al. 2015) helps scale Gaussian Processes (GPs) by approximating the kernel matrix via interpolation at inducing points, achieving linear computational complexity. However, it lacks rigorous theoretical error analysis. This paper bridges the gap: we prove error bounds for the SKI Gram matrix and examine the error's effect on hyperparameter estimation and posterior inference. We further provide a practical guide to selecting the number of inducing points under convolutional cubic interpolation: they should grow as $n^{d/3}$ for error control. Crucially, we identify two dimensionality regimes governing the trade-off between SKI Gram matrix spectral norm error and computational complexity. For $d \leq 3$, any error tolerance can achieve linear time for sufficiently large sample size. For $d &gt; 3$, the error must increase with sample size to maintain linear time. Our analysis provides key insights into SKI's scalability-accuracy trade-offs, establishing precise conditions for achieving linear-time GP inference with controlled approximation error. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01627</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01627</id><created>2025-02-03</created><updated>2025-02-04</updated><authors><author><keyname>Song</keyname><forenames>Yanke</forenames></author><author><keyname>Villar</keyname><forenames>Victoria Ashley</forenames></author><author><keyname>Martinez-Galarza</keyname><forenames>Juan Rafael</forenames></author><author><keyname>Dillmann</keyname><forenames>Steven</forenames></author></authors><title>A Poisson Process AutoDecoder for X-ray Sources</title><categories>astro-ph.IM astro-ph.HE cs.LG stat.AP</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray observing facilities, such as the Chandra X-ray Observatory and the eROSITA, have detected millions of astronomical sources associated with high-energy phenomena. The arrival of photons as a function of time follows a Poisson process and can vary by orders-of-magnitude, presenting obstacles for common tasks such as source classification, physical property derivation, and anomaly detection. Previous work has either failed to directly capture the Poisson nature of the data or only focuses on Poisson rate function reconstruction. In this work, we present Poisson Process AutoDecoder (PPAD). PPAD is a neural field decoder that maps fixed-length latent features to continuous Poisson rate functions across energy band and time via unsupervised learning. PPAD reconstructs the rate function and yields a representation at the same time. We demonstrate the efficacy of PPAD via reconstruction, regression, classification and anomaly detection experiments using the Chandra Source Catalog. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01672</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01672</id><created>2025-02-01</created><authors><author><keyname>Liu</keyname><forenames>Manqing</forenames></author><author><keyname>Beam</keyname><forenames>Andrew L.</forenames></author></authors><title>Doubly Robust Monte Carlo Tree Search</title><categories>stat.ML cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present Doubly Robust Monte Carlo Tree Search (DR-MCTS), a novel algorithm that integrates Doubly Robust (DR) off-policy estimation into Monte Carlo Tree Search (MCTS) to enhance sample efficiency and decision quality in complex environments. Our approach introduces a hybrid estimator that combines MCTS rollouts with DR estimation, offering theoretical guarantees of unbiasedness and variance reduction under specified conditions. Empirical evaluations in Tic-Tac-Toe and the partially observable VirtualHome environment demonstrate DR-MCTS's superior performance over standard MCTS. In Tic-Tac-Toe, DR-MCTS achieves an 88% win rate compared to a 10% win rate for standard MCTS. In compound VirtualHome tasks, DR-MCTS attains a 20.7% success rate versus 10.3% for standard MCTS. Our scaling analysis reveals that DR-MCTS exhibits better sample efficiency, notably outperforming standard MCTS with larger language models while using a smaller model. These results underscore DR-MCTS's potential for efficient decision-making in complex, real-world scenarios where sample efficiency is paramount. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01694</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01694</id><created>2025-02-02</created><authors><author><keyname>Kim</keyname><forenames>Juno</forenames></author><author><keyname>Wu</keyname><forenames>Denny</forenames></author><author><keyname>Lee</keyname><forenames>Jason</forenames></author><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author></authors><title>Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of   Search, RL and Distillation</title><categories>cs.AI cs.LG stat.ML</categories><comments>55 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A key paradigm to improve the reasoning capabilities of large language models (LLMs) is to allocate more inference-time compute to search against a verifier or reward model. This process can then be utilized to refine the pretrained model or distill its reasoning patterns into more efficient models. In this paper, we study inference-time compute by viewing chain-of-thought (CoT) generation as a metastable Markov process: easy reasoning steps (e.g., algebraic manipulations) form densely connected clusters, while hard reasoning steps (e.g., applying a relevant theorem) create sparse, low-probability edges between clusters, leading to phase transitions at longer timescales. Under this framework, we prove that implementing a search protocol that rewards sparse edges improves CoT by decreasing the expected number of steps to reach different clusters. In contrast, we establish a limit on reasoning capability when the model is restricted to local information of the pretrained graph. We also show that the information gained by search can be utilized to obtain a better reasoning model: (1) the pretrained model can be directly finetuned to favor sparse edges via policy gradient methods, and moreover (2) a compressed metastable representation of the reasoning dynamics can be distilled into a smaller, more efficient model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01701</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01701</id><created>2025-02-03</created><authors><author><keyname>Lalanne</keyname><forenames>Clément</forenames><affiliation>IMT, ANITI</affiliation></author><author><keyname>Loubes</keyname><forenames>Jean-Michel</forenames><affiliation>IMT, ANITI</affiliation></author><author><keyname>Rodríguez-Vítores</keyname><forenames>David</forenames><affiliation>UVa, IMUVA</affiliation></author></authors><title>Learning with Differentially Private (Sliced) Wasserstein Gradients</title><categories>cs.LG math.ST stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce a novel framework for privately optimizing objectives that rely on Wasserstein distances between data-dependent empirical measures. Our main theoretical contribution is, based on an explicit formulation of the Wasserstein gradient in a fully discrete setting, a control on the sensitivity of this gradient to individual data points, allowing strong privacy guarantees at minimal utility cost. Building on these insights, we develop a deep learning approach that incorporates gradient and activations clipping, originally designed for DP training of problems with a finite-sum structure. We further demonstrate that privacy accounting methods extend to Wasserstein-based objectives, facilitating large-scale private training. Empirical results confirm that our framework effectively balances accuracy and privacy, offering a theoretically sound solution for privacy-preserving machine learning tasks relying on optimal transport distances such as Wasserstein distance or sliced-Wasserstein distance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01763</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01763</id><created>2025-02-03</created><authors><author><keyname>Zhang</keyname><forenames>Thomas T.</forenames></author><author><keyname>Moniri</keyname><forenames>Behrad</forenames></author><author><keyname>Nagwekar</keyname><forenames>Ansh</forenames></author><author><keyname>Rahman</keyname><forenames>Faraz</forenames></author><author><keyname>Xue</keyname><forenames>Anton</forenames></author><author><keyname>Hassani</keyname><forenames>Hamed</forenames></author><author><keyname>Matni</keyname><forenames>Nikolai</forenames></author></authors><title>On The Concurrence of Layer-wise Preconditioning Methods and Provable   Feature Learning</title><categories>cs.LG math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Layer-wise preconditioning methods are a family of memory-efficient optimization algorithms that introduce preconditioners per axis of each layer's weight tensors. These methods have seen a recent resurgence, demonstrating impressive performance relative to entry-wise ("diagonal") preconditioning methods such as Adam(W) on a wide range of neural network optimization tasks. Complementary to their practical performance, we demonstrate that layer-wise preconditioning methods are provably necessary from a statistical perspective. To showcase this, we consider two prototypical models, linear representation learning and single-index learning, which are widely used to study how typical algorithms efficiently learn useful features to enable generalization. In these problems, we show SGD is a suboptimal feature learner when extending beyond ideal isotropic inputs $\mathbf{x} \sim \mathsf{N}(\mathbf{0}, \mathbf{I})$ and well-conditioned settings typically assumed in prior work. We demonstrate theoretically and numerically that this suboptimality is fundamental, and that layer-wise preconditioning emerges naturally as the solution. We further show that standard tools like Adam preconditioning and batch-norm only mildly mitigate these issues, supporting the unique benefits of layer-wise preconditioning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01780</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01780</id><created>2025-02-03</created><authors><author><keyname>Park</keyname><forenames>Hongju</forenames></author><author><keyname>Bai</keyname><forenames>Shuyang</forenames></author><author><keyname>Ye</keyname><forenames>Zhenyao</forenames></author><author><keyname>Lee</keyname><forenames>Hwiyoung</forenames></author><author><keyname>Ma</keyname><forenames>Tianzhou</forenames></author><author><keyname>Chen</keyname><forenames>Shuo</forenames></author></authors><title>Graph Canonical Correlation Analysis</title><categories>stat.ML cs.LG</categories><comments>40 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Canonical correlation analysis (CCA) is a widely used technique for estimating associations between two sets of multi-dimensional variables. Recent advancements in CCA methods have expanded their application to decipher the interactions of multiomics datasets, imaging-omics datasets, and more. However, conventional CCA methods are limited in their ability to incorporate structured patterns in the cross-correlation matrix, potentially leading to suboptimal estimations. To address this limitation, we propose the graph Canonical Correlation Analysis (gCCA) approach, which calculates canonical correlations based on the graph structure of the cross-correlation matrix between the two sets of variables. We develop computationally efficient algorithms for gCCA, and provide theoretical results for finite sample analysis of best subset selection and canonical correlation estimation by introducing concentration inequalities and stopping time rule based on martingale theories. Extensive simulations demonstrate that gCCA outperforms competing CCA methods. Additionally, we apply gCCA to a multiomics dataset of DNA methylation and RNA-seq transcriptomics, identifying both positively and negatively regulated gene expression pathways by DNA methylation pathways. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01810</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01810</id><created>2025-02-03</created><authors><author><keyname>Mele</keyname><forenames>Angelo</forenames></author></authors><title>Estimating Network Models using Neural Networks</title><categories>cs.SI econ.EM stat.CO stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Exponential random graph models (ERGMs) are very flexible for modeling network formation but pose difficult estimation challenges due to their intractable normalizing constant. Existing methods, such as MCMC-MLE, rely on sequential simulation at every optimization step. We propose a neural network approach that trains on a single, large set of parameter-simulation pairs to learn the mapping from parameters to average network statistics. Once trained, this map can be inverted, yielding a fast and parallelizable estimation method. The procedure also accommodates extra network statistics to mitigate model misspecification. Some simple illustrative examples show that the method performs well in practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01861</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01861</id><created>2025-02-03</created><authors><author><keyname>Harvey</keyname><forenames>Ethan</forenames></author><author><keyname>Petrov</keyname><forenames>Mikhail</forenames></author><author><keyname>Hughes</keyname><forenames>Michael C.</forenames></author></authors><title>Learning Hyperparameters via a Data-Emphasized Variational Objective</title><categories>cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:2410.19675</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When training large flexible models, practitioners often rely on grid search to select hyperparameters that control over-fitting. This grid search has several disadvantages: the search is computationally expensive, requires carving out a validation set that reduces the available data for training, and requires users to specify candidate values. In this paper, we propose an alternative: directly learning regularization hyperparameters on the full training set via the evidence lower bound ("ELBo") objective from variational methods. For deep neural networks with millions of parameters, we recommend a modified ELBo that upweights the influence of the data likelihood relative to the prior. Our proposed technique overcomes all three disadvantages of grid search. In a case study on transfer learning of image classifiers, we show how our method reduces the 88+ hour grid search of past work to under 3 hours while delivering comparable accuracy. We further demonstrate how our approach enables efficient yet accurate approximations of Gaussian processes with learnable length-scale kernels. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01886</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01886</id><created>2025-02-03</created><authors><author><keyname>Díaz</keyname><forenames>Mateo</forenames></author><author><keyname>Drusvyatskiy</keyname><forenames>Dmitriy</forenames></author><author><keyname>Kendrick</keyname><forenames>Jack</forenames></author><author><keyname>Thomas</keyname><forenames>Rekha R.</forenames></author></authors><title>Invariant Kernels: Rank Stabilization and Generalization Across   Dimensions</title><categories>math.OC math.RT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry arises often when learning from high dimensional data. For example, data sets consisting of point clouds, graphs, and unordered sets appear routinely in contemporary applications, and exhibit rich underlying symmetries. Understanding the benefits of symmetry on the statistical and numerical efficiency of learning algorithms is an active area of research. In this work, we show that symmetry has a pronounced impact on the rank of kernel matrices. Specifically, we compute the rank of a polynomial kernel of fixed degree that is invariant under various groups acting independently on its two arguments. In concrete circumstances, including the three aforementioned examples, symmetry dramatically decreases the rank making it independent of the data dimension. In such settings, we show that a simple regression procedure is minimax optimal for estimating an invariant polynomial from finitely many samples drawn across different dimensions. We complete the paper with numerical experiments that illustrate our findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01892</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01892</id><created>2025-02-03</created><authors><author><keyname>Stivala</keyname><forenames>Alex</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Lomi</keyname><forenames>Alessandro</forenames></author></authors><title>Improving exponential-family random graph models for bipartite networks</title><categories>stat.ME stat.AP</categories><comments>54 pages including appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bipartite graphs, representing two-mode networks, arise in many research fields. These networks have two disjoint node sets representing distinct entity types, for example persons and groups, with edges representing associations between the two entity types. In bipartite graphs, the smallest possible cycle is a cycle of length four, and hence four-cycles are the smallest structure to model closure in such networks. Exponential-family random graph models (ERGMs) are a widely used model for social, and other, networks, including specifically bipartite networks. Existing ERGM terms to model four-cycles in bipartite networks, however, are relatively rarely used. In this work we demonstrate some problems with these existing terms to model four-cycles, and define new ERGM terms to help overcome these problems. The position of the new terms in the ERGM dependence hierarchy, and their interpretation, is discussed. The new terms are demonstrated in simulation experiments, and their application illustrated with ERGM models of empirical networks ranging in size from hundreds of nodes to hundreds of thousands of nodes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01919</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01919</id><created>2025-02-03</created><authors><author><keyname>James</keyname><forenames>Lancelot F.</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Pandey</keyname><forenames>Abhinav</forenames></author></authors><title>Poisson Hierarchical Indian Buffet Processes for Within and Across Group   Sharing of Latent Features-With Indications for Microbiome Species Sampling   Models</title><categories>stat.ML cs.LG math.PR math.ST stat.TH</categories><comments>experiments to be added</comments><msc-class>60C05, 60G09 (Primary), 60G57, 60E99 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we present a comprehensive Bayesian posterior analysis of what we term Poisson Hierarchical Indian Buffet Processes, designed for complex random sparse count species sampling models that allow for the sharing of information across and within groups. This analysis covers a potentially infinite number of species and unknown parameters, which, within a Bayesian machine learning context, we are able to learn from as more information is sampled. To achieve our refined results, we employ a range of methodologies drawn from Bayesian latent feature models, random occupancy models, and excursion theory. Despite this complexity, our goal is to make our findings accessible to practitioners, including those who may not be familiar with these areas. To facilitate understanding, we adopt a pseudo-expository style that emphasizes clarity and practical utility. We aim to express our findings in a language that resonates with experts in microbiome and ecological studies, addressing gaps in modeling capabilities while acknowledging that we are not experts ourselves in these fields. This approach encourages the use of our models as basic components of more sophisticated frameworks employed by domain experts, embodying the spirit of the seminal work on the Dirichlet Process. Ultimately, our refined posterior analysis not only yields tractable computational procedures but also enables practical statistical implementation and provides a clear mapping to relevant quantities in microbiome analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01947</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01947</id><created>2025-02-03</created><authors><author><keyname>Zheng</keyname><forenames>Runbing</forenames></author></authors><title>Detection and estimation of vertex-wise latent position shifts across   networks</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pairwise network comparison is essential for various applications, including neuroscience, disease research, and dynamic network analysis. While existing literature primarily focuses on comparing entire network structures, we address a vertex-wise comparison problem where two random networks share the same set of vertices but allow for structural variations in some vertices, enabling a more detailed and flexible analysis of network differences. In our framework, some vertices retain their latent positions between networks, while others undergo shifts. To identify the shifted and unshifted vertices and estimate their latent position shifts, we propose a method that first derives vertex embeddings in a low-rank Euclidean space for each network, then aligns these estimated vertex latent positions into a common space to resolve potential non-identifiability, and finally tests whether each vertex is shifted or not and estimates the vertex shifts. Our theoretical results establish the test statistic for the algorithms, guide parameter selection, and provide performance guarantees. Simulation studies and real data applications, including a case-control study in disease research and dynamic network analysis, demonstrate that the proposed algorithms are both computationally efficient and effective in extracting meaningful insights from network comparisons. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01953</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01953</id><created>2025-02-03</created><authors><author><keyname>Asgari</keyname><forenames>Kiana</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Saeed</keyname><forenames>Basil</forenames></author></authors><title>Local minima of the empirical risk in high dimension: General theorems   and convex examples</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>95 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general model for high-dimensional empirical risk minimization whereby the data $\mathbf{x}_i$ are $d$-dimensional isotropic Gaussian vectors, the model is parametrized by $\mathbf{\Theta}\in\mathbb{R}^{d\times k}$, and the loss depends on the data via the projection $\mathbf{\Theta}^\mathsf{T}\mathbf{x}_i$. This setting covers as special cases classical statistics methods (e.g. multinomial regression and other generalized linear models), but also two-layer fully connected neural networks with $k$ hidden neurons. We use the Kac-Rice formula from Gaussian process theory to derive a bound on the expected number of local minima of this empirical risk, under the proportional asymptotics in which $n,d\to\infty$, with $n\asymp d$. Via Markov's inequality, this bound allows to determine the positions of these minimizers (with exponential deviation bounds) and hence derive sharp asymptotics on the estimation and prediction error. In this paper, we apply our characterization to convex losses, where high-dimensional asymptotics were not (in general) rigorously established for $k\ge 2$. We show that our approach is tight and allows to prove previously conjectured results. In addition, we characterize the spectrum of the Hessian at the minimizer. A companion paper applies our general result to non-convex examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01995</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01995</id><created>2025-02-03</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author><author><keyname>Bondell</keyname><forenames>Howard</forenames></author></authors><title>Theoretical and Practical Analysis of Fr\'echet Regression via   Comparison Geometry</title><categories>stat.ML cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fr\'echet regression extends classical regression methods to non-Euclidean metric spaces, enabling the analysis of data relationships on complex structures such as manifolds and graphs. This work establishes a rigorous theoretical analysis for Fr\'echet regression through the lens of comparison geometry which leads to important considerations for its use in practice. The analysis provides key results on the existence, uniqueness, and stability of the Fr\'echet mean, along with statistical guarantees for nonparametric regression, including exponential concentration bounds and convergence rates. Additionally, insights into angle stability reveal the interplay between curvature of the manifold and the behavior of the regression estimator in these non-Euclidean contexts. Empirical experiments validate the theoretical findings, demonstrating the effectiveness of proposed hyperbolic mappings, particularly for data with heteroscedasticity, and highlighting the practical usefulness of these results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02000</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02000</id><created>2025-02-03</created><authors><author><keyname>Lu</keyname><forenames>Yuchen</forenames></author><author><keyname>Lee</keyname><forenames>Ben Seiyon</forenames></author><author><keyname>Doss-Gollin</keyname><forenames>James</forenames></author></authors><title>Bayesian Spatiotemporal Nonstationary Model Quantifies Robust Increases   in Daily Extreme Rainfall Across the Western Gulf Coast</title><categories>stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precipitation exceedance probabilities are widely used in engineering design, risk assessment, and floodplain management. While common approaches like NOAA Atlas 14 assume that extreme precipitation characteristics are stationary over time, this assumption may underestimate current and future hazards due to anthropogenic climate change. However, the incorporation of nonstationarity in the statistical modeling of extreme precipitation has faced practical challenges that have restricted its applications. In particular, random sampling variability challenges the reliable estimation of trends and parameters, especially when observational records are limited. To address this methodological gap, we propose the Spatially Varying Covariates Model, a hierarchical Bayesian spatial framework that integrates nonstationarity and regionalization for robust frequency analysis of extreme precipitation. This model draws from extreme value theory, spatial statistics, and Bayesian statistics, and is validated through cross-validation and multiple performance metrics. Applying this framework to a case study of daily rainfall in the Western Gulf Coast, we identify robustly increasing trends in extreme precipitation intensity and variability throughout the study area, with notable spatial heterogeneity. This flexible model accommodates stations with varying observation records, yields smooth return level estimates, and can be straightforwardly adapted to the analysis of precipitation frequencies at different durations and for other regions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02002</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02002</id><created>2025-02-03</created><authors><author><keyname>Gruntkowska</keyname><forenames>Kaja</forenames></author><author><keyname>Li</keyname><forenames>Hanmin</forenames></author><author><keyname>Rane</keyname><forenames>Aadi</forenames></author><author><keyname>Richtárik</keyname><forenames>Peter</forenames></author></authors><title>The Ball-Proximal (="Broximal") Point Method: a New Algorithm,   Convergence Theory, and Applications</title><categories>math.OC cs.LG stat.ML</categories><comments>44 pages, 3 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Non-smooth and non-convex global optimization poses significant challenges across various applications, where standard gradient-based methods often struggle. We propose the Ball-Proximal Point Method, Broximal Point Method, or Ball Point Method (BPM) for short - a novel algorithmic framework inspired by the classical Proximal Point Method (PPM) (Rockafellar, 1976), which, as we show, sheds new light on several foundational optimization paradigms and phenomena, including non-convex and non-smooth optimization, acceleration, smoothing, adaptive stepsize selection, and trust-region methods. At the core of BPM lies the ball-proximal ("broximal") operator, which arises from the classical proximal operator by replacing the quadratic distance penalty by a ball constraint. Surprisingly, and in sharp contrast with the sublinear rate of PPM in the nonsmooth convex regime, we prove that BPM converges linearly and in a finite number of steps in the same regime. Furthermore, by introducing the concept of ball-convexity, we prove that BPM retains the same global convergence guarantees under weaker assumptions, making it a powerful tool for a broader class of potentially non-convex optimization problems. Just like PPM plays the role of a conceptual method inspiring the development of practically efficient algorithms and algorithmic elements, e.g., gradient descent, adaptive step sizes, acceleration (Ahn &amp; Sra, 2020), and "W" in AdamW (Zhuang et al., 2022), we believe that BPM should be understood in the same manner: as a blueprint and inspiration for further development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02006</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02006</id><created>2025-02-03</created><authors><author><keyname>Robinson</keyname><forenames>Benjamin D.</forenames></author><author><keyname>Latimer</keyname><forenames>Van</forenames></author></authors><title>Nonlinear Covariance Shrinkage for Hotelling's $T^2$ in High Dimension</title><categories>math.ST math.PR stat.ME stat.TH</categories><comments>41 pages, 9 figures</comments><msc-class>62H15</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we study the problem of comparing the means of a single observation and a reference sample in the presence of a common data covariance matrix, where the data dimension $p$ grows linearly with the number of samples $n$ and $p/n$ converges to a number between 0 and 1. The approach we take is to replace the sample covariance matrix with a nonlinear shrinkage estimator -- i.e., a matrix with the same eigenvectors -- in Hotelling's $T^2$ test. Current approaches of this sort typically assume that the data covariance matrix has a condition number or spiked rank that increases slowly with dimension. However, this assumption is ill-suited to data sets containing many strongly correlated background covariates, as often found in finance, genetics, and remote sensing. To address this problem we construct, using variational methods and new local random-matrix laws, a nonlinear covariance shrinkage method tailored to optimize detection performance across a broad range of spiked ranks and condition numbers. We then demonstrate, via both simulated and real-world data, that our method outperforms existing approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02020</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02020</id><created>2025-02-04</created><authors><author><keyname>Zhao</keyname><forenames>Yijia</forenames></author><author><keyname>Zhou</keyname><forenames>Qing</forenames></author></authors><title>Causal bandits with backdoor adjustment on unknown Gaussian DAGs</title><categories>cs.LG stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The causal bandit problem aims to sequentially learn the intervention that maximizes the expectation of a reward variable within a system governed by a causal graph. Most existing approaches assume prior knowledge of the graph structure, or impose unrealistically restrictive conditions on the graph. In this paper, we assume a Gaussian linear directed acyclic graph (DAG) over arms and the reward variable, and study the causal bandit problem when the graph structure is unknown. We identify backdoor adjustment sets for each arm using sequentially generated experimental and observational data during the decision process, which allows us to estimate causal effects and construct upper confidence bounds. By integrating estimates from both data sources, we develop a novel bandit algorithm, based on modified upper confidence bounds, to sequentially determine the optimal intervention. We establish both case-dependent and case-independent upper bounds on the cumulative regret for our algorithm, which improve upon the bounds of the standard multi-armed bandit algorithms. Our empirical study demonstrates its advantage over existing methods with respect to cumulative regret and computation time. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02032</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02032</id><created>2025-02-04</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author></authors><title>Heteroscedastic Double Bayesian Elastic Net</title><categories>stat.ME cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In many practical applications, regression models are employed to uncover relationships between predictors and a response variable, yet the common assumption of constant error variance is frequently violated. This issue is further compounded in high-dimensional settings where the number of predictors exceeds the sample size, necessitating regularization for effective estimation and variable selection. To address this problem, we propose the Heteroscedastic Double Bayesian Elastic Net (HDBEN), a novel framework that jointly models the mean and log-variance using hierarchical Bayesian priors incorporating both $\ell_1$ and $\ell_2$ penalties. Our approach simultaneously induces sparsity and grouping in the regression coefficients and variance parameters, capturing complex variance structures in the data. Theoretical results demonstrate that proposed HDBEN achieves posterior concentration, variable selection consistency, and asymptotic normality under mild conditions which justifying its behavior. Simulation studies further illustrate that HDBEN outperforms existing methods, particularly in scenarios characterized by heteroscedasticity and high dimensionality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02103</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02103</id><created>2025-02-04</created><authors><author><keyname>Oursland</keyname><forenames>Alan</forenames></author></authors><title>Neural Networks Learn Distance Metrics</title><categories>cs.LG cs.AI stat.ML</categories><comments>14 pages, 1 figures. Code and additional resources available at   https://github.com/alanoursland/neural_networks_learn_distance_metrics</comments><msc-class>68T07 (Primary) 62H12 (Secondary)</msc-class><acm-class>I.5.1; G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural networks may naturally favor distance-based representations, where smaller activations indicate closer proximity to learned prototypes. This contrasts with intensity-based approaches, which rely on activation magnitudes. To test this hypothesis, we conducted experiments with six MNIST architectural variants constrained to learn either distance or intensity representations. Our results reveal that the underlying representation affects model performance. We develop a novel geometric framework that explains these findings and introduce OffsetL2, a new architecture based on Mahalanobis distance equations, to further validate this framework. This work highlights the importance of considering distance-based learning in neural network design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02110</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02110</id><created>2025-02-04</created><authors><author><keyname>Venkatasubramaniam</keyname><forenames>Ashwini</forenames></author><author><keyname>Wolfson</keyname><forenames>Julian</forenames></author></authors><title>Multi-Study Causal Forest (MCF): A flexible framework for data borrowing   in the presence of varying treatment effect heterogeneity</title><categories>stat.ME</categories><comments>5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tailoring treatment assignment to specific individuals can improve the health outcomes, but a single study may offer inadequate information for this purpose. The ability to leverage information from an auxiliary data source deemed to be `most similar' to a primary data source has been shown to improve estimates of treatment effects. In this paper, we introduce a framework, the Multi-Study Causal Forest (MCF), to borrow individual patient-level data from an auxiliary data source in the presence of `varying sources' of treatment effect heterogeneity. We utilise a simulation study to demonstrate the superiority of the MCF in the presence of varying treatment allocation models (between-study heterogeneity) in addition to being able to account for the presence of within-study heterogeneity. This approach can combine data from randomised controlled trials, observational studies or a combination of both. We illustrate using Breast cancer data that the MCF performs favourably compared to an existing methodology in the presence of varying sources of (both between and within) heterogeneity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02121</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02121</id><created>2025-02-04</created><authors><author><keyname>Chew</keyname><forenames>Ruth Wan Theng</forenames></author><author><keyname>Nguyen</keyname><forenames>Quoc Phong</forenames></author><author><keyname>Low</keyname><forenames>Bryan Kian Hsiang</forenames></author></authors><title>BILBO: BILevel Bayesian Optimization</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bilevel optimization is characterized by a two-level optimization structure, where the upper-level problem is constrained by optimal lower-level solutions, and such structures are prevalent in real-world problems. The constraint by optimal lower-level solutions poses significant challenges, especially in noisy, constrained, and derivative-free settings, as repeating lower-level optimizations is sample inefficient and predicted lower-level solutions may be suboptimal. We present BILevel Bayesian Optimization (BILBO), a novel Bayesian optimization algorithm for general bilevel problems with blackbox functions, which optimizes both upper- and lower-level problems simultaneously, without the repeated lower-level optimization required by existing methods. BILBO samples from confidence-bounds based trusted sets, which bounds the suboptimality on the lower level. Moreover, BILBO selects only one function query per iteration, where the function query selection strategy incorporates the uncertainty of estimated lower-level solutions and includes a conditional reassignment of the query to encourage exploration of the lower-level objective. The performance of BILBO is theoretically guaranteed with a sublinear regret bound for commonly used kernels and is empirically evaluated on several synthetic and real-world problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02132</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02132</id><created>2025-02-04</created><authors><author><keyname>Cattaneo</keyname><forenames>Matias D.</forenames></author><author><keyname>Shigida</keyname><forenames>Boris</forenames></author></authors><title>How Memory in Optimization Algorithms Implicitly Modifies the Loss</title><categories>cs.LG cs.AI math.OC stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In modern optimization methods used in deep learning, each update depends on the history of previous iterations, often referred to as memory, and this dependence decays fast as the iterates go further into the past. For example, gradient descent with momentum has exponentially decaying memory through exponentially averaged past gradients. We introduce a general technique for identifying a memoryless algorithm that approximates an optimization algorithm with memory. It is obtained by replacing all past iterates in the update by the current one, and then adding a correction term arising from memory (also a function of the current iterate). This correction term can be interpreted as a perturbation of the loss, and the nature of this perturbation can inform how memory implicitly (anti-)regularizes the optimization dynamics. As an application of our theory, we find that Lion does not have the kind of implicit anti-regularization induced by memory that AdamW does, providing a theory-based explanation for Lion's better generalization performance recently documented. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02140</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02140</id><created>2025-02-04</created><authors><author><keyname>Gouverneur</keyname><forenames>Amaury</forenames></author><author><keyname>Gálvez</keyname><forenames>Borja Rodriguez</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>An Information-Theoretic Analysis of Thompson Sampling with Infinite   Action Spaces</title><categories>stat.ML cs.LG</categories><comments>5 pages, accepted to ICASSP</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the Bayesian regret of the Thompson Sampling algorithm for bandit problems, building on the information-theoretic framework introduced by Russo and Van Roy (2015). Specifically, it extends the rate-distortion analysis of Dong and Van Roy (2018), which provides near-optimal bounds for linear bandits. A limitation of these results is the assumption of a finite action space. We address this by extending the analysis to settings with infinite and continuous action spaces. Additionally, we specialize our results to bandit problems with expected rewards that are Lipschitz continuous with respect to the action space, deriving a regret bound that explicitly accounts for the complexity of the action space. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02148</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02148</id><created>2025-02-04</created><authors><author><keyname>Hemmens</keyname><forenames>Christopher</forenames></author><author><keyname>Robert-Nicoud</keyname><forenames>Stephan</forenames></author></authors><title>Can linear algebra create perfect knockoffs?</title><categories>stat.ME</categories><comments>11 pages</comments><journal-ref>Big Data and Internet of Things. BDIoT 2024. Lecture Notes in   Networks and Systems, vol 887. Springer, Cham</journal-ref><doi>10.1007/978-3-031-74491-4_81</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As new Model-X knockoff construction techniques are developed, primarily concerned with determining the correct conditional distribution from which to sample, we focus less on deriving the correct multivariate distribution and instead ask if ``perfect'' knockoffs can be constructed using linear algebra. Using mean absolute correlation between knockoffs and features as a measure of quality, we do produce knockoffs that are pseudo-perfect, however, the optimization algorithm is computationally very expensive. We outline a series of methods to significantly reduce the computation time of the algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02160</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02160</id><created>2025-02-04</created><authors><author><keyname>Pistone</keyname><forenames>Giovanni</forenames></author></authors><title>Information geometry of Bayes computations</title><categories>math.ST stat.TH</categories><comments>First version of a submitted conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Amari's Information Geometry is a dually affine formalism for parametric probability models. The literature proposes various nonparametric functional versions. Our approach uses classical Weyl's axioms so that the affine velocity of a one-parameter statistical model equals the classical Fisher's score. In the present note, we first offer a concise review of the notion of a statistical bundle as a set of couples of probability densities and Fisher's scores. Then, we show how the nonparametric dually affine setup deals with the basic Bayes and Kullback-Leibler divergence computations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02177</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02177</id><created>2025-02-04</created><authors><author><keyname>Pistone</keyname><forenames>Giovanni</forenames></author></authors><title>Affine calculus for constrained minima of the Kullback-Leibler   divergence</title><categories>math.ST stat.TH</categories><comments>First version of a submitted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper showcases general computations derived from our version of Amari's dually affine Information Geometry. We especially focus on statistics and machine learning algorithms involving the constrained minimization of the Kullback-Liebler divergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02206</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02206</id><created>2025-02-04</created><authors><author><keyname>Llorente</keyname><forenames>F.</forenames></author><author><keyname>Martino</keyname><forenames>L.</forenames></author><author><keyname>Delgado</keyname><forenames>D.</forenames></author></authors><title>Target-aware Bayesian inference via generalized thermodynamic   integration</title><categories>stat.CO cs.CE stat.ME</categories><journal-ref>Computational Statistics, Volume 38, Pages 2097-2119, year 2023</journal-ref><doi>10.1007/s00180-023-01358-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian inference, we are usually interested in the numerical approximation of integrals that are posterior expectations or marginal likelihoods (a.k.a., Bayesian evidence). In this paper, we focus on the computation of the posterior expectation of a function $f(\x)$. We consider a \emph{target-aware} scenario where $f(\x)$ is known in advance and can be exploited in order to improve the estimation of the posterior expectation. In this scenario, this task can be reduced to perform several independent marginal likelihood estimation tasks. The idea of using a path of tempered posterior distributions has been widely applied in the literature for the computation of marginal likelihoods. Thermodynamic integration, path sampling and annealing importance sampling are well-known examples of algorithms belonging to this family of methods. In this work, we introduce a generalized thermodynamic integration (GTI) scheme which is able to perform a target-aware Bayesian inference, i.e., GTI can approximate the posterior expectation of a given function. Several scenarios of application of GTI are discussed and different numerical simulations are provided. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02213</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02213</id><created>2025-02-04</created><authors><author><keyname>Rasines</keyname><forenames>Daniel García</forenames></author><author><keyname>Young</keyname><forenames>G. Alastair</forenames></author></authors><title>Sampling models for selective inference</title><categories>math.ST stat.TH</categories><comments>16 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper explores the challenges of constructing suitable inferential models in scenarios where the parameter of interest is determined in light of the data, such as regression after variable selection. Two compelling arguments for conditioning converge in this context, whose interplay can introduce ambiguity in the choice of conditioning strategy: the Conditionality Principle, from classical statistics, and the `condition on selection' paradigm, central to selective inference. We discuss two general principles that can be employed to resolve this ambiguity in some recurrent contexts. The first one refers to the consideration of how information is processed at the selection stage. The second one concerns an exploration of ancillarity in the presence of selection. We demonstrate that certain notions of ancillarity are preserved after conditioning on the selection event, supporting the application of the Conditionality Principle. We illustrate these concepts through examples and provide guidance on the adequate inferential approach in some common scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02216</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02216</id><created>2025-02-04</created><authors><author><keyname>Chen</keyname><forenames>Dexiong</forenames></author><author><keyname>Krimmel</keyname><forenames>Markus</forenames></author><author><keyname>Borgwardt</keyname><forenames>Karsten</forenames></author></authors><title>Flatten Graphs as Sequences: Transformers are Scalable Graph Generators</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce AutoGraph, a novel autoregressive framework for generating large attributed graphs using decoder-only transformers. At the core of our approach is a reversible "flattening" process that transforms graphs into random sequences. By sampling and learning from these sequences, AutoGraph enables transformers to model and generate complex graph structures in a manner akin to natural language. In contrast to diffusion models that rely on computationally intensive node features, our approach operates exclusively on these sequences. The sampling complexity and sequence length scale linearly with the number of edges, making AutoGraph highly scalable for generating large sparse graphs. Empirically, AutoGraph achieves state-of-the-art performance across diverse synthetic and molecular graph generation benchmarks, while delivering a 100-fold generation and a 3-fold training speedup compared to leading diffusion models. Additionally, it demonstrates promising transfer capabilities and supports substructure-conditioned generation without additional fine-tuning. By extending language modeling techniques to graph generation, this work paves the way for developing graph foundation models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02221</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02221</id><created>2025-02-04</created><authors><author><keyname>Němeček</keyname><forenames>Jiří</forenames></author><author><keyname>Kozdoba</keyname><forenames>Mark</forenames></author><author><keyname>Kryvoviaz</keyname><forenames>Illia</forenames></author><author><keyname>Pevný</keyname><forenames>Tomáš</forenames></author><author><keyname>Mareček</keyname><forenames>Jakub</forenames></author></authors><title>Bias Detection via Maximum Subgroup Discrepancy</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bias evaluation is fundamental to trustworthy AI, both in terms of checking data quality and in terms of checking the outputs of AI systems. In testing data quality, for example, one may study a distance of a given dataset, viewed as a distribution, to a given ground-truth reference dataset. However, classical metrics, such as the Total Variation and the Wasserstein distances, are known to have high sample complexities and, therefore, may fail to provide meaningful distinction in many practical scenarios.   In this paper, we propose a new notion of distance, the Maximum Subgroup Discrepancy (MSD). In this metric, two distributions are close if, roughly, discrepancies are low for all feature subgroups. While the number of subgroups may be exponential, we show that the sample complexity is linear in the number of features, thus making it feasible for practical applications. Moreover, we provide a practical algorithm for the evaluation of the distance, based on Mixed-integer optimization (MIO). We also note that the proposed distance is easily interpretable, thus providing clearer paths to fixing the biases once they have been identified. It also provides guarantees for all subgroups. Finally, we empirically evaluate, compare with other metrics, and demonstrate the above properties of MSD on real-world datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02233</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02233</id><created>2025-02-04</created><authors><author><keyname>Sahoo</keyname><forenames>Satyajeet</forenames></author><author><keyname>Maiti</keyname><forenames>Jhareswar</forenames></author></authors><title>Variance-Adjusted Cosine Distance as Similarity Metric</title><categories>stat.ML cs.LG</categories><comments>6 Pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Cosine similarity is a popular distance measure that measures the similarity between two vectors in the inner product space. It is widely used in many data classification algorithms like K-Nearest Neighbors, Clustering etc. This study demonstrates limitations of application of cosine similarity. Particularly, this study demonstrates that traditional cosine similarity metric is valid only in the Euclidean space, whereas the original data resides in a random variable space. When there is variance and correlation in the data, then cosine distance is not a completely accurate measure of similarity. While new similarity and distance metrics have been developed to make up for the limitations of cosine similarity, these metrics are used as substitutes to cosine distance, and do not make modifications to cosine distance to overcome its limitations. Subsequently, we propose a modified cosine similarity metric, where cosine distance is adjusted by variance-covariance of the data. Application of variance-adjusted cosine distance gives better similarity performance compared to traditional cosine distance. KNN modelling on the Wisconsin Breast Cancer Dataset is performed using both traditional and modified cosine similarity measures and compared. The modified formula shows 100% test accuracy on the data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02270</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02270</id><created>2025-02-04</created><authors><author><keyname>Alcalde</keyname><forenames>Albert</forenames></author><author><keyname>Fantuzzi</keyname><forenames>Giovanni</forenames></author><author><keyname>Zuazua</keyname><forenames>Enrique</forenames></author></authors><title>Exact Sequence Classification with Hardmax Transformers</title><categories>cs.LG math.OC stat.ML</categories><comments>14 pages, 5 figures. Funded by the European Union (Horizon Europe   MSCA project ModConFlex, grant number 101073558)</comments><msc-class>68T07, 68T50</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We prove that hardmax attention transformers perfectly classify datasets of $N$ labeled sequences in $\mathbb{R}^d$, $d\geq 2$. Specifically, given $N$ sequences with an arbitrary but finite length in $\mathbb{R}^d$, we construct a transformer with $\mathcal{O}(N)$ blocks and $\mathcal{O}(Nd)$ parameters perfectly classifying this dataset. Our construction achieves the best complexity estimate to date, independent of the length of the sequences, by innovatively alternating feed-forward and self-attention layers and by capitalizing on the clustering effect inherent to the latter. Our novel constructive method also uses low-rank parameter matrices within the attention mechanism, a common practice in real-life transformer implementations. Consequently, our analysis holds twofold significance: it substantially advances the mathematical theory of transformers and it rigorously justifies their exceptional real-world performance in sequence classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02296</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02296</id><created>2025-02-04</created><authors><author><keyname>Rakitzis</keyname><forenames>Athanasios C.</forenames></author></authors><title>On The Performance of a Two-Sided Shewhart Chart for Continuous   Proportions with Estimated Parameters</title><categories>stat.ME stat.AP</categories><comments>33 pages, 13 figures</comments><msc-class>62P30</msc-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  During the recent years there was an increased interest in studying the performance of different types of control charts, under various distributional models for continuous proportions, such as percentages and rates. In this work we consider the Kumaraswamy distribution, a popular and flexible distributional model for data in the unit interval (0,1) and investigate further the properties of a two-sided chart for individual observations for monitoring these types of processes, when the process parameters are unknown. Specifically, using Monte Carlo simulation, we evaluate the performance of the chart under a conditional perspective and provide empirical rules on how to select the appropriate size for the Phase I sample. In addition, we explore possible adjustments on the control limits of the chart, which take into account the available Phase I sample. The performance of the chart is also investigated for several out-of-control situations. The results show that for small and moderate size Phase I samples, practitioners have to choose whether they prefer a guaranteed in-control performance or an improved out-of-control performance. The implementation of the considered methods in practice is discussed via two numerical examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02305</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02305</id><created>2025-02-04</created><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Information-Theoretic Proofs for Diffusion Sampling</title><categories>stat.ML cs.IT cs.LG math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper provides an elementary, self-contained analysis of diffusion-based sampling methods for generative modeling. In contrast to existing approaches that rely on continuous-time processes and then discretize, our treatment works directly with discrete-time stochastic processes and yields precise non-asymptotic convergence guarantees under broad assumptions. The key insight is to couple the sampling process of interest with an idealized comparison process that has an explicit Gaussian-convolution structure. We then leverage simple identities from information theory, including the I-MMSE relationship, to bound the discrepancy (in terms of the Kullback-Leibler divergence) between these two discrete-time processes. In particular, we show that, if the diffusion step sizes are chosen sufficiently small and one can approximate certain conditional mean estimators well, then the sampling distribution is provably close to the target distribution. Our results also provide a transparent view on how to accelerate convergence by introducing additional randomness in each step to match higher order moments in the comparison process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02331</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02331</id><created>2025-02-04</created><authors><author><keyname>Tsoy</keyname><forenames>Nikita</forenames></author><author><keyname>Kirev</keyname><forenames>Ivan</forenames></author><author><keyname>Rahimiyazdi</keyname><forenames>Negin</forenames></author><author><keyname>Konstantinov</keyname><forenames>Nikola</forenames></author></authors><title>On the Impact of Performative Risk Minimization for Binary Random   Variables</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Performativity, the phenomenon where outcomes are influenced by predictions, is particularly prevalent in social contexts where individuals strategically respond to a deployed model. In order to preserve the high accuracy of machine learning models under distribution shifts caused by performativity, Perdomo et al. (2020) introduced the concept of performative risk minimization (PRM). While this framework ensures model accuracy, it overlooks the impact of the PRM on the underlying distributions and the predictions of the model. In this paper, we initiate the analysis of the impact of PRM, by studying performativity for a sequential performative risk minimization problem with binary random variables and linear performative shifts. We formulate two natural measures of impact. In the case of full information, where the distribution dynamics are known, we derive explicit formulas for the PRM solution and our impact measures. In the case of partial information, we provide performative-aware statistical estimators, as well as simulations. Our analysis contrasts PRM to alternatives that do not model data shift and indicates that PRM can have amplified side effects compared to such methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02363</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02363</id><created>2025-02-04</created><authors><author><keyname>Cortinovis</keyname><forenames>Stefano</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>FAB-PPI: Frequentist, Assisted by Bayes, Prediction-Powered Inference</title><categories>stat.ML cs.LG</categories><comments>28 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction-powered inference (PPI) enables valid statistical inference by combining experimental data with machine learning predictions. When a sufficient number of high-quality predictions is available, PPI results in more accurate estimates and tighter confidence intervals than traditional methods. In this paper, we propose to inform the PPI framework with prior knowledge on the quality of the predictions. The resulting method, which we call frequentist, assisted by Bayes, PPI (FAB-PPI), improves over PPI when the observed prediction quality is likely under the prior, while maintaining its frequentist guarantees. Furthermore, when using heavy-tailed priors, FAB-PPI adaptively reverts to standard PPI in low prior probability regions. We demonstrate the benefits of FAB-PPI in real and synthetic examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02364</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02364</id><created>2025-02-04</created><authors><author><keyname>Baillie</keyname><forenames>Nils</forenames></author><author><keyname>Van Biesbroeck</keyname><forenames>Antoine</forenames></author><author><keyname>Gauchy</keyname><forenames>Clément</forenames></author></authors><title>Variational inference for approximate reference priors using neural   networks</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian statistics, the choice of the prior can have an important influence on the posterior and the parameter estimation, especially when few data samples are available. To limit the added subjectivity from a priori information, one can use the framework of reference priors. However, computing such priors is a difficult task in general. We develop in this paper a flexible algorithm based on variational inference which computes approximations of reference priors from a set of parametric distributions using neural networks. We also show that our algorithm can retrieve reference priors when constraints are specified in the optimization problem to ensure the solution is proper. We propose a simple method to recover a relevant approximation of the parametric posterior distribution using Markov Chain Monte Carlo (MCMC) methods even if the density function of the parametric prior is not known in general. Numerical experiments on several statistical models of increasing complexity are presented. We show the usefulness of this approach by recovering the target distribution. The performance of the algorithm is evaluated on the prior distributions as well as the posterior distributions, jointly using variational inference and MCMC sampling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02369</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02369</id><created>2025-02-04</created><authors><author><keyname>Brinks</keyname><forenames>Ralph</forenames></author></authors><title>Estimation of the incidence rate and mortality rate ratio for chronic   conditions based on aggregated current status data</title><categories>stat.AP q-bio.PE</categories><comments>10 pages, 3 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that the transition rates of the illness-death model (IDM) for chronic conditions are related to the percentages of people in the states by a three-dimensional system of differential equations [Bri24]. The aim of this article is to introduce a method to estimate the age-specific incidence rate together with the mortality rate ratio from aggregated current status (ACS) data. By ACS data we mean counts of (non-necessarily different) people in the three states of the IDM at different points in time. ACS data stem from epidemiological studies where only current disease status and vital status data need to be collected without following-up people (as, for example, in cohort studies). As an application, we use the theory in a simulation study about diabetes in Germany with 600 study subjects at eleven repeated cross-sections each of which with 50% participation quote. Special focus is given to stochastic dependency of the sampled participants. We find a good agreement between the estimates and the input parameters used for the simulation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02379</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02379</id><created>2025-02-04</created><authors><author><keyname>Coupette</keyname><forenames>Corinna</forenames></author><author><keyname>Wayland</keyname><forenames>Jeremy</forenames></author><author><keyname>Simons</keyname><forenames>Emily</forenames></author><author><keyname>Rieck</keyname><forenames>Bastian</forenames></author></authors><title>No Metric to Rule Them All: Toward Principled Evaluations of   Graph-Learning Datasets</title><categories>cs.LG cs.SI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Benchmark datasets have proved pivotal to the success of graph learning, and good benchmark datasets are crucial to guide the development of the field. Recent research has highlighted problems with graph-learning datasets and benchmarking practices -- revealing, for example, that methods which ignore the graph structure can outperform graph-based approaches on popular benchmark datasets. Such findings raise two questions: (1) What makes a good graph-learning dataset, and (2) how can we evaluate dataset quality in graph learning? Our work addresses these questions. As the classic evaluation setup uses datasets to evaluate models, it does not apply to dataset evaluation. Hence, we start from first principles. Observing that graph-learning datasets uniquely combine two modes -- the graph structure and the node features -- , we introduce RINGS, a flexible and extensible mode-perturbation framework to assess the quality of graph-learning datasets based on dataset ablations -- i.e., by quantifying differences between the original dataset and its perturbed representations. Within this framework, we propose two measures -- performance separability and mode complementarity -- as evaluation tools, each assessing, from a distinct angle, the capacity of a graph dataset to benchmark the power and efficacy of graph-learning methods. We demonstrate the utility of our framework for graph-learning dataset evaluation in an extensive set of experiments and derive actionable recommendations for improving the evaluation of graph-learning methods. Our work opens new research directions in data-centric graph learning, and it constitutes a first step toward the systematic evaluation of evaluations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02392</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02392</id><created>2025-02-04</created><authors><author><keyname>Aloni</keyname><forenames>Ofek</forenames></author><author><keyname>Perelman</keyname><forenames>Gal</forenames></author><author><keyname>Fishbain</keyname><forenames>Barak</forenames></author></authors><title>Synthetic Random Environmental Time Series Generation with Similarity   Control, Preserving Original Signal's Statistical Characteristics</title><categories>stat.ME</categories><comments>Accepted for publication 27 November 2024. Code available at   https://github.com/Al-Ofek/stsg.git</comments><journal-ref>Environmental Modelling &amp; Software, Volume 185, February 2025,   106283</journal-ref><doi>10.1016/j.envsoft.2024.106283</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Synthetic datasets are widely used in many applications, such as missing data imputation, examining non-stationary scenarios, in simulations, training data-driven models, and analyzing system robustness. Typically, synthetic data are based on historical data obtained from the observed system. The data needs to represent a specific behavior of the system, yet be new and diverse enough so that the system is challenged with a broad range of inputs. This paper presents a method, based on discrete Fourier transform, for generating synthetic time series with similar statistical moments for any given signal. The suggested method makes it possible to control the level of similarity between the given signal and the generated synthetic signals. Proof shows analytically that this method preserves the first two statistical moments of the input signal, and its autocorrelation function. The method is compared to known methods, ARMA, GAN, and CoSMoS. A large variety of environmental datasets with different temporal resolutions, and from different domains are used, testing the generality and flexibility of the method. A Python library implementing this method is made available as open-source software. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02397</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02397</id><created>2025-02-04</created><authors><author><keyname>Calvi</keyname><forenames>Annalisa</forenames></author><author><keyname>Laa</keyname><forenames>Ursula</forenames></author><author><keyname>Cook</keyname><forenames>Dianne</forenames></author></authors><title>Is this normal? A new projection pursuit index to assess a sample   against a multivariate null distribution</title><categories>stat.ME stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many data problems contain some reference or normal conditions, upon which to compare newly collected data. This scenario occurs in data collected as part of clinical trials to detect adverse events, or for measuring climate change against historical norms. The data is typically multivariate, and often the normal ranges are specified by a multivariate normal distribution. The work presented in this paper develops methods to compare the new sample against the reference distribution with high-dimensional visualisation. It uses a projection pursuit guided tour to produce a sequence of low-dimensional projections steered towards those where the new sample is most different from the reference. A new projection pursuit index is defined for this purpose. The tour visualisation also includes drawing of the projected ellipse, which is computed analytically, corresponding to the reference distribution. The methods are implemented in the R package, tourr. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02407</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02407</id><created>2025-02-04</created><authors><author><keyname>Singh</keyname><forenames>Sidak Pal</forenames></author><author><keyname>Mobahi</keyname><forenames>Hossein</forenames></author><author><keyname>Agarwala</keyname><forenames>Atish</forenames></author><author><keyname>Dauphin</keyname><forenames>Yann</forenames></author></authors><title>Avoiding spurious sharpness minimization broadens applicability of SAM</title><categories>cs.LG cs.CL stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Curvature regularization techniques like Sharpness Aware Minimization (SAM) have shown great promise in improving generalization on vision tasks. However, we find that SAM performs poorly in domains like natural language processing (NLP), often degrading performance -- even with twice the compute budget. We investigate the discrepancy across domains and find that in the NLP setting, SAM is dominated by regularization of the logit statistics -- instead of improving the geometry of the function itself. We use this observation to develop an alternative algorithm we call Functional-SAM, which regularizes curvature only through modification of the statistics of the overall function implemented by the neural network, and avoids spurious minimization through logit manipulation. Furthermore, we argue that preconditioning the SAM perturbation also prevents spurious minimization, and when combined with Functional-SAM, it gives further improvements. Our proposed algorithms show improved performance over AdamW and SAM baselines when trained for an equal number of steps, in both fixed-length and Chinchilla-style training settings, at various model scales (including billion-parameter scale). On the whole, our work highlights the importance of more precise characterizations of sharpness in broadening the applicability of curvature regularization to large language models (LLMs). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02410</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02410</id><created>2025-02-04</created><authors><author><keyname>Schuchardt</keyname><forenames>Jan</forenames></author><author><keyname>Dalirrooyfard</keyname><forenames>Mina</forenames></author><author><keyname>Guzelkabaagac</keyname><forenames>Jed</forenames></author><author><keyname>Schneider</keyname><forenames>Anderson</forenames></author><author><keyname>Nevmyvaka</keyname><forenames>Yuriy</forenames></author><author><keyname>Günnemann</keyname><forenames>Stephan</forenames></author></authors><title>Privacy Amplification by Structured Subsampling for Deep Differentially   Private Time Series Forecasting</title><categories>cs.LG cs.CR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with timeseries-specific tasks like forecasting, since they rely on the privacy amplification attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this structured subsampling to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02430</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02430</id><created>2025-02-04</created><authors><author><keyname>Busa-Fekete</keyname><forenames>Róbert</forenames></author><author><keyname>Zimmert</keyname><forenames>Julian</forenames></author><author><keyname>György</keyname><forenames>András</forenames></author><author><keyname>Qiu</keyname><forenames>Linhai</forenames></author><author><keyname>Sung</keyname><forenames>Tzu-Wei</forenames></author><author><keyname>Shen</keyname><forenames>Hao</forenames></author><author><keyname>Choi</keyname><forenames>Hyomin</forenames></author><author><keyname>Subramaniam</keyname><forenames>Sharmila</forenames></author><author><keyname>Xiao</keyname><forenames>Li</forenames></author></authors><title>A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals</title><categories>stat.ML cs.IR cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Web refresh crawling is the problem of keeping a cache of web pages fresh, that is, having the most recent copy available when a page is requested, given a limited bandwidth available to the crawler. Under the assumption that the change and request events, resp., to each web page follow independent Poisson processes, the optimal scheduling policy was derived by Azar et al. 2018. In this paper, we study an extension of this problem where side information indicating content changes, such as various types of web pings, for example, signals from sitemaps, content delivery networks, etc., is available. Incorporating such side information into the crawling policy is challenging, because (i) the signals can be noisy with false positive events and with missing change events; and (ii) the crawler should achieve a fair performance over web pages regardless of the quality of the side information, which might differ from web page to web page. We propose a scalable crawling algorithm which (i) uses the noisy side information in an optimal way under mild assumptions; (ii) can be deployed without heavy centralized computation; (iii) is able to crawl web pages at a constant total rate without spikes in the total bandwidth usage over any time interval, and automatically adapt to the new optimal solution when the total bandwidth changes without centralized computation. Experiments clearly demonstrate the versatility of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02450</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02450</id><created>2025-02-04</created><authors><author><keyname>Laplante</keyname><forenames>William</forenames></author><author><keyname>Altamirano</keyname><forenames>Matias</forenames></author><author><keyname>Duncan</keyname><forenames>Andrew</forenames></author><author><keyname>Knoblauch</keyname><forenames>Jeremias</forenames></author><author><keyname>Briol</keyname><forenames>François-Xavier</forenames></author></authors><title>Robust and Conjugate Spatio-Temporal Gaussian Processes</title><categories>stat.CO stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  State-space formulations allow for Gaussian process (GP) regression with linear-in-time computational cost in spatio-temporal settings, but performance typically suffers in the presence of outliers. In this paper, we adapt and specialise the robust and conjugate GP (RCGP) framework of Altamirano et al. (2024) to the spatio-temporal setting. In doing so, we obtain an outlier-robust spatio-temporal GP with a computational cost comparable to classical spatio-temporal GPs. We also overcome the three main drawbacks of RCGPs: their unreliable performance when the prior mean is chosen poorly, their lack of reliable uncertainty quantification, and the need to carefully select a hyperparameter by hand. We study our method extensively in finance and weather forecasting applications, demonstrating that it provides a reliable approach to spatio-temporal modelling in the presence of outliers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02463</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02463</id><created>2025-02-04</created><authors><author><keyname>Whittle</keyname><forenames>George</forenames></author><author><keyname>Ziomek</keyname><forenames>Juliusz</forenames></author><author><keyname>Rawling</keyname><forenames>Jacob</forenames></author><author><keyname>Osborne</keyname><forenames>Michael A</forenames></author></authors><title>Distribution Transformers: Fast Approximate Bayesian Inference With   On-The-Fly Prior Adaptation</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  While Bayesian inference provides a principled framework for reasoning under uncertainty, its widespread adoption is limited by the intractability of exact posterior computation, necessitating the use of approximate inference. However, existing methods are often computationally expensive, or demand costly retraining when priors change, limiting their utility, particularly in sequential inference problems such as real-time sensor fusion. To address these challenges, we introduce the Distribution Transformer -- a novel architecture that can learn arbitrary distribution-to-distribution mappings. Our method can be trained to map a prior to the corresponding posterior, conditioned on some dataset -- thus performing approximate Bayesian inference. Our novel architecture represents a prior distribution as a (universally-approximating) Gaussian Mixture Model (GMM), and transforms it into a GMM representation of the posterior. The components of the GMM attend to each other via self-attention, and to the datapoints via cross-attention. We demonstrate that Distribution Transformers both maintain flexibility to vary the prior, and significantly reduces computation times-from minutes to milliseconds-while achieving log-likelihood performance on par with or superior to existing approximate inference methods across tasks such as sequential inference, quantum system parameter inference, and Gaussian Process predictive posterior inference with hyperpriors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02472</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02472</id><created>2025-02-04</created><authors><author><keyname>Bartosh</keyname><forenames>Grigory</forenames></author><author><keyname>Vetrov</keyname><forenames>Dmitry</forenames></author><author><keyname>Naesseth</keyname><forenames>Christian A.</forenames></author></authors><title>SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic   Differential Equations</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Latent Stochastic Differential Equation (SDE) is a powerful tool for time series and sequence modeling. However, training Latent SDEs typically relies on adjoint sensitivity methods, which depend on simulation and backpropagation through approximate SDE solutions, which limit scalability. In this work, we propose SDE Matching, a new simulation-free method for training Latent SDEs. Inspired by modern Score- and Flow Matching algorithms for learning generative dynamics, we extend these ideas to the domain of stochastic dynamics for time series and sequence modeling, eliminating the need for costly numerical simulations. Our results demonstrate that SDE Matching achieves performance comparable to adjoint sensitivity methods while drastically reducing computational complexity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02483</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02483</id><created>2025-02-04</created><authors><author><keyname>De Bortoli</keyname><forenames>Valentin</forenames></author><author><keyname>Galashov</keyname><forenames>Alexandre</forenames></author><author><keyname>Guntupalli</keyname><forenames>J. Swaroop</forenames></author><author><keyname>Zhou</keyname><forenames>Guangyao</forenames></author><author><keyname>Murphy</keyname><forenames>Kevin</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Doucet</keyname><forenames>Arnaud</forenames></author></authors><title>Distributional Diffusion Models with Scoring Rules</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion models generate high-quality synthetic data. They operate by defining a continuous-time forward process which gradually adds Gaussian noise to data until fully corrupted. The corresponding reverse process progressively "denoises" a Gaussian sample into a sample from the data distribution. However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process. This is expensive and has motivated the development of many acceleration methods. We propose to accomplish sample generation by learning the posterior {\em distribution} of clean data samples given their noisy versions, instead of only the mean of this distribution. This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output. This is accomplished by replacing the standard regression loss used to estimate conditional means with a scoring rule. We validate our method on image and robot trajectory generation, where we consistently outperform standard diffusion models at few discretization steps. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02486</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02486</id><created>2025-02-04</created><authors><author><keyname>Ye</keyname><forenames>Chenlu</forenames></author><author><keyname>Jin</keyname><forenames>Yujia</forenames></author><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Catoni Contextual Bandits are Robust to Heavy-tailed Rewards</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Typical contextual bandit algorithms assume that the rewards at each round lie in some fixed range $[0, R]$, and their regret scales polynomially with this reward range $R$. However, many practical scenarios naturally involve heavy-tailed rewards or rewards where the worst-case range can be substantially larger than the variance. In this paper, we develop an algorithmic approach building on Catoni's estimator from robust statistics, and apply it to contextual bandits with general function approximation. When the variance of the reward at each round is known, we use a variance-weighted regression approach and establish a regret bound that depends only on the cumulative reward variance and logarithmically on the reward range $R$ as well as the number of rounds $T$. For the unknown-variance case, we further propose a careful peeling-based algorithm and remove the need for cumbersome variance estimation. With additional dependence on the fourth moment, our algorithm also enjoys a variance-based bound with logarithmic reward-range dependence. Moreover, we demonstrate the optimality of the leading-order term in our regret bound through a matching lower bound. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02496</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02496</id><created>2025-02-04</created><authors><author><keyname>Kolb</keyname><forenames>Chris</forenames></author><author><keyname>Weber</keyname><forenames>Tobias</forenames></author><author><keyname>Bischl</keyname><forenames>Bernd</forenames></author><author><keyname>Rügamer</keyname><forenames>David</forenames></author></authors><title>Deep Weight Factorization: Sparse Learning Through the Lens of   Artificial Symmetries</title><categories>cs.LG stat.ML</categories><comments>accepted at ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse regularization techniques are well-established in machine learning, yet their application in neural networks remains challenging due to the non-differentiability of penalties like the $L_1$ norm, which is incompatible with stochastic gradient descent. A promising alternative is shallow weight factorization, where weights are decomposed into two factors, allowing for smooth optimization of $L_1$-penalized neural networks by adding differentiable $L_2$ regularization to the factors. In this work, we introduce deep weight factorization, extending previous shallow approaches to more than two factors. We theoretically establish equivalence of our deep factorization with non-convex sparse regularization and analyze its impact on training dynamics and optimization. Due to the limitations posed by standard training practices, we propose a tailored initialization scheme and identify important learning rate requirements necessary for training factorized networks. We demonstrate the effectiveness of our deep weight factorization through experiments on various architectures and datasets, consistently outperforming its shallow counterpart and widely used pruning methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02516</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02516</id><created>2025-02-04</created><authors><author><keyname>Russo</keyname><forenames>Alessio</forenames></author><author><keyname>Pacchiano</keyname><forenames>Aldo</forenames></author></authors><title>Adaptive Exploration for Multi-Reward Multi-Policy Evaluation</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the policy evaluation problem in an online multi-reward multi-policy discounted setting, where multiple reward functions must be evaluated simultaneously for different policies. We adopt an $(\epsilon,\delta)$-PAC perspective to achieve $\epsilon$-accurate estimates with high confidence across finite or convex sets of rewards, a setting that has not been investigated in the literature. Building on prior work on Multi-Reward Best Policy Identification, we adapt the MR-NaS exploration scheme to jointly minimize sample complexity for evaluating different policies across different reward sets. Our approach leverages an instance-specific lower bound revealing how the sample complexity scales with a measure of value deviation, guiding the design of an efficient exploration policy. Although computing this bound entails a hard non-convex optimization, we propose an efficient convex approximation that holds for both finite and convex reward sets. Experiments in tabular domains demonstrate the effectiveness of this adaptive exploration scheme. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02529</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02529</id><created>2025-02-04</created><authors><author><keyname>Hult</keyname><forenames>Henrik</forenames></author><author><keyname>Lindhe</keyname><forenames>Adam</forenames></author><author><keyname>Nyquist</keyname><forenames>Pierre</forenames></author><author><keyname>Wu</keyname><forenames>Guo-Jhen</forenames></author></authors><title>A weak convergence approach to large deviations for stochastic   approximations</title><categories>math.PR math.OC stat.ML</categories><comments>60 p</comments><msc-class>60F10, 62L20, 60J20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of stochastic approximations form the theoretical foundation for studying convergence properties of many popular recursive learning algorithms in statistics, machine learning and statistical physics. Large deviations for stochastic approximations provide asymptotic estimates of the probability that the learning algorithm deviates from its expected path, given by a limit ODE, and the large deviation rate function gives insights to the most likely way that such deviations occur.   In this paper we prove a large deviation principle for general stochastic approximations with state-dependent Markovian noise and decreasing step size. Using the weak convergence approach to large deviations, we generalize previous results for stochastic approximations and identify the appropriate scaling sequence for the large deviation principle. We also give a new representation for the rate function, in which the rate function is expressed as an action functional involving the family of Markov transition kernels. Examples of learning algorithms that are covered by the large deviation principle include stochastic gradient descent, persistent contrastive divergence and the Wang-Landau algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02531</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02531</id><created>2025-02-04</created><updated>2025-02-05</updated><authors><author><keyname>Bordelon</keyname><forenames>Blake</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Deep Linear Network Training Dynamics from Random Initialization: Data,   Width, Depth, and Hyperparameter Transfer</title><categories>cs.LG cond-mat.dis-nn stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data. Our theory captures the ``wider is better" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width. We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\sqrt{\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration. Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02552</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02552</id><created>2025-02-04</created><authors><author><keyname>Zhu</keyname><forenames>Haonan</forenames></author><author><keyname>Goncalves</keyname><forenames>Andre R.</forenames></author><author><keyname>Valdes</keyname><forenames>Camilo</forenames></author><author><keyname>Ranganathan</keyname><forenames>Hiranmayi</forenames></author><author><keyname>Zhang</keyname><forenames>Boya</forenames></author><author><keyname>Martí</keyname><forenames>Jose Manuel</forenames></author><author><keyname>Kok</keyname><forenames>Car Reen</forenames></author><author><keyname>Borucki</keyname><forenames>Monica K.</forenames></author><author><keyname>Mulakken</keyname><forenames>Nisha J.</forenames></author><author><keyname>Thissen</keyname><forenames>James B.</forenames></author><author><keyname>Jaing</keyname><forenames>Crystal</forenames></author><author><keyname>Hero</keyname><forenames>Alfred</forenames></author><author><keyname>Be</keyname><forenames>Nicholas A.</forenames></author></authors><title>Hierarchical Sparse Bayesian Multitask Model with Scalable Inference for   Microbiome Analysis</title><categories>cs.LG q-bio.BM stat.AP stat.CO stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a hierarchical Bayesian multitask learning model that is applicable to the general multi-task binary classification learning problem where the model assumes a shared sparsity structure across different tasks. We derive a computationally efficient inference algorithm based on variational inference to approximate the posterior distribution. We demonstrate the potential of the new approach on various synthetic datasets and for predicting human health status based on microbiome profile. Our analysis incorporates data pooled from multiple microbiome studies, along with a comprehensive comparison with other benchmark methods. Results in synthetic datasets show that the proposed approach has superior support recovery property when the underlying regression coefficients share a common sparsity structure across different tasks. Our experiments on microbiome classification demonstrate the utility of the method in extracting informative taxa while providing well-calibrated predictions with uncertainty quantification and achieving competitive performance in terms of prediction metrics. Notably, despite the heterogeneity of the pooled datasets (e.g., different experimental objectives, laboratory setups, sequencing equipment, patient demographics), our method delivers robust results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02561</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02561</id><created>2025-02-04</created><authors><author><keyname>Kiyani</keyname><forenames>Shayan</forenames></author><author><keyname>Pappas</keyname><forenames>George</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Hassani</keyname><forenames>Hamed</forenames></author></authors><title>Decision Theoretic Foundations for Conformal Prediction: Optimal   Uncertainty Quantification for Risk-Averse Agents</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions in ways that can usefully inform downstream action. This interface between prediction uncertainty and decision-making is especially important in risk-sensitive domains, such as medicine. In this paper, we develop decision-theoretic foundations that connect uncertainty quantification using prediction sets with risk-averse decision-making. Specifically, we answer three fundamental questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. Answering these questions naturally leads to an algorithm, Risk-Averse Calibration (RAC), which follows a provably optimal design for deriving action policies from predictions. RAC is designed to be both practical-capable of leveraging the quality of predictions in a black-box manner to enhance downstream utility-and safe-adhering to a user-defined risk threshold and optimizing the corresponding risk quantile of the user's downstream utility. Finally, we experimentally demonstrate the significant advantages of RAC in applications such as medical diagnosis and recommendation systems. Specifically, we show that RAC achieves a substantially improved trade-off between safety and utility, offering higher utility compared to existing methods while maintaining the safety guarantee. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02562</identifier><datestamp>2025-02-05</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02562</id><created>2025-02-04</created><authors><author><keyname>Schenck</keyname><forenames>Connor</forenames></author><author><keyname>Reid</keyname><forenames>Isaac</forenames></author><author><keyname>Jacob</keyname><forenames>Mithun George</forenames></author><author><keyname>Bewley</keyname><forenames>Alex</forenames></author><author><keyname>Ainslie</keyname><forenames>Joshua</forenames></author><author><keyname>Rendleman</keyname><forenames>David</forenames></author><author><keyname>Jain</keyname><forenames>Deepali</forenames></author><author><keyname>Sharma</keyname><forenames>Mohit</forenames></author><author><keyname>Dubey</keyname><forenames>Avinava</forenames></author><author><keyname>Wahid</keyname><forenames>Ayzaan</forenames></author><author><keyname>Singh</keyname><forenames>Sumeet</forenames></author><author><keyname>Wagner</keyname><forenames>Rene</forenames></author><author><keyname>Ding</keyname><forenames>Tianli</forenames></author><author><keyname>Fu</keyname><forenames>Chuyuan</forenames></author><author><keyname>Byravan</keyname><forenames>Arunkumar</forenames></author><author><keyname>Varley</keyname><forenames>Jake</forenames></author><author><keyname>Gritsenko</keyname><forenames>Alexey</forenames></author><author><keyname>Minderer</keyname><forenames>Matthias</forenames></author><author><keyname>Kalashnikov</keyname><forenames>Dmitry</forenames></author><author><keyname>Tompson</keyname><forenames>Jonathan</forenames></author><author><keyname>Sindhwani</keyname><forenames>Vikas</forenames></author><author><keyname>Choromanski</keyname><forenames>Krzysztof</forenames></author></authors><title>Learning the RoPEs: Better 2D and 3D Position Encodings with STRING</title><categories>cs.LG cs.AI cs.CV cs.RO stat.ML</categories><comments>Videos of STRING-based robotics controllers can be found here:   https://sites.google.com/view/string-robotics</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce STRING: Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers. We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02580</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02580</id><created>2025-02-04</created><updated>2025-02-04</updated><authors><author><keyname>Huang</keyname><forenames>Chengzhu</forenames></author><author><keyname>Gu</keyname><forenames>Yuqi</forenames></author></authors><title>Minimax-Optimal Dimension-Reduced Clustering for High-Dimensional   Nonspherical Mixtures</title><categories>math.ST stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mixture models, nonspherical (anisotropic) noise within each cluster is widely present in real-world data. We study both the minimax rate and optimal statistical procedure for clustering under high-dimensional nonspherical mixture models. In high-dimensional settings, we first establish the information-theoretic limits for clustering under Gaussian mixtures. The minimax lower bound unveils an intriguing informational dimension-reduction phenomenon: there exists a substantial gap between the minimax rate and the oracle clustering risk, with the former determined solely by the projected centers and projected covariance matrices in a low-dimensional space. Motivated by the lower bound, we propose a novel computationally efficient clustering method: Covariance Projected Spectral Clustering (COPO). Its key step is to project the high-dimensional data onto the low-dimensional space spanned by the cluster centers and then use the projected covariance matrices in this space to enhance clustering. We establish tight algorithmic upper bounds for COPO, both for Gaussian noise with flexible covariance and general noise with local dependence. Our theory indicates the minimax-optimality of COPO in the Gaussian case and highlights its adaptivity to a broad spectrum of dependent noise. Extensive simulation studies under various noise structures and real data analysis demonstrate our method's superior performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02623</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02623</id><created>2025-02-04</created><authors><author><keyname>Matilla</keyname><forenames>German Martinez</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author></authors><title>Sample Complexity of Bias Detection with Subsampled Point-to-Subspace   Distances</title><categories>cs.LG cs.AI math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sample complexity of bias estimation is a lower bound on the runtime of any bias detection method. Many regulatory frameworks require the bias to be tested for all subgroups, whose number grows exponentially with the number of protected attributes. Unless one wishes to run a bias detection with a doubly-exponential run-time, one should like to have polynomial complexity of bias detection for a single subgroup. At the same time, the reference data may be based on surveys, and thus come with non-trivial uncertainty.   Here, we reformulate bias detection as a point-to-subspace problem on the space of measures and show that, for supremum norm, it can be subsampled efficiently. In particular, our probabilistically approximately correct (PAC) results are corroborated by tests on well-known instances. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02671</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02671</id><created>2025-02-04</created><authors><author><keyname>Tiapkin</keyname><forenames>Daniil</forenames></author><author><keyname>Calandriello</keyname><forenames>Daniele</forenames></author><author><keyname>Ferret</keyname><forenames>Johan</forenames></author><author><keyname>Perrin</keyname><forenames>Sarah</forenames></author><author><keyname>Vieillard</keyname><forenames>Nino</forenames></author><author><keyname>Ramé</keyname><forenames>Alexandre</forenames></author><author><keyname>Blondel</keyname><forenames>Mathieu</forenames></author></authors><title>On Teacher Hacking in Language Model Distillation</title><categories>cs.LG cs.AI cs.CL stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Post-training of language models (LMs) increasingly relies on the following two stages: (i) knowledge distillation, where the LM is trained to imitate a larger teacher LM, and (ii) reinforcement learning from human feedback (RLHF), where the LM is aligned by optimizing a reward model. In the second RLHF stage, a well-known challenge is reward hacking, where the LM over-optimizes the reward model. Such phenomenon is in line with Goodhart's law and can lead to degraded performance on the true objective. In this paper, we investigate whether a similar phenomenon, that we call teacher hacking, can occur during knowledge distillation. This could arise because the teacher LM is itself an imperfect approximation of the true distribution. To study this, we propose a controlled experimental setup involving: (i) an oracle LM representing the ground-truth distribution, (ii) a teacher LM distilled from the oracle, and (iii) a student LM distilled from the teacher. Our experiments reveal the following insights. When using a fixed offline dataset for distillation, teacher hacking occurs; moreover, we can detect it by observing when the optimization process deviates from polynomial convergence laws. In contrast, employing online data generation techniques effectively mitigates teacher hacking. More precisely, we identify data diversity as the key factor in preventing hacking. Overall, our findings provide a deeper understanding of the benefits and limitations of distillation for building robust and efficient LMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02674</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02674</id><created>2025-02-04</created><authors><author><keyname>Stanley</keyname><forenames>Michael</forenames></author><author><keyname>Batlle</keyname><forenames>Pau</forenames></author><author><keyname>Patil</keyname><forenames>Pratik</forenames></author><author><keyname>Owhadi</keyname><forenames>Houman</forenames></author><author><keyname>Kuusela</keyname><forenames>Mikael</forenames></author></authors><title>Confidence intervals for functionals in constrained inverse problems via   data-adaptive sampling-based calibration</title><categories>stat.ME stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address functional uncertainty quantification for ill-posed inverse problems where it is possible to evaluate a possibly rank-deficient forward model, the observation noise distribution is known, and there are known parameter constraints. We present four constraint-aware confidence intervals extending the work of Batlle et al. (2023) by making the intervals both computationally feasible and less conservative. Our approach first shrinks the potentially unbounded constraint set compact in a data-adaptive way, obtains samples of the relevant test statistic inside this set to estimate a quantile function, and then uses these computed quantities to produce the intervals. Our data-adaptive bounding approach is based on the approach by Berger and Boos (1994), and involves defining a subset of the constraint set where the true parameter exists with high probability. This probabilistic guarantee is then incorporated into the final coverage guarantee in the form of an uncertainty budget. We then propose custom sampling algorithms to efficiently sample from this subset, even when the parameter space is high-dimensional. Optimization-based interval methods formulate confidence interval computation as two endpoint optimizations, where the optimization constraints can be set to achieve different types of interval calibration while seamlessly incorporating parameter constraints. However, choosing valid optimization constraints has been elusive. We show that all four proposed intervals achieve nominal coverage for a particular functional both theoretically and in practice, with numerical examples demonstrating superior performance of our intervals over the OSB interval in terms of both coverage and expected length. In particular, we show the superior performance in a realistic unfolding simulation from high-energy physics that is severely ill-posed and involves a rank-deficient forward model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02679</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02679</id><created>2025-02-04</created><authors><author><keyname>Kurkova</keyname><forenames>Vera</forenames></author><author><keyname>Sanguineti</keyname><forenames>Marcello</forenames></author></authors><title>Networks with Finite VC Dimension: Pro and Contra</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Approximation and learning of classifiers of large data sets by neural networks in terms of high-dimensional geometry and statistical learning theory are investigated. The influence of the VC dimension of sets of input-output functions of networks on approximation capabilities is compared with its influence on consistency in learning from samples of data. It is shown that, whereas finite VC dimension is desirable for uniform convergence of empirical errors, it may not be desirable for approximation of functions drawn from a probability distribution modeling the likelihood that they occur in a given type of application. Based on the concentration-of-measure properties of high dimensional geometry, it is proven that both errors in approximation and empirical errors behave almost deterministically for networks implementing sets of input-output functions with finite VC dimensions in processing large data sets. Practical limitations of the universal approximation property, the trade-offs between the accuracy of approximation and consistency in learning from data, and the influence of depth of networks with ReLU units on their accuracy and consistency are discussed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02701</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02701</id><created>2025-02-04</created><authors><author><keyname>Noda</keyname><forenames>Atsushi</forenames></author><author><keyname>Isozaki</keyname><forenames>Takashi</forenames></author></authors><title>Practically Effective Adjustment Variable Selection in Causal Inference</title><categories>cs.LG cs.AI physics.data-an stat.ME</categories><comments>20 pages, 8 figures</comments><journal-ref>Journal of Physics: Complexity 6, 015001 (2025)</journal-ref><doi>10.1088/2632-072X/ada861</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the estimation of causal effects, one common method for removing the influence of confounders is to adjust the variables that satisfy the back-door criterion. However, it is not always possible to uniquely determine sets of such variables. Moreover, real-world data is almost always limited, which means it may be insufficient for statistical estimation. Therefore, we propose criteria for selecting variables from a list of candidate adjustment variables along with an algorithm to prevent accuracy degradation in causal effect estimation. We initially focus on directed acyclic graphs (DAGs) and then outlines specific steps for applying this method to completed partially directed acyclic graphs (CPDAGs). We also present and prove a theorem on causal effect computation possibility in CPDAGs. Finally, we demonstrate the practical utility of our method using both existing and artificial data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02710</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02710</id><created>2025-02-04</created><authors><author><keyname>Kostin</keyname><forenames>Julia</forenames></author><author><keyname>Gnecco</keyname><forenames>Nicola</forenames></author><author><keyname>Yang</keyname><forenames>Fanny</forenames></author></authors><title>Achievable distributional robustness when the robust risk is only   partially identified</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In safety-critical applications, machine learning models should generalize well under worst-case distribution shifts, that is, have a small robust risk. Invariance-based algorithms can provably take advantage of structural assumptions on the shifts when the training distributions are heterogeneous enough to identify the robust risk. However, in practice, such identifiability conditions are rarely satisfied -- a scenario so far underexplored in the theoretical literature. In this paper, we aim to fill the gap and propose to study the more general setting when the robust risk is only partially identifiable. In particular, we introduce the worst-case robust risk as a new measure of robustness that is always well-defined regardless of identifiability. Its minimum corresponds to an algorithm-independent (population) minimax quantity that measures the best achievable robustness under partial identifiability. While these concepts can be defined more broadly, in this paper we introduce and derive them explicitly for a linear model for concreteness of the presentation. First, we show that existing robustness methods are provably suboptimal in the partially identifiable case. We then evaluate these methods and the minimizer of the (empirical) worst-case robust risk on real-world gene expression data and find a similar trend: the test error of existing robustness methods grows increasingly suboptimal as the fraction of data from unseen environments increases, whereas accounting for partial identifiability allows for better generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02726</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02726</id><created>2025-02-04</created><authors><author><keyname>Li</keyname><forenames>Pengtao</forenames></author><author><keyname>Chen</keyname><forenames>Xiaohui</forenames></author></authors><title>Multimarginal Schr\"{o}dinger Barycenter</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Wasserstein barycenter plays a fundamental role in averaging measure-valued data under the framework of optimal transport. However, there are tremendous challenges in computing and estimating the Wasserstein barycenter for high-dimensional distributions. In this paper, we introduce the multimarginal Schr\"{o}dinger barycenter (MSB) based on the entropy regularized multimarginal optimal transport problem that admits general-purpose fast algorithms for computation. By recognizing a proper dual geometry, we derive non-asymptotic rates of convergence for estimating several key MSB quantities from point clouds randomly sampled from the input marginal distributions. Specifically, we show that our obtained sample complexity is statistically optimal for estimating the cost functional, Schr\"{o}dinger coupling and barycenter. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02736</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02736</id><created>2025-02-04</created><authors><author><keyname>Dong</keyname><forenames>Larry</forenames></author><author><keyname>Pullenayegum</keyname><forenames>Eleanor</forenames></author><author><keyname>Thiébaut</keyname><forenames>Rodolphe</forenames></author><author><keyname>Saarela</keyname><forenames>Olli</forenames></author></authors><title>Estimating Optimal Dynamic Treatment Regimes Using Irregularly Observed   Data: A Target Trial Emulation and Bayesian Joint Modeling Approach</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimal dynamic treatment regime (DTR) is a sequence of decision rules aimed at providing the best course of treatments individualized to patients. While conventional DTR estimation uses longitudinal data, such data can also be irregular, where patient-level variables can affect visit times, treatment assignments and outcomes. In this work, we first extend the target trial framework - a paradigm to estimate statistical estimands specified under hypothetical randomized trials using observational data - to the DTR context; this extension allows treatment regimes to be defined with intervenable visit times. We propose an adapted version of G-computation marginalizing over random effects for rewards that encapsulate a treatment strategy's value. To estimate components of the G-computation formula, we then articulate a Bayesian joint model to handle correlated random effects between the outcome, visit and treatment processes. We show via simulation studies that, in the estimation of regime rewards, failure to account for the observational treatment and visit processes produces bias which can be removed through joint modeling. We also apply our proposed method on data from INSPIRE 2 and 3 studies to estimate optimal injection cycles of Interleukin 7 to treat HIV-infected individuals. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02771</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02771</id><created>2025-02-04</created><authors><author><keyname>Cheung</keyname><forenames>Matt Y.</forenames></author><author><keyname>Zorek</keyname><forenames>Sophia</forenames></author><author><keyname>Netherton</keyname><forenames>Tucker J.</forenames></author><author><keyname>Court</keyname><forenames>Laurence E.</forenames></author><author><keyname>Al-Kindi</keyname><forenames>Sadeer</forenames></author><author><keyname>Veeraraghavan</keyname><forenames>Ashok</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Guha</forenames></author></authors><title>When are Diffusion Priors Helpful in Sparse Reconstruction? A Study with   Sparse-view CT</title><categories>physics.med-ph cs.CV cs.LG eess.IV stat.AP</categories><comments>Accepted at IEEE ISBI 2025, 5 pages, 2 figures, 1 table</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion models demonstrate state-of-the-art performance on image generation, and are gaining traction for sparse medical image reconstruction tasks. However, compared to classical reconstruction algorithms relying on simple analytical priors, diffusion models have the dangerous property of producing realistic looking results \emph{even when incorrect}, particularly with few observations. We investigate the utility of diffusion models as priors for image reconstruction by varying the number of observations and comparing their performance to classical priors (sparse and Tikhonov regularization) using pixel-based, structural, and downstream metrics. We make comparisons on low-dose chest wall computed tomography (CT) for fat mass quantification. First, we find that classical priors are superior to diffusion priors when the number of projections is ``sufficient''. Second, we find that diffusion priors can capture a large amount of detail with very few observations, significantly outperforming classical priors. However, they fall short of capturing all details, even with many observations. Finally, we find that the performance of diffusion priors plateau after extremely few ($\approx$10-15) projections. Ultimately, our work highlights potential issues with diffusion-based sparse reconstruction and underscores the importance of further investigation, particularly in high-stakes clinical settings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02781</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02781</id><created>2025-02-04</created><authors><author><keyname>Forzani</keyname><forenames>Liliana</forenames></author><author><keyname>Arancibia</keyname><forenames>Rodrigo García</forenames></author><author><keyname>Gieco</keyname><forenames>Antonella</forenames></author><author><keyname>Llop</keyname><forenames>Pamela</forenames></author><author><keyname>Yao</keyname><forenames>Anne</forenames></author></authors><title>Sufficient dimension reduction for regression with spatially correlated   errors: application to prediction</title><categories>stat.ME math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this paper, we address the problem of predicting a response variable in the context of both, spatially correlated and high-dimensional data. To reduce the dimensionality of the predictor variables, we apply the sufficient dimension reduction (SDR) paradigm, which reduces the predictor space while retaining relevant information about the response. To achieve this, we impose two different spatial models on the inverse regression: the separable spatial covariance model (SSCM) and the spatial autoregressive error model (SEM). For these models, we derive maximum likelihood estimators for the reduction and use them to predict the response via nonparametric rules for forward regression. Through simulations and real data applications, we demonstrate the effectiveness of our approach for spatial data prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02793</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02793</id><created>2025-02-04</created><authors><author><keyname>Cui</keyname><forenames>Zihan</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Early Stopping in Contextual Bandits and Inferences</title><categories>math.ST math.OC math.PR stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandit algorithms sequentially accumulate data using adaptive sampling policies, offering flexibility for real-world applications. However, excessive sampling can be costly, motivating the devolopment of early stopping methods and reliable post-experiment conditional inferences. This paper studies early stopping methods in linear contextual bandits, including both pre-determined and online stopping rules, to minimize in-experiment regrets while accounting for sampling costs. We propose stopping rules based on the Opportunity Cost and Threshold Method, utilizing the variances of unbiased or consistent online estimators to quantify the upper regret bounds of learned optimal policy. The study focuses on batched settings for stability, selecting a weighed combination of batched estimators as the online estimator and deriving its asymptotic distribution. Online statistical inferences are performed based on the selected estimator, conditional on the realized stopping time. Our proposed method provides a systematic approach to minimize in-experiment regret and conduct robust post-experiment inferences, facilitating decision-making in future applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02797</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02797</id><created>2025-02-04</created><authors><author><keyname>Sanyal</keyname><forenames>Sunny</forenames></author><author><keyname>Prairie</keyname><forenames>Hayden</forenames></author><author><keyname>Das</keyname><forenames>Rudrajit</forenames></author><author><keyname>Kavis</keyname><forenames>Ali</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting</title><categories>cs.LG cs.AI stat.ML</categories><comments>49 pages, 4 figures, 12 tables. Code available at   https://github.com/sanyalsunny111/FLOW_finetuning</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as "catastrophic forgetting". This is especially an issue when one does not have access to the data and recipe used to develop the pre-trained model. Under this constraint, most existing methods for mitigating forgetting are inapplicable. To address this challenge, we propose a sample weighting scheme for the fine-tuning data solely based on the pre-trained model's losses. Specifically, we upweight the easy samples on which the pre-trained model's loss is low and vice versa to limit the drift from the pre-trained model. Our approach is orthogonal and yet complementary to existing methods; while such methods mostly operate on parameter or gradient space, we concentrate on the sample space. We theoretically analyze the impact of fine-tuning with our method in a linear setting, showing that it stalls learning in a certain subspace which inhibits overfitting to the target task. We empirically demonstrate the efficacy of our method on both language and vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our method results in only a $0.8\%$ drop in accuracy on GSM8K (another math dataset) compared to standard fine-tuning, while preserving $5.4\%$ more accuracy on the pre-training datasets. Our code is publicly available at https://github.com/sanyalsunny111/FLOW_finetuning . </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02812</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02812</id><created>2025-02-04</created><authors><author><keyname>Propp</keyname><forenames>Adrienne M.</forenames></author><author><keyname>Vardavas</keyname><forenames>Raffaele</forenames></author><author><keyname>Price</keyname><forenames>Carter C.</forenames></author><author><keyname>Kapinos</keyname><forenames>Kandice A.</forenames></author></authors><title>LHIEM: the Longitudinal Health, Income, and Employment Model</title><categories>stat.AP</categories><comments>To appear in Journal of Artificial Societies and Social Simulation,   2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic microsimulation has long been recognized as a powerful tool for policy analysis, but in fact most major health policy simulations lack path dependency, a critical feature for evaluating policies that depend on accumulated outcomes such as retirement savings, wealth, or debt. We propose LHIEM (the Longitudinal Health, Income and Employment Model), a path-dependent discrete-time microsimulation that predicts annual health care expenditures, family income, and health status for the U.S. population over a multi-year period. LHIEM advances the population from year to year as a Markov chain with modules capturing the particular dynamics of each predictive attribute. LHIEM was designed to assess a health care financing proposal that would allow individuals to borrow from the U.S. government to cover health care costs, requiring careful tracking of medical expenditures and medical debt over time. However, LHIEM is flexible enough to be used for a range of modeling needs related to predicting health care spending and income over time. In this paper, we present the details of the model and all dynamic modules, and include a case study to demonstrate how LHIEM can be used to evaluate proposed policy changes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02846</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02846</id><created>2025-02-04</created><authors><author><keyname>Sun</keyname><forenames>Siqi</forenames></author><author><keyname>Schmidt</keyname><forenames>Karen M.</forenames></author><author><keyname>Henry</keyname><forenames>Teague R.</forenames></author></authors><title>Don't Let Your Likert Scales Grow Up To Be Visual Analog Scales:   Understanding the Relationship Between Number of Response Categories and   Measurement Error</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of Visual Analog Scales (VAS), which can be broadly conceptualized as items where the response scale is 0-100, has surged recently due to the convenience of digital assessments. However, there is no consensus as to whether the use of VAS scales is optimal in a measurement sense. Put differently, in the 90+ years since Likert introduced his eponymous scale, the field does not know how to determine the optimal number of response options for a given item. In the current work, we investigate the optimal number of response categories using a series of simulations. We find that when the measurement error of an item is not dependent on the number of response categories, there is no true optimum; rather, reliability increases with number of response options and then plateaus. However, under the more realistic assumption that the measurement error of an item increases with the number of response categories, we find a clear optimum that depends on the rate of that increase. If measurement error increases with the number of response categories, then conversion of any Likert scale item to VAS will result in a drastic decrease in reliability. Finally, if researchers do want to change the response scale of a validated measure, they must re-validate the new measure as the measurement error of the scale is likely to change. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02848</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02848</id><created>2025-02-04</created><authors><author><keyname>Zhou</keyname><forenames>Shuheng</forenames></author><author><keyname>Park</keyname><forenames>Seyoung</forenames></author><author><keyname>Shedden</keyname><forenames>Kerby</forenames></author></authors><title>Kronecker sum covariance models for spatio-temporal data</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we study the subgaussian matrix variate model, where we observe the matrix variate data $X$ which consists of a signal matrix $X_0$ and a noise matrix $W$. More specifically, we study a subgaussian model using the Kronecker sum covariance as in Rudelson and Zhou (2017). Let $Z_1, Z_2$ be independent copies of a subgaussian random matrix $Z =(Z_{ij})$, where $Z_{ij}, \forall i, j$ are independent mean 0, unit variance, subgaussian random variables with bounded $\psi_2$ norm. We use $X \sim \mathcal{M}_{n,m}(0, A \oplus B)$ to denote the subgaussian random matrix $X_{n \times m}$ which is generated using: $$ X = Z_1 A^{1/2} + B^{1/2} Z_2. $$ In this covariance model, the first component $A \otimes I_n$ describes the covariance of the signal $X_0 = Z_1 A^{1/2}$, which is an ${n \times m}$ random design matrix with independent subgaussian row vectors, and the other component $I_m \otimes B$ describes the covariance for the noise matrix $W =B^{1/2} Z_2$, which contains independent subgaussian column vectors $w^1, \ldots, w^m$, independent of $X_0$. This leads to a non-separable class of models for the observation $X$, which we denote by $X \sim \mathcal{M}_{n,m}(0, A \oplus B)$ throughout this paper. Our method on inverse covariance estimation corresponds to the proposal in Yuan (2010) and Loh and Wainwright (2012), only now dropping the i.i.d. or Gaussian assumptions. We present the statistical rates of convergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02859</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02859</id><created>2025-02-04</created><authors><author><keyname>Zhang</keyname><forenames>Haochen</forenames></author><author><keyname>Zheng</keyname><forenames>Zhong</forenames></author><author><keyname>Xue</keyname><forenames>Lingzhou</forenames></author></authors><title>Gap-Dependent Bounds for Federated $Q$-learning</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present the first gap-dependent analysis of regret and communication cost for on-policy federated $Q$-Learning in tabular episodic finite-horizon Markov decision processes (MDPs). Existing FRL methods focus on worst-case scenarios, leading to $\sqrt{T}$-type regret bounds and communication cost bounds with a $\log T$ term scaling with the number of agents $M$, states $S$, and actions $A$, where $T$ is the average total number of steps per agent. In contrast, our novel framework leverages the benign structures of MDPs, such as a strictly positive suboptimality gap, to achieve a $\log T$-type regret bound and a refined communication cost bound that disentangles exploration and exploitation. Our gap-dependent regret bound reveals a distinct multi-agent speedup pattern, and our gap-dependent communication cost bound removes the dependence on $MSA$ from the $\log T$ term. Notably, our gap-dependent communication cost bound also yields a better global switching cost when $M=1$, removing $SA$ from the $\log T$ term. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02861</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02861</id><created>2025-02-04</created><authors><author><keyname>Shen</keyname><forenames>Judy</forenames></author><author><keyname>Vitercik</keyname><forenames>Ellen</forenames></author><author><keyname>Wikum</keyname><forenames>Anders</forenames></author></authors><title>Algorithms with Calibrated Machine Learning Predictions</title><categories>stat.ML cs.DS cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The field of algorithms with predictions incorporates machine learning advice in the design of online algorithms to improve real-world performance. While this theoretical framework often assumes uniform reliability across all predictions, modern machine learning models can now provide instance-level uncertainty estimates. In this paper, we propose calibration as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the ski rental and online job scheduling problems. For ski rental, we design an algorithm that achieves optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02870</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02870</id><created>2025-02-04</created><authors><author><keyname>Wilson</keyname><forenames>Joseph</forenames></author><author><keyname>van der Heide</keyname><forenames>Chris</forenames></author><author><keyname>Hodgkinson</keyname><forenames>Liam</forenames></author><author><keyname>Roosta</keyname><forenames>Fred</forenames></author></authors><title>Uncertainty Quantification with the Empirical Neural Tangent Kernel</title><categories>stat.ML cs.LG</categories><comments>24 pages, 5 figures, 9 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While neural networks have demonstrated impressive performance across various tasks, accurately quantifying uncertainty in their predictions is essential to ensure their trustworthiness and enable widespread adoption in critical systems. Several Bayesian uncertainty quantification (UQ) methods exist that are either cheap or reliable, but not both. We propose a post-hoc, sampling-based UQ method for over-parameterized networks at the end of training. Our approach constructs efficient and meaningful deep ensembles by employing a (stochastic) gradient-descent sampling process on appropriately linearized networks. We demonstrate that our method effectively approximates the posterior of a Gaussian process using the empirical Neural Tangent Kernel. Through a series of numerical experiments, we show that our method not only outperforms competing approaches in computational efficiency (often reducing costs by multiple factors) but also maintains state-of-the-art performance across a variety of UQ metrics for both regression and classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02887</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02887</id><created>2025-02-04</created><authors><author><keyname>Perlaza</keyname><forenames>Samir M.</forenames></author><author><keyname>Bisson</keyname><forenames>Gaetan</forenames></author></authors><title>Variations on the Expectation Due to Changes in the Probability Measure</title><categories>cs.IT cs.LG math.IT math.PR math.ST stat.TH</categories><comments>Submitted to the IEEE International Symposium on Information Theory   (ISIT2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Closed-form expressions are presented for the variation of the expectation of a given function due to changes in the probability measure used for the expectation. They unveil interesting connections with Gibbs probability measures, the mutual information, and the lautum information. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02892</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02892</id><created>2025-02-05</created><authors><author><keyname>Nguyen</keyname><forenames>Cattram D</forenames></author><author><keyname>Lee</keyname><forenames>Katherine J</forenames></author><author><keyname>White</keyname><forenames>Ian R</forenames></author><author><keyname>van Buuren</keyname><forenames>Stef</forenames></author><author><keyname>Moreno-Betancur</keyname><forenames>Margarita</forenames></author></authors><title>Sensitivity analysis for multivariable missing data using multiple   imputation: a tutorial</title><categories>stat.ME</categories><comments>24 pages, 3 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multiple imputation is a popular method for handling missing data, with fully conditional specification (FCS) being one of the predominant imputation approaches for multivariable missingness. Unbiased estimation with standard implementations of multiple imputation depends on assumptions concerning the missingness mechanism (e.g. that data are "missing at random"). The plausibility of these assumptions can only be assessed using subject-matter knowledge, and not data alone. It is therefore important to perform sensitivity analyses to explore the robustness of results to violations of these assumptions (e.g. if the data are in fact "missing not at random"). In this tutorial, we provide a roadmap for conducting sensitivity analysis using the Not at Random Fully Conditional Specification (NARFCS) procedure for multivariate imputation. Using a case study from the Longitudinal Study of Australian Children, we work through the steps involved, from assessing the need to perform the sensitivity analysis, and specifying the NARFCS models and sensitivity parameters, through to implementing NARFCS using FCS procedures in R and Stata. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02914</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02914</id><created>2025-02-05</created><authors><author><keyname>Kelter</keyname><forenames>Riko</forenames></author><author><keyname>Pawel</keyname><forenames>Samuel</forenames></author></authors><title>Bayesian Power and Sample Size Calculations for Bayes Factors in the   Binomial Setting</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Bayesian design of experiments and sample size calculations usually rely on complex Monte Carlo simulations in practice. Obtaining bounds on Bayesian notions of the false-positive rate and power therefore often lack closed-form or approximate numerical solutions. In this paper, we focus on the sample size calculation in the binomial setting via Bayes factors, the predictive updating factor from prior to posterior odds. We discuss the drawbacks of sample size calculations via Monte Carlo simulations and propose a numerical root-finding approach which allows to determine the necessary sample size to obtain prespecified bounds of Bayesian power and type-I-error rate almost instantaneously. Real-world examples and applications in clinical trials illustrate the advantage of the proposed method. We focus on point-null versus composite and directional hypothesis tests, derive the corresponding Bayes factors, and discuss relevant aspects to consider when pursuing Bayesian design of experiments with the introduced approach. In summary, our approach allows for a Bayes-frequentist compromise by providing a Bayesian analogue to a frequentist power analysis for the Bayes factor in binomial settings. A case study from a Phase II trial illustrates the utility of our approach. The methods are implemented in our R package bfpwr. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02925</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02925</id><created>2025-02-05</created><authors><author><keyname>Hiew</keyname><forenames>Joshua Zoen-Git</forenames></author><author><keyname>Lim</keyname><forenames>Tongseok</forenames></author><author><keyname>Pass</keyname><forenames>Brendan</forenames></author><author><keyname>de Souza</keyname><forenames>Marcelo Cruz</forenames></author></authors><title>Data denoising with self consistency, variance maximization, and the   Kantorovich dominance</title><categories>stat.ME cs.LG math.PR math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a new framework for data denoising, partially inspired by martingale optimal transport. For a given noisy distribution (the data), our approach involves finding the closest distribution to it among all distributions which 1) have a particular prescribed structure (expressed by requiring they lie in a particular domain), and 2) are self-consistent with the data. We show that this amounts to maximizing the variance among measures in the domain which are dominated in convex order by the data. For particular choices of the domain, this problem and a relaxed version of it, in which the self-consistency condition is removed, are intimately related to various classical approaches to denoising. We prove that our general problem has certain desirable features: solutions exist under mild assumptions, have certain robustness properties, and, for very simple domains, coincide with solutions to the relaxed problem.   We also introduce a novel relationship between distributions, termed Kantorovich dominance, which retains certain aspects of the convex order while being a weaker, more robust, and easier-to-verify condition. Building on this, we propose and analyze a new denoising problem by substituting the convex order in the previously described framework with Kantorovich dominance. We demonstrate that this revised problem shares some characteristics with the full convex order problem but offers enhanced stability, greater computational efficiency, and, in specific domains, more meaningful solutions. Finally, we present simple numerical examples illustrating solutions for both the full convex order problem and the Kantorovich dominance problem. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02927</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02927</id><created>2025-02-05</created><authors><author><keyname>Azhad</keyname><forenames>Qazi J.</forenames></author><author><keyname>Khan</keyname><forenames>Abdul Nasir</forenames></author><author><keyname>Devi</keyname><forenames>Bhagwati</forenames></author><author><keyname>Khan</keyname><forenames>Jahangir Sabbir</forenames></author><author><keyname>Tripathi</keyname><forenames>Ayush</forenames></author></authors><title>Bayesian estimation of Unit-Weibull distribution based on dual   generalized order statistics with application to the Cotton Production Data</title><categories>stat.ME math.ST stat.OT stat.TH</categories><comments>19 Pages, 1 figure, 12 tables, preprint</comments><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Unit Weibull distribution with parameters $\alpha$ and $\beta$ is considered to study in the context of dual generalized order statistics. For the analysis purpose, Bayes estimators based on symmetric and asymmetric loss functions are obtained. The methods which are utilized for Bayesian estimation are approximation and simulation tools such as Lindley, Tierney-Kadane and Markov chain Monte Carlo methods. The authors have considered squared error loss function as symmetric and LINEX and general entropy loss function as asymmetric loss functions. After presenting the mathematical results, a simulation study is conducted to exhibit the performances of various derived estimators. As this study is considered for the dual generalized order statistics that is unification of models based distinct ordered random variable such as order statistics, record values, etc. This provides flexibility in our results and in continuation of this, the cotton production data of USA is analyzed for both submodels of ordered random variables: order statistics and record values. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02986</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02986</id><created>2025-02-05</created><authors><author><keyname>Sturma</keyname><forenames>Nils</forenames></author><author><keyname>Kranzlmueller</keyname><forenames>Miriam</forenames></author><author><keyname>Portakal</keyname><forenames>Irem</forenames></author><author><keyname>Drton</keyname><forenames>Mathias</forenames></author></authors><title>Matching Criterion for Identifiability in Sparse Factor Analysis</title><categories>math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Factor analysis models explain dependence among observed variables by a smaller number of unobserved factors. A main challenge in confirmatory factor analysis is determining whether the factor loading matrix is identifiable from the observed covariance matrix. The factor loading matrix captures the linear effects of the factors and, if unrestricted, can only be identified up to an orthogonal transformation of the factors. However, in many applications the factor loadings exhibit an interesting sparsity pattern that may lead to identifiability up to column signs. We study this phenomenon by connecting sparse factor models to bipartite graphs and providing sufficient graphical conditions for identifiability of the factor loading matrix up to column signs. In contrast to previous work, our main contribution, the matching criterion, exploits sparsity by operating locally on the graph structure, thereby improving existing conditions. Our criterion is efficiently decidable in time that is polynomial in the size of the graph, when restricting the search steps to sets of bounded size. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02996</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02996</id><created>2025-02-05</created><authors><author><keyname>Stewart</keyname><forenames>Lawrence</forenames><affiliation>DI-ENS, LIENS, Inria</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, SIERRA</affiliation></author><author><keyname>Berthet</keyname><forenames>Quentin</forenames></author></authors><title>Building Bridges between Regression, Clustering, and Classification</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regression, the task of predicting a continuous scalar target y based on some features x is one of the most fundamental tasks in machine learning and statistics. It has been observed and theoretically analyzed that the classical approach, meansquared error minimization, can lead to suboptimal results when training neural networks. In this work, we propose a new method to improve the training of these models on regression tasks, with continuous scalar targets. Our method is based on casting this task in a different fashion, using a target encoder, and a prediction decoder, inspired by approaches in classification and clustering. We showcase the performance of our method on a wide range of real-world datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03023</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03023</id><created>2025-02-05</created><authors><author><keyname>Zeng</keyname><forenames>Hao</forenames></author><author><keyname>Liu</keyname><forenames>Kangdao</forenames></author><author><keyname>Jing</keyname><forenames>Bingyi</forenames></author><author><keyname>Wei</keyname><forenames>Hongxin</forenames></author></authors><title>Parametric Scaling Law of Tuning Bias in Conformal Prediction</title><categories>cs.LG math.ST stat.ME stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional holdout set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03030</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03030</id><created>2025-02-05</created><authors><author><keyname>Hughes</keyname><forenames>Arthur</forenames></author><author><keyname>Parast</keyname><forenames>Layla</forenames></author><author><keyname>Thiébaut</keyname><forenames>Rodolphe</forenames></author><author><keyname>Hejblum</keyname><forenames>Boris P.</forenames></author></authors><title>Rank-Based Identification of High-dimensional Surrogate Markers:   Application to Vaccinology</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In vaccine trials with long-term participant follow-up, it is of great importance to identify surrogate markers that accurately infer long-term immune responses. These markers offer practical advantages such as providing early, indirect evidence of vaccine efficacy, and can accelerate vaccine development while identifying potential biomarkers. High-throughput technologies like RNA-sequencing have emerged as promising tools for understanding complex biological systems and informing new treatment strategies. However, these data are high-dimensional, presenting unique statistical challenges for existing surrogate marker identification methods. We introduce Rank-based Identification of high-dimensional SurrogatE Markers (RISE), a novel approach designed for small sample, high-dimensional settings typical in modern vaccine experiments. RISE employs a non-parametric univariate test to screen variables for promising candidates, followed by surrogate evaluation on independent data. Our simulation studies demonstrate RISE's desirable properties, including type one error rate control and empirical power under various conditions. Applying RISE to a clinical trial for inactivated influenza vaccination, we sought to identify genes whose post-vaccination expression could serve as a surrogate for the induced immune response. This analysis revealed a signature of genes whose combined expression at 1 day post-injection appears to be a reasonable surrogate for the neutralising antibody titres at 28 days after vaccination. Pathways related to innate antiviral signalling and interferon stimulation were strongly represented in this derived surrogate, providing a clear immunological interpretation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03048</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03048</id><created>2025-02-05</created><authors><author><keyname>MacKinlay</keyname><forenames>Dan</forenames></author></authors><title>The Ensemble Kalman Update is an Empirical Matheron Update</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Ensemble Kalman Filter (EnKF) is a widely used method for data assimilation in high-dimensional systems. In this paper, we show that the ensemble update step of the EnKF is equivalent to an empirical version of the Matheron update popular in the study of Gaussian process regression.   While this connection is simple, it seems not to be widely known, the literature about each technique seems distinct, and connections between the methods are not exploited. This paper exists to provide an informal introduction to the connection, with the necessary definitions so that it is intelligible to as broad an audience as possible. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03062</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03062</id><created>2025-02-05</created><authors><author><keyname>Yamada</keyname><forenames>Akifumi</forenames></author><author><keyname>Shiraishi</keyname><forenames>Tomohiro</forenames></author><author><keyname>Nishino</keyname><forenames>Shuichi</forenames></author><author><keyname>Katsuoka</keyname><forenames>Teruyuki</forenames></author><author><keyname>Taji</keyname><forenames>Kouichi</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Time Series Anomaly Detection in the Frequency Domain with Statistical   Reliability</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Effective anomaly detection in complex systems requires identifying change points (CPs) in the frequency domain, as abnormalities often arise across multiple frequencies. This paper extends recent advancements in statistically significant CP detection, based on Selective Inference (SI), to the frequency domain. The proposed SI method quantifies the statistical significance of detected CPs in the frequency domain using $p$-values, ensuring that the detected changes reflect genuine structural shifts in the target system. We address two major technical challenges to achieve this. First, we extend the existing SI framework to the frequency domain by appropriately utilizing the properties of discrete Fourier transform (DFT). Second, we develop an SI method that provides valid $p$-values for CPs where changes occur across multiple frequencies. Experimental results demonstrate that the proposed method reliably identifies genuine CPs with strong statistical guarantees, enabling more accurate root-cause analysis in the frequency domain of complex systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03090</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03090</id><created>2025-02-05</created><authors><author><keyname>Li</keyname><forenames>Jinglai</forenames></author><author><keyname>Wang</keyname><forenames>Hongqiao</forenames></author></authors><title>Gaussian Processes Regression for Uncertainty Quantification: An   Introductory Tutorial</title><categories>stat.CO cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian Process Regression (GPR) is a powerful method widely used in Uncertainty Quantification (UQ). This tutorial serves as an introductory guide for beginners, aiming to offer a structured and accessible overview of GPR's applications in UQ. We begin with an introduction to UQ and outline its key tasks, including uncertainty propagation, risk estimation, optimization under uncertainty, parameter estimation, and sensitivity analysis. We then introduce Gaussian Processes (GPs) as a surrogate modeling technique, detailing their formulation, choice of covariance kernels, hyperparameter estimation, and active learning strategies for efficient data acquisition. The tutorial further explores how GPR can be applied to different UQ tasks, including Bayesian quadrature for uncertainty propagation, active learning-based risk estimation, Bayesian optimization for optimization under uncertainty, and surrogate-based sensitivity analysis. Throughout, we emphasize how to leverage the unique formulation of GP for these UQ tasks, rather than simply using it as a standard surrogate model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03099</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03099</id><created>2025-02-05</created><authors><author><keyname>Betken</keyname><forenames>Annika</forenames></author><author><keyname>Micali</keyname><forenames>Giorgio</forenames></author><author><keyname>Schmidt-Hieber</keyname><forenames>Johannes</forenames></author></authors><title>Ordinal Patterns Based Change Points Detection</title><categories>math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ordinal patterns of a fixed number of consecutive values in a time series is the spatial ordering of these values. Counting how often a specific ordinal pattern occurs in a time series provides important insights into the properties of the time series. In this work, we prove the asymptotic normality of the relative frequency of ordinal patterns for time series with linear increments. Moreover, we apply ordinal patterns to detect changes in the distribution of a time series. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03119</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03119</id><created>2025-02-05</created><authors><author><keyname>Graf</keyname><forenames>Ricarda</forenames></author><author><keyname>Todd</keyname><forenames>Susan</forenames></author><author><keyname>Baksh</keyname><forenames>M. Fazil</forenames></author></authors><title>Comparison of the Cox proportional hazards model and Random Survival   Forest algorithm for predicting patient-specific survival probabilities in   clinical trial data</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Cox proportional hazards model is often used for model development in data from randomized controlled trials (RCT) with time-to-event outcomes. Random survival forests (RSF) is a machine-learning algorithm known for its high predictive performance. We conduct a comprehensive neutral comparison study to compare the predictive performance of Cox regression and RSF in real-world as well as simulated data. Performance is compared using multiple performance measures according to recommendations for the comparison of prognostic prediction models. We found that while the RSF usually outperforms the Cox model when using the $C$ index, Cox model predictions may be better calibrated. With respect to overall performance, the Cox model often exceeds the RSF in nonproportional hazards settings, while otherwise the RSF typically performs better especially for smaller sample sizes. Overall performance of the RSF is more affected by higher censoring rates, while overall performance of the Cox model suffers more from smaller sample sizes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03156</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03156</id><created>2025-02-05</created><authors><author><keyname>Jonzon</keyname><forenames>Gustav</forenames></author><author><keyname>Gabriel</keyname><forenames>Erin E</forenames></author><author><keyname>Sjölander</keyname><forenames>Arvid</forenames></author><author><keyname>Sachs</keyname><forenames>Michael C</forenames></author></authors><title>Adding covariates to bounds: What is the question?</title><categories>stat.ME</categories><msc-class>62D20</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Symbolic nonparametric bounds for partial identification of causal effects now have a long history in the causal literature. Sharp bounds, bounds that use all available information to make the range of values as narrow as possible, are often the goal. For this reason, many publications have focused on deriving sharp bounds, but the concept of sharp bounds is nuanced and can be misleading. In settings with ancillary covariates, the situation becomes more complex. We provide clear definitions for pointwise and uniform sharpness of covariate-conditional bounds, that we then use to prove some general and some specific to the IV setting results about the relationship between these two concepts. As we demonstrate, general conditions are much more difficult to determine and thus, we urge authors to be clear when including ancillary covariates in bounds via conditioning about the setting of interest and the assumptions made. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03163</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03163</id><created>2025-02-05</created><authors><author><keyname>Glückstad</keyname><forenames>Mie</forenames></author><author><keyname>Cirone</keyname><forenames>Nicola Muca</forenames></author><author><keyname>Teichmann</keyname><forenames>Josef</forenames></author></authors><title>Signature Reconstruction from Randomized Signatures</title><categories>math.CA cs.LG math.PR stat.ML</categories><comments>37 pages, 7 figures</comments><msc-class>60L10 (Primary) 60L70, 60L90, 68T07 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Controlled ordinary differential equations driven by continuous bounded variation curves can be considered a continuous time analogue of recurrent neural networks for the construction of expressive features of the input curves. We ask up to which extent well known signature features of such curves can be reconstructed from controlled ordinary differential equations with (untrained) random vector fields. The answer turns out to be algebraically involved, but essentially the number of signature features, which can be reconstructed from the non-linear flow of the controlled ordinary differential equation, is exponential in its hidden dimension, when the vector fields are chosen to be neural with depth two. Moreover, we characterize a general linear independence condition on arbitrary vector fields, under which the signature features up to some fixed order can always be reconstructed. Algebraically speaking this complements in a quantitative manner several well known results from the theory of Lie algebras of vector fields and puts them in a context of machine learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03174</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03174</id><created>2025-02-05</created><authors><author><keyname>Lecestre</keyname><forenames>Alexandre</forenames></author></authors><title>Robust Label Shift Quantification</title><categories>math.ST stat.ML stat.TH</categories><msc-class>62F35</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the label shift quantification problem. We propose robust estimators of the label distribution which turn out to coincide with the Maximum Likelihood Estimator. We analyze the theoretical aspects and derive deviation bounds for the proposed method, providing optimal guarantees in the well-specified case, along with notable robustness properties against outliers and contamination. Our results provide theoretical validation for empirical observations on the robustness of Maximum Likelihood Label Shift. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03208</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03208</id><created>2025-02-05</created><authors><author><keyname>Sziklai</keyname><forenames>Balázs R.</forenames></author><author><keyname>Gere</keyname><forenames>Attila</forenames></author><author><keyname>Héberger</keyname><forenames>Károly</forenames></author><author><keyname>Staudacher</keyname><forenames>Jochen</forenames></author></authors><title>rSRD: An R package for the Sum of Ranking Differences statistical   procedure</title><categories>math.ST stat.TH</categories><msc-class>62-04</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Sum of Ranking Differences (SRD) is a relatively novel, non-para-metric statistical procedure that has become increasingly popular recently. SRD compares solutions via a reference by applying a rank transformation on the input and calculating the distance from the reference in $L_1$ norm. Although the computation of the test statistics is simple, validating the results is cumbersome -- at least by hand. There are two validation steps involved. Comparison of Ranks with Random Numbers, which is a permutation-test, and cross-validation combined with statistical testing. Both options impose computational difficulties albeit different ones. The rSRD package was devised to simplify the validation process by reducing both validation steps into single function calls. In addition, the package provides various useful tools including data preprocessing and plotting. The package makes SRD accessible to a wide audience as there are currently no other software options with such a comprehensive toolkit. This paper aims to serve as a guide for practitioners by offering a detailed presentation of the features. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03210</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03210</id><created>2025-02-05</created><authors><author><keyname>Rubin</keyname><forenames>Noa</forenames></author><author><keyname>Fischer</keyname><forenames>Kirsten</forenames></author><author><keyname>Lindner</keyname><forenames>Javed</forenames></author><author><keyname>Dahmen</keyname><forenames>David</forenames></author><author><keyname>Seroussi</keyname><forenames>Inbar</forenames></author><author><keyname>Ringel</keyname><forenames>Zohar</forenames></author><author><keyname>Krämer</keyname><forenames>Michael</forenames></author><author><keyname>Helias</keyname><forenames>Moritz</forenames></author></authors><title>From Kernels to Features: A Multi-Scale Adaptive Theory of Feature   Learning</title><categories>cond-mat.dis-nn cs.LG stat.ML</categories><comments>24 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Theoretically describing feature learning in neural networks is crucial for understanding their expressive power and inductive biases, motivating various approaches. Some approaches describe network behavior after training through a simple change in kernel scale from initialization, resulting in a generalization power comparable to a Gaussian process. Conversely, in other approaches training results in the adaptation of the kernel to the data, involving complex directional changes to the kernel. While these approaches capture different facets of network behavior, their relationship and respective strengths across scaling regimes remains an open question. This work presents a theoretical framework of multi-scale adaptive feature learning bridging these approaches. Using methods from statistical mechanics, we derive analytical expressions for network output statistics which are valid across scaling regimes and in the continuum between them. A systematic expansion of the network's probability distribution reveals that mean-field scaling requires only a saddle-point approximation, while standard scaling necessitates additional correction terms. Remarkably, we find across regimes that kernel adaptation can be reduced to an effective kernel rescaling when predicting the mean network output of a linear network. However, even in this case, the multi-scale adaptive approach captures directional feature learning effects, providing richer insights than what could be recovered from a rescaling of the kernel alone. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03217</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03217</id><created>2025-02-05</created><authors><author><keyname>Cuellar</keyname><forenames>Maria</forenames></author></authors><title>The Prosecutor's Fallacy and Expert Testimony: A Modern Take Using   Likelihood Ratios</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Forensic examiners and attorneys need to know how to express evidence in favor or against a prosecutor's hypothesis in a way that avoids the prosecutor's fallacy and follows the modern reporting standards for forensic evidence. This article delves into the inherent conflict between legal and scientific principles, exacerbated by the prevalence of alternative facts in contemporary discourse. Courts grapple with contradictory expert testimonies, leading to a surge in erroneous rulings based on flawed amicus briefs and testimonies, notably the persistent prosecutor's fallacy. The piece underscores the necessity for legal practitioners to navigate this fallacy within the modern forensic science framework, emphasizing the importance of reporting likelihood ratios (LRs) over posterior probabilities. Recognizing the challenge of lay comprehension of LRs, the article calls for updated recommendations to mitigate the prosecutor's fallacy. Its contribution lies in providing a detailed analysis of the fallacy using LRs and advocating for a sound interpretation of evidence. Illustrated through a modified real case, this article serves as a valuable guide for legal professionals, offering insights into avoiding fallacious reasoning in forensic evidence assessment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03237</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03237</id><created>2025-02-05</created><authors><author><keyname>Mane</keyname><forenames>S. R.</forenames></author></authors><title>New technique for parameter estimation and improved fits to experimental   data for a set of compound Poisson distributions</title><categories>stat.ME math.PR</categories><comments>43 pages, 18 figures</comments><report-no>CC25-2</report-no><msc-class>62F30, 60-06, 05-08</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Compound Poisson distributions have been employed by many authors to fit experimental data, typically via the method of moments or maximum likelihood estimation. We propose a new technique and apply it to several sets of published data. It yields better fits than those obtained by the original authors for a set of widely employed compound Poisson distributions (in some cases, significantly better). The technique employs the power spectrum (the absolute square of the characteristic function). The new idea is suggested as a useful addition to the tools for parameter estimation of compound Poisson distributions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03241</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03241</id><created>2025-02-05</created><authors><author><keyname>Wang</keyname><forenames>Yaping</forenames></author><author><keyname>Liu</keyname><forenames>Sixu</forenames></author><author><keyname>Xiao</keyname><forenames>Qian</forenames></author></authors><title>Optimal design of experiments with quantitative-sequence factors</title><categories>stat.ME</categories><comments>This is the English version of the published paper in Chinese by   SCIENCE CHINA Mathematics</comments><msc-class>62K20, 62K99</msc-class><journal-ref>SCIENCE CHINA Mathematics, 2025, 55: 1-24 (in Chinese)</journal-ref><doi>10.1360/SCM-2024-0039</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A new type of experiment with joint considerations of quantitative and sequence factors is recently drawing much attention in medical science, bio-engineering, and many other disciplines. The input spaces of such experiments are semi-discrete and often very large. Thus, efficient and economical experimental designs are required. Based on the transformations and aggregations of good lattice point sets, we construct a new class of optimal quantitative-sequence (QS) designs that are marginally coupled, pair-balanced, space-filling, and asymptotically orthogonal. The proposed QS designs have a certain flexibility in run and factor sizes and are especially appealing for high-dimensional cases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03254</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03254</id><created>2025-02-05</created><authors><author><keyname>Młynarczyk</keyname><forenames>Dorota</forenames></author><author><keyname>Calvo</keyname><forenames>Gabriel</forenames></author><author><keyname>Palmi-Perales</keyname><forenames>Francisco</forenames></author><author><keyname>Armero</keyname><forenames>Carmen</forenames></author><author><keyname>Gómez-Rubio</keyname><forenames>Virgilio</forenames></author><author><keyname>Martinez-Iranzo</keyname><forenames>Ursula</forenames></author></authors><title>Bayesian network approach to building an affective module for a driver   behavioural model</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper focuses on the affective component of a Driver Behavioural Model (DBM), specifically modelling some driver's mental states, such as mental load and active fatigue, which may affect driving performance. We used Bayesian networks (BNs) to explore the dependencies between various relevant variables and estimate the probability that a driver was in a particular mental state based on their physiological and demographic conditions. Through this approach, our goal is to improve our understanding of driver behaviour in dynamic environments, with potential applications in traffic safety and autonomous vehicle technologies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03261</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03261</id><created>2025-02-05</created><authors><author><keyname>Somerstep</keyname><forenames>Seamus</forenames></author><author><keyname>Polo</keyname><forenames>Felipe Maia</forenames></author><author><keyname>de Oliveira</keyname><forenames>Allysson Flavio Melo</forenames></author><author><keyname>Mangal</keyname><forenames>Prattyush</forenames></author><author><keyname>Silva</keyname><forenames>Mírian</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Onkar</forenames></author><author><keyname>Yurochkin</keyname><forenames>Mikhail</forenames></author><author><keyname>Maity</keyname><forenames>Subha</forenames></author></authors><title>CARROT: A Cost Aware Rate Optimal Router</title><categories>stat.ML cs.LG cs.NI math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in LLM routing, or directing queries to the cheapest LLM that can deliver a suitable response. Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware Routing (SPROUT) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03273</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03273</id><created>2025-02-05</created><authors><author><keyname>Hadj-Amar</keyname><forenames>Beniamino</forenames></author><author><keyname>Krishnan</keyname><forenames>Vaishnav</forenames></author><author><keyname>Vannucci</keyname><forenames>Marina</forenames></author></authors><title>Bayesian Covariate-Dependent Circadian Modeling of Rest-Activity Rhythms</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a Bayesian covariate-dependent anti-logistic circadian model for analyzing activity data collected via wrist-worn wearable devices. The proposed approach integrates covariates into the modeling of the amplitude and phase parameters, facilitating cohort-level analysis with enhanced flexibility and interpretability. To promote model sparsity, we employ an l_1-ball projection prior, enabling precise control over complexity while identifying significant predictors. We assess performances on simulated data and then apply the method to real-world actigraphy data from people with epilepsy. Our results demonstrate the model's effectiveness in uncovering complex relationships among demographic, psychological, and medical factors influencing rest-activity rhythms, offering insights for personalized clinical assessments and healthcare interventions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03279</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03279</id><created>2025-02-05</created><authors><author><keyname>Säilynoja</keyname><forenames>Teemu</forenames></author><author><keyname>Schmitt</keyname><forenames>Marvin</forenames></author><author><keyname>Bürkner</keyname><forenames>Paul</forenames></author><author><keyname>Vehtari</keyname><forenames>Aki</forenames></author></authors><title>Posterior SBC: Simulation-Based Calibration Checking Conditional on Data</title><categories>stat.ME stat.CO stat.ML</categories><comments>22 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Simulation-based calibration checking (SBC) refers to the validation of an inference algorithm and model implementation through repeated inference on data simulated from a generative model. In the original and commonly used approach, the generative model uses parameters drawn from the prior, and thus the approach is testing whether the inference works for simulated data generated with parameter values plausible under that prior. This approach is natural and desirable when we want to test whether the inference works for a wide range of datasets we might observe. However, after observing data, we are interested in answering whether the inference works conditional on that particular data. In this paper, we propose posterior SBC and demonstrate how it can be used to validate the inference conditionally on observed data. We illustrate the utility of posterior SBC in three case studies: (1) A simple multilevel model; (2) a model that is governed by differential equations; and (3) a joint integrative neuroscience model which is approximated via amortized Bayesian inference with neural networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03327</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03327</id><created>2025-02-05</created><authors><author><keyname>Kratsios</keyname><forenames>Anastasis</forenames></author><author><keyname>Furuya</keyname><forenames>Takashi</forenames></author></authors><title>Is In-Context Universality Enough? MLPs are Also Universal In-Context</title><categories>stat.ML cs.LG cs.NA cs.NE math.NA math.PR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The success of transformers is often linked to their ability to perform in-context learning. Recent work shows that transformers are universal in context, capable of approximating any real-valued continuous function of a context (a probability measure over $\mathcal{X}\subseteq \mathbb{R}^d$) and a query $x\in \mathcal{X}$. This raises the question: Does in-context universality explain their advantage over classical models? We answer this in the negative by proving that MLPs with trainable activation functions are also universal in-context. This suggests the transformer's success is likely due to other factors like inductive bias or training stability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03329</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03329</id><created>2025-02-05</created><authors><author><keyname>Parra</keyname><forenames>Camila Olarte</forenames></author><author><keyname>Daniel</keyname><forenames>Rhian M.</forenames></author><author><keyname>Bartlett</keyname><forenames>Jonathan W.</forenames></author></authors><title>Dealing with multiple intercurrent events using hypothetical and   treatment policy strategies simultaneously</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To precisely define the treatment effect of interest in a clinical trial, the ICH E9 estimand addendum describes that relevant so-called intercurrent events should be identified and strategies specified to deal with them. Handling intercurrent events with different strategies leads to different estimands. In this paper, we focus on estimands that involve addressing one intercurrent event with the treatment policy strategy and another with the hypothetical strategy. We define these estimands using potential outcomes and causal diagrams, considering the possible causal relationships between the two intercurrent events and other variables. We show that there are different causal estimand definitions and assumptions one could adopt, each having different implications for estimation, which is demonstrated in a simulation study. The different considerations are illustrated conceptually using a diabetes trial as an example. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03332</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03332</id><created>2025-02-05</created><authors><author><keyname>Janati</keyname><forenames>Yazid</forenames></author><author><keyname>Moufad</keyname><forenames>Badr</forenames></author><author><keyname>Qassime</keyname><forenames>Mehdi Abou El</forenames></author><author><keyname>Durmus</keyname><forenames>Alain</forenames></author><author><keyname>Moulines</keyname><forenames>Eric</forenames></author><author><keyname>Olsson</keyname><forenames>Jimmy</forenames></author></authors><title>A Mixture-Based Framework for Guiding Diffusion Models</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Denoising diffusion models have driven significant progress in the field of Bayesian inverse problems. Recent approaches use pre-trained diffusion models as priors to solve a wide range of such problems, only leveraging inference-time compute and thereby eliminating the need to retrain task-specific models on the same dataset. To approximate the posterior of a Bayesian inverse problem, a diffusion model samples from a sequence of intermediate posterior distributions, each with an intractable likelihood function. This work proposes a novel mixture approximation of these intermediate distributions. Since direct gradient-based sampling of these mixtures is infeasible due to intractable terms, we propose a practical method based on Gibbs sampling. We validate our approach through extensive experiments on image inverse problems, utilizing both pixel- and latent-space diffusion priors, as well as on source separation with an audio diffusion model. The code is available at https://www.github.com/badr-moufad/mgdm </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03341</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03341</id><created>2025-02-05</created><authors><author><keyname>Leisenberger</keyname><forenames>Harald</forenames></author><author><keyname>Pernkopf</keyname><forenames>Franz</forenames></author></authors><title>Adaptive Variational Inference in Probabilistic Graphical Models: Beyond   Bethe, Tree-Reweighted, and Convex Free Energies</title><categories>stat.ML cs.AI cs.LG</categories><comments>This work has been submitted to the Conference on Uncertainty in   Artificial Intelligence (UAI) 2025 for possible publication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Variational inference in probabilistic graphical models aims to approximate fundamental quantities such as marginal distributions and the partition function. Popular approaches are the Bethe approximation, tree-reweighted, and other types of convex free energies. These approximations are efficient but can fail if the model is complex and highly interactive. In this work, we analyze two classes of approximations that include the above methods as special cases: first, if the model parameters are changed; and second, if the entropy approximation is changed. We discuss benefits and drawbacks of either approach, and deduce from this analysis how a free energy approximation should ideally be constructed. Based on our observations, we propose approximations that automatically adapt to a given model and demonstrate their effectiveness for a range of difficult problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03342</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03342</id><created>2025-02-05</created><authors><author><keyname>Baouan</keyname><forenames>Ali</forenames></author></authors><title>Statistical analysis of team formation and player roles in football</title><categories>stat.AP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The availability of tracking data in football presents unique opportunities for analyzing team shape and player roles, but leveraging it effectively remains challenging. This difficulty arises from the significant overlap in player positions, which complicates the identification of distinct roles and team formations. In this work, we propose a novel model that incorporates a hidden permutation matrix to simultaneously estimate team formations and assign roles to players at the frame level. To address the cardinality of permutation sets, we develop a statistical procedure to parsimoniously select relevant matrices prior to parameter estimation. Additionally, to capture formation changes during a match, we introduce a latent regime variable, enabling the modeling of dynamic tactical adjustments. This framework disentangles player locations from role-specific positions, providing a clear representation of team structure. We demonstrate the applicability of our approach using player tracking data, showcasing its potential for detailed team and player analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03350</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03350</id><created>2025-02-05</created><authors><author><keyname>Li</keyname><forenames>Ziyan</forenames></author><author><keyname>Hiratani</keyname><forenames>Naoki</forenames></author></authors><title>Optimal Task Order for Continual Learning of Multiple Tasks</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continual learning of multiple tasks remains a major challenge for neural networks. Here, we investigate how task order influences continual learning and propose a strategy for optimizing it. Leveraging a linear teacher-student model with latent factors, we derive an analytical expression relating task similarity and ordering to learning performance. Our analysis reveals two principles that hold under a wide parameter range: (1) tasks should be arranged from the least representative to the most typical, and (2) adjacent tasks should be dissimilar. We validate these rules on both synthetic data and real-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100), demonstrating consistent performance improvements in both multilayer perceptrons and convolutional neural networks. Our work thus presents a generalizable framework for task-order optimization in task-incremental continual learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03366</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03366</id><created>2025-02-05</created><authors><author><keyname>Mucsányi</keyname><forenames>Bálint</forenames></author><author><keyname>Da Costa</keyname><forenames>Nathaël</forenames></author><author><keyname>Hennig</keyname><forenames>Philipp</forenames></author></authors><title>Rethinking Approximate Gaussian Inference in Classification</title><categories>cs.LG stat.ML</categories><comments>29 pages, 15 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In classification tasks, softmax functions are ubiquitously used as output activations to produce predictive probabilities. Such outputs only capture aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian inference methods have been proposed, which output Gaussian distributions over the logit space. Predictives are then obtained as the expectations of the Gaussian distributions pushed forward through the softmax. However, such softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC) approximations can be costly and noisy. We propose a simple change in the learning objective which allows the exact computation of predictives and enjoys improved training dynamics, with no runtime or memory overhead. This framework is compatible with a family of output activation functions that includes the softmax, as well as element-wise normCDF and sigmoid. Moreover, it allows for approximating the Gaussian pushforwards with Dirichlet distributions by analytic moment matching. We evaluate our approach combined with several approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and small-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertainty quantification capabilities compared to softmax MC sampling. Code is available at https://github.com/bmucsanyi/probit. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03414</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03414</id><created>2025-02-05</created><authors><author><keyname>Jetsupphasuk</keyname><forenames>Michael</forenames></author><author><keyname>Li</keyname><forenames>Didong</forenames></author><author><keyname>Hudgens</keyname><forenames>Michael G.</forenames></author></authors><title>Estimating causal effects using difference-in-differences under network   dependency and interference</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differences-in-differences (DiD) is a causal inference method for observational longitudinal data that assumes parallel expected outcome trajectories between treatment groups under the (possible) counterfactual of receiving a specific treatment. In this paper DiD is extended to allow for (i) network dependency where outcomes, treatments, and covariates may exhibit between-unit latent correlation, and (ii) interference, where treatments can affect outcomes in neighboring units. In this setting, the causal estimand of interest is the average exposure effect among units with a specific exposure level, where the exposure is a function of treatments from potentially many units. Under a conditional parallel trends assumption and suitable network dependency conditions, a doubly robust estimator allowing for data-adaptive nuisance function estimation is proposed and shown to be consistent and asymptotically normal with variance reaching the semiparametric efficiency bound. The proposed methods are evaluated in simulations and applied to study the effects of adopting emission control technologies in coal power plants on county-level mortality due to cardiovascular disease. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03435</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03435</id><created>2025-02-05</created><authors><author><keyname>Wu</keyname><forenames>Yu-Han</forenames></author><author><keyname>Marion</keyname><forenames>Pierre</forenames></author><author><keyname>Biau</keyname><forenames>Gérard</forenames></author><author><keyname>Boyer</keyname><forenames>Claire</forenames></author></authors><title>Taking a Big Step: Large Learning Rates in Denoising Score Matching   Prevent Memorization</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Denoising score matching plays a pivotal role in the performance of diffusion-based generative models. However, the empirical optimal score--the exact solution to the denoising score matching--leads to memorization, where generated samples replicate the training data. Yet, in practice, only a moderate degree of memorization is observed, even without explicit regularization. In this paper, we investigate this phenomenon by uncovering an implicit regularization mechanism driven by large learning rates. Specifically, we show that in the small-noise regime, the empirical optimal score exhibits high irregularity. We then prove that, when trained by stochastic gradient descent with a large enough learning rate, neural networks cannot stably converge to a local minimum with arbitrarily small excess risk. Consequently, the learned score cannot be arbitrarily close to the empirical optimal score, thereby mitigating memorization. To make the analysis tractable, we consider one-dimensional data and two-layer neural networks. Experiments validate the crucial role of the learning rate in preventing memorization, even beyond the one-dimensional setting. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03439</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03439</id><created>2025-02-05</created><authors><author><keyname>Linwu</keyname><forenames>Jun</forenames></author><author><keyname>Khurana</keyname><forenames>Varun</forenames></author><author><keyname>Karris</keyname><forenames>Nicholas</forenames></author><author><keyname>Cloninger</keyname><forenames>Alexander</forenames></author></authors><title>Linearized Optimal Transport pyLOT Library: A Toolkit for Machine   Learning on Point Clouds</title><categories>stat.ML cs.LG cs.MS stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pyLOT library offers a Python implementation of linearized optimal transport (LOT) techniques and methods to use in downstream tasks. The pipeline embeds probability distributions into a Hilbert space via the Optimal Transport maps from a fixed reference distribution, and this linearization allows downstream tasks to be completed using off the shelf (linear) machine learning algorithms. We provide a case study of performing ML on 3D scans of lemur teeth, where the original questions of classification, clustering, dimension reduction, and data generation reduce to simple linear operations performed on the LOT embedded representations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03458</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03458</id><created>2025-02-05</created><authors><author><keyname>Johnston</keyname><forenames>Tim</forenames></author><author><keyname>Lytras</keyname><forenames>Iosif</forenames></author><author><keyname>Makras</keyname><forenames>Nikolaos</forenames></author><author><keyname>Sabanis</keyname><forenames>Sotirios</forenames></author></authors><title>The Performance Of The Unadjusted Langevin Algorithm Without Smoothness   Assumptions</title><categories>stat.ML math.OC math.PR stat.CO</categories><comments>26pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this article, we study the problem of sampling from distributions whose densities are not necessarily smooth nor log-concave. We propose a simple Langevin-based algorithm that does not rely on popular but computationally challenging techniques, such as the Moreau Yosida envelope or Gaussian smoothing. We derive non-asymptotic guarantees for the convergence of the algorithm to the target distribution in Wasserstein distances. Non asymptotic bounds are also provided for the performance of the algorithm as an optimizer, specifically for the solution of associated excess risk optimization problems. </abstract></arXiv></metadata></record>
