<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1401.1137</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1401.1137</id><created>2014-01-06</created><updated>2015-03-27</updated><authors><author><keyname>Caron</keyname><forenames>François</forenames></author><author><keyname>Fox</keyname><forenames>Emily B.</forenames></author></authors><title>Sparse graphs using exchangeable random measures</title><categories>stat.ME cs.SI math.ST stat.ML stat.TH</categories><comments>New title. Extended version</comments><journal-ref>Journal of the Royal Statistical Society Series B: Statistical   Methodology, Volume 79, Issue 5, November 2017, Pages 1295-1366</journal-ref><doi>10.1111/rssb.12233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical network modeling has focused on representing the graph as a discrete structure, namely the adjacency matrix, and considering the exchangeability of this array. In such cases, the Aldous-Hoover representation theorem (Aldous, 1981;Hoover, 1979} applies and informs us that the graph is necessarily either dense or empty. In this paper, we instead consider representing the graph as a measure on $\mathbb{R}_+^2$. For the associated definition of exchangeability in this continuous space, we rely on the Kallenberg representation theorem (Kallenberg, 2005). We show that for certain choices of such exchangeable random measures underlying our graph construction, our network process is sparse with power-law degree distribution. In particular, we build on the framework of completely random measures (CRMs) and use the theory associated with such processes to derive important network properties, such as an urn representation for our analysis and network simulation. Our theoretical results are explored empirically and compared to common network models. We then present a Hamiltonian Monte Carlo algorithm for efficient exploration of the posterior distribution and demonstrate that we are able to recover graphs ranging from dense to sparse--and perform associated tests--based on our flexible CRM-based formulation. We explore network properties in a range of real datasets, including Facebook social circles, a political blogosphere, protein networks, citation networks, and world wide web networks, including networks with hundreds of thousands of nodes and millions of edges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1602.02114</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1602.02114</id><created>2016-02-05</created><updated>2017-08-23</updated><authors><author><keyname>Todeschini</keyname><forenames>Adrien</forenames></author><author><keyname>Miscouridou</keyname><forenames>Xenia</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Exchangeable Random Measures for Sparse and Modular Graphs with   Overlapping Communities</title><categories>stat.ME cs.SI physics.soc-ph stat.ML</categories><journal-ref>Journal of the Royal Statistical Society Series B: Statistical   Methodology, Volume 82, Issue 2, April 2020, Pages 487-520</journal-ref><doi>10.1111/rssb.12363</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel statistical model for sparse networks with overlapping community structure. The model is based on representing the graph as an exchangeable point process, and naturally generalizes existing probabilistic models with overlapping block-structure to the sparse regime. Our construction builds on vectors of completely random measures, and has interpretable parameters, each node being assigned a vector representing its level of affiliation to some latent communities. We develop methods for simulating this class of random graphs, as well as to perform posterior inference. We show that the proposed approach can recover interpretable structure from two real-world networks and can handle graphs with thousands of nodes and tens of thousands of edges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1708.03120</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1708.03120</id><created>2017-08-10</created><updated>2022-11-01</updated><authors><author><keyname>Caron</keyname><forenames>François</forenames></author><author><keyname>Panero</keyname><forenames>Francesca</forenames></author><author><keyname>Rousseau</keyname><forenames>Judith</forenames></author></authors><title>On sparsity, power-law and clustering properties of graphex processes</title><categories>math.ST math.PR stat.TH</categories><journal-ref>Advances in Applied Probability, Volume 55, Issue 4, December   2023, pp. 1211 - 1253</journal-ref><doi>10.1017/apr.2022.75</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates properties of the class of graphs based on exchangeable point processes. We provide asymptotic expressions for the number of edges, number of nodes and degree distributions, identifying four regimes: (i) a dense regime, (ii) a sparse almost dense regime, (iii) a sparse regime with power-law behaviour, and (iv) an almost extremely sparse regime. We show that under mild assumptions, both the global and local clustering coefficients converge to constants which may or may not be the same. We also derive a central limit theorem for the number of nodes. Finally, we propose a class of models within this framework where one can separately control the latent structure and the global sparsity/power-law properties of the graph. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1902.04714</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1902.04714</id><created>2019-02-12</created><updated>2019-07-09</updated><authors><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Beyond the Chinese Restaurant and Pitman-Yor processes: Statistical   Models with Double Power-law Behavior</title><categories>stat.ML cs.LG</categories><journal-ref>Proceedings of the 36th International Conference on Machine   Learning, PMLR 97:395-404, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian nonparametric approaches, in particular the Pitman-Yor process and the associated two-parameter Chinese Restaurant process, have been successfully used in applications where the data exhibit a power-law behavior. Examples include natural language processing, natural images or networks. There is also growing empirical evidence that some datasets exhibit a two-regime power-law behavior: one regime for small frequencies, and a second regime, with a different exponent, for high frequencies. In this paper, we introduce a class of completely random measures which are doubly regularly-varying. Contrary to the Pitman-Yor process, we show that when completely random measures in this class are normalized to obtain random probability measures and associated random partitions, such partitions exhibit a double power-law behavior. We discuss in particular three models within this class: the beta prime process (Broderick et al. (2015, 2018), a novel process called generalized BFRY process, and a mixture construction. We derive efficient Markov chain Monte Carlo algorithms to estimate the parameters of these models. Finally, we show that the proposed models provide a better fit than the Pitman-Yor process on various datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1905.09059</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1905.09059</id><created>2019-05-22</created><authors><author><keyname>Rathasamuth</keyname><forenames>Wanthanee</forenames></author><author><keyname>Pasupa</keyname><forenames>Kitsuchart</forenames></author><author><keyname>Tongsima</keyname><forenames>Sissades</forenames></author></authors><title>Selection of a Minimal Number of Significant Porcine SNPs by an   Information Gain and Genetic Algorithm Hybrid Model</title><categories>q-bio.QM cs.NE stat.AP</categories><comments>16 pages, 9 figures, preprint submitted to Malaysian Journal of   Computer Science</comments><journal-ref>Malaysian Journal of Computer Science, SI2, 79--95 (2019)</journal-ref><doi>10.22452/mjcs.sp2019no2.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A panel of large number of common Single Nucleotide Polymorphisms (SNPs) distributed across an entire porcine genome has been widely used to represent genetic variability of pig. With the advent of SNP-array technology, a genome-wide genetic profile of a specimen can be easily observed. Among the large number of such variations, there exist a much smaller subset of the SNP panel that could equally be used to correctly identify the corresponding breed. This work presents a SNP selection heuristic that can still be used effectively in the breed classification process. The proposed feature selection was done by the approach of combining a filter method and a wrapper method--information gain method and genetic algorithm--plus a feature frequency selection step, while classification was done by support vector machine. The approach was able to reduce the number of significant SNPs to 0.86 % of the total number of SNPs in a swine dataset and provided a high classification accuracy of 94.80 %. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1905.10733</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1905.10733</id><created>2019-05-26</created><authors><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Miscouridou</keyname><forenames>Xenia</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>A unified construction for series representations and finite   approximations of completely random measures</title><categories>math.ST cs.LG stat.ML stat.TH</categories><journal-ref>Bernoulli 29(3): 2142-2166, 2023</journal-ref><doi>10.3150/22-BEJ1536</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infinite-activity completely random measures (CRMs) have become important building blocks of complex Bayesian nonparametric models. They have been successfully used in various applications such as clustering, density estimation, latent feature models, survival analysis or network science. Popular infinite-activity CRMs include the (generalized) gamma process and the (stable) beta process. However, except in some specific cases, exact simulation or scalable inference with these models is challenging and finite-dimensional approximations are often considered. In this work, we propose a general and unified framework to derive both series representations and finite-dimensional approximations of CRMs. Our framework can be seen as an extension of constructions based on size-biased sampling of Poisson point process [Perman1992]. It includes as special cases several known series representations as well as novel ones. In particular, we show that one can get novel series representations for the generalized gamma process and the stable beta process. We also provide some analysis of the truncation error. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1911.06869</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1911.06869</id><created>2019-11-15</created><updated>2025-02-05</updated><authors><author><keyname>Bhadra</keyname><forenames>Somnath</forenames></author><author><keyname>Chakraborty</keyname><forenames>Kaustav</forenames></author><author><keyname>Sengupta</keyname><forenames>Srijan</forenames></author><author><keyname>Lahiri</keyname><forenames>Soumendra</forenames></author></authors><title>A Bootstrap-based Method for Testing Network Similarity</title><categories>stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the matched network inference problem, where the goal is to determine if two networks, defined on a common set of nodes, exhibit a specific form of stochastic similarity. Two notions of similarity are considered: (i) equality, i.e., testing whether the networks arise from the same random graph model, and (ii) scaling, i.e., testing whether their probability matrices are proportional for some unknown scaling constant. We develop a testing framework based on a parametric bootstrap approach and a Frobenius norm-based test statistic. The proposed approach is highly versatile as it covers both the equality and scaling problems, and ensures adaptability under various model settings, including stochastic blockmodels, Chung-Lu models, and random dot product graph models. We establish theoretical consistency of the proposed tests and demonstrate their empirical performance through extensive simulations under a wide range of model classes. Our results establish the flexibility and computational efficiency of the proposed method compared to existing approaches. We also report a real-world application involving the Aarhus network dataset, which reveals meaningful sociological patterns across different communication layers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2006.10968</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2006.10968</id><created>2020-06-19</created><updated>2022-11-28</updated><authors><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>The Normal-Generalised Gamma-Pareto process: A novel pure-jump L\'evy   process with flexible tail and jump-activity properties</title><categories>stat.ME math.ST stat.TH</categories><journal-ref>Bayesian Anal. 19(1): 123-152, 2024</journal-ref><doi>10.1214/22-BA1343</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pure-jump L\'evy processes are popular classes of stochastic processes which have found many applications in finance, statistics or machine learning. In this paper, we propose a novel family of self-decomposable L\'evy processes where one can control separately the tail behavior and the jump activity of the process, via two different parameters. Crucially, we show that one can sample exactly increments of this process, at any time scale; this allows the implementation of likelihood-free Markov chain Monte Carlo algorithms for (asymptotically) exact posterior inference. We use this novel process in L\'evy-based stochastic volatility models to predict the returns of stock market data, and show that the proposed class of models leads to superior predictive performances compared to classical alternatives. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2010.08891</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2010.08891</id><created>2020-10-17</created><updated>2025-02-04</updated><authors><author><keyname>Shrestha</keyname><forenames>Aayam</forenames></author><author><keyname>Lee</keyname><forenames>Stefan</forenames></author><author><keyname>Tadepalli</keyname><forenames>Prasad</forenames></author><author><keyname>Fern</keyname><forenames>Alan</forenames></author></authors><title>DeepAveragers: Offline Reinforcement Learning by Solving Derived   Non-Parametric MDPs</title><categories>cs.LG cs.AI stat.ML</categories><comments>Camera Ready ICLR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an approach to offline reinforcement learning (RL) based on optimally solving finitely-represented MDPs derived from a static dataset of experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals. Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL. DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model. In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2011.01591</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2011.01591</id><created>2020-11-03</created><updated>2025-02-05</updated><authors><author><keyname>Hermann</keyname><forenames>Philipp</forenames></author><author><keyname>Holzmann</keyname><forenames>Hajo</forenames></author></authors><title>Support estimation in high-dimensional heteroscedastic mean regression</title><categories>math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A current strand of research in high-dimensional statistics deals with robustifying the available methodology with respect to deviations from the pervasive light-tail assumptions. In this paper we consider a linear mean regression model with random design and potentially heteroscedastic, heavy-tailed errors, and investigate support estimation in this framework. We use a strictly convex, smooth variant of the Huber loss function with tuning parameter depending on the parameters of the problem, as well as the adaptive LASSO penalty for computational efficiency. For the resulting estimator we show sign-consistency and optimal rates of convergence in the $\ell_\infty$ norm as in the homoscedastic, light-tailed setting. In our analysis, we have to deal with the issue that the support of the target parameter in the linear mean regression model and its robustified version may differ substantially even for small values of the tuning parameter of the Huber loss function. Simulations illustrate the favorable numerical performance of the proposed methodology. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2101.07718</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2101.07718</id><created>2021-01-19</created><updated>2025-02-04</updated><authors><author><keyname>Wang</keyname><forenames>Zhu</forenames></author></authors><title>Unified Robust Boosting</title><categories>stat.CO</categories><msc-class>62H30, 62G35, 68Q32</msc-class><journal-ref>Journal of Data Science, 2025, 23(1): 90-108</journal-ref><doi>10.6339/24-JDS1138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting is a popular algorithm in supervised machine learning with wide applications in regression and classification problems. It combines weak learners, such as regression trees, to obtain accurate predictions. However, in the presence of outliers, traditional boosting may yield inferior results since the algorithm optimizes a convex loss function. Recent literature has proposed boosting algorithms that optimize robust nonconvex loss functions. Nevertheless, there is a lack of weighted estimation to indicate the outlier status of observations. This article introduces the iteratively reweighted boosting (IRBoost) algorithm, which combines robust loss optimization and weighted estimation. It can be conveniently constructed with existing software. The output includes weights as valuable diagnostics for the outlier status of observations. For practitioners interested in the boosting algorithm, the new method can be interpreted as a way to tune robust observation weights. IRBoost is implemented in the R package irboost and is demonstrated using publicly available data in generalized linear models, classification, and survival data analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2107.00587</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2107.00587</id><created>2021-07-01</created><authors><author><keyname>Lecestre</keyname><forenames>Alexandre</forenames></author></authors><title>Robust Estimation in Finite Mixture Models</title><categories>math.ST stat.TH</categories><msc-class>62G05, 62G35, 62F35 (Primary) 62G07 (Secondary)</msc-class><journal-ref>ESAIM:PS, 27(2023), 402--460</journal-ref><doi>10.1051/ps/2023004</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We observe a $n$-sample, the distribution of which is assumed to belong, or at least to be close enough, to a given mixture model. We propose an estimator of this distribution that belongs to our model and possesses some robustness properties with respect to a possible misspecification of it. We establish a non-asymptotic deviation bound for the Hellinger distance between the target distribution and its estimator when the model consists of a mixture of densities that belong to VC-subgraph classes. Under suitable assumptions and when the mixture model is well-specified, we derive risk bounds for the parameters of the mixture. Finally, we design a statistical procedure that allows us to select from the data the number of components as well as suitable models for each of the densities that are involved in the mixture. These models are chosen among a collection of candidate ones and we show that our selection rule combined with our estimation strategy result in an estimator which satisfies an oracle-type inequality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2107.01120</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2107.01120</id><created>2021-07-02</created><updated>2022-05-25</updated><authors><author><keyname>Naulet</keyname><forenames>Zacharie</forenames></author><author><keyname>Rousseau</keyname><forenames>Judith</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Asymptotic Analysis of Statistical Estimators related to MultiGraphex   Processes under Misspecification</title><categories>math.ST stat.TH</categories><journal-ref>Bernoulli 30(4): 2644-2675, 2024</journal-ref><doi>10.3150/23-BEJ1689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the asymptotic properties of Bayesian or frequentist estimators of a vector of parameters related to structural properties of sequences of graphs. The estimators studied originate from a particular class of graphex model introduced by Caron and Fox. The analysis is however performed here under very weak assumptions on the underlying data generating process, which may be different from the model of Caron and Fox or from a graphex model. In particular, we consider generic sparse graph models, with unbounded degree, whose degree distribution satisfies some assumptions. We show that one can relate the limit of the estimator of one of the parameters to the sparsity constant of the true graph generating process. When taking a Bayesian approach, we also show that the posterior distribution is asymptotically normal. We discuss situations where classical random graphs models such as configuration models, sparse graphon models, edge exchangeable models or graphon processes satisfy our assumptions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2110.06250</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2110.06250</id><created>2021-10-12</created><updated>2025-02-05</updated><authors><author><keyname>Weinstein</keyname><forenames>Asaf</forenames></author></authors><title>On the Minimum Attainable Risk in Permutation Invariant Problems</title><categories>math.ST stat.TH</categories><comments>1 figure</comments><msc-class>62C05, 62C12, 62C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a broad class of permutation invariant statistical problems by extending the standard decision theoretic definition to allow also selective inference tasks, where the target is specified only after seeing the data. For any such problem we show that, among all permutation invariant procedures, the minimizer of the risk at $\boldsymbol{\theta}$ is precisely the rule that minimizes the Bayes risk under a (postulated) discrete prior assigning equal probability to every permutation of $\boldsymbol{\theta}$. This gives an explicit characterization of the greatest lower bound on the risk of every sensible procedure in a wide range of problems. Furthermore, in a permutation invariant problem of estimating the parameter of a selected population under squared loss, we prove that this lower bound coincides asymptotically with a simpler lower bound, attained by the Bayes solution that replaces the aforementioned uniform prior on all permutations of $\boldsymbol{\theta}$ by the i.i.d. prior with the same marginals. This has important algorithmic implications because it suggests that our greatest lower bound is asymptotically attainable uniformly in $\boldsymbol{\theta}$ by an empirical Bayes procedure. Altogether, the above extends theory that has been established in the existing literature only for the very special case of compound decision problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.03513</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.03513</id><created>2022-02-07</created><updated>2025-02-05</updated><authors><author><keyname>Díaz</keyname><forenames>Iván</forenames></author><author><keyname>Hoffman</keyname><forenames>Katherine L</forenames></author><author><keyname>Hejazi</keyname><forenames>Nima S.</forenames></author></authors><title>Causal survival analysis under competing risks using longitudinal   modified treatment policies</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Longitudinal modified treatment policies (LMTP) have been recently developed as a novel method to define and estimate causal parameters that depend on the natural value of treatment. LMTPs represent an important advancement in causal inference for longitudinal studies as they allow the non-parametric definition and estimation of the joint effect of multiple categorical, numerical, or continuous exposures measured at several time points. We extend the LMTP methodology to problems in which the outcome is a time-to-event variable subject to right-censoring and competing risks. We present identification results and non-parametric locally efficient estimators that use flexible data-adaptive regression techniques to alleviate model misspecification bias, while retaining important asymptotic properties such as $\sqrt{n}$-consistency. We present an application to the estimation of the effect of the time-to-intubation on acute kidney injury amongst COVID-19 hospitalized patients, where death by other causes is taken to be the competing event. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.11886</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.11886</id><created>2022-02-23</created><updated>2025-02-04</updated><authors><author><keyname>Jeong</keyname><forenames>Yujin</forenames></author><author><keyname>Rothenhäusler</keyname><forenames>Dominik</forenames></author></authors><title>Calibrated inference: statistical inference that accounts for both   sampling uncertainty and distributional uncertainty</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  How can we draw trustworthy scientific conclusions? One criterion is that a study can be replicated by independent teams. While replication is critically important, it is arguably insufficient. If a study is biased for some reason and other studies recapitulate the approach then findings might be consistently incorrect. It has been argued that trustworthy scientific conclusions require disparate sources of evidence. However, different methods might have shared biases, making it difficult to judge the trustworthiness of a result. We formalize this issue by introducing a "distributional uncertainty model", wherein dense distributional shifts emerge as the superposition of numerous small random changes. The distributional perturbation model arises under a symmetry assumption on distributional shifts and is strictly weaker than assuming that the data is i.i.d. from the target distribution. We show that a stability analysis on a single data set allows us to construct confidence intervals that account for both sampling uncertainty and distributional uncertainty. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2205.08187</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2205.08187</id><created>2022-05-17</created><updated>2023-09-11</updated><authors><author><keyname>Lee</keyname><forenames>Hoil</forenames></author><author><keyname>Ayed</keyname><forenames>Fadhel</forenames></author><author><keyname>Jung</keyname><forenames>Paul</forenames></author><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Yang</keyname><forenames>Hongseok</forenames></author><author><keyname>Caron</keyname><forenames>François</forenames></author></authors><title>Deep neural networks with dependent weights: Gaussian Process mixture   limit, heavy tails, sparsity and compressibility</title><categories>stat.ML cs.LG math.PR math.ST stat.TH</categories><comments>96 pages, 15 figures, 9 tables</comments><msc-class>68T07 (Primary), 62M45, 60F99 (Secondary)</msc-class><journal-ref>Journal Of Machine Learning Research, 24(289):1-78, 2023</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the infinite-width limit of deep feedforward neural networks whose weights are dependent, and modelled via a mixture of Gaussian distributions. Each hidden node of the network is assigned a nonnegative random variable that controls the variance of the outgoing weights of that node. We make minimal assumptions on these per-node random variables: they are iid and their sum, in each layer, converges to some finite random variable in the infinite-width limit. Under this model, we show that each layer of the infinite-width neural network can be characterised by two simple quantities: a non-negative scalar parameter and a L\'evy measure on the positive reals. If the scalar parameters are strictly positive and the L\'evy measures are trivial at all hidden layers, then one recovers the classical Gaussian process (GP) limit, obtained with iid Gaussian weights. More interestingly, if the L\'evy measure of at least one layer is non-trivial, we obtain a mixture of Gaussian processes (MoGP) in the large-width limit. The behaviour of the neural network in this regime is very different from the GP regime. One obtains correlated outputs, with non-Gaussian distributions, possibly with heavy tails. Additionally, we show that, in this regime, the weights are compressible, and some nodes have asymptotically non-negligible contributions, therefore representing important hidden features. Many sparsity-promoting neural network models can be recast as special cases of our approach, and we discuss their infinite-width limits; we also present an asymptotic analysis of the pruning error. We illustrate some of the benefits of the MoGP regime over the GP regime in terms of representation learning and compressibility on simulated, MNIST and Fashion MNIST datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2206.02204</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2206.02204</id><created>2022-06-05</created><updated>2025-02-05</updated><authors><author><keyname>Lu</keyname><forenames>Jun</forenames></author><author><keyname>Mao</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Li</keyname><forenames>Mengyao</forenames></author><author><keyname>Hou</keyname><forenames>Chenping</forenames></author></authors><title>Adaptive weighted approach for high-dimensional statistical learning and   inference</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We propose a new weighted average estimator for the high dimensional parameters under the distributed learning system, in which the weight assigned to each coordinate is precisely proportional to the inverse of the variance of the local estimates for that coordinate. This strategy empowers the new estimator to achieve a minimal mean squared error, comparable to the current state-of-the-art one-shot distributed learning methods. While at the same time, the new weighting approach maintains remarkably low communication costs, as each agent is required to transmit only two vectors to the central server. As a result, the newly proposed method achieves optimal statistical efficiency while significantly reducing communication overhead. We further demonstrate the effectiveness of the new estimator by investigating the error bound and the asymptotic properties of the estimation, as well as the numerical performance on some simulated examples and a real data analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2208.07853</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2208.07853</id><created>2022-08-16</created><updated>2025-02-05</updated><authors><author><keyname>Neto</keyname><forenames>Jeova Farias Sales Rocha</forenames></author></authors><title>Estimating Appearance Models for Image Segmentation via Tensor   Factorization</title><categories>cs.CV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Image Segmentation is one of the core tasks in Computer Vision and solving it often depends on modeling the image appearance data via the color distributions of each it its constituent regions. Whereas many segmentation algorithms handle the appearance models dependence using alternation or implicit methods, we propose here a new approach to directly estimate them from the image without prior information on the underlying segmentation. Our method uses local high order color statistics from the image as an input to tensor factorization-based estimator for latent variable models. This approach is able to estimate models in multiregion images and automatically output the regions proportions without prior user interaction, overcoming the drawbacks from a prior attempt to this problem. We also demonstrate the performance of our proposed method in many challenging synthetic and real imaging scenarios and show that it leads to an efficient segmentation algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2211.02609</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2211.02609</id><created>2022-11-04</created><updated>2025-02-05</updated><authors><author><keyname>Costello</keyname><forenames>Fintan</forenames></author><author><keyname>Watts</keyname><forenames>Paul</forenames></author></authors><title>How to Tell When a Result Will Replicate: Significance and Replication   in Distributional Null Hypothesis Tests</title><categories>stat.ME math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  There is a well-known problem in Null Hypothesis Significance Testing: many statistically significant results fail to replicate in subsequent experiments. We show that this problem arises because standard `point-form null' significance tests consider only within-experiment but ignore between-experiment variation, and so systematically underestimate the degree of random variation in results. We give an extension to standard significance testing that addresses this problem by analysing both within- and between-experiment variation. This `distributional null' approach does not underestimate experimental variability and so is not overconfident in identifying significance; because this approach addresses between-experiment variation, it gives mathematically coherent estimates for the probability of replication of significant results. Using a large-scale replication dataset (the first `Many Labs' project), we show that many experimental results that appear statistically significant in standard tests are in fact consistent with random variation when both within- and between-experiment variation are taken into account in this approach. Further, grouping experiments in this dataset into `predictor-target' pairs we show that the predicted replication probabilities for target experiments produced in this approach (given predictor experiment results and the sample sizes of the two experiments) are strongly correlated with observed replication rates. Distributional null hypothesis testing thus gives researchers a statistical tool for identifying statistically significant and reliably replicable results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2303.11293</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2303.11293</id><created>2023-03-13</created><updated>2025-02-05</updated><authors><author><keyname>Pran</keyname><forenames>Rakib Hassan</forenames></author></authors><title>Advancing Network Securing Strategies with Network Algorithms for   Integrated Air Defense System (IADS) Missile Batteries</title><categories>cs.SI stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently, the Integrated Air Defense System (IADS) has become vital for the defense system as the military defense system is vital for national security. Placing Integrated Air Defense System batteries among locations to protect locations assets is a crucial problem because optimal solutions are needed for interceptor missiles to intercept attacker missiles for maximizing protection of assets across locations or places. In this research, the procedures of using network algorithms along with developing several network algorithms are going to be demonstrated to develop a model for sequential development of seven network securing strategies of placing Surface to Air Missile (SAM) batteries to maximize the protection of assets across locations (based on given asset values) by generating optimal solutions through computation to destroy maximum attacker missiles by using minimum interceptor missiles with given intercept probability. This network securing strategies can be implemented not only for Integrated Air Defense System (IADS) planning but also Counter Air (CA) planning as Integrated Air Defense System (IADS) is conducted with defensive counter air supported by attack operations in offensive counter air. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.05242</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.05242</id><created>2023-04-11</created><updated>2025-02-05</updated><authors><author><keyname>Baouan</keyname><forenames>Ali</forenames></author><author><keyname>Coustou</keyname><forenames>Sébastien</forenames></author><author><keyname>Lacome</keyname><forenames>Mathieu</forenames></author><author><keyname>Pulido</keyname><forenames>Sergio</forenames></author><author><keyname>Rosenbaum</keyname><forenames>Mathieu</forenames></author></authors><title>Generation of Threat: Crediting football players for creating dangerous   actions in an unbiased way</title><categories>stat.AP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We introduce an innovative methodology to identify football players at the origin of threatening actions in a team. In our framework, a threat is defined as entering the opposing team's danger area. We investigate the timing of threat events and ball touches of players, and capture their correlation using Hawkes processes. Our model-based approach allows us to evaluate a player's ability to create danger both directly and through interactions with teammates. We define a new index, called Generation of Threat (GoT), that measures in an unbiased way the contribution of a player to threat generation. For illustration, we present a detailed analysis of Chelsea's 2016-2017 season, with a standout performance from Eden Hazard. We are able to credit each player for his involvement in danger creation and determine the main circuits leading to threat. In the same spirit, we investigate the danger generation process of Stade Rennais in the 2021-2022 season. Furthermore, we establish a comprehensive ranking of Ligue 1 players based on their generated threat in the 2021-2022 season. Our analysis reveals surprising results, with players such as Jason Berthomier, Moses Simon and Frederic Guilbert among the top performers in the GoT rankings. We also present a ranking of Ligue 1 central defenders in terms of generation of threat and confirm the great performance of some center-back pairs, such as Nayef Aguerd and Warmed Omari. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.12218</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.12218</id><created>2023-04-24</created><updated>2025-02-05</updated><authors><author><keyname>Clarke</keyname><forenames>Bertrand</forenames></author><author><keyname>Yao</keyname><forenames>Yuling</forenames></author></authors><title>A Cheat Sheet for Bayesian Prediction</title><categories>stat.ME</categories><comments>23 pages</comments><msc-class>62-02</msc-class><journal-ref>Statist. Sci. 2025, Vol. 40, 3-24</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper reviews the growing field of Bayesian prediction. Bayes point and interval prediction are defined and exemplified and situated in statistical prediction more generally. Then, four general approaches to Bayes prediction are defined and we turn to predictor selection. This can be done predictively or non-predictively and predictors can be based on single models or multiple models. We call these latter cases unitary predictors and model average predictors, respectively. Then we turn to the most recent aspect of prediction to emerge, namely prediction in the context of large observational data sets and discuss three further classes of techniques. We conclude with a summary and statement of several current open problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.05153</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.05153</id><created>2023-12-08</created><updated>2025-02-05</updated><authors><author><keyname>Reiser</keyname><forenames>Philipp</forenames></author><author><keyname>Aguilar</keyname><forenames>Javier Enrique</forenames></author><author><keyname>Guthke</keyname><forenames>Anneli</forenames></author><author><keyname>Bürkner</keyname><forenames>Paul-Christian</forenames></author></authors><title>Uncertainty Quantification and Propagation in Surrogate-based Bayesian   Inference</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Surrogate models are statistical or conceptual approximations for more complex simulation models. In this context, it is crucial to propagate the uncertainty induced by limited simulation budget and surrogate approximation error to predictions, inference, and subsequent decision-relevant quantities. However, quantifying and then propagating the uncertainty of surrogates is usually limited to special analytic cases or is otherwise computationally very expensive. In this paper, we propose a framework enabling a scalable, Bayesian approach to surrogate modeling with thorough uncertainty quantification, propagation, and validation. Specifically, we present three methods for Bayesian inference with surrogate models given measurement data. This is a task where the propagation of surrogate uncertainty is especially relevant, because failing to account for it may lead to biased and/or overconfident estimates of the parameters of interest. We showcase our approach in three detailed case studies for linear and nonlinear real-world modeling scenarios. Uncertainty propagation in surrogate models enables more reliable and safe approximation of expensive simulators and will therefore be useful in various fields of applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.04933</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.04933</id><created>2024-02-07</created><updated>2025-02-05</updated><authors><author><keyname>Liang</keyname><forenames>Biyonka</forenames></author><author><keyname>Xu</keyname><forenames>Lily</forenames></author><author><keyname>Taneja</keyname><forenames>Aparna</forenames></author><author><keyname>Tambe</keyname><forenames>Milind</forenames></author><author><keyname>Janson</keyname><forenames>Lucas</forenames></author></authors><title>Context in Public Health for Underserved Communities: A Bayesian   Approach to Online Restless Bandits</title><categories>cs.LG stat.AP</categories><comments>29 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public health programs often provide interventions to encourage program adherence, and effectively allocating interventions is vital for producing the greatest overall health outcomes, especially in underserved communities where resources are limited. Such resource allocation problems are often modeled as restless multi-armed bandits (RMABs) with unknown underlying transition dynamics, hence requiring online reinforcement learning (RL). We present Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs that novelly combines techniques in Bayesian modeling with Thompson sampling to flexibly model the complex RMAB settings present in public health program adherence problems, namely context and non-stationarity. BCoR's key strength is the ability to leverage shared information within and between arms to learn the unknown RMAB transition dynamics quickly in intervention-scarce settings with relatively short time horizons, which is common in public health applications. Empirically, BCoR achieves substantially higher finite-sample performance over a range of experimental settings, including a setting using real-world adherence data that was developed in collaboration with ARMMAN, an NGO in India which runs a large-scale maternal mHealth program, showcasing BCoR practical utility and potential for real-world deployment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.14645</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.14645</id><created>2024-02-22</created><updated>2025-02-04</updated><authors><author><keyname>Gupte</keyname><forenames>Aparna</forenames></author><author><keyname>Vafa</keyname><forenames>Neekon</forenames></author><author><keyname>Vaikuntanathan</keyname><forenames>Vinod</forenames></author></authors><title>Sparse Linear Regression and Lattice Problems</title><categories>cs.LG stat.ML</categories><comments>TCC 2024; minor edits</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse linear regression (SLR) is a well-studied problem in statistics where one is given a design matrix $X\in\mathbb{R}^{m\times n}$ and a response vector $y=X\theta^*+w$ for a $k$-sparse vector $\theta^*$ (that is, $\|\theta^*\|_0\leq k$) and small, arbitrary noise $w$, and the goal is to find a $k$-sparse $\widehat{\theta} \in \mathbb{R}^n$ that minimizes the mean squared prediction error $\frac{1}{m}\|X\widehat{\theta}-X\theta^*\|^2_2$. While $\ell_1$-relaxation methods such as basis pursuit, Lasso, and the Dantzig selector solve SLR when the design matrix is well-conditioned, no general algorithm is known, nor is there any formal evidence of hardness in an average-case setting with respect to all efficient algorithms.   We give evidence of average-case hardness of SLR w.r.t. all efficient algorithms assuming the worst-case hardness of lattice problems. Specifically, we give an instance-by-instance reduction from a variant of the bounded distance decoding (BDD) problem on lattices to SLR, where the condition number of the lattice basis that defines the BDD instance is directly related to the restricted eigenvalue condition of the design matrix, which characterizes some of the classical statistical-computational gaps for sparse linear regression. Also, by appealing to worst-case to average-case reductions from the world of lattices, this shows hardness for a distribution of SLR instances; while the design matrices are ill-conditioned, the resulting SLR instances are in the identifiable regime.   Furthermore, for well-conditioned (essentially) isotropic Gaussian design matrices, where Lasso is known to behave well in the identifiable regime, we show hardness of outputting any good solution in the unidentifiable regime where there are many solutions, assuming the worst-case hardness of standard and well-studied lattice problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.18213</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.18213</id><created>2024-02-28</created><updated>2025-02-04</updated><authors><author><keyname>Sukthanker</keyname><forenames>Rhea Sanjay</forenames></author><author><keyname>Zela</keyname><forenames>Arber</forenames></author><author><keyname>Staffler</keyname><forenames>Benedikt</forenames></author><author><keyname>Dooley</keyname><forenames>Samuel</forenames></author><author><keyname>Grabocka</keyname><forenames>Josif</forenames></author><author><keyname>Hutter</keyname><forenames>Frank</forenames></author></authors><title>Multi-objective Differentiable Neural Architecture Search</title><categories>cs.LG cs.CV stat.ML</categories><comments>44 pages, 34 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Pareto front profiling in multi-objective optimization (MOO), i.e., finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives that require training a neural network. Typically, in MOO for neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a computationally expensive search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences to trade-off performance and hardware metrics, yielding representative and diverse architectures across multiple devices in just a single search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot transferability to new devices. Extensive experiments involving up to 19 hardware devices and 3 different objectives demonstrate the effectiveness and scalability of our method. Finally, we show that, without any additional costs, our method outperforms existing MOO NAS methods across a broad range of qualitatively different search spaces and datasets, including MobileNetV3 on ImageNet-1k, an encoder-decoder transformer space for machine translation and a decoder-only space for language modelling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.02233</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.02233</id><created>2024-03-04</created><updated>2025-02-05</updated><authors><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Wen</keyname><forenames>Zixin</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author></authors><title>A Theoretical Analysis of Self-Supervised Learning for Vision   Transformers</title><categories>cs.LG math.OC stat.ML</categories><comments>Accepted by ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-supervised learning has become a cornerstone in computer vision, primarily divided into reconstruction-based methods like masked autoencoders (MAE) and discriminative methods such as contrastive learning (CL). Recent empirical observations reveal that MAE and CL capture different types of representations: CL tends to focus on global patterns, while MAE adeptly captures both global and subtle local information simultaneously. Despite a flurry of recent empirical investigations to shed light on this difference, theoretical understanding remains limited, especially on the dominant architecture vision transformers (ViTs). In this paper, to provide rigorous insights, we model the visual data distribution by considering two types of spatial features: dominant global features and comparatively minuscule local features, and study the impact of imbalance among these features. We analyze the training dynamics of one-layer softmax-based ViTs on both MAE and CL objectives using gradient descent. Our analysis shows that as the degree of feature imbalance varies, ViTs trained with the MAE objective effectively learn both global and local features to achieve near-optimal reconstruction, while the CL-trained ViTs favor predominantly global features, even under mild imbalance. These results provide a theoretical explanation for distinct behaviors of MAE and CL observed in empirical studies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.05038</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.05038</id><created>2024-03-07</created><updated>2025-02-04</updated><authors><author><keyname>Krantz</keyname><forenames>Sebastian</forenames></author></authors><title>collapse: Advanced and Fast Statistical Computing and Data   Transformation in R</title><categories>stat.CO</categories><comments>32 pages, 0 figures. Submitted to the Journal of Statistical Software</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  collapse is a large C/C++-based infrastructure package facilitating complex statistical computing, data transformation, and exploration tasks in R - at outstanding levels of performance and memory efficiency. It also implements a class-agnostic approach to R programming, supporting vector, matrix and data frame-like objects and their popular extensions (units, integer64, xts, tibble, data.table, sf, pdata.frame), enabling its seamless integration with large parts of the R ecosystem. This article introduces the package's key components and design principles in a structured way, supported by a rich set of examples. A small benchmark demonstrates its computational performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.14337</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.14337</id><created>2024-04-22</created><updated>2025-02-05</updated><authors><author><keyname>Sadeghi</keyname><forenames>Agathe</forenames></author><author><keyname>Feinstein</keyname><forenames>Zachary</forenames></author></authors><title>Statistical Validation of Contagion Centrality in Financial Networks</title><categories>q-fin.MF q-fin.RM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an impact centrality measure to evaluate shock propagation on financial networks capturing a notion of contagion and systemic risk contributions, permitting comparisons of these risks over time. In addition, we provide a statistical validation method when the network is estimated from data, as is done in practice. This statistical test allows us to reliably assess the computed centrality values. We validate our methodology on simulated data and conduct empirical case studies using financial data. We find that our proposed centrality measure increases significantly during times of financial distress and is able to provide insights into the (market implied) risk-levels of different firms and sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.02140</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.02140</id><created>2024-05-03</created><updated>2024-06-26</updated><authors><author><keyname>Correia</keyname><forenames>Alvaro H. C.</forenames></author><author><keyname>Massoli</keyname><forenames>Fabio Valerio</forenames></author><author><keyname>Louizos</keyname><forenames>Christos</forenames></author><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author></authors><title>An Information Theoretic Perspective on Conformal Prediction</title><categories>cs.LG cs.IT math.IT stat.ML</categories><journal-ref>Advances in Neural Information Processing Systems 37 (NeurIPS   2024)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conformal Prediction (CP) is a distribution-free uncertainty estimation framework that constructs prediction sets guaranteed to contain the true answer with a user-specified probability. Intuitively, the size of the prediction set encodes a general notion of uncertainty, with larger sets associated with higher degrees of uncertainty. In this work, we leverage information theory to connect conformal prediction to other notions of uncertainty. More precisely, we prove three different ways to upper bound the intrinsic uncertainty, as described by the conditional entropy of the target variable given the inputs, by combining CP with information theoretical inequalities. Moreover, we demonstrate two direct and useful applications of such connection between conformal prediction and information theory: (i) more principled and effective conformal training objectives that generalize previous approaches and enable end-to-end training of machine learning models from scratch, and (ii) a natural mechanism to incorporate side information into conformal prediction. We empirically validate both applications in centralized and federated learning settings, showing our theoretical results translate to lower inefficiency (average prediction set size) for popular CP methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.05238</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.05238</id><created>2024-05-08</created><updated>2025-02-04</updated><authors><author><keyname>Glazer</keyname><forenames>Amanda K.</forenames></author><author><keyname>Stark</keyname><forenames>Philip B.</forenames></author></authors><title>Fast Conservative Monte Carlo Confidence Intervals</title><categories>stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Extant "fast" algorithms for Monte Carlo confidence sets are limited to univariate shift parameters for the one-sample and two-sample problems using the sample mean as the test statistic; moreover, some do not converge reliably and most do not produce conservative confidence sets. We outline general methods for constructing confidence sets for real-valued and multidimensional parameters by inverting Monte Carlo tests using any test statistic and a broad range of randomization schemes. The method exploits two facts that, to our knowledge, had not been combined: (i) there are Monte Carlo tests that are conservative despite relying on simulation, and (ii) since the coverage probability of confidence sets depends only on the significance level of the test of the true null, every null can be tested using the same Monte Carlo sample. The Monte Carlo sample can be arbitrarily small, although the highest nontrivial attainable confidence level generally increases as the number $N$ of Monte Carlo replicates increases. We present open-source Python and R implementations of new algorithms to compute conservative confidence sets for real-valued and multidimensional parameters from Monte Carlo tests, for test statistics and randomization schemes that yield $P$-values that are monotone or weakly unimodal in the parameter, with the data and Monte Carlo sample held fixed. In this case, the new method finds conservative confidence sets for real-valued parameters in $O(n)$ time, where $n$ is the number of data. The values of some test statistics for different simulations and parameter values have a simple relationship that makes more savings possible. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.07432</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.07432</id><created>2024-05-12</created><updated>2025-02-04</updated><authors><author><keyname>Hou</keyname><forenames>Boya</forenames></author><author><keyname>Sanjari</keyname><forenames>Sina</forenames></author><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author></authors><title>Nonparametric Sparse Online Learning of the Koopman Operator</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>49 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.11751</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.11751</id><created>2024-05-19</created><updated>2025-02-04</updated><authors><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author><author><keyname>Letey</keyname><forenames>Mary I.</forenames></author><author><keyname>Zavatone-Veth</keyname><forenames>Jacob A.</forenames></author><author><keyname>Maiti</keyname><forenames>Anindita</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Asymptotic theory of in-context learning by linear attention</title><categories>stat.ML cond-mat.dis-nn cs.LG</categories><comments>17 pages (main doc), 6 figures, and supplementary information (23   pages)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transformers have a remarkable ability to learn and execute tasks based on examples provided within the input itself, without explicit prior training. It has been argued that this capability, known as in-context learning (ICL), is a cornerstone of Transformers' success, yet questions about the necessary sample complexity, pretraining task diversity, and context length for successful ICL remain unresolved. Here, we provide a precise answer to these questions in an exactly solvable model of ICL of a linear regression task by linear attention. We derive sharp asymptotics for the learning curve in a phenomenologically-rich scaling regime where the token dimension is taken to infinity; the context length and pretraining task diversity scale proportionally with the token dimension; and the number of pretraining examples scales quadratically. We demonstrate a double-descent learning curve with increasing pretraining examples, and uncover a phase transition in the model's behavior between low and high task diversity regimes: In the low diversity regime, the model tends toward memorization of training tasks, whereas in the high diversity regime, it achieves genuine in-context learning and generalization beyond the scope of pretrained tasks. These theoretical insights are empirically validated through experiments with both linear attention and full nonlinear Transformer architectures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.13690</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.13690</id><created>2024-05-22</created><updated>2025-02-05</updated><authors><author><keyname>Massa</keyname><forenames>Emanuele</forenames></author><author><keyname>Coolen</keyname><forenames>Anthony</forenames></author></authors><title>Observable asymptotics of regularized Cox regression models with   standard Gaussian designs: a statistical mechanics approach</title><categories>math.ST cond-mat.dis-nn stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic behaviour of the Regularized Maximum Partial Likelihood Estimator (RMPLE) in the proportional limit, considering an arbitrary convex regularizer and assuming that the covariates $\mathbf{X}_i\in\mathbb{R}^{p}$ follow a multivariate Gaussian law with covariance $\mathbf{I}_p/p$ for each $i=1, \dots, n$. In order to efficiently compute the estimator under investigation, we propose a modified Approximate Message Passing (AMP) algorithm, that we name COX-AMP, and compare its performance with the Coordinate-wise Descent (CD) algorithm, which is taken as reference. By means of the Replica method, we derive a set of six Replica Symmetric (RS) equations that we show to correctly describe the average behaviour of the estimators when the sample size and the number of covariates is large and commensurate. These equations cannot be solved in practice, as the data generating process (that we are trying to estimate) is not known. However, the update equations of COX-AMP suggest the construction of a local field that can in turn be used to accurately estimate all the RS order parameters of the theory \emph{solely from the data}, \emph{without} actually solving the RS equations. We emphasize that this approach can be applied when the estimator is computed via any method and is not restricted to COX-AMP. Once the RS order parameters are estimated, we have access to the amount of signal and noise in the RMPLE, but also its generalization error, directly from the data. Although we focus on the Partial Likelihood objective, we envisage broader application of the methodology proposed here, for instance to GLMs with nuisance parameters, which include some non-proportional hazards models, e.g. Accelerated Failure Time models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.15885</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.15885</id><created>2024-05-24</created><updated>2025-02-05</updated><authors><author><keyname>Zheng</keyname><forenames>Kaiwen</forenames></author><author><keyname>He</keyname><forenames>Guande</forenames></author><author><keyname>Chen</keyname><forenames>Jianfei</forenames></author><author><keyname>Bao</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>Jun</forenames></author></authors><title>Diffusion Bridge Implicit Models</title><categories>cs.LG stat.ML</categories><comments>Accepted at ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at https://github.com/thu-ml/DiffusionBridge. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.15887</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.15887</id><created>2024-05-24</created><updated>2025-02-04</updated><authors><author><keyname>Thiyageswaran</keyname><forenames>Vydhourie</forenames></author><author><keyname>McCormick</keyname><forenames>Tyler</forenames></author><author><keyname>Brennan</keyname><forenames>Jennifer</forenames></author></authors><title>Data-adaptive exposure thresholds for the Horvitz-Thompson estimator of   the Average Treatment Effect in experiments with network interference</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Randomized controlled trials often suffer from interference, a violation of the Stable Unit Treatment Values Assumption (SUTVA) in which a unit's treatment assignment affects the outcomes of its neighbors. This interference causes bias in naive estimators of the average treatment effect (ATE). A popular method to achieve unbiasedness is to pair the Horvitz-Thompson estimator of the ATE with a known exposure mapping: a function that identifies which units in a given randomization are not subject to interference. For example, an exposure mapping can specify that any unit with at least $h$-fraction of its neighbors having the same treatment status does not experience interference. However, this threshold $h$ is difficult to elicit from domain experts, and a misspecified threshold can induce bias. In this work, we propose a data-adaptive method to select the "$h$"-fraction threshold that minimizes the mean squared error of the Hortvitz-Thompson estimator. Our method estimates the bias and variance of the Horvitz-Thompson estimator under different thresholds using a linear dose-response model of the potential outcomes. We present simulations illustrating that our method improves upon non-adaptive choices of the threshold. We further illustrate the performance of our estimator by running experiments on a publicly-available Amazon product similarity graph. Furthermore, we demonstrate that our method is robust to deviations from the linear potential outcomes model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.19466</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.19466</id><created>2024-05-29</created><updated>2025-02-05</updated><authors><author><keyname>Cai</keyname><forenames>Tiffany Tianhui</forenames></author><author><keyname>Namkoong</keyname><forenames>Hongseok</forenames></author><author><keyname>Russo</keyname><forenames>Daniel</forenames></author><author><keyname>Zhang</keyname><forenames>Kelly W</forenames></author></authors><title>Active Exploration via Autoregressive Generation of Missing Data</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We pose uncertainty quantification and exploration in online decision-making as a problem of training and generation from an autoregressive sequence model, an area experiencing rapid innovation. Our approach rests on viewing uncertainty as arising from missing future outcomes that would be revealed through appropriate action choices, rather than from unobservable latent parameters of the environment. This reformulation aligns naturally with modern machine learning capabilities: we can i) train generative models through next-outcome prediction rather than fit explicit priors, ii) assess uncertainty through autoregressive generation rather than parameter sampling, and iii) adapt to new information through in-context learning rather than explicit posterior updating. To showcase these ideas, we formulate a challenging meta-bandit problem where effective performance requires leveraging unstructured prior information (like text features) while exploring judiciously to resolve key remaining uncertainties. We validate our approach through both theory and experiments. Our theory establishes a reduction, showing success at offline next-outcome prediction translates to reliable online uncertainty quantification and decision-making, even with strategically collected data. Semi-synthetic experiments show our insights bear out in a news-article recommendation task, where article text can be leveraged to minimize exploration. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.05242</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.05242</id><created>2024-06-07</created><updated>2025-02-05</updated><authors><author><keyname>Yuan</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Guanyang</forenames></author></authors><title>Markov chain Monte Carlo without evaluating the target: an auxiliary   variable approach</title><categories>stat.CO stat.ME stat.ML</categories><comments>62 pages, 13 figures, 3 tables. Add additional illustrations and   experiments. Codes available at https://github.com/ywwes26/MCMC-Auxiliary</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sampling tasks, it is common for target distributions to be known up to a normalizing constant. However, in many situations, even evaluating the unnormalized distribution can be costly or infeasible. This issue arises in scenarios such as sampling from the Bayesian posterior for tall datasets and the 'doubly-intractable' distributions. In this paper, we begin by observing that seemingly different Markov chain Monte Carlo (MCMC) algorithms, such as the exchange algorithm, PoissonMH, and TunaMH, can be unified under a simple common procedure. We then extend this procedure into a novel framework that allows the use of auxiliary variables in both the proposal and the acceptance-rejection step. Several new MCMC algorithms emerge from this framework that utilize estimated gradients to guide the proposal moves. They have demonstrated significantly better performance than existing methods on both synthetic and real datasets. Additionally, we develop the theory of the new framework and apply it to existing algorithms to simplify and extend their results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.02700</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.02700</id><created>2024-07-02</created><updated>2025-02-04</updated><authors><author><keyname>Rojas</keyname><forenames>Helder</forenames></author><author><keyname>Rojas</keyname><forenames>Nilton</forenames></author><author><keyname>B.</keyname><forenames>Espinoza J.</forenames></author><author><keyname>Huamanchumo</keyname><forenames>Luis</forenames></author></authors><title>A simple algorithm for output range analysis for deep neural networks</title><categories>cs.LG math.PR stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a novel approach for the output range estimation problem in Deep Neural Networks (DNNs) by integrating a Simulated Annealing (SA) algorithm tailored to operate within constrained domains and ensure convergence towards global optima. The method effectively addresses the challenges posed by the lack of local geometric information and the high non-linearity inherent to DNNs, making it applicable to a wide variety of architectures, with a special focus on Residual Networks (ResNets) due to their practical importance. Unlike existing methods, our algorithm imposes minimal assumptions on the internal architecture of neural networks, thereby extending its usability to complex models. Theoretical analysis guarantees convergence, while extensive empirical evaluations-including optimization tests involving functions with multiple local minima-demonstrate the robustness of our algorithm in navigating non-convex response surfaces. The experimental results highlight the algorithm's efficiency in accurately estimating DNN output ranges, even in scenarios characterized by high non-linearity and complex constraints. For reproducibility, Python codes and datasets used in the experiments are publicly available through our GitHub repository. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.12482</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.12482</id><created>2024-08-22</created><updated>2025-02-04</updated><authors><author><keyname>Rodríguez</keyname><forenames>Ignacio Echave-Sustaeta</forenames></author><author><keyname>Röttger</keyname><forenames>Frank</forenames></author></authors><title>Latent Gaussian and H\"usler--Reiss Graphical Models with Golazo Penalty</title><categories>stat.ME math.ST stat.TH</categories><comments>20 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of latent variables in practical problems is common, for example when some variables are difficult or expensive to measure, or simply unknown. When latent variables are unaccounted for, structure learning for Gaussian graphical models can be blurred by additional correlation between the observed variables that is incurred by the latent variables. A standard approach for this problem is a latent version of the graphical lasso that splits the inverse covariance matrix into a sparse and a low-rank part that are penalized separately. This approach has recently been extended successfully to H\"usler--Reiss graphical models, which can be considered as an analogue of Gaussian graphical models in extreme value statistics. In this paper we propose a generalization of structure learning for Gaussian and H\"usler--Reiss graphical models via the flexible Golazo penalty. This allows us to introduce latent versions of for example the adaptive lasso, positive dependence constraints or predetermined sparsity patterns, and combinations of those. We develop algorithms for both latent graphical models with the Golazo penalty and demonstrate them on simulated and real data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.12830</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.12830</id><created>2024-08-23</created><updated>2025-02-05</updated><authors><author><keyname>Luo</keyname><forenames>Wang</forenames></author><author><keyname>Li</keyname><forenames>Haoran</forenames></author><author><keyname>Zhang</keyname><forenames>Zicheng</forenames></author><author><keyname>Han</keyname><forenames>Congying</forenames></author><author><keyname>Lv</keyname><forenames>Jiayu</forenames></author><author><keyname>Guo</keyname><forenames>Tiande</forenames></author></authors><title>SAMBO-RL: Shifts-aware Model-based Offline Reinforcement Learning</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based offline reinforcement learning trains policies using pre-collected datasets and learned environment models, eliminating the need for direct real-world environment interaction. However, this paradigm is inherently challenged by distribution shift (DS). Existing methods address this issue by leveraging off-policy mechanisms and estimating model uncertainty, but they often result in inconsistent objectives and lack a unified theoretical foundation. This paper offers a comprehensive analysis that disentangles the problem into two fundamental components: model bias and policy shift. Our theoretical and empirical investigations reveal how these factors distort value estimation and restrict policy optimization. To tackle these challenges, we derive a novel Shifts-aware Reward (SAR) through a unified probabilistic inference framework, which modifies the vanilla reward to refine value learning and facilitate policy training. Building on this, we introduce Shifts-aware Model-based Offline Reinforcement Learning (SAMBO-RL), a practical framework that efficiently trains classifiers to approximate SAR for policy optimization. Empirical experiments show that SAR effectively mitigates DS, and SAMBO-RL achieves superior or comparable performance across various benchmarks, underscoring its effectiveness and validating our theoretical analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.03845</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.03845</id><created>2024-09-05</created><updated>2025-02-05</updated><authors><author><keyname>Cheng</keyname><forenames>Sheng</forenames></author><author><keyname>Kong</keyname><forenames>Deqian</forenames></author><author><keyname>Xie</keyname><forenames>Jianwen</forenames></author><author><keyname>Lee</keyname><forenames>Kookjin</forenames></author><author><keyname>Wu</keyname><forenames>Ying Nian</forenames></author><author><keyname>Yang</keyname><forenames>Yezhou</forenames></author></authors><title>Latent Space Energy-based Neural ODEs</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces novel deep dynamical models designed to represent continuous-time sequences. Our approach employs a neural emission model to generate each data point in the time series through a non-linear transformation of a latent state vector. The evolution of these latent states is implicitly defined by a neural ordinary differential equation (ODE), with the initial state drawn from an informative prior distribution parameterized by an Energy-based model (EBM). This framework is extended to disentangle dynamic states from underlying static factors of variation, represented as time-invariant variables in the latent space. We train the model using maximum likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end manner. Experimental results on oscillating systems, videos and real-world state sequences (MuJoCo) demonstrate that our model with the learnable energy-based prior outperforms existing counterparts, and can generalize to new dynamic parameterization, enabling long-horizon predictions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.14557</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.14557</id><created>2024-09-22</created><updated>2025-02-05</updated><authors><author><keyname>Wan</keyname><forenames>Jia</forenames></author><author><keyname>Sinclair</keyname><forenames>Sean R.</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Exploiting Exogenous Structure for Sample-Efficient Reinforcement   Learning</title><categories>stat.ML cs.LG math.OC</categories><comments>43 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Exo-MDPs, a structured class of Markov Decision Processes (MDPs) where the state space is partitioned into exogenous and endogenous components. Exogenous states evolve stochastically, independent of the agent's actions, while endogenous states evolve deterministically based on both state components and actions. Exo-MDPs are useful for applications including inventory control, portfolio management, and ride-sharing. Our first result is structural, establishing a representational equivalence between the classes of discrete MDPs, Exo-MDPs, and discrete linear mixture MDPs. Specifically, any discrete MDP can be represented as an Exo-MDP, and the transition and reward dynamics can be written as linear functions of the exogenous state distribution, showing that Exo-MDPs are instances of linear mixture MDPs. For unobserved exogenous states, we prove a regret upper bound of $O(H^{3/2}d\sqrt{K})$ over $K$ trajectories of horizon $H$, with $d$ as the size of the exogenous state space, and establish nearly-matching lower bounds. Our findings demonstrate how Exo-MDPs decouple sample complexity from action and endogenous state sizes, and we validate our theoretical insights with experiments on inventory control. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.18959</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.18959</id><created>2024-10-24</created><updated>2025-02-04</updated><authors><author><keyname>Williams</keyname><forenames>Andrew Robert</forenames></author><author><keyname>Ashok</keyname><forenames>Arjun</forenames></author><author><keyname>Marcotte</keyname><forenames>Étienne</forenames></author><author><keyname>Zantedeschi</keyname><forenames>Valentina</forenames></author><author><keyname>Subramanian</keyname><forenames>Jithendaraa</forenames></author><author><keyname>Riachi</keyname><forenames>Roland</forenames></author><author><keyname>Requeima</keyname><forenames>James</forenames></author><author><keyname>Lacoste</keyname><forenames>Alexandre</forenames></author><author><keyname>Rish</keyname><forenames>Irina</forenames></author><author><keyname>Chapados</keyname><forenames>Nicolas</forenames></author><author><keyname>Drouin</keyname><forenames>Alexandre</forenames></author></authors><title>Context is Key: A Benchmark for Forecasting with Essential Textual   Information</title><categories>cs.LG cs.AI stat.ML</categories><comments>Preprint; under review. First two authors contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Forecasting is a critical task in decision-making across numerous domains. While historical numerical data provide a start, they fail to convey the complete context for reliable and accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge and constraints, which can efficiently be communicated through natural language. However, in spite of recent progress with LLM-based forecasters, their ability to effectively integrate this textual information remains an open question. To address this, we introduce "Context is Key" (CiK), a time-series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities; crucially, every task in CiK requires understanding textual context to be solved successfully. We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. This benchmark aims to advance multimodal forecasting by promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://anon-forecast.github.io/benchmark_report_dev/. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.22333</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.22333</id><created>2024-10-29</created><updated>2025-02-05</updated><authors><author><keyname>Koch</keyname><forenames>Lukas</forenames></author></authors><title>Hypothesis tests and model parameter estimation on data sets with   missing correlation information</title><categories>stat.ME hep-ph stat.AP</categories><comments>19 pages, 10 figures; follow-up of arxiv.org:2102.06172; Fixed some   typos, made tables prettier, added funding</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ideally, all analyses of normally distributed data should include the full covariance information between all data points. In practice, the full covariance matrix between all data points is not always available. Either because a result was published without a covariance matrix, or because one tries to combine multiple results from separate publications. For simple hypothesis tests, it is possible to define robust test statistics that will behave conservatively in the presence on unknown correlations. For model parameter fits, one can inflate the variance by a factor to ensure that things remain conservative at least up to a chosen confidence level. This paper describes a class of robust test statistics for simple hypothesis tests, as well as an algorithm to determine the necessary inflation factor for model parameter fits and Goodness of Fit tests and composite hypothesis tests. It then presents some example applications of the methods to real neutrino interaction data and model comparisons. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.06568</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.06568</id><created>2024-11-10</created><updated>2025-02-04</updated><authors><author><keyname>Alfano</keyname><forenames>Carlo</forenames></author><author><keyname>Sapora</keyname><forenames>Silvia</forenames></author><author><keyname>Foerster</keyname><forenames>Jakob Nicolaus</forenames></author><author><keyname>Rebeschini</keyname><forenames>Patrick</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Meta-Learning Objectives for Preference Optimization</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluating preference optimization (PO) algorithms on LLM alignment is a challenging task that presents prohibitive costs, noise, and several variables like model size and hyper-parameters. In this work, we show that it is possible to gain insights on the efficacy of PO algorithm on much simpler benchmarks. We design a diagnostic suite of MuJoCo tasks and datasets, which we use to systematically evaluate PO algorithms, establishing a more controlled and cheaper benchmark. We then propose a novel family of PO algorithms based on mirror descent, which we call Mirror Preference Optimization (MPO). Through evolutionary strategies, we search this class to discover algorithms specialized to specific properties of preference datasets, such as mixed-quality or noisy data. We demonstrate that our discovered PO algorithms outperform all known algorithms in the targeted MuJoCo settings. Finally, based on the insights gained from our MuJoCo experiments, we design a novel PO algorithm that significantly outperforms existing baselines in an LLM alignment task. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.16303</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.16303</id><created>2024-11-25</created><updated>2025-02-05</updated><authors><author><keyname>Zeng</keyname><forenames>Dun</forenames></author><author><keyname>Wu</keyname><forenames>Zheshun</forenames></author><author><keyname>Liu</keyname><forenames>Shiyu</forenames></author><author><keyname>Pan</keyname><forenames>Yu</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoying</forenames></author><author><keyname>Xu</keyname><forenames>Zenglin</forenames></author></authors><title>Understanding Generalization of Federated Learning: the Trade-off   between Model Stability and Optimization</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Federated Learning (FL) is a distributed learning approach that trains machine learning models across multiple devices while keeping their local data private. However, FL often faces challenges due to data heterogeneity, leading to inconsistent local optima among clients. These inconsistencies can cause unfavorable convergence behavior and generalization performance degradation. Existing studies mainly describe this issue through \textit{convergence analysis}, focusing on how well a model fits training data, or through \textit{algorithmic stability}, which examines the generalization gap. However, neither approach precisely captures the generalization performance of FL algorithms, especially for neural networks. This paper introduces an innovative generalization dynamics analysis framework, named as Libra, for algorithm-dependent excess risk minimization, highlighting the trade-offs between model stability and optimization. Through this framework, we show how the generalization of FL algorithms is affected by the interplay of algorithmic stability and optimization. This framework applies to standard federated optimization and its advanced variants, such as server momentum. Our findings suggest that larger local steps or momentum accelerate convergence but enlarge stability, while yielding a better minimum excess risk. These insights can guide the design of future algorithms to achieve stronger generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.02529</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.02529</id><created>2024-12-03</created><updated>2025-02-04</updated><authors><author><keyname>Wagenmaker</keyname><forenames>Andrew</forenames></author><author><keyname>Mi</keyname><forenames>Lu</forenames></author><author><keyname>Rozsa</keyname><forenames>Marton</forenames></author><author><keyname>Bull</keyname><forenames>Matthew S.</forenames></author><author><keyname>Svoboda</keyname><forenames>Karel</forenames></author><author><keyname>Daie</keyname><forenames>Kayvon</forenames></author><author><keyname>Golub</keyname><forenames>Matthew D.</forenames></author><author><keyname>Jamieson</keyname><forenames>Kevin</forenames></author></authors><title>Active learning of neural population dynamics using two-photon   holographic optogenetics</title><categories>q-bio.NC cs.LG stat.ML</categories><comments>NeurIPS 2024</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in techniques for monitoring and perturbing neural populations have greatly enhanced our ability to study circuits in the brain. In particular, two-photon holographic optogenetics now enables precise photostimulation of experimenter-specified groups of individual neurons, while simultaneous two-photon calcium imaging enables the measurement of ongoing and induced activity across the neural population. Despite the enormous space of potential photostimulation patterns and the time-consuming nature of photostimulation experiments, very little algorithmic work has been done to determine the most effective photostimulation patterns for identifying the neural population dynamics. Here, we develop methods to efficiently select which neurons to stimulate such that the resulting neural responses will best inform a dynamical model of the neural population activity. Using neural population responses to photostimulation in mouse motor cortex, we demonstrate the efficacy of a low-rank linear dynamical systems model, and develop an active learning procedure which takes advantage of low-rank structure to determine informative photostimulation patterns. We demonstrate our approach on both real and synthetic data, obtaining in some cases as much as a two-fold reduction in the amount of data required to reach a given predictive power. Our active stimulation design method is based on a novel active learning procedure for low-rank regression, which may be of independent interest. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.06540</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.06540</id><created>2024-12-09</created><updated>2025-02-04</updated><authors><author><keyname>Polo</keyname><forenames>Felipe Maia</forenames></author><author><keyname>Somerstep</keyname><forenames>Seamus</forenames></author><author><keyname>Choshen</keyname><forenames>Leshem</forenames></author><author><keyname>Sun</keyname><forenames>Yuekai</forenames></author><author><keyname>Yurochkin</keyname><forenames>Mikhail</forenames></author></authors><title>Sloth: scaling laws for LLM skills to predict multi-benchmark   performance across families</title><categories>cs.LG cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scaling laws for large language models (LLMs) predict model performance based on parameters like size and training data. However, differences in training configurations and data processing across model families lead to significant variations in benchmark performance, making it difficult for a single scaling law to generalize across all LLMs. On the other hand, training family-specific scaling laws requires training models of varying sizes for every family. In this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a novel scaling law that leverages publicly available benchmark data and assumes LLM performance is driven by low-dimensional latent skills, such as reasoning and instruction following. These latent skills are influenced by computational resources like model size and training tokens but with varying efficiencies across model families. Sloth exploits correlations across benchmarks to provide more accurate and interpretable predictions while alleviating the need to train multiple LLMs per family. We present both theoretical results on parameter identification and empirical evaluations on 12 prominent benchmarks, from Open LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance efficiently and offers insights into scaling behaviors for complex downstream tasks and increased test-time compute. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.10038</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.10038</id><created>2024-12-13</created><updated>2025-02-05</updated><authors><author><keyname>Callegher</keyname><forenames>Gianmarco</forenames></author><author><keyname>Kneib</keyname><forenames>Thomas</forenames></author><author><keyname>Söding</keyname><forenames>Johannes</forenames></author><author><keyname>Wiemann</keyname><forenames>Paul</forenames></author></authors><title>Stochastic Variational Inference for Structured Additive Distributional   Regression</title><categories>stat.CO</categories><msc-class>62</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In structured additive distributional regression, the conditional distribution of the response variables given the covariate information and the vector of model parameters is modelled using a P-parametric probability density function where each parameter is modelled through a linear predictor and a bijective response function that maps the domain of the predictor into the domain of the parameter. We present a method to perform inference in structured additive distributional regression using stochastic variational inference. We propose two strategies for constructing a multivariate Gaussian variational distribution to estimate the posterior distribution of the regression coefficients. The first strategy leverages covariate information and hyperparameters to learn both the location vector and the precision matrix. The second strategy tackles the complexity challenges of the first by initially assuming independence among all smooth terms and then introducing correlations through an additional set of variational parameters. Furthermore, we present two approaches for estimating the smoothing parameters. The first treats them as free parameters and provides point estimates, while the second accounts for uncertainty by applying a variational approximation to the posterior distribution. Our model was benchmarked against state-of-the-art competitors in logistic and gamma regression simulation studies. Finally, we validated our approach by comparing its posterior estimates to those obtained using Markov Chain Monte Carlo on a dataset of patents from the biotechnology/pharmaceutics and semiconductor/computer sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20824</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20824</id><created>2024-12-30</created><updated>2025-02-05</updated><authors><author><keyname>Jorge</keyname><forenames>Emilio</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Basu</keyname><forenames>Debabrota</forenames></author></authors><title>Isoperimetry is All We Need: Langevin Posterior Sampling for RL with   Sublinear Regret</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common assumptions, like linear or RKHS models, and Gaussian or log-concave posteriors over the models, do not explain practical success of RL across a wider range of distributions and models. Thus, we study how to design RL algorithms with sublinear regret for isoperimetric distributions, specifically the ones satisfying the Log-Sobolev Inequality (LSI). LSI distributions include the standard setups of RL theory, and others, such as many non-log-concave and perturbed distributions. First, we show that the Posterior Sampling-based RL (PSRL) algorithm yields sublinear regret if the data distributions satisfy LSI and some mild additional assumptions. Also, when we cannot compute or sample from an exact posterior, we propose a Langevin sampling-based algorithm design: LaPSRL. We show that LaPSRL achieves order-optimal regret and subquadratic complexity per episode. Finally, we deploy LaPSRL with a Langevin sampler -- SARAH-LD, and test it for different bandit and MDP environments. Experimental results validate the generality of LaPSRL across environments and its competitive performance with respect to the baselines. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.04871</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.04871</id><created>2025-01-08</created><updated>2025-02-04</updated><authors><author><keyname>Lee</keyname><forenames>Kaitlyn J.</forenames></author><author><keyname>Schuler</keyname><forenames>Alejandro</forenames></author></authors><title>RieszBoost: Gradient Boosting for Riesz Regression</title><categories>stat.ML cs.LG stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Answering causal questions often involves estimating linear functionals of conditional expectations, such as the average treatment effect or the effect of a longitudinal modified treatment policy. By the Riesz representation theorem, these functionals can be expressed as the expected product of the conditional expectation of the outcome and the Riesz representer, a key component in doubly robust estimation methods. Traditionally, the Riesz representer is estimated indirectly by deriving its explicit analytical form, estimating its components, and substituting these estimates into the known form (e.g., the inverse propensity score). However, deriving or estimating the analytical form can be challenging, and substitution methods are often sensitive to practical positivity violations, leading to higher variance and wider confidence intervals. In this paper, we propose a novel gradient boosting algorithm to directly estimate the Riesz representer without requiring its explicit analytical form. This method is particularly suited for tabular data, offering a flexible, nonparametric, and computationally efficient alternative to existing methods for Riesz regression. Through simulation studies, we demonstrate that our algorithm performs on par with or better than indirect estimation techniques across a range of functionals, providing a user-friendly and robust solution for estimating causal quantities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08270</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08270</id><created>2025-01-14</created><updated>2025-02-04</updated><authors><author><keyname>Fowler</keyname><forenames>Charlotte R.</forenames></author><author><keyname>Cai</keyname><forenames>Xiaoxuan</forenames></author><author><keyname>Rahimi-Eichi</keyname><forenames>Habiballah</forenames></author><author><keyname>Dixon</keyname><forenames>Lisa</forenames></author><author><keyname>Baker</keyname><forenames>Justin T.</forenames></author><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author><author><keyname>Valeri</keyname><forenames>Linda</forenames></author></authors><title>Individual causal effect estimation accounting for latent disease state   modification among bipolar participants in mobile health studies</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Individuals with bipolar disorder tend to cycle through disease states such as depression and mania. The heterogeneous nature of disease across states complicates the evaluation of interventions for bipolar disorder patients, as varied interventional success is observed within and across individuals. In fact, we hypothesize that disease state acts as an effect modifier for the causal effect of a given intervention on health outcomes. To address this dilemma, we propose an N-of-1 approach using an adapted autoregressive hidden Markov model, applied to longitudinal mobile health data collected from individuals with bipolar disorder. This method allows us to identify a latent variable from mobile health data to be treated as an effect modifier between the exposure and outcome of interest while allowing for missing data in the outcome. A counterfactual approach is employed for causal inference and to obtain a g-formula estimator to recover said effect. The performance of the proposed method is compared with a naive approach across extensive simulations and application to a multi-year smartphone study of bipolar patients, evaluating the individual effect of digital social activity on sleep duration across different latent disease states. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.09683</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.09683</id><created>2025-01-16</created><updated>2025-02-05</updated><authors><author><keyname>Cirone</keyname><forenames>Nicola Muca</forenames></author><author><keyname>Salvi</keyname><forenames>Cristopher</forenames></author></authors><title>Rough kernel hedging</title><categories>math.FA cs.LG stat.ML</categories><comments>v2. minor corrections to presentation</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Building on the functional-analytic framework of operator-valued kernels and un-truncated signature kernels, we propose a scalable, provably convergent signature-based algorithm for a broad class of high-dimensional, path-dependent hedging problems. We make minimal assumptions about market dynamics by modelling them as general geometric rough paths, yielding a fully model-free approach. Furthermore, through a representer theorem, we provide theoretical guarantees on the existence and uniqueness of a global minimum for the resulting optimization problem and derive an analytic solution under highly general loss functions. Similar to the popular deep hedging approach, but in a more rigorous fashion, our method can also incorporate additional features via the underlying operator-valued kernel, such as trading signals, news analytics, and past hedging decisions, closely aligning with true machine-learning practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10910</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10910</id><created>2025-01-18</created><updated>2025-02-05</updated><authors><author><keyname>Kowsar</keyname><forenames>Ibna</forenames></author><author><keyname>Rabbani</keyname><forenames>Shourav B.</forenames></author><author><keyname>Hou</keyname><forenames>Yina</forenames></author><author><keyname>Samad</keyname><forenames>Manar D.</forenames></author></authors><title>DeepIFSAC: Deep Imputation of Missing Values Using Feature and Sample   Attention within Contrastive Framework</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Missing values of varying patterns and rates in real-world tabular data pose a significant challenge in developing reliable data-driven models. Existing missing value imputation methods use statistical and traditional machine learning and are ineffective when the missing rate is high and not at random. This paper explores row and column attention in tabular data as between-feature and between-sample attention in a novel framework to reconstruct missing values. The proposed method uses the CutMix data augmentation within a contrastive learning framework to improve the uncertainty of missing value estimation. The performance and generalizability of trained imputation models are evaluated on set-aside test data folds with missing values. The proposed framework outperforms nine state-of-the-art imputation methods across several missing value types and rates (10\%-50\%) on a diverse selection of twelve tabular data sets. We evaluate the quality of imputed data using real-world electronic health records with missing values, demonstrating our proposed framework's superiority to state-of-the-art statistical, machine learning, and deep imputation methods. This paper highlights the heterogeneity of tabular data sets to recommend imputation methods based on missing value types and data characteristics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11280</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11280</id><created>2025-01-20</created><updated>2025-02-04</updated><authors><author><keyname>Yoshida</keyname><forenames>Tsukasa</forenames></author><author><keyname>Watanabe</keyname><forenames>Kazuho</forenames></author></authors><title>Empirical Bayes Estimation for Lasso-Type Regularizers: Analysis of   Automatic Relevance Determination</title><categories>math.ST cs.IT cs.LG math.IT stat.TH</categories><comments>8 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper focuses on linear regression models with non-conjugate sparsity-inducing regularizers such as lasso and group lasso. Although empirical Bayes approach enables us to estimate the regularization parameter, little is known on the properties of the estimators. In particular, there are many unexplained aspects regarding the specific conditions under which the mechanism of automatic relevance determination (ARD) occurs. In this paper, we derive the empirical Bayes estimators for the group lasso regularized linear regression models with a limited number of parameters. It is shown that the estimators diverge under a certain condition, giving rise to the ARD mechanism. We also prove that empirical Bayes methods can produce ARD mechanism in general regularized linear regression models and clarify the conditions under which models such as ridge, lasso, and group lasso can produce ARD mechanism. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11650</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11650</id><created>2025-01-20</created><updated>2025-02-05</updated><authors><author><keyname>Leach</keyname><forenames>Callum</forenames></author><author><keyname>Ewans</keyname><forenames>Kevin</forenames></author><author><keyname>Jonathan</keyname><forenames>Philip</forenames></author></authors><title>Changes over time in the 100-year return value of climate model   variables</title><categories>stat.AP physics.ao-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We assess evidence for changes in tail characteristics of wind, solar irradiance and temperature variables output from CMIP6 global climate models (GCMs) due to climate forcing. We estimate global and climate zone annual maximum and annual means for period (2015, 2100) from daily output of seven GCMs for daily wind speed, maximum wind speed, solar irradiance and near-surface temperature. We calculate corresponding annualised data for individual locations within neighbourhoods of the North Atlantic and Celtic Sea region. We consider output for three climate scenarios and multiple climate ensembles. We estimate non-stationary extreme value models for annual extremes, and non-homogeneous Gaussian regressions for annual means, using Bayesian inference. We use estimated statistical models to quantify the distribution of (i) the change in 100-year return value for annual extremes, and (2) the change in annual mean, over the period (2025, 2125). To summarise results, we estimate linear mixed effects models for observed variation of (i) and (ii). Evidence for changes in the 100-year return value for annual maxima of solar irradiance and temperature is much stronger than for wind variables over time and with climate scenario. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11689</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11689</id><created>2025-01-20</created><updated>2025-02-05</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Randomness, exchangeability, and conformal prediction</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>24 pages, 1 figure; v2 includes several new results about the   optimality of results in v1</comments><msc-class>68Q32 (Primary) 62G15, 68T05, 03D32 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper continues development of the functional theory of randomness, a modification of the algorithmic theory of randomness getting rid of unspecified additive constants. It introduces new kinds of confidence predictors, including randomness predictors (the most general confidence predictors based on the assumption of IID observations) and exchangeability predictors (the most general confidence predictors based on the assumption of exchangeable observations). The main result implies that both are close to conformal predictors and quantifies the difference between randomness prediction and conformal prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.15753</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.15753</id><created>2025-01-26</created><updated>2025-02-05</updated><authors><author><keyname>Fallahgoul</keyname><forenames>Hasan</forenames></author></authors><title>Scale-Insensitive Neural Network Significance Tests</title><categories>stat.ML cs.LG econ.EM</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper develops a scale-insensitive framework for neural network significance testing, substantially generalizing existing approaches through three key innovations. First, we replace metric entropy calculations with Rademacher complexity bounds, enabling the analysis of neural networks without requiring bounded weights or specific architectural constraints. Second, we weaken the regularity conditions on the target function to require only Sobolev space membership $H^s([-1,1]^d)$ with $s &gt; d/2$, significantly relaxing previous smoothness assumptions while maintaining optimal approximation rates. Third, we introduce a modified sieve space construction based on moment bounds rather than weight constraints, providing a more natural theoretical framework for modern deep learning practices. Our approach achieves these generalizations while preserving optimal convergence rates and establishing valid asymptotic distributions for test statistics. The technical foundation combines localization theory, sharp concentration inequalities, and scale-insensitive complexity measures to handle unbounded weights and general Lipschitz activation functions. This framework better aligns theoretical guarantees with contemporary deep learning practice while maintaining mathematical rigor. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.16489</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.16489</id><created>2025-01-27</created><updated>2025-02-04</updated><authors><author><keyname>Hou</keyname><forenames>Boya</forenames></author><author><keyname>Sanjari</keyname><forenames>Sina</forenames></author><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author></authors><title>Nonparametric Sparse Online Learning of the Koopman Operator</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>This work was intended as a replacement of arXiv:2405.07432 and any   subsequent updates will appear there</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.18095</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.18095</id><created>2025-01-29</created><updated>2025-02-04</updated><authors><author><keyname>Han</keyname><forenames>Barron</forenames></author><author><keyname>Akhtiamov</keyname><forenames>Danil</forenames></author><author><keyname>Ghane</keyname><forenames>Reza</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Robust Mean Estimation With Auxiliary Samples</title><categories>math.ST stat.TH</categories><comments>Submitted to International Symposium on Information Theory 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In data-driven learning and inference tasks, the high cost of acquiring samples from the target distribution often limits performance. A common strategy to mitigate this challenge is to augment the limited target samples with data from a more accessible "auxiliary" distribution. This paper establishes fundamental limits of this approach by analyzing the improvement in the mean square error (MSE) when estimating the mean of the target distribution. Using the Wasserstein-2 metric to quantify the distance between distributions, we derive expressions for the worst-case MSE when samples are drawn (with labels) from both a target distribution and an auxiliary distribution within a specified Wasserstein-2 distance from the target distribution. We explicitly characterize the achievable MSE and the optimal estimator in terms of the problem dimension, the number of samples from the target and auxiliary distributions, the Wasserstein-2 distance, and the covariance of the target distribution. We note that utilizing samples from the auxiliary distribution effectively improves the MSE when the squared radius of the Wasserstein-2 uncertainty ball is small compared to the variance of the true distribution and the number of samples from the true distribution is limited. Numerical simulations in the Gaussian location model illustrate the theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.18184</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.18184</id><created>2025-01-30</created><updated>2025-02-05</updated><authors><author><keyname>Lyu</keyname><forenames>Qingchuan</forenames></author></authors><title>Genetic Algorithm with Border Trades (GAB)</title><categories>cs.LG cs.NE stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel approach to improving Genetic Algorithms (GA) in large or complex problem spaces by incorporating new chromosome patterns in the breeding process through border trade activities. These strategies increase chromosome diversity, preventing premature convergence and enhancing the GA's ability to explore the solution space more effectively. Empirical evidence demonstrates significant improvements in convergence behavior. This approach offers a promising pathway to addressing challenges in optimizing large or complex problem domains. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01627</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01627</id><created>2025-02-03</created><updated>2025-02-04</updated><authors><author><keyname>Song</keyname><forenames>Yanke</forenames></author><author><keyname>Villar</keyname><forenames>Victoria Ashley</forenames></author><author><keyname>Martinez-Galarza</keyname><forenames>Juan Rafael</forenames></author><author><keyname>Dillmann</keyname><forenames>Steven</forenames></author></authors><title>A Poisson Process AutoDecoder for X-ray Sources</title><categories>astro-ph.IM astro-ph.HE cs.LG stat.AP</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray observing facilities, such as the Chandra X-ray Observatory and the eROSITA, have detected millions of astronomical sources associated with high-energy phenomena. The arrival of photons as a function of time follows a Poisson process and can vary by orders-of-magnitude, presenting obstacles for common tasks such as source classification, physical property derivation, and anomaly detection. Previous work has either failed to directly capture the Poisson nature of the data or only focuses on Poisson rate function reconstruction. In this work, we present Poisson Process AutoDecoder (PPAD). PPAD is a neural field decoder that maps fixed-length latent features to continuous Poisson rate functions across energy band and time via unsupervised learning. PPAD reconstructs the rate function and yields a representation at the same time. We demonstrate the efficacy of PPAD via reconstruction, regression, classification and anomaly detection experiments using the Chandra Source Catalog. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.01886</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.01886</id><created>2025-02-03</created><authors><author><keyname>Díaz</keyname><forenames>Mateo</forenames></author><author><keyname>Drusvyatskiy</keyname><forenames>Dmitriy</forenames></author><author><keyname>Kendrick</keyname><forenames>Jack</forenames></author><author><keyname>Thomas</keyname><forenames>Rekha R.</forenames></author></authors><title>Invariant Kernels: Rank Stabilization and Generalization Across   Dimensions</title><categories>math.OC math.RT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry arises often when learning from high dimensional data. For example, data sets consisting of point clouds, graphs, and unordered sets appear routinely in contemporary applications, and exhibit rich underlying symmetries. Understanding the benefits of symmetry on the statistical and numerical efficiency of learning algorithms is an active area of research. In this work, we show that symmetry has a pronounced impact on the rank of kernel matrices. Specifically, we compute the rank of a polynomial kernel of fixed degree that is invariant under various groups acting independently on its two arguments. In concrete circumstances, including the three aforementioned examples, symmetry dramatically decreases the rank making it independent of the data dimension. In such settings, we show that a simple regression procedure is minimax optimal for estimating an invariant polynomial from finitely many samples drawn across different dimensions. We complete the paper with numerical experiments that illustrate our findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02531</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02531</id><created>2025-02-04</created><updated>2025-02-05</updated><authors><author><keyname>Bordelon</keyname><forenames>Blake</forenames></author><author><keyname>Pehlevan</keyname><forenames>Cengiz</forenames></author></authors><title>Deep Linear Network Training Dynamics from Random Initialization: Data,   Width, Depth, and Hyperparameter Transfer</title><categories>cs.LG cond-mat.dis-nn stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data. Our theory captures the ``wider is better" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width. We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\sqrt{\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration. Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02580</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02580</id><created>2025-02-04</created><updated>2025-02-04</updated><authors><author><keyname>Huang</keyname><forenames>Chengzhu</forenames></author><author><keyname>Gu</keyname><forenames>Yuqi</forenames></author></authors><title>Minimax-Optimal Dimension-Reduced Clustering for High-Dimensional   Nonspherical Mixtures</title><categories>math.ST stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mixture models, nonspherical (anisotropic) noise within each cluster is widely present in real-world data. We study both the minimax rate and optimal statistical procedure for clustering under high-dimensional nonspherical mixture models. In high-dimensional settings, we first establish the information-theoretic limits for clustering under Gaussian mixtures. The minimax lower bound unveils an intriguing informational dimension-reduction phenomenon: there exists a substantial gap between the minimax rate and the oracle clustering risk, with the former determined solely by the projected centers and projected covariance matrices in a low-dimensional space. Motivated by the lower bound, we propose a novel computationally efficient clustering method: Covariance Projected Spectral Clustering (COPO). Its key step is to project the high-dimensional data onto the low-dimensional space spanned by the cluster centers and then use the projected covariance matrices in this space to enhance clustering. We establish tight algorithmic upper bounds for COPO, both for Gaussian noise with flexible covariance and general noise with local dependence. Our theory indicates the minimax-optimality of COPO in the Gaussian case and highlights its adaptivity to a broad spectrum of dependent noise. Extensive simulation studies under various noise structures and real data analysis demonstrate our method's superior performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02623</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02623</id><created>2025-02-04</created><authors><author><keyname>Matilla</keyname><forenames>German Martinez</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author></authors><title>Sample Complexity of Bias Detection with Subsampled Point-to-Subspace   Distances</title><categories>cs.LG cs.AI math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sample complexity of bias estimation is a lower bound on the runtime of any bias detection method. Many regulatory frameworks require the bias to be tested for all subgroups, whose number grows exponentially with the number of protected attributes. Unless one wishes to run a bias detection with a doubly-exponential run-time, one should like to have polynomial complexity of bias detection for a single subgroup. At the same time, the reference data may be based on surveys, and thus come with non-trivial uncertainty.   Here, we reformulate bias detection as a point-to-subspace problem on the space of measures and show that, for supremum norm, it can be subsampled efficiently. In particular, our probabilistically approximately correct (PAC) results are corroborated by tests on well-known instances. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02671</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02671</id><created>2025-02-04</created><authors><author><keyname>Tiapkin</keyname><forenames>Daniil</forenames></author><author><keyname>Calandriello</keyname><forenames>Daniele</forenames></author><author><keyname>Ferret</keyname><forenames>Johan</forenames></author><author><keyname>Perrin</keyname><forenames>Sarah</forenames></author><author><keyname>Vieillard</keyname><forenames>Nino</forenames></author><author><keyname>Ramé</keyname><forenames>Alexandre</forenames></author><author><keyname>Blondel</keyname><forenames>Mathieu</forenames></author></authors><title>On Teacher Hacking in Language Model Distillation</title><categories>cs.LG cs.AI cs.CL stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Post-training of language models (LMs) increasingly relies on the following two stages: (i) knowledge distillation, where the LM is trained to imitate a larger teacher LM, and (ii) reinforcement learning from human feedback (RLHF), where the LM is aligned by optimizing a reward model. In the second RLHF stage, a well-known challenge is reward hacking, where the LM over-optimizes the reward model. Such phenomenon is in line with Goodhart's law and can lead to degraded performance on the true objective. In this paper, we investigate whether a similar phenomenon, that we call teacher hacking, can occur during knowledge distillation. This could arise because the teacher LM is itself an imperfect approximation of the true distribution. To study this, we propose a controlled experimental setup involving: (i) an oracle LM representing the ground-truth distribution, (ii) a teacher LM distilled from the oracle, and (iii) a student LM distilled from the teacher. Our experiments reveal the following insights. When using a fixed offline dataset for distillation, teacher hacking occurs; moreover, we can detect it by observing when the optimization process deviates from polynomial convergence laws. In contrast, employing online data generation techniques effectively mitigates teacher hacking. More precisely, we identify data diversity as the key factor in preventing hacking. Overall, our findings provide a deeper understanding of the benefits and limitations of distillation for building robust and efficient LMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02674</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02674</id><created>2025-02-04</created><authors><author><keyname>Stanley</keyname><forenames>Michael</forenames></author><author><keyname>Batlle</keyname><forenames>Pau</forenames></author><author><keyname>Patil</keyname><forenames>Pratik</forenames></author><author><keyname>Owhadi</keyname><forenames>Houman</forenames></author><author><keyname>Kuusela</keyname><forenames>Mikael</forenames></author></authors><title>Confidence intervals for functionals in constrained inverse problems via   data-adaptive sampling-based calibration</title><categories>stat.ME stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address functional uncertainty quantification for ill-posed inverse problems where it is possible to evaluate a possibly rank-deficient forward model, the observation noise distribution is known, and there are known parameter constraints. We present four constraint-aware confidence intervals extending the work of Batlle et al. (2023) by making the intervals both computationally feasible and less conservative. Our approach first shrinks the potentially unbounded constraint set compact in a data-adaptive way, obtains samples of the relevant test statistic inside this set to estimate a quantile function, and then uses these computed quantities to produce the intervals. Our data-adaptive bounding approach is based on the approach by Berger and Boos (1994), and involves defining a subset of the constraint set where the true parameter exists with high probability. This probabilistic guarantee is then incorporated into the final coverage guarantee in the form of an uncertainty budget. We then propose custom sampling algorithms to efficiently sample from this subset, even when the parameter space is high-dimensional. Optimization-based interval methods formulate confidence interval computation as two endpoint optimizations, where the optimization constraints can be set to achieve different types of interval calibration while seamlessly incorporating parameter constraints. However, choosing valid optimization constraints has been elusive. We show that all four proposed intervals achieve nominal coverage for a particular functional both theoretically and in practice, with numerical examples demonstrating superior performance of our intervals over the OSB interval in terms of both coverage and expected length. In particular, we show the superior performance in a realistic unfolding simulation from high-energy physics that is severely ill-posed and involves a rank-deficient forward model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02679</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02679</id><created>2025-02-04</created><authors><author><keyname>Kurkova</keyname><forenames>Vera</forenames></author><author><keyname>Sanguineti</keyname><forenames>Marcello</forenames></author></authors><title>Networks with Finite VC Dimension: Pro and Contra</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Approximation and learning of classifiers of large data sets by neural networks in terms of high-dimensional geometry and statistical learning theory are investigated. The influence of the VC dimension of sets of input-output functions of networks on approximation capabilities is compared with its influence on consistency in learning from samples of data. It is shown that, whereas finite VC dimension is desirable for uniform convergence of empirical errors, it may not be desirable for approximation of functions drawn from a probability distribution modeling the likelihood that they occur in a given type of application. Based on the concentration-of-measure properties of high dimensional geometry, it is proven that both errors in approximation and empirical errors behave almost deterministically for networks implementing sets of input-output functions with finite VC dimensions in processing large data sets. Practical limitations of the universal approximation property, the trade-offs between the accuracy of approximation and consistency in learning from data, and the influence of depth of networks with ReLU units on their accuracy and consistency are discussed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02701</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02701</id><created>2025-02-04</created><authors><author><keyname>Noda</keyname><forenames>Atsushi</forenames></author><author><keyname>Isozaki</keyname><forenames>Takashi</forenames></author></authors><title>Practically Effective Adjustment Variable Selection in Causal Inference</title><categories>cs.LG cs.AI physics.data-an stat.ME</categories><comments>20 pages, 8 figures</comments><journal-ref>Journal of Physics: Complexity 6, 015001 (2025)</journal-ref><doi>10.1088/2632-072X/ada861</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the estimation of causal effects, one common method for removing the influence of confounders is to adjust the variables that satisfy the back-door criterion. However, it is not always possible to uniquely determine sets of such variables. Moreover, real-world data is almost always limited, which means it may be insufficient for statistical estimation. Therefore, we propose criteria for selecting variables from a list of candidate adjustment variables along with an algorithm to prevent accuracy degradation in causal effect estimation. We initially focus on directed acyclic graphs (DAGs) and then outlines specific steps for applying this method to completed partially directed acyclic graphs (CPDAGs). We also present and prove a theorem on causal effect computation possibility in CPDAGs. Finally, we demonstrate the practical utility of our method using both existing and artificial data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02710</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02710</id><created>2025-02-04</created><authors><author><keyname>Kostin</keyname><forenames>Julia</forenames></author><author><keyname>Gnecco</keyname><forenames>Nicola</forenames></author><author><keyname>Yang</keyname><forenames>Fanny</forenames></author></authors><title>Achievable distributional robustness when the robust risk is only   partially identified</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In safety-critical applications, machine learning models should generalize well under worst-case distribution shifts, that is, have a small robust risk. Invariance-based algorithms can provably take advantage of structural assumptions on the shifts when the training distributions are heterogeneous enough to identify the robust risk. However, in practice, such identifiability conditions are rarely satisfied -- a scenario so far underexplored in the theoretical literature. In this paper, we aim to fill the gap and propose to study the more general setting when the robust risk is only partially identifiable. In particular, we introduce the worst-case robust risk as a new measure of robustness that is always well-defined regardless of identifiability. Its minimum corresponds to an algorithm-independent (population) minimax quantity that measures the best achievable robustness under partial identifiability. While these concepts can be defined more broadly, in this paper we introduce and derive them explicitly for a linear model for concreteness of the presentation. First, we show that existing robustness methods are provably suboptimal in the partially identifiable case. We then evaluate these methods and the minimizer of the (empirical) worst-case robust risk on real-world gene expression data and find a similar trend: the test error of existing robustness methods grows increasingly suboptimal as the fraction of data from unseen environments increases, whereas accounting for partial identifiability allows for better generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02726</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02726</id><created>2025-02-04</created><authors><author><keyname>Li</keyname><forenames>Pengtao</forenames></author><author><keyname>Chen</keyname><forenames>Xiaohui</forenames></author></authors><title>Multimarginal Schr\"{o}dinger Barycenter</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Wasserstein barycenter plays a fundamental role in averaging measure-valued data under the framework of optimal transport. However, there are tremendous challenges in computing and estimating the Wasserstein barycenter for high-dimensional distributions. In this paper, we introduce the multimarginal Schr\"{o}dinger barycenter (MSB) based on the entropy regularized multimarginal optimal transport problem that admits general-purpose fast algorithms for computation. By recognizing a proper dual geometry, we derive non-asymptotic rates of convergence for estimating several key MSB quantities from point clouds randomly sampled from the input marginal distributions. Specifically, we show that our obtained sample complexity is statistically optimal for estimating the cost functional, Schr\"{o}dinger coupling and barycenter. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02736</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02736</id><created>2025-02-04</created><authors><author><keyname>Dong</keyname><forenames>Larry</forenames></author><author><keyname>Pullenayegum</keyname><forenames>Eleanor</forenames></author><author><keyname>Thiébaut</keyname><forenames>Rodolphe</forenames></author><author><keyname>Saarela</keyname><forenames>Olli</forenames></author></authors><title>Estimating Optimal Dynamic Treatment Regimes Using Irregularly Observed   Data: A Target Trial Emulation and Bayesian Joint Modeling Approach</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimal dynamic treatment regime (DTR) is a sequence of decision rules aimed at providing the best course of treatments individualized to patients. While conventional DTR estimation uses longitudinal data, such data can also be irregular, where patient-level variables can affect visit times, treatment assignments and outcomes. In this work, we first extend the target trial framework - a paradigm to estimate statistical estimands specified under hypothetical randomized trials using observational data - to the DTR context; this extension allows treatment regimes to be defined with intervenable visit times. We propose an adapted version of G-computation marginalizing over random effects for rewards that encapsulate a treatment strategy's value. To estimate components of the G-computation formula, we then articulate a Bayesian joint model to handle correlated random effects between the outcome, visit and treatment processes. We show via simulation studies that, in the estimation of regime rewards, failure to account for the observational treatment and visit processes produces bias which can be removed through joint modeling. We also apply our proposed method on data from INSPIRE 2 and 3 studies to estimate optimal injection cycles of Interleukin 7 to treat HIV-infected individuals. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02771</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02771</id><created>2025-02-04</created><authors><author><keyname>Cheung</keyname><forenames>Matt Y.</forenames></author><author><keyname>Zorek</keyname><forenames>Sophia</forenames></author><author><keyname>Netherton</keyname><forenames>Tucker J.</forenames></author><author><keyname>Court</keyname><forenames>Laurence E.</forenames></author><author><keyname>Al-Kindi</keyname><forenames>Sadeer</forenames></author><author><keyname>Veeraraghavan</keyname><forenames>Ashok</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Guha</forenames></author></authors><title>When are Diffusion Priors Helpful in Sparse Reconstruction? A Study with   Sparse-view CT</title><categories>physics.med-ph cs.CV cs.LG eess.IV stat.AP</categories><comments>Accepted at IEEE ISBI 2025, 5 pages, 2 figures, 1 table</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion models demonstrate state-of-the-art performance on image generation, and are gaining traction for sparse medical image reconstruction tasks. However, compared to classical reconstruction algorithms relying on simple analytical priors, diffusion models have the dangerous property of producing realistic looking results \emph{even when incorrect}, particularly with few observations. We investigate the utility of diffusion models as priors for image reconstruction by varying the number of observations and comparing their performance to classical priors (sparse and Tikhonov regularization) using pixel-based, structural, and downstream metrics. We make comparisons on low-dose chest wall computed tomography (CT) for fat mass quantification. First, we find that classical priors are superior to diffusion priors when the number of projections is ``sufficient''. Second, we find that diffusion priors can capture a large amount of detail with very few observations, significantly outperforming classical priors. However, they fall short of capturing all details, even with many observations. Finally, we find that the performance of diffusion priors plateau after extremely few ($\approx$10-15) projections. Ultimately, our work highlights potential issues with diffusion-based sparse reconstruction and underscores the importance of further investigation, particularly in high-stakes clinical settings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02781</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02781</id><created>2025-02-04</created><authors><author><keyname>Forzani</keyname><forenames>Liliana</forenames></author><author><keyname>Arancibia</keyname><forenames>Rodrigo García</forenames></author><author><keyname>Gieco</keyname><forenames>Antonella</forenames></author><author><keyname>Llop</keyname><forenames>Pamela</forenames></author><author><keyname>Yao</keyname><forenames>Anne</forenames></author></authors><title>Sufficient dimension reduction for regression with spatially correlated   errors: application to prediction</title><categories>stat.ME math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this paper, we address the problem of predicting a response variable in the context of both, spatially correlated and high-dimensional data. To reduce the dimensionality of the predictor variables, we apply the sufficient dimension reduction (SDR) paradigm, which reduces the predictor space while retaining relevant information about the response. To achieve this, we impose two different spatial models on the inverse regression: the separable spatial covariance model (SSCM) and the spatial autoregressive error model (SEM). For these models, we derive maximum likelihood estimators for the reduction and use them to predict the response via nonparametric rules for forward regression. Through simulations and real data applications, we demonstrate the effectiveness of our approach for spatial data prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02793</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02793</id><created>2025-02-04</created><authors><author><keyname>Cui</keyname><forenames>Zihan</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Early Stopping in Contextual Bandits and Inferences</title><categories>math.ST math.OC math.PR stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandit algorithms sequentially accumulate data using adaptive sampling policies, offering flexibility for real-world applications. However, excessive sampling can be costly, motivating the devolopment of early stopping methods and reliable post-experiment conditional inferences. This paper studies early stopping methods in linear contextual bandits, including both pre-determined and online stopping rules, to minimize in-experiment regrets while accounting for sampling costs. We propose stopping rules based on the Opportunity Cost and Threshold Method, utilizing the variances of unbiased or consistent online estimators to quantify the upper regret bounds of learned optimal policy. The study focuses on batched settings for stability, selecting a weighed combination of batched estimators as the online estimator and deriving its asymptotic distribution. Online statistical inferences are performed based on the selected estimator, conditional on the realized stopping time. Our proposed method provides a systematic approach to minimize in-experiment regret and conduct robust post-experiment inferences, facilitating decision-making in future applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02797</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02797</id><created>2025-02-04</created><authors><author><keyname>Sanyal</keyname><forenames>Sunny</forenames></author><author><keyname>Prairie</keyname><forenames>Hayden</forenames></author><author><keyname>Das</keyname><forenames>Rudrajit</forenames></author><author><keyname>Kavis</keyname><forenames>Ali</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting</title><categories>cs.LG cs.AI stat.ML</categories><comments>49 pages, 4 figures, 12 tables. Code available at   https://github.com/sanyalsunny111/FLOW_finetuning</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as "catastrophic forgetting". This is especially an issue when one does not have access to the data and recipe used to develop the pre-trained model. Under this constraint, most existing methods for mitigating forgetting are inapplicable. To address this challenge, we propose a sample weighting scheme for the fine-tuning data solely based on the pre-trained model's losses. Specifically, we upweight the easy samples on which the pre-trained model's loss is low and vice versa to limit the drift from the pre-trained model. Our approach is orthogonal and yet complementary to existing methods; while such methods mostly operate on parameter or gradient space, we concentrate on the sample space. We theoretically analyze the impact of fine-tuning with our method in a linear setting, showing that it stalls learning in a certain subspace which inhibits overfitting to the target task. We empirically demonstrate the efficacy of our method on both language and vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our method results in only a $0.8\%$ drop in accuracy on GSM8K (another math dataset) compared to standard fine-tuning, while preserving $5.4\%$ more accuracy on the pre-training datasets. Our code is publicly available at https://github.com/sanyalsunny111/FLOW_finetuning . </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02812</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02812</id><created>2025-02-04</created><authors><author><keyname>Propp</keyname><forenames>Adrienne M.</forenames></author><author><keyname>Vardavas</keyname><forenames>Raffaele</forenames></author><author><keyname>Price</keyname><forenames>Carter C.</forenames></author><author><keyname>Kapinos</keyname><forenames>Kandice A.</forenames></author></authors><title>LHIEM: the Longitudinal Health, Income, and Employment Model</title><categories>stat.AP</categories><comments>To appear in Journal of Artificial Societies and Social Simulation,   2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic microsimulation has long been recognized as a powerful tool for policy analysis, but in fact most major health policy simulations lack path dependency, a critical feature for evaluating policies that depend on accumulated outcomes such as retirement savings, wealth, or debt. We propose LHIEM (the Longitudinal Health, Income and Employment Model), a path-dependent discrete-time microsimulation that predicts annual health care expenditures, family income, and health status for the U.S. population over a multi-year period. LHIEM advances the population from year to year as a Markov chain with modules capturing the particular dynamics of each predictive attribute. LHIEM was designed to assess a health care financing proposal that would allow individuals to borrow from the U.S. government to cover health care costs, requiring careful tracking of medical expenditures and medical debt over time. However, LHIEM is flexible enough to be used for a range of modeling needs related to predicting health care spending and income over time. In this paper, we present the details of the model and all dynamic modules, and include a case study to demonstrate how LHIEM can be used to evaluate proposed policy changes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02846</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02846</id><created>2025-02-04</created><authors><author><keyname>Sun</keyname><forenames>Siqi</forenames></author><author><keyname>Schmidt</keyname><forenames>Karen M.</forenames></author><author><keyname>Henry</keyname><forenames>Teague R.</forenames></author></authors><title>Don't Let Your Likert Scales Grow Up To Be Visual Analog Scales:   Understanding the Relationship Between Number of Response Categories and   Measurement Error</title><categories>stat.ME</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of Visual Analog Scales (VAS), which can be broadly conceptualized as items where the response scale is 0-100, has surged recently due to the convenience of digital assessments. However, there is no consensus as to whether the use of VAS scales is optimal in a measurement sense. Put differently, in the 90+ years since Likert introduced his eponymous scale, the field does not know how to determine the optimal number of response options for a given item. In the current work, we investigate the optimal number of response categories using a series of simulations. We find that when the measurement error of an item is not dependent on the number of response categories, there is no true optimum; rather, reliability increases with number of response options and then plateaus. However, under the more realistic assumption that the measurement error of an item increases with the number of response categories, we find a clear optimum that depends on the rate of that increase. If measurement error increases with the number of response categories, then conversion of any Likert scale item to VAS will result in a drastic decrease in reliability. Finally, if researchers do want to change the response scale of a validated measure, they must re-validate the new measure as the measurement error of the scale is likely to change. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02848</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02848</id><created>2025-02-04</created><authors><author><keyname>Zhou</keyname><forenames>Shuheng</forenames></author><author><keyname>Park</keyname><forenames>Seyoung</forenames></author><author><keyname>Shedden</keyname><forenames>Kerby</forenames></author></authors><title>Kronecker sum covariance models for spatio-temporal data</title><categories>math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we study the subgaussian matrix variate model, where we observe the matrix variate data $X$ which consists of a signal matrix $X_0$ and a noise matrix $W$. More specifically, we study a subgaussian model using the Kronecker sum covariance as in Rudelson and Zhou (2017). Let $Z_1, Z_2$ be independent copies of a subgaussian random matrix $Z =(Z_{ij})$, where $Z_{ij}, \forall i, j$ are independent mean 0, unit variance, subgaussian random variables with bounded $\psi_2$ norm. We use $X \sim \mathcal{M}_{n,m}(0, A \oplus B)$ to denote the subgaussian random matrix $X_{n \times m}$ which is generated using: $$ X = Z_1 A^{1/2} + B^{1/2} Z_2. $$ In this covariance model, the first component $A \otimes I_n$ describes the covariance of the signal $X_0 = Z_1 A^{1/2}$, which is an ${n \times m}$ random design matrix with independent subgaussian row vectors, and the other component $I_m \otimes B$ describes the covariance for the noise matrix $W =B^{1/2} Z_2$, which contains independent subgaussian column vectors $w^1, \ldots, w^m$, independent of $X_0$. This leads to a non-separable class of models for the observation $X$, which we denote by $X \sim \mathcal{M}_{n,m}(0, A \oplus B)$ throughout this paper. Our method on inverse covariance estimation corresponds to the proposal in Yuan (2010) and Loh and Wainwright (2012), only now dropping the i.i.d. or Gaussian assumptions. We present the statistical rates of convergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02859</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02859</id><created>2025-02-04</created><authors><author><keyname>Zhang</keyname><forenames>Haochen</forenames></author><author><keyname>Zheng</keyname><forenames>Zhong</forenames></author><author><keyname>Xue</keyname><forenames>Lingzhou</forenames></author></authors><title>Gap-Dependent Bounds for Federated $Q$-learning</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present the first gap-dependent analysis of regret and communication cost for on-policy federated $Q$-Learning in tabular episodic finite-horizon Markov decision processes (MDPs). Existing FRL methods focus on worst-case scenarios, leading to $\sqrt{T}$-type regret bounds and communication cost bounds with a $\log T$ term scaling with the number of agents $M$, states $S$, and actions $A$, where $T$ is the average total number of steps per agent. In contrast, our novel framework leverages the benign structures of MDPs, such as a strictly positive suboptimality gap, to achieve a $\log T$-type regret bound and a refined communication cost bound that disentangles exploration and exploitation. Our gap-dependent regret bound reveals a distinct multi-agent speedup pattern, and our gap-dependent communication cost bound removes the dependence on $MSA$ from the $\log T$ term. Notably, our gap-dependent communication cost bound also yields a better global switching cost when $M=1$, removing $SA$ from the $\log T$ term. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02861</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02861</id><created>2025-02-04</created><authors><author><keyname>Shen</keyname><forenames>Judy</forenames></author><author><keyname>Vitercik</keyname><forenames>Ellen</forenames></author><author><keyname>Wikum</keyname><forenames>Anders</forenames></author></authors><title>Algorithms with Calibrated Machine Learning Predictions</title><categories>stat.ML cs.DS cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The field of algorithms with predictions incorporates machine learning advice in the design of online algorithms to improve real-world performance. While this theoretical framework often assumes uniform reliability across all predictions, modern machine learning models can now provide instance-level uncertainty estimates. In this paper, we propose calibration as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the ski rental and online job scheduling problems. For ski rental, we design an algorithm that achieves optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02870</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02870</id><created>2025-02-04</created><authors><author><keyname>Wilson</keyname><forenames>Joseph</forenames></author><author><keyname>van der Heide</keyname><forenames>Chris</forenames></author><author><keyname>Hodgkinson</keyname><forenames>Liam</forenames></author><author><keyname>Roosta</keyname><forenames>Fred</forenames></author></authors><title>Uncertainty Quantification with the Empirical Neural Tangent Kernel</title><categories>stat.ML cs.LG</categories><comments>24 pages, 5 figures, 9 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While neural networks have demonstrated impressive performance across various tasks, accurately quantifying uncertainty in their predictions is essential to ensure their trustworthiness and enable widespread adoption in critical systems. Several Bayesian uncertainty quantification (UQ) methods exist that are either cheap or reliable, but not both. We propose a post-hoc, sampling-based UQ method for over-parameterized networks at the end of training. Our approach constructs efficient and meaningful deep ensembles by employing a (stochastic) gradient-descent sampling process on appropriately linearized networks. We demonstrate that our method effectively approximates the posterior of a Gaussian process using the empirical Neural Tangent Kernel. Through a series of numerical experiments, we show that our method not only outperforms competing approaches in computational efficiency (often reducing costs by multiple factors) but also maintains state-of-the-art performance across a variety of UQ metrics for both regression and classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02887</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02887</id><created>2025-02-04</created><authors><author><keyname>Perlaza</keyname><forenames>Samir M.</forenames></author><author><keyname>Bisson</keyname><forenames>Gaetan</forenames></author></authors><title>Variations on the Expectation Due to Changes in the Probability Measure</title><categories>cs.IT cs.LG math.IT math.PR math.ST stat.TH</categories><comments>Submitted to the IEEE International Symposium on Information Theory   (ISIT2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Closed-form expressions are presented for the variation of the expectation of a given function due to changes in the probability measure used for the expectation. They unveil interesting connections with Gibbs probability measures, the mutual information, and the lautum information. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02892</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02892</id><created>2025-02-05</created><authors><author><keyname>Nguyen</keyname><forenames>Cattram D</forenames></author><author><keyname>Lee</keyname><forenames>Katherine J</forenames></author><author><keyname>White</keyname><forenames>Ian R</forenames></author><author><keyname>van Buuren</keyname><forenames>Stef</forenames></author><author><keyname>Moreno-Betancur</keyname><forenames>Margarita</forenames></author></authors><title>Sensitivity analysis for multivariable missing data using multiple   imputation: a tutorial</title><categories>stat.ME</categories><comments>24 pages, 3 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multiple imputation is a popular method for handling missing data, with fully conditional specification (FCS) being one of the predominant imputation approaches for multivariable missingness. Unbiased estimation with standard implementations of multiple imputation depends on assumptions concerning the missingness mechanism (e.g. that data are "missing at random"). The plausibility of these assumptions can only be assessed using subject-matter knowledge, and not data alone. It is therefore important to perform sensitivity analyses to explore the robustness of results to violations of these assumptions (e.g. if the data are in fact "missing not at random"). In this tutorial, we provide a roadmap for conducting sensitivity analysis using the Not at Random Fully Conditional Specification (NARFCS) procedure for multivariate imputation. Using a case study from the Longitudinal Study of Australian Children, we work through the steps involved, from assessing the need to perform the sensitivity analysis, and specifying the NARFCS models and sensitivity parameters, through to implementing NARFCS using FCS procedures in R and Stata. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02914</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02914</id><created>2025-02-05</created><authors><author><keyname>Kelter</keyname><forenames>Riko</forenames></author><author><keyname>Pawel</keyname><forenames>Samuel</forenames></author></authors><title>Bayesian Power and Sample Size Calculations for Bayes Factors in the   Binomial Setting</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Bayesian design of experiments and sample size calculations usually rely on complex Monte Carlo simulations in practice. Obtaining bounds on Bayesian notions of the false-positive rate and power therefore often lack closed-form or approximate numerical solutions. In this paper, we focus on the sample size calculation in the binomial setting via Bayes factors, the predictive updating factor from prior to posterior odds. We discuss the drawbacks of sample size calculations via Monte Carlo simulations and propose a numerical root-finding approach which allows to determine the necessary sample size to obtain prespecified bounds of Bayesian power and type-I-error rate almost instantaneously. Real-world examples and applications in clinical trials illustrate the advantage of the proposed method. We focus on point-null versus composite and directional hypothesis tests, derive the corresponding Bayes factors, and discuss relevant aspects to consider when pursuing Bayesian design of experiments with the introduced approach. In summary, our approach allows for a Bayes-frequentist compromise by providing a Bayesian analogue to a frequentist power analysis for the Bayes factor in binomial settings. A case study from a Phase II trial illustrates the utility of our approach. The methods are implemented in our R package bfpwr. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02925</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02925</id><created>2025-02-05</created><authors><author><keyname>Hiew</keyname><forenames>Joshua Zoen-Git</forenames></author><author><keyname>Lim</keyname><forenames>Tongseok</forenames></author><author><keyname>Pass</keyname><forenames>Brendan</forenames></author><author><keyname>de Souza</keyname><forenames>Marcelo Cruz</forenames></author></authors><title>Data denoising with self consistency, variance maximization, and the   Kantorovich dominance</title><categories>stat.ME cs.LG math.PR math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a new framework for data denoising, partially inspired by martingale optimal transport. For a given noisy distribution (the data), our approach involves finding the closest distribution to it among all distributions which 1) have a particular prescribed structure (expressed by requiring they lie in a particular domain), and 2) are self-consistent with the data. We show that this amounts to maximizing the variance among measures in the domain which are dominated in convex order by the data. For particular choices of the domain, this problem and a relaxed version of it, in which the self-consistency condition is removed, are intimately related to various classical approaches to denoising. We prove that our general problem has certain desirable features: solutions exist under mild assumptions, have certain robustness properties, and, for very simple domains, coincide with solutions to the relaxed problem.   We also introduce a novel relationship between distributions, termed Kantorovich dominance, which retains certain aspects of the convex order while being a weaker, more robust, and easier-to-verify condition. Building on this, we propose and analyze a new denoising problem by substituting the convex order in the previously described framework with Kantorovich dominance. We demonstrate that this revised problem shares some characteristics with the full convex order problem but offers enhanced stability, greater computational efficiency, and, in specific domains, more meaningful solutions. Finally, we present simple numerical examples illustrating solutions for both the full convex order problem and the Kantorovich dominance problem. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02927</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02927</id><created>2025-02-05</created><authors><author><keyname>Azhad</keyname><forenames>Qazi J.</forenames></author><author><keyname>Khan</keyname><forenames>Abdul Nasir</forenames></author><author><keyname>Devi</keyname><forenames>Bhagwati</forenames></author><author><keyname>Khan</keyname><forenames>Jahangir Sabbir</forenames></author><author><keyname>Tripathi</keyname><forenames>Ayush</forenames></author></authors><title>Bayesian estimation of Unit-Weibull distribution based on dual   generalized order statistics with application to the Cotton Production Data</title><categories>stat.ME math.ST stat.OT stat.TH</categories><comments>19 Pages, 1 figure, 12 tables, preprint</comments><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Unit Weibull distribution with parameters $\alpha$ and $\beta$ is considered to study in the context of dual generalized order statistics. For the analysis purpose, Bayes estimators based on symmetric and asymmetric loss functions are obtained. The methods which are utilized for Bayesian estimation are approximation and simulation tools such as Lindley, Tierney-Kadane and Markov chain Monte Carlo methods. The authors have considered squared error loss function as symmetric and LINEX and general entropy loss function as asymmetric loss functions. After presenting the mathematical results, a simulation study is conducted to exhibit the performances of various derived estimators. As this study is considered for the dual generalized order statistics that is unification of models based distinct ordered random variable such as order statistics, record values, etc. This provides flexibility in our results and in continuation of this, the cotton production data of USA is analyzed for both submodels of ordered random variables: order statistics and record values. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02986</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02986</id><created>2025-02-05</created><authors><author><keyname>Sturma</keyname><forenames>Nils</forenames></author><author><keyname>Kranzlmueller</keyname><forenames>Miriam</forenames></author><author><keyname>Portakal</keyname><forenames>Irem</forenames></author><author><keyname>Drton</keyname><forenames>Mathias</forenames></author></authors><title>Matching Criterion for Identifiability in Sparse Factor Analysis</title><categories>math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Factor analysis models explain dependence among observed variables by a smaller number of unobserved factors. A main challenge in confirmatory factor analysis is determining whether the factor loading matrix is identifiable from the observed covariance matrix. The factor loading matrix captures the linear effects of the factors and, if unrestricted, can only be identified up to an orthogonal transformation of the factors. However, in many applications the factor loadings exhibit an interesting sparsity pattern that may lead to identifiability up to column signs. We study this phenomenon by connecting sparse factor models to bipartite graphs and providing sufficient graphical conditions for identifiability of the factor loading matrix up to column signs. In contrast to previous work, our main contribution, the matching criterion, exploits sparsity by operating locally on the graph structure, thereby improving existing conditions. Our criterion is efficiently decidable in time that is polynomial in the size of the graph, when restricting the search steps to sets of bounded size. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.02996</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.02996</id><created>2025-02-05</created><authors><author><keyname>Stewart</keyname><forenames>Lawrence</forenames><affiliation>DI-ENS, LIENS, Inria</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, SIERRA</affiliation></author><author><keyname>Berthet</keyname><forenames>Quentin</forenames></author></authors><title>Building Bridges between Regression, Clustering, and Classification</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regression, the task of predicting a continuous scalar target y based on some features x is one of the most fundamental tasks in machine learning and statistics. It has been observed and theoretically analyzed that the classical approach, meansquared error minimization, can lead to suboptimal results when training neural networks. In this work, we propose a new method to improve the training of these models on regression tasks, with continuous scalar targets. Our method is based on casting this task in a different fashion, using a target encoder, and a prediction decoder, inspired by approaches in classification and clustering. We showcase the performance of our method on a wide range of real-world datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03023</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03023</id><created>2025-02-05</created><authors><author><keyname>Zeng</keyname><forenames>Hao</forenames></author><author><keyname>Liu</keyname><forenames>Kangdao</forenames></author><author><keyname>Jing</keyname><forenames>Bingyi</forenames></author><author><keyname>Wei</keyname><forenames>Hongxin</forenames></author></authors><title>Parametric Scaling Law of Tuning Bias in Conformal Prediction</title><categories>cs.LG math.ST stat.ME stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional holdout set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03030</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03030</id><created>2025-02-05</created><authors><author><keyname>Hughes</keyname><forenames>Arthur</forenames></author><author><keyname>Parast</keyname><forenames>Layla</forenames></author><author><keyname>Thiébaut</keyname><forenames>Rodolphe</forenames></author><author><keyname>Hejblum</keyname><forenames>Boris P.</forenames></author></authors><title>Rank-Based Identification of High-dimensional Surrogate Markers:   Application to Vaccinology</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In vaccine trials with long-term participant follow-up, it is of great importance to identify surrogate markers that accurately infer long-term immune responses. These markers offer practical advantages such as providing early, indirect evidence of vaccine efficacy, and can accelerate vaccine development while identifying potential biomarkers. High-throughput technologies like RNA-sequencing have emerged as promising tools for understanding complex biological systems and informing new treatment strategies. However, these data are high-dimensional, presenting unique statistical challenges for existing surrogate marker identification methods. We introduce Rank-based Identification of high-dimensional SurrogatE Markers (RISE), a novel approach designed for small sample, high-dimensional settings typical in modern vaccine experiments. RISE employs a non-parametric univariate test to screen variables for promising candidates, followed by surrogate evaluation on independent data. Our simulation studies demonstrate RISE's desirable properties, including type one error rate control and empirical power under various conditions. Applying RISE to a clinical trial for inactivated influenza vaccination, we sought to identify genes whose post-vaccination expression could serve as a surrogate for the induced immune response. This analysis revealed a signature of genes whose combined expression at 1 day post-injection appears to be a reasonable surrogate for the neutralising antibody titres at 28 days after vaccination. Pathways related to innate antiviral signalling and interferon stimulation were strongly represented in this derived surrogate, providing a clear immunological interpretation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03048</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03048</id><created>2025-02-05</created><authors><author><keyname>MacKinlay</keyname><forenames>Dan</forenames></author></authors><title>The Ensemble Kalman Update is an Empirical Matheron Update</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Ensemble Kalman Filter (EnKF) is a widely used method for data assimilation in high-dimensional systems. In this paper, we show that the ensemble update step of the EnKF is equivalent to an empirical version of the Matheron update popular in the study of Gaussian process regression.   While this connection is simple, it seems not to be widely known, the literature about each technique seems distinct, and connections between the methods are not exploited. This paper exists to provide an informal introduction to the connection, with the necessary definitions so that it is intelligible to as broad an audience as possible. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03062</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03062</id><created>2025-02-05</created><authors><author><keyname>Yamada</keyname><forenames>Akifumi</forenames></author><author><keyname>Shiraishi</keyname><forenames>Tomohiro</forenames></author><author><keyname>Nishino</keyname><forenames>Shuichi</forenames></author><author><keyname>Katsuoka</keyname><forenames>Teruyuki</forenames></author><author><keyname>Taji</keyname><forenames>Kouichi</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Time Series Anomaly Detection in the Frequency Domain with Statistical   Reliability</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Effective anomaly detection in complex systems requires identifying change points (CPs) in the frequency domain, as abnormalities often arise across multiple frequencies. This paper extends recent advancements in statistically significant CP detection, based on Selective Inference (SI), to the frequency domain. The proposed SI method quantifies the statistical significance of detected CPs in the frequency domain using $p$-values, ensuring that the detected changes reflect genuine structural shifts in the target system. We address two major technical challenges to achieve this. First, we extend the existing SI framework to the frequency domain by appropriately utilizing the properties of discrete Fourier transform (DFT). Second, we develop an SI method that provides valid $p$-values for CPs where changes occur across multiple frequencies. Experimental results demonstrate that the proposed method reliably identifies genuine CPs with strong statistical guarantees, enabling more accurate root-cause analysis in the frequency domain of complex systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03090</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03090</id><created>2025-02-05</created><authors><author><keyname>Li</keyname><forenames>Jinglai</forenames></author><author><keyname>Wang</keyname><forenames>Hongqiao</forenames></author></authors><title>Gaussian Processes Regression for Uncertainty Quantification: An   Introductory Tutorial</title><categories>stat.CO cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian Process Regression (GPR) is a powerful method widely used in Uncertainty Quantification (UQ). This tutorial serves as an introductory guide for beginners, aiming to offer a structured and accessible overview of GPR's applications in UQ. We begin with an introduction to UQ and outline its key tasks, including uncertainty propagation, risk estimation, optimization under uncertainty, parameter estimation, and sensitivity analysis. We then introduce Gaussian Processes (GPs) as a surrogate modeling technique, detailing their formulation, choice of covariance kernels, hyperparameter estimation, and active learning strategies for efficient data acquisition. The tutorial further explores how GPR can be applied to different UQ tasks, including Bayesian quadrature for uncertainty propagation, active learning-based risk estimation, Bayesian optimization for optimization under uncertainty, and surrogate-based sensitivity analysis. Throughout, we emphasize how to leverage the unique formulation of GP for these UQ tasks, rather than simply using it as a standard surrogate model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03099</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03099</id><created>2025-02-05</created><authors><author><keyname>Betken</keyname><forenames>Annika</forenames></author><author><keyname>Micali</keyname><forenames>Giorgio</forenames></author><author><keyname>Schmidt-Hieber</keyname><forenames>Johannes</forenames></author></authors><title>Ordinal Patterns Based Change Points Detection</title><categories>math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ordinal patterns of a fixed number of consecutive values in a time series is the spatial ordering of these values. Counting how often a specific ordinal pattern occurs in a time series provides important insights into the properties of the time series. In this work, we prove the asymptotic normality of the relative frequency of ordinal patterns for time series with linear increments. Moreover, we apply ordinal patterns to detect changes in the distribution of a time series. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03119</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03119</id><created>2025-02-05</created><authors><author><keyname>Graf</keyname><forenames>Ricarda</forenames></author><author><keyname>Todd</keyname><forenames>Susan</forenames></author><author><keyname>Baksh</keyname><forenames>M. Fazil</forenames></author></authors><title>Comparison of the Cox proportional hazards model and Random Survival   Forest algorithm for predicting patient-specific survival probabilities in   clinical trial data</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Cox proportional hazards model is often used for model development in data from randomized controlled trials (RCT) with time-to-event outcomes. Random survival forests (RSF) is a machine-learning algorithm known for its high predictive performance. We conduct a comprehensive neutral comparison study to compare the predictive performance of Cox regression and RSF in real-world as well as simulated data. Performance is compared using multiple performance measures according to recommendations for the comparison of prognostic prediction models. We found that while the RSF usually outperforms the Cox model when using the $C$ index, Cox model predictions may be better calibrated. With respect to overall performance, the Cox model often exceeds the RSF in nonproportional hazards settings, while otherwise the RSF typically performs better especially for smaller sample sizes. Overall performance of the RSF is more affected by higher censoring rates, while overall performance of the Cox model suffers more from smaller sample sizes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03156</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03156</id><created>2025-02-05</created><authors><author><keyname>Jonzon</keyname><forenames>Gustav</forenames></author><author><keyname>Gabriel</keyname><forenames>Erin E</forenames></author><author><keyname>Sjölander</keyname><forenames>Arvid</forenames></author><author><keyname>Sachs</keyname><forenames>Michael C</forenames></author></authors><title>Adding covariates to bounds: What is the question?</title><categories>stat.ME</categories><msc-class>62D20</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Symbolic nonparametric bounds for partial identification of causal effects now have a long history in the causal literature. Sharp bounds, bounds that use all available information to make the range of values as narrow as possible, are often the goal. For this reason, many publications have focused on deriving sharp bounds, but the concept of sharp bounds is nuanced and can be misleading. In settings with ancillary covariates, the situation becomes more complex. We provide clear definitions for pointwise and uniform sharpness of covariate-conditional bounds, that we then use to prove some general and some specific to the IV setting results about the relationship between these two concepts. As we demonstrate, general conditions are much more difficult to determine and thus, we urge authors to be clear when including ancillary covariates in bounds via conditioning about the setting of interest and the assumptions made. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03163</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03163</id><created>2025-02-05</created><authors><author><keyname>Glückstad</keyname><forenames>Mie</forenames></author><author><keyname>Cirone</keyname><forenames>Nicola Muca</forenames></author><author><keyname>Teichmann</keyname><forenames>Josef</forenames></author></authors><title>Signature Reconstruction from Randomized Signatures</title><categories>math.CA cs.LG math.PR stat.ML</categories><comments>37 pages, 7 figures</comments><msc-class>60L10 (Primary) 60L70, 60L90, 68T07 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Controlled ordinary differential equations driven by continuous bounded variation curves can be considered a continuous time analogue of recurrent neural networks for the construction of expressive features of the input curves. We ask up to which extent well known signature features of such curves can be reconstructed from controlled ordinary differential equations with (untrained) random vector fields. The answer turns out to be algebraically involved, but essentially the number of signature features, which can be reconstructed from the non-linear flow of the controlled ordinary differential equation, is exponential in its hidden dimension, when the vector fields are chosen to be neural with depth two. Moreover, we characterize a general linear independence condition on arbitrary vector fields, under which the signature features up to some fixed order can always be reconstructed. Algebraically speaking this complements in a quantitative manner several well known results from the theory of Lie algebras of vector fields and puts them in a context of machine learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03174</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03174</id><created>2025-02-05</created><authors><author><keyname>Lecestre</keyname><forenames>Alexandre</forenames></author></authors><title>Robust Label Shift Quantification</title><categories>math.ST stat.ML stat.TH</categories><msc-class>62F35</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the label shift quantification problem. We propose robust estimators of the label distribution which turn out to coincide with the Maximum Likelihood Estimator. We analyze the theoretical aspects and derive deviation bounds for the proposed method, providing optimal guarantees in the well-specified case, along with notable robustness properties against outliers and contamination. Our results provide theoretical validation for empirical observations on the robustness of Maximum Likelihood Label Shift. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03208</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03208</id><created>2025-02-05</created><authors><author><keyname>Sziklai</keyname><forenames>Balázs R.</forenames></author><author><keyname>Gere</keyname><forenames>Attila</forenames></author><author><keyname>Héberger</keyname><forenames>Károly</forenames></author><author><keyname>Staudacher</keyname><forenames>Jochen</forenames></author></authors><title>rSRD: An R package for the Sum of Ranking Differences statistical   procedure</title><categories>math.ST stat.TH</categories><msc-class>62-04</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Sum of Ranking Differences (SRD) is a relatively novel, non-para-metric statistical procedure that has become increasingly popular recently. SRD compares solutions via a reference by applying a rank transformation on the input and calculating the distance from the reference in $L_1$ norm. Although the computation of the test statistics is simple, validating the results is cumbersome -- at least by hand. There are two validation steps involved. Comparison of Ranks with Random Numbers, which is a permutation-test, and cross-validation combined with statistical testing. Both options impose computational difficulties albeit different ones. The rSRD package was devised to simplify the validation process by reducing both validation steps into single function calls. In addition, the package provides various useful tools including data preprocessing and plotting. The package makes SRD accessible to a wide audience as there are currently no other software options with such a comprehensive toolkit. This paper aims to serve as a guide for practitioners by offering a detailed presentation of the features. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03210</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03210</id><created>2025-02-05</created><authors><author><keyname>Rubin</keyname><forenames>Noa</forenames></author><author><keyname>Fischer</keyname><forenames>Kirsten</forenames></author><author><keyname>Lindner</keyname><forenames>Javed</forenames></author><author><keyname>Dahmen</keyname><forenames>David</forenames></author><author><keyname>Seroussi</keyname><forenames>Inbar</forenames></author><author><keyname>Ringel</keyname><forenames>Zohar</forenames></author><author><keyname>Krämer</keyname><forenames>Michael</forenames></author><author><keyname>Helias</keyname><forenames>Moritz</forenames></author></authors><title>From Kernels to Features: A Multi-Scale Adaptive Theory of Feature   Learning</title><categories>cond-mat.dis-nn cs.LG stat.ML</categories><comments>24 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Theoretically describing feature learning in neural networks is crucial for understanding their expressive power and inductive biases, motivating various approaches. Some approaches describe network behavior after training through a simple change in kernel scale from initialization, resulting in a generalization power comparable to a Gaussian process. Conversely, in other approaches training results in the adaptation of the kernel to the data, involving complex directional changes to the kernel. While these approaches capture different facets of network behavior, their relationship and respective strengths across scaling regimes remains an open question. This work presents a theoretical framework of multi-scale adaptive feature learning bridging these approaches. Using methods from statistical mechanics, we derive analytical expressions for network output statistics which are valid across scaling regimes and in the continuum between them. A systematic expansion of the network's probability distribution reveals that mean-field scaling requires only a saddle-point approximation, while standard scaling necessitates additional correction terms. Remarkably, we find across regimes that kernel adaptation can be reduced to an effective kernel rescaling when predicting the mean network output of a linear network. However, even in this case, the multi-scale adaptive approach captures directional feature learning effects, providing richer insights than what could be recovered from a rescaling of the kernel alone. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03217</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03217</id><created>2025-02-05</created><authors><author><keyname>Cuellar</keyname><forenames>Maria</forenames></author></authors><title>The Prosecutor's Fallacy and Expert Testimony: A Modern Take Using   Likelihood Ratios</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Forensic examiners and attorneys need to know how to express evidence in favor or against a prosecutor's hypothesis in a way that avoids the prosecutor's fallacy and follows the modern reporting standards for forensic evidence. This article delves into the inherent conflict between legal and scientific principles, exacerbated by the prevalence of alternative facts in contemporary discourse. Courts grapple with contradictory expert testimonies, leading to a surge in erroneous rulings based on flawed amicus briefs and testimonies, notably the persistent prosecutor's fallacy. The piece underscores the necessity for legal practitioners to navigate this fallacy within the modern forensic science framework, emphasizing the importance of reporting likelihood ratios (LRs) over posterior probabilities. Recognizing the challenge of lay comprehension of LRs, the article calls for updated recommendations to mitigate the prosecutor's fallacy. Its contribution lies in providing a detailed analysis of the fallacy using LRs and advocating for a sound interpretation of evidence. Illustrated through a modified real case, this article serves as a valuable guide for legal professionals, offering insights into avoiding fallacious reasoning in forensic evidence assessment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03237</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03237</id><created>2025-02-05</created><authors><author><keyname>Mane</keyname><forenames>S. R.</forenames></author></authors><title>New technique for parameter estimation and improved fits to experimental   data for a set of compound Poisson distributions</title><categories>stat.ME math.PR</categories><comments>43 pages, 18 figures</comments><report-no>CC25-2</report-no><msc-class>62F30, 60-06, 05-08</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Compound Poisson distributions have been employed by many authors to fit experimental data, typically via the method of moments or maximum likelihood estimation. We propose a new technique and apply it to several sets of published data. It yields better fits than those obtained by the original authors for a set of widely employed compound Poisson distributions (in some cases, significantly better). The technique employs the power spectrum (the absolute square of the characteristic function). The new idea is suggested as a useful addition to the tools for parameter estimation of compound Poisson distributions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03241</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03241</id><created>2025-02-05</created><authors><author><keyname>Wang</keyname><forenames>Yaping</forenames></author><author><keyname>Liu</keyname><forenames>Sixu</forenames></author><author><keyname>Xiao</keyname><forenames>Qian</forenames></author></authors><title>Optimal design of experiments with quantitative-sequence factors</title><categories>stat.ME</categories><comments>This is the English version of the published paper in Chinese by   SCIENCE CHINA Mathematics</comments><msc-class>62K20, 62K99</msc-class><journal-ref>SCIENCE CHINA Mathematics, 2025, 55: 1-24 (in Chinese)</journal-ref><doi>10.1360/SCM-2024-0039</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A new type of experiment with joint considerations of quantitative and sequence factors is recently drawing much attention in medical science, bio-engineering, and many other disciplines. The input spaces of such experiments are semi-discrete and often very large. Thus, efficient and economical experimental designs are required. Based on the transformations and aggregations of good lattice point sets, we construct a new class of optimal quantitative-sequence (QS) designs that are marginally coupled, pair-balanced, space-filling, and asymptotically orthogonal. The proposed QS designs have a certain flexibility in run and factor sizes and are especially appealing for high-dimensional cases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03254</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03254</id><created>2025-02-05</created><authors><author><keyname>Młynarczyk</keyname><forenames>Dorota</forenames></author><author><keyname>Calvo</keyname><forenames>Gabriel</forenames></author><author><keyname>Palmi-Perales</keyname><forenames>Francisco</forenames></author><author><keyname>Armero</keyname><forenames>Carmen</forenames></author><author><keyname>Gómez-Rubio</keyname><forenames>Virgilio</forenames></author><author><keyname>Martinez-Iranzo</keyname><forenames>Ursula</forenames></author></authors><title>Bayesian network approach to building an affective module for a driver   behavioural model</title><categories>stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper focuses on the affective component of a Driver Behavioural Model (DBM), specifically modelling some driver's mental states, such as mental load and active fatigue, which may affect driving performance. We used Bayesian networks (BNs) to explore the dependencies between various relevant variables and estimate the probability that a driver was in a particular mental state based on their physiological and demographic conditions. Through this approach, our goal is to improve our understanding of driver behaviour in dynamic environments, with potential applications in traffic safety and autonomous vehicle technologies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03261</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03261</id><created>2025-02-05</created><authors><author><keyname>Somerstep</keyname><forenames>Seamus</forenames></author><author><keyname>Polo</keyname><forenames>Felipe Maia</forenames></author><author><keyname>de Oliveira</keyname><forenames>Allysson Flavio Melo</forenames></author><author><keyname>Mangal</keyname><forenames>Prattyush</forenames></author><author><keyname>Silva</keyname><forenames>Mírian</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Onkar</forenames></author><author><keyname>Yurochkin</keyname><forenames>Mikhail</forenames></author><author><keyname>Maity</keyname><forenames>Subha</forenames></author></authors><title>CARROT: A Cost Aware Rate Optimal Router</title><categories>stat.ML cs.LG cs.NI math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in LLM routing, or directing queries to the cheapest LLM that can deliver a suitable response. Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware Routing (SPROUT) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03273</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03273</id><created>2025-02-05</created><authors><author><keyname>Hadj-Amar</keyname><forenames>Beniamino</forenames></author><author><keyname>Krishnan</keyname><forenames>Vaishnav</forenames></author><author><keyname>Vannucci</keyname><forenames>Marina</forenames></author></authors><title>Bayesian Covariate-Dependent Circadian Modeling of Rest-Activity Rhythms</title><categories>stat.ME stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a Bayesian covariate-dependent anti-logistic circadian model for analyzing activity data collected via wrist-worn wearable devices. The proposed approach integrates covariates into the modeling of the amplitude and phase parameters, facilitating cohort-level analysis with enhanced flexibility and interpretability. To promote model sparsity, we employ an l_1-ball projection prior, enabling precise control over complexity while identifying significant predictors. We assess performances on simulated data and then apply the method to real-world actigraphy data from people with epilepsy. Our results demonstrate the model's effectiveness in uncovering complex relationships among demographic, psychological, and medical factors influencing rest-activity rhythms, offering insights for personalized clinical assessments and healthcare interventions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03279</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03279</id><created>2025-02-05</created><authors><author><keyname>Säilynoja</keyname><forenames>Teemu</forenames></author><author><keyname>Schmitt</keyname><forenames>Marvin</forenames></author><author><keyname>Bürkner</keyname><forenames>Paul</forenames></author><author><keyname>Vehtari</keyname><forenames>Aki</forenames></author></authors><title>Posterior SBC: Simulation-Based Calibration Checking Conditional on Data</title><categories>stat.ME stat.CO stat.ML</categories><comments>22 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Simulation-based calibration checking (SBC) refers to the validation of an inference algorithm and model implementation through repeated inference on data simulated from a generative model. In the original and commonly used approach, the generative model uses parameters drawn from the prior, and thus the approach is testing whether the inference works for simulated data generated with parameter values plausible under that prior. This approach is natural and desirable when we want to test whether the inference works for a wide range of datasets we might observe. However, after observing data, we are interested in answering whether the inference works conditional on that particular data. In this paper, we propose posterior SBC and demonstrate how it can be used to validate the inference conditionally on observed data. We illustrate the utility of posterior SBC in three case studies: (1) A simple multilevel model; (2) a model that is governed by differential equations; and (3) a joint integrative neuroscience model which is approximated via amortized Bayesian inference with neural networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03327</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03327</id><created>2025-02-05</created><authors><author><keyname>Kratsios</keyname><forenames>Anastasis</forenames></author><author><keyname>Furuya</keyname><forenames>Takashi</forenames></author></authors><title>Is In-Context Universality Enough? MLPs are Also Universal In-Context</title><categories>stat.ML cs.LG cs.NA cs.NE math.NA math.PR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The success of transformers is often linked to their ability to perform in-context learning. Recent work shows that transformers are universal in context, capable of approximating any real-valued continuous function of a context (a probability measure over $\mathcal{X}\subseteq \mathbb{R}^d$) and a query $x\in \mathcal{X}$. This raises the question: Does in-context universality explain their advantage over classical models? We answer this in the negative by proving that MLPs with trainable activation functions are also universal in-context. This suggests the transformer's success is likely due to other factors like inductive bias or training stability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03329</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03329</id><created>2025-02-05</created><authors><author><keyname>Parra</keyname><forenames>Camila Olarte</forenames></author><author><keyname>Daniel</keyname><forenames>Rhian M.</forenames></author><author><keyname>Bartlett</keyname><forenames>Jonathan W.</forenames></author></authors><title>Dealing with multiple intercurrent events using hypothetical and   treatment policy strategies simultaneously</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To precisely define the treatment effect of interest in a clinical trial, the ICH E9 estimand addendum describes that relevant so-called intercurrent events should be identified and strategies specified to deal with them. Handling intercurrent events with different strategies leads to different estimands. In this paper, we focus on estimands that involve addressing one intercurrent event with the treatment policy strategy and another with the hypothetical strategy. We define these estimands using potential outcomes and causal diagrams, considering the possible causal relationships between the two intercurrent events and other variables. We show that there are different causal estimand definitions and assumptions one could adopt, each having different implications for estimation, which is demonstrated in a simulation study. The different considerations are illustrated conceptually using a diabetes trial as an example. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03332</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03332</id><created>2025-02-05</created><authors><author><keyname>Janati</keyname><forenames>Yazid</forenames></author><author><keyname>Moufad</keyname><forenames>Badr</forenames></author><author><keyname>Qassime</keyname><forenames>Mehdi Abou El</forenames></author><author><keyname>Durmus</keyname><forenames>Alain</forenames></author><author><keyname>Moulines</keyname><forenames>Eric</forenames></author><author><keyname>Olsson</keyname><forenames>Jimmy</forenames></author></authors><title>A Mixture-Based Framework for Guiding Diffusion Models</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Denoising diffusion models have driven significant progress in the field of Bayesian inverse problems. Recent approaches use pre-trained diffusion models as priors to solve a wide range of such problems, only leveraging inference-time compute and thereby eliminating the need to retrain task-specific models on the same dataset. To approximate the posterior of a Bayesian inverse problem, a diffusion model samples from a sequence of intermediate posterior distributions, each with an intractable likelihood function. This work proposes a novel mixture approximation of these intermediate distributions. Since direct gradient-based sampling of these mixtures is infeasible due to intractable terms, we propose a practical method based on Gibbs sampling. We validate our approach through extensive experiments on image inverse problems, utilizing both pixel- and latent-space diffusion priors, as well as on source separation with an audio diffusion model. The code is available at https://www.github.com/badr-moufad/mgdm </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03341</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03341</id><created>2025-02-05</created><authors><author><keyname>Leisenberger</keyname><forenames>Harald</forenames></author><author><keyname>Pernkopf</keyname><forenames>Franz</forenames></author></authors><title>Adaptive Variational Inference in Probabilistic Graphical Models: Beyond   Bethe, Tree-Reweighted, and Convex Free Energies</title><categories>stat.ML cs.AI cs.LG</categories><comments>This work has been submitted to the Conference on Uncertainty in   Artificial Intelligence (UAI) 2025 for possible publication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Variational inference in probabilistic graphical models aims to approximate fundamental quantities such as marginal distributions and the partition function. Popular approaches are the Bethe approximation, tree-reweighted, and other types of convex free energies. These approximations are efficient but can fail if the model is complex and highly interactive. In this work, we analyze two classes of approximations that include the above methods as special cases: first, if the model parameters are changed; and second, if the entropy approximation is changed. We discuss benefits and drawbacks of either approach, and deduce from this analysis how a free energy approximation should ideally be constructed. Based on our observations, we propose approximations that automatically adapt to a given model and demonstrate their effectiveness for a range of difficult problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03342</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03342</id><created>2025-02-05</created><authors><author><keyname>Baouan</keyname><forenames>Ali</forenames></author></authors><title>Statistical analysis of team formation and player roles in football</title><categories>stat.AP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The availability of tracking data in football presents unique opportunities for analyzing team shape and player roles, but leveraging it effectively remains challenging. This difficulty arises from the significant overlap in player positions, which complicates the identification of distinct roles and team formations. In this work, we propose a novel model that incorporates a hidden permutation matrix to simultaneously estimate team formations and assign roles to players at the frame level. To address the cardinality of permutation sets, we develop a statistical procedure to parsimoniously select relevant matrices prior to parameter estimation. Additionally, to capture formation changes during a match, we introduce a latent regime variable, enabling the modeling of dynamic tactical adjustments. This framework disentangles player locations from role-specific positions, providing a clear representation of team structure. We demonstrate the applicability of our approach using player tracking data, showcasing its potential for detailed team and player analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03350</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03350</id><created>2025-02-05</created><authors><author><keyname>Li</keyname><forenames>Ziyan</forenames></author><author><keyname>Hiratani</keyname><forenames>Naoki</forenames></author></authors><title>Optimal Task Order for Continual Learning of Multiple Tasks</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continual learning of multiple tasks remains a major challenge for neural networks. Here, we investigate how task order influences continual learning and propose a strategy for optimizing it. Leveraging a linear teacher-student model with latent factors, we derive an analytical expression relating task similarity and ordering to learning performance. Our analysis reveals two principles that hold under a wide parameter range: (1) tasks should be arranged from the least representative to the most typical, and (2) adjacent tasks should be dissimilar. We validate these rules on both synthetic data and real-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100), demonstrating consistent performance improvements in both multilayer perceptrons and convolutional neural networks. Our work thus presents a generalizable framework for task-order optimization in task-incremental continual learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03366</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03366</id><created>2025-02-05</created><authors><author><keyname>Mucsányi</keyname><forenames>Bálint</forenames></author><author><keyname>Da Costa</keyname><forenames>Nathaël</forenames></author><author><keyname>Hennig</keyname><forenames>Philipp</forenames></author></authors><title>Rethinking Approximate Gaussian Inference in Classification</title><categories>cs.LG stat.ML</categories><comments>29 pages, 15 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In classification tasks, softmax functions are ubiquitously used as output activations to produce predictive probabilities. Such outputs only capture aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian inference methods have been proposed, which output Gaussian distributions over the logit space. Predictives are then obtained as the expectations of the Gaussian distributions pushed forward through the softmax. However, such softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC) approximations can be costly and noisy. We propose a simple change in the learning objective which allows the exact computation of predictives and enjoys improved training dynamics, with no runtime or memory overhead. This framework is compatible with a family of output activation functions that includes the softmax, as well as element-wise normCDF and sigmoid. Moreover, it allows for approximating the Gaussian pushforwards with Dirichlet distributions by analytic moment matching. We evaluate our approach combined with several approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and small-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertainty quantification capabilities compared to softmax MC sampling. Code is available at https://github.com/bmucsanyi/probit. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03414</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03414</id><created>2025-02-05</created><authors><author><keyname>Jetsupphasuk</keyname><forenames>Michael</forenames></author><author><keyname>Li</keyname><forenames>Didong</forenames></author><author><keyname>Hudgens</keyname><forenames>Michael G.</forenames></author></authors><title>Estimating causal effects using difference-in-differences under network   dependency and interference</title><categories>stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differences-in-differences (DiD) is a causal inference method for observational longitudinal data that assumes parallel expected outcome trajectories between treatment groups under the (possible) counterfactual of receiving a specific treatment. In this paper DiD is extended to allow for (i) network dependency where outcomes, treatments, and covariates may exhibit between-unit latent correlation, and (ii) interference, where treatments can affect outcomes in neighboring units. In this setting, the causal estimand of interest is the average exposure effect among units with a specific exposure level, where the exposure is a function of treatments from potentially many units. Under a conditional parallel trends assumption and suitable network dependency conditions, a doubly robust estimator allowing for data-adaptive nuisance function estimation is proposed and shown to be consistent and asymptotically normal with variance reaching the semiparametric efficiency bound. The proposed methods are evaluated in simulations and applied to study the effects of adopting emission control technologies in coal power plants on county-level mortality due to cardiovascular disease. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03435</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03435</id><created>2025-02-05</created><authors><author><keyname>Wu</keyname><forenames>Yu-Han</forenames></author><author><keyname>Marion</keyname><forenames>Pierre</forenames></author><author><keyname>Biau</keyname><forenames>Gérard</forenames></author><author><keyname>Boyer</keyname><forenames>Claire</forenames></author></authors><title>Taking a Big Step: Large Learning Rates in Denoising Score Matching   Prevent Memorization</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Denoising score matching plays a pivotal role in the performance of diffusion-based generative models. However, the empirical optimal score--the exact solution to the denoising score matching--leads to memorization, where generated samples replicate the training data. Yet, in practice, only a moderate degree of memorization is observed, even without explicit regularization. In this paper, we investigate this phenomenon by uncovering an implicit regularization mechanism driven by large learning rates. Specifically, we show that in the small-noise regime, the empirical optimal score exhibits high irregularity. We then prove that, when trained by stochastic gradient descent with a large enough learning rate, neural networks cannot stably converge to a local minimum with arbitrarily small excess risk. Consequently, the learned score cannot be arbitrarily close to the empirical optimal score, thereby mitigating memorization. To make the analysis tractable, we consider one-dimensional data and two-layer neural networks. Experiments validate the crucial role of the learning rate in preventing memorization, even beyond the one-dimensional setting. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03439</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03439</id><created>2025-02-05</created><authors><author><keyname>Linwu</keyname><forenames>Jun</forenames></author><author><keyname>Khurana</keyname><forenames>Varun</forenames></author><author><keyname>Karris</keyname><forenames>Nicholas</forenames></author><author><keyname>Cloninger</keyname><forenames>Alexander</forenames></author></authors><title>Linearized Optimal Transport pyLOT Library: A Toolkit for Machine   Learning on Point Clouds</title><categories>stat.ML cs.LG cs.MS stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pyLOT library offers a Python implementation of linearized optimal transport (LOT) techniques and methods to use in downstream tasks. The pipeline embeds probability distributions into a Hilbert space via the Optimal Transport maps from a fixed reference distribution, and this linearization allows downstream tasks to be completed using off the shelf (linear) machine learning algorithms. We provide a case study of performing ML on 3D scans of lemur teeth, where the original questions of classification, clustering, dimension reduction, and data generation reduce to simple linear operations performed on the LOT embedded representations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2502.03458</identifier><datestamp>2025-02-06</datestamp><setSpec>stat</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2502.03458</id><created>2025-02-05</created><authors><author><keyname>Johnston</keyname><forenames>Tim</forenames></author><author><keyname>Lytras</keyname><forenames>Iosif</forenames></author><author><keyname>Makras</keyname><forenames>Nikolaos</forenames></author><author><keyname>Sabanis</keyname><forenames>Sotirios</forenames></author></authors><title>The Performance Of The Unadjusted Langevin Algorithm Without Smoothness   Assumptions</title><categories>stat.ML math.OC math.PR stat.CO</categories><comments>26pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this article, we study the problem of sampling from distributions whose densities are not necessarily smooth nor log-concave. We propose a simple Langevin-based algorithm that does not rely on popular but computationally challenging techniques, such as the Moreau Yosida envelope or Gaussian smoothing. We derive non-asymptotic guarantees for the convergence of the algorithm to the target distribution in Wasserstein distances. Non asymptotic bounds are also provided for the performance of the algorithm as an optimizer, specifically for the solution of associated excess risk optimization problems. </abstract></arXiv></metadata></record>
