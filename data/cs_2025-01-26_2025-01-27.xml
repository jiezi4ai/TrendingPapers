<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1803.04660</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1803.04660</id><created>2018-03-13</created><updated>2025-01-24</updated><authors><author><keyname>Dragan</keyname><forenames>Feodor F.</forenames><affiliation>UniBuc, ICI</affiliation></author><author><keyname>Ducoffe</keyname><forenames>Guillaume</forenames><affiliation>UniBuc, ICI</affiliation></author><author><keyname>Habib</keyname><forenames>Michel</forenames><affiliation>IRIF</affiliation></author><author><keyname>Viennot</keyname><forenames>Laurent</forenames><affiliation>DI-ENS, ARGO</affiliation></author></authors><title>Certificates in P and Subquadratic-Time Computation of Radius, Diameter,   and all Eccentricities in Graphs</title><categories>cs.DM cs.CC cs.DS cs.NI</categories><comments>Accept{\'e} {\`a} SODA 2025</comments><proxy>ccsd</proxy><journal-ref>Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete   Algorithms (SODA), Jan 2025, New Orleans (LA), United States. pp.2157-2193</journal-ref><doi>10.1137/1.9781611978322.70</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of fine-grained complexity, we investigate the notion of certificate enabling faster polynomial-time algorithms. We specifically target radius (minimum eccentricity), diameter (maximum eccentricity), and all-eccentricity computations for which quadratic-time lower bounds are known under plausible conjectures. In each case, we introduce a notion of certificate as a specific set of nodes from which appropriate bounds on all eccentricities can be derived in subquadratic time when this set has sublinear size. The existence of small certificates is a barrier against SETH-based lower bounds for these problems. We indeed prove that for graph classes with small certificates, there exist randomized subquadratic-time algorithms for computing the radius, the diameter, and all eccentricities respectively.Moreover, these notions of certificates are tightly related to algorithms probing the graph through one-to-all distance queries and allow to explain the efficiency of practical radius and diameter algorithms from the literature. Our formalization enables a novel primal-dual analysis of a classical approach for diameter computation that leads to algorithms for radius, diameter and all eccentricities with theoretical guarantees with respect to certain graph parameters. This is complemented by experimental results on various types of real-world graphs showing that these parameters appear to be low in practice. Finally, we obtain refined results for several graph classes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:1912.11209</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>1912.11209</id><created>2019-12-23</created><authors><author><keyname>Singh</keyname><forenames>Vikas</forenames></author><author><keyname>Verma</keyname><forenames>Nishchal K.</forenames></author></authors><title>An Entropy-based Variable Feature Weighted Fuzzy k-Means Algorithm for   High Dimensional Data</title><categories>cs.LG stat.ML</categories><doi>10.1007/s11042-024-20493-4</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a new fuzzy k-means algorithm for the clustering of high dimensional data in various subspaces. Since, In the case of high dimensional data, some features might be irrelevant and relevant but may have different significance in the clustering. For a better clustering, it is crucial to incorporate the contribution of these features in the clustering process. To combine these features, in this paper, we have proposed a new fuzzy k-means clustering algorithm in which the objective function of the fuzzy k-means is modified using two different entropy term. The first entropy term helps to minimize the within-cluster dispersion and maximize the negative entropy to determine clusters to contribute to the association of data points. The second entropy term helps to control the weight of the features because different features have different contributing weights in the clustering process for obtaining the better partition of the data. The efficacy of the proposed method is presented in terms of various clustering measures on multiple datasets and compared with various state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2008.04615</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2008.04615</id><created>2020-08-11</created><authors><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Degerli</keyname><forenames>Aysen</forenames></author><author><keyname>Hamid</keyname><forenames>Tahir</forenames></author><author><keyname>Mazhar</keyname><forenames>Rashid</forenames></author><author><keyname>Ahmed</keyname><forenames>Rayyan</forenames></author><author><keyname>Abouhasera</keyname><forenames>Rayaan</forenames></author><author><keyname>Zabihi</keyname><forenames>Morteza</forenames></author><author><keyname>Malik</keyname><forenames>Junaid</forenames></author><author><keyname>Hamila</keyname><forenames>Ridha</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>Left Ventricular Wall Motion Estimation by Active Polynomials for Acute   Myocardial Infarction Detection</title><categories>eess.IV cs.CV</categories><doi>10.1109/ACCESS.2020.3038743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Echocardiogram (echo) is the earliest and the primary tool for identifying regional wall motion abnormalities (RWMA) in order to diagnose myocardial infarction (MI) or commonly known as heart attack. This paper proposes a novel approach, Active Polynomials, which can accurately and robustly estimate the global motion of the Left Ventricular (LV) wall from any echo in a robust and accurate way. The proposed algorithm quantifies the true wall motion occurring in LV wall segments so as to assist cardiologists diagnose early signs of an acute MI. It further enables medical experts to gain an enhanced visualization capability of echo images through color-coded segments along with their "maximum motion displacement" plots helping them to better assess wall motion and LV Ejection-Fraction (LVEF). The outputs of the method can further help echo-technicians to assess and improve the quality of the echocardiogram recording. A major contribution of this study is the first public echo database collection composed by physicians at the Hamad Medical Corporation Hospital in Qatar. The so-called HMC-QU database will serve as the benchmark for the forthcoming relevant studies. The results over the HMC-QU dataset show that the proposed approach can achieve high accuracy, sensitivity and precision in MI detection even though the echo quality is quite poor, and the temporal resolution is low. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2008.09985</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2008.09985</id><created>2020-08-23</created><authors><author><keyname>Belikov</keyname><forenames>Alexander V.</forenames></author><author><keyname>Rzhetsky</keyname><forenames>Andrey</forenames></author><author><keyname>Evans</keyname><forenames>James</forenames></author></authors><title>Detecting signal from science:The structure of research communities and   prior knowledge improves prediction of genetic regulatory experiments</title><categories>cs.SI physics.soc-ph q-bio.MN</categories><comments>61 pages, 20 figures</comments><acm-class>J.2; I.6.3</acm-class><doi>10.1038/s42256-022-00474-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explosive growth of scientists, scientific journals, articles and findings in recent years exponentially increases the difficulty scientists face in navigating prior knowledge. This challenge is exacerbated by uncertainty about the reproducibility of published findings. The availability of massive digital archives, machine reading and extraction tools on the one hand, and automated high-throughput experiments on the other, allow us to evaluate these challenges at scale and identify novel opportunities for accelerating scientific advance. Here we demonstrate a Bayesian calculus that enables the positive prediction of robust, replicable scientific claims with findings automatically extracted from published literature on gene interactions. We matched these findings, filtered by science, with unfiltered gene interactions measured by the massive LINCS L1000 high-throughput experiment to identify and counteract sources of bias. Our calculus is built on easily extracted publication meta-data regarding the position of a scientific claim within the web of prior knowledge, and its breadth of support across institutions, authors and communities, revealing that scientifically focused but socially and institutionally independent research activity is most likely to replicate. These findings recommend policies that go against the common practice of channeling biomedical research funding into centralized research consortia and institutes rather than dispersing it more broadly. Our results demonstrate that robust scientific findings hinge upon a delicate balance of shared focus and independence, and that this complex pattern can be computationally exploited to decode bias and predict the replicability of published findings. These insights provide guidance for scientists navigating the research literature and for science funders seeking to improve it. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2009.12698</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2009.12698</id><created>2020-09-26</created><updated>2021-01-06</updated><authors><author><keyname>Degerli</keyname><forenames>Aysen</forenames></author><author><keyname>Ahishali</keyname><forenames>Mete</forenames></author><author><keyname>Yamac</keyname><forenames>Mehmet</forenames></author><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Chowdhury</keyname><forenames>Muhammad E. H.</forenames></author><author><keyname>Hameed</keyname><forenames>Khalid</forenames></author><author><keyname>Hamid</keyname><forenames>Tahir</forenames></author><author><keyname>Mazhar</keyname><forenames>Rashid</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>COVID-19 Infection Map Generation and Detection from Chest X-Ray Images</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1007/s13755-021-00146-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-aided diagnosis has become a necessity for accurate and immediate coronavirus disease 2019 (COVID-19) detection to aid treatment and prevent the spread of the virus. Numerous studies have proposed to use Deep Learning techniques for COVID-19 diagnosis. However, they have used very limited chest X-ray (CXR) image repositories for evaluation with a small number, a few hundreds, of COVID-19 samples. Moreover, these methods can neither localize nor grade the severity of COVID-19 infection. For this purpose, recent studies proposed to explore the activation maps of deep networks. However, they remain inaccurate for localizing the actual infestation making them unreliable for clinical use. This study proposes a novel method for the joint localization, severity grading, and detection of COVID-19 from CXR images by generating the so-called infection maps. To accomplish this, we have compiled the largest dataset with 119,316 CXR images including 2951 COVID-19 samples, where the annotation of the ground-truth segmentation masks is performed on CXRs by a novel collaborative human-machine approach. Furthermore, we publicly release the first CXR dataset with the ground-truth segmentation masks of the COVID-19 infected regions. A detailed set of experiments show that state-of-the-art segmentation networks can learn to localize COVID-19 infection with an F1-score of 83.20%, which is significantly superior to the activation maps created by the previous methods. Finally, the proposed approach achieved a COVID-19 detection performance with 94.96% sensitivity and 99.88% specificity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2101.12254</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2101.12254</id><created>2021-01-28</created><authors><author><keyname>Degerli</keyname><forenames>Aysen</forenames></author><author><keyname>Ahishali</keyname><forenames>Mete</forenames></author><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Chowdhury</keyname><forenames>Muhammad E. H.</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>Reliable COVID-19 Detection Using Chest X-ray Images</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1109/ICIP42928.2021.9506442</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Coronavirus disease 2019 (COVID-19) has emerged the need for computer-aided diagnosis with automatic, accurate, and fast algorithms. Recent studies have applied Machine Learning algorithms for COVID-19 diagnosis over chest X-ray (CXR) images. However, the data scarcity in these studies prevents a reliable evaluation with the potential of overfitting and limits the performance of deep networks. Moreover, these networks can discriminate COVID-19 pneumonia usually from healthy subjects only or occasionally, from limited pneumonia types. Thus, there is a need for a robust and accurate COVID-19 detector evaluated over a large CXR dataset. To address this need, in this study, we propose a reliable COVID-19 detection network: ReCovNet, which can discriminate COVID-19 pneumonia from 14 different thoracic diseases and healthy subjects. To accomplish this, we have compiled the largest COVID-19 CXR dataset: QaTa-COV19 with 124,616 images including 4603 COVID-19 samples. The proposed ReCovNet achieved a detection performance with 98.57% sensitivity and 99.77% specificity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2103.03223</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2103.03223</id><created>2021-03-04</created><updated>2025-01-24</updated><authors><author><keyname>Schumacher</keyname><forenames>Tobias</forenames></author><author><keyname>Strohmaier</keyname><forenames>Markus</forenames></author><author><keyname>Lemmerich</keyname><forenames>Florian</forenames></author></authors><title>A Comparative Evaluation of Quantification Methods</title><categories>cs.LG cs.AI cs.IR</categories><comments>40 pages, 18 figures, 9 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Quantification represents the problem of estimating the distribution of class labels on unseen data. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on overall more than 40 data sets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods including the threshold selection-based Median Sweep and TSMax methods, the DyS framework including the HDy method, Forman's mixture model, and Friedman's method that performs best in the binary setting. For the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the HDx method, the Generalized Probabilistic Adjusted Count, the readme method, the energy distance minimization method, the EM algorithm for quantification, and Friedman's method. We also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. More generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. Our results can guide practitioners who intend to apply quantification algorithms and help researchers to identify opportunities for future research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2110.09934</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2110.09934</id><created>2021-10-19</created><updated>2024-11-22</updated><authors><author><keyname>Saboor</keyname><forenames>Abdul</forenames></author><author><keyname>Vinogradov</keyname><forenames>Evgenii</forenames></author><author><keyname>Cui</keyname><forenames>Zhuangzhuang</forenames></author><author><keyname>Coene</keyname><forenames>Sander</forenames></author><author><keyname>Joseph</keyname><forenames>Wout</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author></authors><title>Elevating the future of mobility: UAV-enabled Intelligent Transportation   Systems</title><categories>cs.NI</categories><comments>The 7th International Conference on Advanced Communication   Technologies and Networking (CommNet 2024)</comments><doi>10.1109/CommNet63022.2024.10793277</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Intelligent Transportation Systems (ITS) increasingly rely on connectivity for efficient traffic management and enhanced user experience. The existing ITS solutions operate mainly within a 2D domain, thus missing the potential benefits of aerial platforms. This paper envisions 3D ITS by integrating aerial platforms, such as Unmanned Aerial Vehicles (UAVs), to simultaneously improve network coverage and support multi-modal transportation, including Advanced Air Mobility (AAM). Using stochastic models, we investigate how UAV-based Aerial Base Stations (ABSs) can address the limitations of traditional Terrestrial Base Stations (TBSs) by offering superior coverage, particularly in urban environments. Our results demonstrate that ABSs have 106.67% more coverage area than TBS, higher Signal-to-Noise Ratio (SNR) distribution, and are suitable for high-throughput ITS applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2111.04960</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2111.04960</id><created>2021-11-09</created><authors><author><keyname>El-Arsh</keyname><forenames>Hassan Y.</forenames></author><author><keyname>Abdelaziz</keyname><forenames>Amr</forenames></author><author><keyname>Elliethy</keyname><forenames>Ahmed</forenames></author><author><keyname>Aly</keyname><forenames>Hussein A.</forenames></author></authors><title>Information-Theoretic Limits for Steganography in Multimedia</title><categories>cs.CR cs.IT math.IT</categories><comments>Manuscript posted on 03.07.2021, 23:19 at   "https://www.techrxiv.org/articles/preprint/Information-Theoretic_Limits_for_Steganography_in_Multimedia/14867241"</comments><journal-ref>Journal of Information Security and Applications, 2025</journal-ref><doi>10.1016/j.jisa.2025.103966</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Steganography is the art and science of hiding data within innocent-looking objects (cover objects). Multimedia objects such as images and videos are an attractive type of cover objects due to their high embedding rates. There exist many techniques for performing steganography in both the literature and the practical world. Meanwhile, the definition of the steganographic capacity for multimedia and how to be calculated has not taken full attention. In this paper, for multivariate quantized-Gaussian-distributed multimedia, we study the maximum achievable embedding rate with respect to the statistical properties of cover objects against the maximum achievable performance by any steganalytic detector. Toward this goal, we evaluate the maximum allowed entropy of the hidden message source subject to the maximum probability of error of the steganalytic detector which is bounded by the KL-divergence between the statistical distributions for the cover and the stego objects. We give the exact scaling constant that governs the relationship between the entropies of the hidden message and the cover object. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2111.05790</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2111.05790</id><created>2021-11-09</created><updated>2023-02-26</updated><authors><author><keyname>Degerli</keyname><forenames>Aysen</forenames></author><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Hamid</keyname><forenames>Tahir</forenames></author><author><keyname>Mazhar</keyname><forenames>Rashid</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>Early Myocardial Infarction Detection over Multi-view Echocardiography</title><categories>eess.IV cs.AI cs.CV cs.LG physics.med-ph</categories><doi>10.1016/j.bspc.2023.105448</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Myocardial infarction (MI) is the leading cause of mortality in the world that occurs due to a blockage of the coronary arteries feeding the myocardium. An early diagnosis of MI and its localization can mitigate the extent of myocardial damage by facilitating early therapeutic interventions. Following the blockage of a coronary artery, the regional wall motion abnormality (RWMA) of the ischemic myocardial segments is the earliest change to set in. Echocardiography is the fundamental tool to assess any RWMA. Assessing the motion of the left ventricle (LV) wall only from a single echocardiography view may lead to missing the diagnosis of MI as the RWMA may not be visible on that specific view. Therefore, in this study, we propose to fuse apical 4-chamber (A4C) and apical 2-chamber (A2C) views in which a total of 12 myocardial segments can be analyzed for MI detection. The proposed method first estimates the motion of the LV wall by Active Polynomials (APs), which extract and track the endocardial boundary to compute myocardial segment displacements. The features are extracted from the A4C and A2C view displacements, which are concatenated and fed into the classifiers to detect MI. The main contributions of this study are 1) creation of a new benchmark dataset by including both A4C and A2C views in a total of 260 echocardiography recordings, which is publicly shared with the research community, 2) improving the performance of the prior work of threshold-based APs by a Machine Learning based approach, and 3) a pioneer MI detection approach via multi-view echocardiography by fusing the information of A4C and A2C views. Experimental results show that the proposed method achieves 90.91% sensitivity and 86.36% precision for MI detection over multi-view echocardiography. The software implementation is shared at https://github.com/degerliaysen/MultiEchoAI. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.07645</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.07645</id><created>2022-02-15</created><updated>2025-01-24</updated><authors><author><keyname>Hohm</keyname><forenames>Julian</forenames></author><author><keyname>Heinemann</keyname><forenames>Andreas</forenames></author><author><keyname>Wiesmaier</keyname><forenames>Alexander</forenames></author></authors><title>Towards a maturity model for crypto-agility assessment</title><categories>cs.CR</categories><comments>added a red box pointing to the PFS publication and project site</comments><journal-ref>Lecture Notes in Computer Science 13877 (2023) 104-119</journal-ref><doi>10.1007/978-3-031-30122-3_7</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This work proposes the Crypto-Agility Maturity Model (CAMM for short), a maturity model for determining the state of crypto-agility of a given software or IT landscape. CAMM consists of five levels, for each level a set of requirements have been formulated based on literature review. Initial feedback from field experts confirms that CAMM has a well-designed structure and is easy to comprehend. Based on our model, the crytographic agility of an IT landscape can be systematically measured and improved step by step. We expect that this will enable companies and to respond better and faster to threats resulting from broken cryptographic schemes. This work serves to promote CAMM and encourage others to apply it in practice and develop it jointly. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.10185</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.10185</id><created>2022-02-21</created><updated>2022-05-30</updated><authors><author><keyname>Degerli</keyname><forenames>Aysen</forenames></author><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Chowdhury</keyname><forenames>Muhammad E. H.</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>OSegNet: Operational Segmentation Network for COVID-19 Detection using   Chest X-ray Images</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1109/ICIP46576.2022.9897412</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Coronavirus disease 2019 (COVID-19) has been diagnosed automatically using Machine Learning algorithms over chest X-ray (CXR) images. However, most of the earlier studies used Deep Learning models over scarce datasets bearing the risk of overfitting. Additionally, previous studies have revealed the fact that deep networks are not reliable for classification since their decisions may originate from irrelevant areas on the CXRs. Therefore, in this study, we propose Operational Segmentation Network (OSegNet) that performs detection by segmenting COVID-19 pneumonia for a reliable diagnosis. To address the data scarcity encountered in training and especially in evaluation, this study extends the largest COVID-19 CXR dataset: QaTa-COV19 with 121,378 CXRs including 9258 COVID-19 samples with their corresponding ground-truth segmentation masks that are publicly shared with the research community. Consequently, OSegNet has achieved a detection performance with the highest accuracy of 99.65% among the state-of-the-art deep models with 98.09% precision. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2202.13075</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2202.13075</id><created>2022-02-26</created><updated>2025-01-23</updated><authors><author><keyname>Grasselli</keyname><forenames>Maurizio</forenames></author><author><keyname>Parolini</keyname><forenames>Nicola</forenames></author><author><keyname>Poiatti</keyname><forenames>Andrea</forenames></author><author><keyname>Verani</keyname><forenames>Marco</forenames></author></authors><title>Non-isothermal non-Newtonian fluids: the stationary case</title><categories>math.AP cs.NA math.NA</categories><journal-ref>Mathematical Models and Methods in Applied Sciences, 33(9) pp.   1747-1801, 2023</journal-ref><doi>10.1142/S0218202523500410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stationary Navier-Stokes equations for a non-Newtonian incompressible fluid are coupled with the stationary heat equation and subject to Dirichlet type boundary conditions. The viscosity is supposed to depend on the temperature and the stress depends on the strain through a suit-able power law depending on $p \in (1,2)$ (shear thinning case). For this problem we establish the existence of a weak solution as well as we prove some regularity results both for the Navier-Stokes and the Stokes cases. Then, the latter case with the Carreau power law is approximated through a FEM scheme and some error estimates are obtained. Such estimates are then validated through some two-dimensional numerical experiments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2203.02968</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2203.02968</id><created>2022-03-06</created><updated>2025-01-24</updated><authors><author><keyname>Cornelissen</keyname><forenames>Arjan</forenames></author><author><keyname>Mande</keyname><forenames>Nikhil S.</forenames></author><author><keyname>Patro</keyname><forenames>Subhasree</forenames></author></authors><title>Improved Quantum Query Upper Bounds Based on Classical Decision Trees</title><categories>quant-ph cs.CC</categories><doi>10.4230/LIPIcs.FSTTCS.2022.15</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Given a classical query algorithm as a decision tree, when does there exist a quantum query algorithm with a speed-up over the classical one? We provide a general construction based on the structure of the underlying decision tree, and prove that this can give us an up-to-quadratic quantum speed-up. In particular, we obtain a bounded-error quantum query algorithm of cost $O(\sqrt{s})$ to compute a Boolean function (more generally, a relation) that can be computed by a classical (even randomized) decision tree of size $s$.   Lin and Lin [ToC'16] and Beigi and Taghavi [Quantum'20] showed results of a similar flavor, and gave upper bounds in terms of a quantity which we call the "guessing complexity" of a decision tree. We identify that the guessing complexity of a decision tree equals its rank, a notion introduced by Ehrenfeucht and Haussler [Inf. Comp.'89] in the context of learning theory. This answers a question posed by Lin and Lin, who asked whether the guessing complexity of a decision tree is related to any complexity-theoretic measure. We also show a polynomial separation between rank and randomized rank for the complete binary AND-OR tree.   Beigi and Taghavi constructed span programs and dual adversary solutions for Boolean functions given classical decision trees computing them and an assignment of non-negative weights to its edges. We explore the effect of changing these weights on the resulting span program complexity and objective value of the dual adversary bound, and capture the best possible weighting scheme by an optimization program. We exhibit a solution to this program and argue its optimality from first principles. We also exhibit decision trees for which our bounds are asymptotically stronger than those of Lin and Lin, and Beigi and Taghavi. This answers a question of Beigi and Taghavi, who asked whether different weighting schemes could yield better upper bounds. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2206.08178</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2206.08178</id><created>2022-06-16</created><updated>2022-06-23</updated><authors><author><keyname>Olaniyi</keyname><forenames>Babaniyi Yusuf</forenames></author><author><keyname>del Río</keyname><forenames>Ana Fernández</forenames></author><author><keyname>Periáñez</keyname><forenames>África</forenames></author><author><keyname>Bellhouse</keyname><forenames>Lauren</forenames></author></authors><title>User Engagement in Mobile Health Applications</title><categories>stat.ML cs.CY cs.LG stat.AP</categories><comments>Accepted at KDD 2022 Health Day, will be appear in the KDD2022   proceedings as a full paper</comments><journal-ref>KDD '22: Proceedings of the 28th ACM SIGKDD Conference on   Knowledge Discovery and Data Mining, 4704-4712, 2022</journal-ref><doi>10.1145/3534678.3542681</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Mobile health apps are revolutionizing the healthcare ecosystem by improving communication, efficiency, and quality of service. In low- and middle-income countries, they also play a unique role as a source of information about health outcomes and behaviors of patients and healthcare workers, while providing a suitable channel to deliver both personalized and collective policy interventions. We propose a framework to study user engagement with mobile health, focusing on healthcare workers and digital health apps designed to support them in resource-poor settings. The behavioral logs produced by these apps can be transformed into daily time series characterizing each user's activity. We use probabilistic and survival analysis to build multiple personalized measures of meaningful engagement, which could serve to tailor content and digital interventions suiting each health worker's specific needs. Special attention is given to the problem of detecting churn, understood as a marker of complete disengagement. We discuss the application of our methods to the Indian and Ethiopian users of the Safe Delivery App, a capacity-building tool for skilled birth attendants. This work represents an important step towards a full characterization of user engagement in mobile health applications, which can significantly enhance the abilities of health workers and, ultimately, save lives. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2206.14674</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2206.14674</id><created>2022-06-29</created><updated>2025-01-24</updated><authors><author><keyname>Lyons</keyname><forenames>Terry</forenames></author><author><keyname>McLeod</keyname><forenames>Andrew D.</forenames></author></authors><title>Signature Methods in Machine Learning</title><categories>stat.ML cs.LG cs.NA math.CA math.NA math.ST stat.ME stat.TH</categories><comments>Version accepted for publication in EMS Surveys in Mathematical   Sciences</comments><msc-class>60L10, 93C15, 68Q32, 34F05</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Signature-based techniques give mathematical insight into the interactions between complex streams of evolving data. These insights can be quite naturally translated into numerical approaches to understanding streamed data, and perhaps because of their mathematical precision, have proved useful in analysing streamed data in situations where the data is irregular, and not stationary, and the dimension of the data and the sample sizes are both moderate. Understanding streamed multi-modal data is exponential: a word in $n$ letters from an alphabet of size $d$ can be any one of $d^n$ messages. Signatures remove the exponential amount of noise that arises from sampling irregularity, but an exponential amount of information still remain. This survey aims to stay in the domain where that exponential scaling can be managed directly. Scalability issues are an important challenge in many problems but would require another survey article and further ideas. This survey describes a range of contexts where the data sets are small enough to remove the possibility of massive machine learning, and the existence of small sets of context free and principled features can be used effectively. The mathematical nature of the tools can make their use intimidating to non-mathematicians. The examples presented in this article are intended to bridge this communication gap and provide tractable working examples drawn from the machine learning context. Notebooks are available online for several of these examples. This survey builds on the earlier paper of Ilya Chevryev and Andrey Kormilitzin which had broadly similar aims at an earlier point in the development of this machinery. This article illustrates how the theoretical insights offered by signatures are simply realised in the analysis of application data in a way that is largely agnostic to the data type. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2211.05408</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2211.05408</id><created>2022-11-10</created><updated>2025-01-24</updated><authors><author><keyname>Kanagawa</keyname><forenames>Heishiro</forenames></author><author><keyname>Barp</keyname><forenames>Alessandro</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Mackey</keyname><forenames>Lester</forenames></author></authors><title>Controlling Moments with Kernel Stein Discrepancies</title><categories>stat.ML cs.LG stat.CO</categories><comments>102 pages, 10 figures, Update key citations</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Kernel Stein discrepancies (KSDs) measure the quality of a distributional approximation and can be computed even when the target density has an intractable normalizing constant. Notable applications include the diagnosis of approximate MCMC samplers and goodness-of-fit tests for unnormalized statistical models. The present work analyzes the convergence control properties of KSDs. We first show that standard KSDs used for weak convergence control fail to control moment convergence. To address this limitation, we next provide sufficient conditions under which alternative diffusion KSDs control both moment and weak convergence. As an immediate consequence we develop, for each $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wasserstein convergence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2211.08373</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2211.08373</id><created>2022-11-15</created><updated>2025-01-24</updated><authors><author><keyname>Brakensiek</keyname><forenames>Joshua</forenames></author><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Sandeep</keyname><forenames>Sai</forenames></author></authors><title>SDPs and Robust Satisfiability of Promise CSP</title><categories>cs.DS cs.DM cs.LO</categories><comments>74 pages, numerous revisions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a constraint satisfaction problem (CSP), a robust satisfaction algorithm is one that outputs an assignment satisfying most of the constraints on instances that are near-satisfiable. It is known that the CSPs that admit efficient robust satisfaction algorithms are precisely those of bounded width, i.e., CSPs whose satisfiability can be checked by a simple local consistency algorithm (eg., 2-SAT or Horn-SAT in the Boolean case). While the exact satisfiability of a bounded width CSP can be checked by combinatorial algorithms, the robust algorithm is based on rounding a canonical Semidefinite Programming (SDP) relaxation.   In this work, we initiate the study of robust satisfaction algorithms for promise CSPs, which are a vast generalization of CSPs that have received much attention recently. The motivation is to extend the theory beyond CSPs, as well as to better understand the power of SDPs. We present robust SDP rounding algorithms under some general conditions, namely the existence of particular high-dimensional Boolean symmetries known as majority or alternating threshold polymorphisms. On the hardness front, we prove that the lack of such polymorphisms makes the PCSP hard for all pairs of symmetric Boolean predicates. Our approach relies on SDP integrality gaps argued via the absence of certain colorings of the sphere, with connections to sphere Ramsey theory.   We conjecture that PCSPs with robust satisfaction algorithms are precisely those for which the feasibility of the canonical SDP implies (exact) satisfiability. We also give a precise algebraic condition, known as a minion characterization, of which PCSPs have the latter property. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2212.12770</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2212.12770</id><created>2022-12-24</created><updated>2025-01-24</updated><authors><author><keyname>Hossain</keyname><forenames>Md. Ismail</forenames></author><author><keyname>Rakib</keyname><forenames>Mohammed</forenames></author><author><keyname>Elahi</keyname><forenames>M. M. Lutfe</forenames></author><author><keyname>Mohammed</keyname><forenames>Nabeel</forenames></author><author><keyname>Rahman</keyname><forenames>Shafin</forenames></author></authors><title>COLT: Cyclic Overlapping Lottery Tickets for Faster Pruning of   Convolutional Neural Networks</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pruning refers to the elimination of trivial weights from neural networks. The sub-networks within an overparameterized model produced after pruning are often called Lottery tickets. This research aims to generate winning lottery tickets from a set of lottery tickets that can achieve similar accuracy to the original unpruned network. We introduce a novel winning ticket called Cyclic Overlapping Lottery Ticket (COLT) by data splitting and cyclic retraining of the pruned network from scratch. We apply a cyclic pruning algorithm that keeps only the overlapping weights of different pruned models trained on different data segments. Our results demonstrate that COLT can achieve similar accuracies (obtained by the unpruned model) while maintaining high sparsities. We show that the accuracy of COLT is on par with the winning tickets of Lottery Ticket Hypothesis (LTH) and, at times, is better. Moreover, COLTs can be generated using fewer iterations than tickets generated by the popular Iterative Magnitude Pruning (IMP) method. In addition, we also notice COLTs generated on large datasets can be transferred to small ones without compromising performance, demonstrating its generalizing capability. We conduct all our experiments on Cifar-10, Cifar-100 &amp; TinyImageNet datasets and report superior performance than the state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2303.02304</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2303.02304</id><created>2023-03-03</created><updated>2025-01-24</updated><authors><author><keyname>Xiao</keyname><forenames>Xiongye</forenames></author><author><keyname>Cao</keyname><forenames>Defu</forenames></author><author><keyname>Yang</keyname><forenames>Ruochen</forenames></author><author><keyname>Gupta</keyname><forenames>Gaurav</forenames></author><author><keyname>Liu</keyname><forenames>Gengshuo</forenames></author><author><keyname>Yin</keyname><forenames>Chenzhong</forenames></author><author><keyname>Balan</keyname><forenames>Radu</forenames></author><author><keyname>Bogdan</keyname><forenames>Paul</forenames></author></authors><title>Coupled Multiwavelet Neural Operator Learning for Coupled Partial   Differential Equations</title><categories>cs.LG</categories><comments>Accepted to ICLR 2023: https://openreview.net/forum?id=kIo_C6QmMOM;   This article is alternatively titled: Coupled Multiwavelet Operator Learning   for Coupled Differential Equations</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Coupled partial differential equations (PDEs) are key tasks in modeling the complex dynamics of many physical processes. Recently, neural operators have shown the ability to solve PDEs by learning the integral kernel directly in Fourier/Wavelet space, so the difficulty for solving the coupled PDEs depends on dealing with the coupled mappings between the functions. Towards this end, we propose a \textit{coupled multiwavelets neural operator} (CMWNO) learning scheme by decoupling the coupled integral kernels during the multiwavelet decomposition and reconstruction procedures in the Wavelet space. The proposed model achieves significantly higher accuracy compared to previous learning-based solvers in solving the coupled PDEs including Gray-Scott (GS) equations and the non-local mean field game (MFG) problem. According to our experimental results, the proposed model exhibits a $2\times \sim 4\times$ improvement relative $L$2 error compared to the best results from the state-of-the-art models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2303.13410</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2303.13410</id><created>2023-03-23</created><authors><author><keyname>Suchde</keyname><forenames>Pratik</forenames></author><author><keyname>Leithäuser</keyname><forenames>Christian</forenames></author><author><keyname>Kuhnert</keyname><forenames>Jörg</forenames></author><author><keyname>Bordas</keyname><forenames>Stéphane P. A.</forenames></author></authors><title>Volume and Mass Conservation in Lagrangian Meshfree Methods</title><categories>physics.flu-dyn cs.NA math.NA</categories><report-no>126: e7657</report-no><journal-ref>Int J Numer Methods Eng 2025</journal-ref><doi>10.1002/nme.7657</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Meshfree Lagrangian frameworks for free surface flow simulations do not conserve fluid volume. Meshfree particle methods like SPH are not mimetic, in the sense that discrete mass conservation does not imply discrete volume conservation. On the other hand, meshfree collocation methods typically do not use any notion of mass. As a result, they are neither mass conservative nor volume conservative at the discrete level. In this paper, we give an overview of various sources of conservation errors across different meshfree methods. The present work focuses on one specific issue: unreliable volume and mass definitions. We introduce the concept of representative masses and densities, which are essential for accurate post-processing especially in meshfree collocation methods. Using these, we introduce an artificial compression or expansion in the fluid to rectify errors in volume conservation. Numerical experiments show that the introduced frameworks significantly improve volume conservation behaviour, even for complex industrial test cases such as automotive water crossing. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.04411</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.04411</id><created>2023-04-10</created><updated>2025-01-23</updated><authors><author><keyname>Shakib</keyname><forenames>Kazi Hassan</forenames></author><author><keyname>Rahman</keyname><forenames>Mizanur</forenames></author><author><keyname>Islam</keyname><forenames>Mhafuzul</forenames></author><author><keyname>Chowdhury</keyname><forenames>Mashrur</forenames></author></authors><title>Quantum Cyber-Attack on Blockchain-based VANET</title><categories>cs.CR</categories><comments>This paper consists of 16 pages with 10 figures. It has been accepted   to IEEE Transactions of Intelligent Transportation Systems</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Blockchain-based Vehicular Ad-hoc Network (VANET) is widely considered as secure communication architecture for a connected transportation system. With the advent of quantum computing, there are concerns regarding the vulnerability of this architecture against cyber-attacks. In this study, a potential threat is investigated in a blockchain-based VANET, and a corresponding quantum cyber-attack is developed. Specifically, a quantum impersonation attack using Quantum-Shor algorithm is developed to break the Rivest-Shamir-Adleman (RSA) encrypted digital signatures of VANET and thus create a threat for the trust-based blockchain scheme of VANET. A blockchain-based VANET, vehicle-to-everything (V2X) communication, and vehicular mobility are simulated using OMNET++, the extended INET library, and vehicles-in-network simulation (VEINS) along with simulation of urban mobility (SUMO), respectively. A small key RSA based message encryption is implemented using IBM Qiskit, which is an open-source quantum software development kit. The findings reveal that the quantum cyber-attack, example, impersonation attack is able to successfully break the trust chain of a blockchain-based VANET. This highlights the need for a quantum secured blockchain. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.06701</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.06701</id><created>2023-04-13</created><updated>2025-01-23</updated><authors><author><keyname>Bhatt</keyname><forenames>Umang</forenames></author><author><keyname>Chen</keyname><forenames>Valerie</forenames></author><author><keyname>Collins</keyname><forenames>Katherine M.</forenames></author><author><keyname>Kamalaruban</keyname><forenames>Parameswaran</forenames></author><author><keyname>Kallina</keyname><forenames>Emma</forenames></author><author><keyname>Weller</keyname><forenames>Adrian</forenames></author><author><keyname>Talwalkar</keyname><forenames>Ameet</forenames></author></authors><title>Learning Personalized Decision Support Policies</title><categories>cs.LG cs.AI cs.CY cs.HC</categories><comments>AAAI 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Individual human decision-makers may benefit from different forms of support to improve decision outcomes, but when each form of support will yield better outcomes? In this work, we posit that personalizing access to decision support tools can be an effective mechanism for instantiating the appropriate use of AI assistance. Specifically, we propose the general problem of learning a decision support policy that, for a given input, chooses which form of support to provide to decision-makers for whom we initially have no prior information. We develop $\texttt{Modiste}$, an interactive tool to learn personalized decision support policies. $\texttt{Modiste}$ leverages stochastic contextual bandit techniques to personalize a decision support policy for each decision-maker and supports extensions to the multi-objective setting to account for auxiliary objectives like the cost of support. We find that personalized policies outperform offline policies, and, in the cost-aware setting, reduce the incurred cost with minimal degradation to performance. Our experiments include various realistic forms of support (e.g., expert consensus and predictions from a large language model) on vision and language tasks. Our human subject experiments validate our computational experiments, demonstrating that personalization can yield benefits in practice for real users, who interact with $\texttt{Modiste}$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2304.09466</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2304.09466</id><created>2023-04-19</created><updated>2023-08-11</updated><authors><author><keyname>Degerli</keyname><forenames>Aysen</forenames></author><author><keyname>Jakala</keyname><forenames>Pekka</forenames></author><author><keyname>Pajula</keyname><forenames>Juha</forenames></author><author><keyname>Immonen</keyname><forenames>Milla</forenames></author><author><keyname>Lopez</keyname><forenames>Miguel Bordallo</forenames></author></authors><title>MAMAF-Net: Motion-Aware and Multi-Attention Fusion Network for Stroke   Diagnosis</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1016/j.bspc.2024.106381</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Stroke is a major cause of mortality and disability worldwide from which one in four people are in danger of incurring in their lifetime. The pre-hospital stroke assessment plays a vital role in identifying stroke patients accurately to accelerate further examination and treatment in hospitals. Accordingly, the National Institutes of Health Stroke Scale (NIHSS), Cincinnati Pre-hospital Stroke Scale (CPSS) and Face Arm Speed Time (F.A.S.T.) are globally known tests for stroke assessment. However, the validity of these tests is skeptical in the absence of neurologists and access to healthcare may be limited. Therefore, in this study, we propose a motion-aware and multi-attention fusion network (MAMAF-Net) that can detect stroke from multimodal examination videos. Contrary to other studies on stroke detection from video analysis, our study for the first time proposes an end-to-end solution from multiple video recordings of each subject with a dataset encapsulating stroke, transient ischemic attack (TIA), and healthy controls. The proposed MAMAF-Net consists of motion-aware modules to sense the mobility of patients, attention modules to fuse the multi-input video data, and 3D convolutional layers to perform diagnosis from the attention-based extracted features. Experimental results over the collected Stroke-data dataset show that the proposed MAMAF-Net achieves a successful detection of stroke with 93.62% sensitivity and 95.33% AUC score. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2305.06070</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2305.06070</id><created>2023-05-10</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Zhihui</forenames></author></authors><title>Numerical Ergodicity and Uniform Estimate of Monotone SPDEs Driven by   Multiplicative Noise</title><categories>math.NA cs.NA math.PR</categories><comments>To appear in Journal of Computational Mathematics,   doi:10.4208/jcm.2409-m2024-0041</comments><msc-class>Primary 60H35, 60H15, 65L60</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We analyze the long-time behavior of numerical schemes for a class of monotone stochastic partial differential equations (SPDEs) driven by multiplicative noise. By deriving several time-independent a priori estimates for the numerical solutions, combined with the ergodic theory of Markov processes, we establish the exponential ergodicity of these schemes with a unique invariant measure, respectively. Applying these results to the stochastic Allen--Cahn equation indicates that these schemes always have at least one invariant measure, respectively, and converge strongly to the exact solution with sharp time-independent rates. We also show that these numerical invariant measures are exponentially ergodic and thus give an affirmative answer to a question proposed in (J. Cui, J. Hong, and L. Sun, Stochastic Process. Appl. (2021): 55--93), provided that the interface thickness is not too small. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2308.03496</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2308.03496</id><created>2023-08-07</created><updated>2025-01-23</updated><authors><author><keyname>Gadekar</keyname><forenames>Abhijit</forenames></author></authors><title>Design and Implementation of an Efficient Onboard Computer System for   CanSat Atmosphere Monitoring</title><categories>eess.SY cs.AR cs.RO cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With advancements in technology, the smaller versions of satellites have gained momentum in the space industry for earth monitoring and communication-based applications. The rise of CanSat technology has significantly impacted the space industry by providing a cost-effective solution for space exploration. CanSat is a simulation model of a real satellite and plays a crucial role in collecting and transmitting atmospheric data. This paper discusses the design of an Onboard Computer System forCanSat, used to study various environmental parameters by monitoring the concentrations of gases in the atmosphere. The Onboard Computer System uses GPS, accelerometer, altitude, temperature, pressure, gyroscope, magnetometer, UV radiation, and air quality sensors for atmospheric sensing. A highly efficient and low-power ESP32 microcontroller and a transceiver module are used to acquire data, facilitate seamless communication and transmit the collected data to the ground station. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2308.08475</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2308.08475</id><created>2023-08-16</created><authors><author><keyname>Elavsky</keyname><forenames>Frank</forenames></author><author><keyname>Nadolskis</keyname><forenames>Lucas</forenames></author><author><keyname>Moritz</keyname><forenames>Dominik</forenames></author></authors><title>Data Navigator: An accessibility-centered data navigation toolkit</title><categories>cs.HC</categories><comments>To appear at IEEE VIS 2023</comments><doi>10.1109/TVCG.2023.3327393</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Making data visualizations accessible for people with disabilities remains a significant challenge in current practitioner efforts. Existing visualizations often lack an underlying navigable structure, fail to engage necessary input modalities, and rely heavily on visual-only rendering practices. These limitations exclude people with disabilities, especially users of assistive technologies. To address these challenges, we present Data Navigator: a system built on a dynamic graph structure, enabling developers to construct navigable lists, trees, graphs, and flows as well as spatial, diagrammatic, and geographic relations. Data Navigator supports a wide range of input modalities: screen reader, keyboard, speech, gesture detection, and even fabricated assistive devices. We present 3 case examples with Data Navigator, demonstrating we can provide accessible navigation structures on top of raster images, integrate with existing toolkits at scale, and rapidly develop novel prototypes. Data Navigator is a step towards making accessible data visualizations easier to design and implement. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2308.09081</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2308.09081</id><created>2023-08-17</created><authors><author><keyname>Blackwell</keyname><forenames>Daniel</forenames></author><author><keyname>Becker</keyname><forenames>Ingolf</forenames></author><author><keyname>Clark</keyname><forenames>David</forenames></author></authors><title>Hyperfuzzing: black-box security hypertesting with a grey-box fuzzer</title><categories>cs.SE cs.CR</categories><comments>11 pages, 4 figures</comments><acm-class>D.2.5</acm-class><doi>10.1007/s10664-024-10556-3</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Information leakage is a class of error that can lead to severe consequences. However unlike other errors, it is rarely explicitly considered during the software testing process. LeakFuzzer advances the state of the art by using a noninterference security property together with a security flow policy as an oracle. As the tool extends the state of the art fuzzer, AFL++, LeakFuzzer inherits the advantages of AFL++ such as scalability, automated input generation, high coverage and low developer intervention.   The tool can detect the same set of errors that a normal fuzzer can detect, with the addition of being able to detect violations of secure information flow policies.   We evaluated LeakFuzzer on a diverse set of 10 C and C++ benchmarks containing known information leaks, ranging in size from just 80 to over 900k lines of code. Seven of these are taken from real-world CVEs including Heartbleed and a recent error in PostgreSQL. Given 20 24-hour runs, LeakFuzzer can find 100% of the leaks in the SUTs whereas existing techniques using such as the CBMC model checker and AFL++ augmented with different sanitizers can only find 40% at best. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2308.12891</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2308.12891</id><created>2023-08-24</created><updated>2024-11-06</updated><authors><author><keyname>Grekas</keyname><forenames>Georgios</forenames></author><author><keyname>Koumatos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Makridakis</keyname><forenames>Charalambos</forenames></author><author><keyname>Vikelis</keyname><forenames>Andreas</forenames></author></authors><title>A class of Discontinuous Galerkin methods for nonlinear variational   problems</title><categories>math.NA cs.NA</categories><doi>10.1090/mcom/4040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of Discontinuous Galerkin methods, we study approximations of nonlinear variational problems associated with convex energies. We propose element-wise nonconforming finite element methods to discretize the continuous minimisation problem. Using $\Gamma$-convergence arguments we show that the discrete minimisers converge to the unique minimiser of the continuous problem as the mesh parameter tends to zero, under the additional contribution of appropriately defined penalty terms at the level of the discrete energies. We finally substantiate the feasibility of our methods by numerical examples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2308.14241</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2308.14241</id><created>2023-08-27</created><authors><author><keyname>Zeng</keyname><forenames>Zehua</forenames></author><author><keyname>Yang</keyname><forenames>Junran</forenames></author><author><keyname>Moritz</keyname><forenames>Dominik</forenames></author><author><keyname>Heer</keyname><forenames>Jeffrey</forenames></author><author><keyname>Battle</keyname><forenames>Leilani</forenames></author></authors><title>Too Many Cooks: Exploring How Graphical Perception Studies Influence   Visualization Recommendations in Draco</title><categories>cs.HC</categories><doi>10.1109/TVCG.2023.3326527</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Findings from graphical perception can guide visualization recommendation algorithms in identifying effective visualization designs. However, existing algorithms use knowledge from, at best, a few studies, limiting our understanding of how complementary (or contradictory) graphical perception results influence generated recommendations. In this paper, we present a pipeline of applying a large body of graphical perception results to develop new visualization recommendation algorithms and conduct an exploratory study to investigate how results from graphical perception can alter the behavior of downstream algorithms. Specifically, we model graphical perception results from 30 papers in Draco -- a framework to model visualization knowledge -- to develop new recommendation algorithms. By analyzing Draco-generated algorithms, we showcase the feasibility of our method to (1) identify gaps in existing graphical perception literature informing recommendation algorithms, (2) cluster papers by their preferred design rules and constraints, and (3) investigate why certain studies can dominate Draco's recommendations, whereas others may have little influence. Given our findings, we discuss the potential for mutually reinforcing advancements in graphical perception and visualization recommendation research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2309.00843</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2309.00843</id><created>2023-09-02</created><authors><author><keyname>Vinogradov</keyname><forenames>Evgenii</forenames></author><author><keyname>Kumar</keyname><forenames>A. V. S. Sai Bhargav</forenames></author><author><keyname>Minucci</keyname><forenames>Franco</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author><author><keyname>Natalizio</keyname><forenames>Enrico</forenames></author></authors><title>Remote ID for separation provision and multi-agent navigation</title><categories>cs.RO cs.NI</categories><comments>10 pages, 8 figures, 2023 IEEE/AIAA 42nd Digital Avionics Systems   Conference (DASC)</comments><doi>10.1109/DASC58513.2023.10311133</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the integration of drone identification data (Remote ID) with collision avoidance mechanisms to improve the safety and efficiency of multi-drone operations. We introduce an improved Near Mid-Air Collision (NMAC) definition, termed as UAV NMAC (uNMAC), which accounts for uncertainties in the drone's location due to self-localization errors and possible displacements between two location reports. Our proposed uNMAC-based Reciprocal Velocity Obstacle (RVO) model integrates Remote ID messages with RVO to enable enhanced collision-free navigation. We propose modifications to the Remote ID format to include data on localization accuracy and drone airframe size, facilitating more efficient collision avoidance decisions. Through extensive simulations, we demonstrate that our approach halves mission execution times compared to a conservative standard Remote ID-based RVO. Importantly, it ensures collision-free operations even under localization uncertainties. By integrating the improved Remote ID messages and uNMAC-based RVO, we offer a solution to significantly increase airspace capacity while adhering to strict safety standards. Our study emphasizes the potential to augment the safety and efficiency of future drone operations, thereby benefiting industries reliant on drone technologies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2309.02208</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2309.02208</id><created>2023-09-05</created><updated>2025-01-24</updated><authors><author><keyname>Fjordholm</keyname><forenames>Ulrik S.</forenames></author><author><keyname>Karlsen</keyname><forenames>Kenneth H.</forenames></author><author><keyname>Pang</keyname><forenames>Peter H. C.</forenames></author></authors><title>Convergent finite difference schemes for stochastic transport equations</title><categories>math.NA cs.NA math.AP</categories><comments>42 pages; minor amendments and typos corrected</comments><msc-class>60H15, 65M12, 60H50, 65M80</msc-class><doi>10.1137/23M159946X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present difference schemes for stochastic transport equations with low-regularity velocity fields. We establish $L^2$ stability and convergence of the difference approximations under conditions that are less strict than those required for deterministic transport equations. The $L^2$ estimate, crucial for the analysis, is obtained through a discrete duality argument and a comprehensive examination of a class of backward parabolic difference schemes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2309.04589</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2309.04589</id><created>2023-09-08</created><updated>2025-01-23</updated><authors><author><keyname>Inae</keyname><forenames>Eric</forenames></author><author><keyname>Liu</keyname><forenames>Gang</forenames></author><author><keyname>Jiang</keyname><forenames>Meng</forenames></author></authors><title>Motif-aware Attribute Masking for Molecular Graph Pre-training</title><categories>cs.LG q-bio.QM</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Attribute reconstruction is used to predict node or edge features in the pre-training of graph neural networks. Given a large number of molecules, they learn to capture structural knowledge, which is transferable for various downstream property prediction tasks and vital in chemistry, biomedicine, and material science. Previous strategies that randomly select nodes to do attribute masking leverage the information of local neighbors However, the over-reliance of these neighbors inhibits the model's ability to learn from higher-level substructures. For example, the model would learn little from predicting three carbon atoms in a benzene ring based on the other three but could learn more from the inter-connections between the functional groups, or called chemical motifs. In this work, we propose and investigate motif-aware attribute masking strategies to capture inter-motif structures by leveraging the information of atoms in neighboring motifs. Once each graph is decomposed into disjoint motifs, the features for every node within a sample motif are masked. The graph decoder then predicts the masked features of each node within the motif for reconstruction. We evaluate our approach on eight molecular property prediction datasets and demonstrate its advantages. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2309.12397</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2309.12397</id><created>2023-09-21</created><updated>2025-01-23</updated><authors><author><keyname>Chen</keyname><forenames>Bo-Hsun</forenames></author><author><keyname>Negrut</keyname><forenames>Peter</forenames></author><author><keyname>Liang</keyname><forenames>Thomas</forenames></author><author><keyname>Batagoda</keyname><forenames>Nevindu</forenames></author><author><keyname>Zhang</keyname><forenames>Harry</forenames></author><author><keyname>Negrut</keyname><forenames>Dan</forenames></author></authors><title>POLAR-Sim: Augmenting NASA's POLAR Dataset for Data-Driven Lunar   Perception and Rover Simulation</title><categories>cs.RO cs.CV</categories><comments>11 pages, 9 figures. This work has been submitted to the IEEE for   possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NASA's POLAR dataset contains approximately 2,600 pairs of high dynamic range stereo photos captured across 13 varied terrain scenarios, including areas with sparse or dense rock distributions, craters, and rocks of different sizes. The purpose of these photos is to spur development in robotics, AI-based perception, and autonomous navigation. Acknowledging a scarcity of lunar images from around the lunar poles, NASA Ames produced on Earth but in controlled conditions images that resemble rover operating conditions from these regions of the Moon. We report on the outcomes of an effort aimed at accomplishing two tasks. In Task 1, we provided bounding boxes and semantic segmentation information for all the images in NASA's POLAR dataset. This effort resulted in 23,000 labels and semantic segmentation annotations pertaining to rocks, shadows, and craters. In Task 2, we generated the digital twins of the 13 scenarios that have been used to produce all the photos in the POLAR dataset. Specifically, for each of these scenarios, we produced individual meshes, texture information, and material properties associated with the ground and the rocks in each scenario. This allows anyone with a camera model to synthesize images associated with any of the 13 scenarios of the POLAR dataset. Effectively, one can generate as many semantically labeled synthetic images as desired -- with different locations and exposure values in the scene, for different positions of the sun, with or without the presence of active illumination, etc. The benefit of this work is twofold. Using outcomes of Task 1, one can train and/or test perception algorithms that deal with Moon images. For Task 2, one can produce as much data as desired to train and test AI algorithms that are anticipated to work in lunar conditions. All the outcomes of this work are available in a public repository for unfettered use and distribution. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2309.12887</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2309.12887</id><created>2023-09-22</created><updated>2025-01-23</updated><authors><author><keyname>Culf</keyname><forenames>Eric</forenames></author><author><keyname>Mehta</keyname><forenames>Arthur</forenames></author></authors><title>New Approaches to Complexity via Quantum Graphs</title><categories>quant-ph cs.CC math.OA</categories><comments>v2: 47 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Problems based on the structure of graphs -- for example finding cliques, independent sets, or colourings -- are of fundamental importance in classical complexity. Defining well-formulated decision problems for quantum graphs, which are an operator system generalisation of graphs, presents several technical challenges. Consequently, the connections between quantum graphs and complexity have been underexplored.   In this work, we introduce and study the clique problem for quantum graphs. Our approach utilizes a well-known connection between quantum graphs and quantum channels. The inputs for our problems are presented as circuits inducing quantum channel, which implicitly determine a corresponding quantum graph. We show that, quantified over all channels, this problem is complete for QMA(2); in fact, it remains QMA(2)-complete when restricted to channels that are probabilistic mixtures of entanglement-breaking and partial trace channels. Quantified over a subset of entanglement-breaking channels, this problem becomes QMA-complete, and restricting further to deterministic or classical noisy channels gives rise to complete problems for NP and MA, respectively. In this way, we exhibit a classical complexity problem whose natural quantisation is QMA(2), rather than QMA, and provide the first problem that allows for a direct comparison of the classes QMA(2), QMA, MA, and NP by quantifying over increasingly larger families of instances.   We use methods that are inspired by self-testing to provide a direct proof of QMA(2)-completeness, rather than reducing to a previously-studied complete problem. We also give a new proof of the celebrated reduction of QMA(k) to QMA(2). In parallel, we study a version of the closely-related independent set problem for quantum graphs, and provide preliminary evidence that it may be in general weaker in complexity, contrasting to the classical case. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.04118</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.04118</id><created>2023-10-06</created><updated>2025-01-22</updated><authors><author><keyname>Muñoz</keyname><forenames>Thomas</forenames></author><author><keyname>Riveros</keyname><forenames>Cristian</forenames></author><author><keyname>Vansummeren</keyname><forenames>Stijn</forenames></author></authors><title>Enumeration and updates for conjunctive linear algebra queries through   expressibility</title><categories>cs.CC cs.DB cs.DS cs.LO</categories><comments>70 pages total: 63 main body, 3 of references and 4 of appendix which   contains additional proofs</comments><acm-class>H.2.1; H.2.5; F.2.2; F.4.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Due to the importance of linear algebra and matrix operations in data analytics, there is significant interest in using relational query optimization and processing techniques for evaluating (sparse) linear algebra programs. In particular, in recent years close connections have been established between linear algebra programs and relational algebra that allow transferring optimization techniques of the latter to the former. In this paper, we ask ourselves which linear algebra programs in MATLANG correspond to the free-connex and q-hierarchical fragments of conjunctive first-order logic. Both fragments have desirable query processing properties: free-connex conjunctive queries support constant-delay enumeration after a linear-time preprocessing phase, and q-hierarchical conjunctive queries further allow constant-time updates. By characterizing the corresponding fragments of MATLANG, we hence identify the fragments of linear algebra programs that one can evaluate with constant-delay enumeration after linear-time preprocessing and with constant-time updates. To derive our results, we improve and generalize previous correspondences between MATLANG and relational algebra evaluated over semiring-annotated relations. In addition, we identify properties on semirings that allow to generalize the complexity bounds for free-connex and q-hierarchical conjunctive queries from Boolean annotations to general semirings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.08507</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.08507</id><created>2023-10-12</created><updated>2025-01-24</updated><authors><author><keyname>Nitin</keyname><forenames>Vikram</forenames></author><author><keyname>Mulhern</keyname><forenames>Anne</forenames></author><author><keyname>Arora</keyname><forenames>Sanjay</forenames></author><author><keyname>Ray</keyname><forenames>Baishakhi</forenames></author></authors><title>Yuga: Automatically Detecting Lifetime Annotation Bugs in the Rust   Language</title><categories>cs.SE</categories><journal-ref>IEEE Transactions on Software Engineering, vol. 50, no. 10, pp.   2602-2613, Oct. 2024</journal-ref><doi>10.1109/TSE.2024.3447671</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Rust programming language is becoming increasingly popular among systems programmers due to its efficient performance and robust memory safety guarantees. Rust employs an ownership model to ensure this guarantee by allowing each value to be owned by only one identifier at a time. Additionally, it introduces the concept of borrowing and lifetimes to enable other variables to borrow the values under certain conditions temporarily. Despite its benefits, security vulnerabilities have been reported in Rust projects, often attributed to the use of "unsafe" Rust code. These vulnerabilities, in part, arise from incorrect lifetime annotations on function signatures. However, existing tools fail to detect these bugs, primarily because such bugs are rare, challenging to detect through dynamic analysis, and require explicit memory models. To overcome these limitations, first, we characterize incorrect lifetime annotations as a source of memory safety bugs and leverage this understanding to devise a novel static analysis tool, Yuga, to detect potential lifetime annotation bugs. Yuga uses a multi-phase analysis approach, starting with a quick pattern-matching algorithm to identify potential buggy components and then conducting a flow and field-sensitive alias analysis to confirm the bugs. We also curate new datasets of lifetime annotation bugs. Yuga successfully detects bugs with good precision on these datasets, and we make the code and datasets publicly available for review. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.10259</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.10259</id><created>2023-10-16</created><updated>2025-01-24</updated><authors><author><keyname>Faruk</keyname><forenames>Ahmed Sayeed</forenames></author><author><keyname>Zheleva</keyname><forenames>Elena</forenames></author></authors><title>Leveraging heterogeneous spillover in maximizing contextual bandit   rewards</title><categories>cs.LG cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recommender systems relying on contextual multi-armed bandits continuously improve relevant item recommendations by taking into account the contextual information. The objective of bandit algorithms is to learn the best arm (e.g., best item to recommend) for each user and thus maximize the cumulative rewards from user engagement with the recommendations. The context that these algorithms typically consider are the user and item attributes. However, in the context of social networks where $\textit{the action of one user can influence the actions and rewards of other users,}$ neighbors' actions are also a very important context, as they can have not only predictive power but also can impact future rewards through spillover. Moreover, influence susceptibility can vary for different people based on their preferences and the closeness of ties to other users which leads to heterogeneity in the spillover effects. Here, we present a framework that allows contextual multi-armed bandits to account for such heterogeneous spillovers when choosing the best arm for each user. Our experiments on several semi-synthetic and real-world datasets show that our framework leads to significantly higher rewards than existing state-of-the-art solutions that ignore the network information and potential spillover. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2310.19574</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2310.19574</id><created>2023-10-30</created><updated>2025-01-23</updated><authors><author><keyname>Varshney</keyname><forenames>Debvrat</forenames></author><author><keyname>Yari</keyname><forenames>Masoud</forenames></author><author><keyname>Ibikunle</keyname><forenames>Oluwanisola</forenames></author><author><keyname>Li</keyname><forenames>Jilu</forenames></author><author><keyname>Paden</keyname><forenames>John</forenames></author><author><keyname>Gangopadhyay</keyname><forenames>Aryya</forenames></author><author><keyname>Rahnemoonfar</keyname><forenames>Maryam</forenames></author></authors><title>Skip-WaveNet: A Wavelet based Multi-scale Architecture to Trace Snow   Layers in Radar Echograms</title><categories>cs.CV eess.IV</categories><journal-ref>Environmental Data Science, Volume 3, 2024, e39</journal-ref><doi>10.1017/eds.2024.25</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Airborne radar sensors capture the profile of snow layers present on top of an ice sheet. Accurate tracking of these layers is essential to calculate their thicknesses, which are required to investigate the contribution of polar ice cap melt to sea-level rise. However, automatically processing the radar echograms to detect the underlying snow layers is a challenging problem. In our work, we develop wavelet-based multi-scale deep learning architectures for these radar echograms to improve snow layer detection. These architectures estimate the layer depths with a mean absolute error of 3.31 pixels and 94.3% average precision, achieving higher generalizability as compared to state-of-the-art snow layer detection networks. These depth estimates also agree well with physically drilled stake measurements. Such robust architectures can be used on echograms from future missions to efficiently trace snow layers, estimate their individual thicknesses and thus support sea-level rise projection models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2311.11046</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2311.11046</id><created>2023-11-18</created><updated>2025-01-24</updated><authors><author><keyname>Goya-Maldonado</keyname><forenames>Roberto</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Erwin-Grabner</keyname><forenames>Tracy</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Zeng</keyname><forenames>Ling-Li</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Ching</keyname><forenames>Christopher R. K.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Aleman</keyname><forenames>Andre</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Amod</keyname><forenames>Alyssa R.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Basgoze</keyname><forenames>Zeynep</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Benedetti</keyname><forenames>Francesco</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Besteher</keyname><forenames>Bianca</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Brosch</keyname><forenames>Katharina</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Bülow</keyname><forenames>Robin</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Colle</keyname><forenames>Romain</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Connolly</keyname><forenames>Colm G.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Corruble</keyname><forenames>Emmanuelle</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Couvy-Duchesne</keyname><forenames>Baptiste</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Cullen</keyname><forenames>Kathryn</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Dannlowski</keyname><forenames>Udo</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Davey</keyname><forenames>Christopher G.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Dols</keyname><forenames>Annemiek</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Ernsting</keyname><forenames>Jan</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Evans</keyname><forenames>Jennifer W.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Fisch</keyname><forenames>Lukas</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Fuentes-Claramonte</keyname><forenames>Paola</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Gonul</keyname><forenames>Ali Saffet</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Gotlib</keyname><forenames>Ian H.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Grabe</keyname><forenames>Hans J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Groenewold</keyname><forenames>Nynke A.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Grotegerd</keyname><forenames>Dominik</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Hahn</keyname><forenames>Tim</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Hamilton</keyname><forenames>J. Paul</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Han</keyname><forenames>Laura K. M.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Harrison</keyname><forenames>Ben J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Ho</keyname><forenames>Tiffany C.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Jahanshad</keyname><forenames>Neda</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Jamieson</keyname><forenames>Alec J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Karuk</keyname><forenames>Andriana</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Kircher</keyname><forenames>Tilo</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Klimes-Dougan</keyname><forenames>Bonnie</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Koopowitz</keyname><forenames>Sheri-Michelle</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Lancaster</keyname><forenames>Thomas</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Leenings</keyname><forenames>Ramona</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Li</keyname><forenames>Meng</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Linden</keyname><forenames>David E. J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>MacMaster</keyname><forenames>Frank P.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Mehler</keyname><forenames>David M. A.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Meinert</keyname><forenames>Susanne</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Melloni</keyname><forenames>Elisa</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Mueller</keyname><forenames>Bryon A.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Mwangi</keyname><forenames>Benson</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Nenadić</keyname><forenames>Igor</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Ojha</keyname><forenames>Amar</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Okamoto</keyname><forenames>Yasumasa</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Oudega</keyname><forenames>Mardien L.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Penninx</keyname><forenames>Brenda W. J. H.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Poletti</keyname><forenames>Sara</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Pomarol-Clotet</keyname><forenames>Edith</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Portella</keyname><forenames>Maria J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Pozzi</keyname><forenames>Elena</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Radua</keyname><forenames>Joaquim</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Rodríguez-Cano</keyname><forenames>Elena</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Sacchet</keyname><forenames>Matthew D.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Salvador</keyname><forenames>Raymond</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Schrantee</keyname><forenames>Anouk</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Sim</keyname><forenames>Kang</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Soares</keyname><forenames>Jair C.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Solanes</keyname><forenames>Aleix</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Stein</keyname><forenames>Dan J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Stein</keyname><forenames>Frederike</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Stolicyn</keyname><forenames>Aleks</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Thomopoulos</keyname><forenames>Sophia I.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Toenders</keyname><forenames>Yara J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Uyar-Demir</keyname><forenames>Aslihan</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Vieta</keyname><forenames>Eduard</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Vives-Gilabert</keyname><forenames>Yolanda</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Völzke</keyname><forenames>Henry</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Walter</keyname><forenames>Martin</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Whalley</keyname><forenames>Heather C.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Whittle</keyname><forenames>Sarah</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Winter</keyname><forenames>Nils</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Wittfeld</keyname><forenames>Katharina</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Wright</keyname><forenames>Margaret J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Wu</keyname><forenames>Mon-Ju</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Yang</keyname><forenames>Tony T.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Zarate</keyname><forenames>Carlos</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Veltman</keyname><forenames>Dick J.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Schmaal</keyname><forenames>Lianne</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author><author><keyname>Thompson</keyname><forenames>Paul M.</forenames><affiliation>for the ENIGMA Major Depressive Disorder working group</affiliation></author></authors><title>Classification of Major Depressive Disorder Using Vertex-Wise Brain   Sulcal Depth, Curvature, and Thickness with a Deep and a Shallow Learning   Model</title><categories>q-bio.QM cs.LG q-bio.NC</categories><comments>arXiv admin note: text overlap with arXiv:2206.08122</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Major depressive disorder (MDD) is a complex psychiatric disorder that affects the lives of hundreds of millions of individuals around the globe. Even today, researchers debate if morphological alterations in the brain are linked to MDD, likely due to the heterogeneity of this disorder. The application of deep learning tools to neuroimaging data, capable of capturing complex non-linear patterns, has the potential to provide diagnostic and predictive biomarkers for MDD. However, previous attempts to demarcate MDD patients and healthy controls (HC) based on segmented cortical features via linear machine learning approaches have reported low accuracies. Here, we used globally representative data from the ENIGMA-MDD working group containing 7,012 participants from 30 sites (N=2,772 MDD and N=4,240 HC), which allows a comprehensive analysis with generalizable results. Based on the hypothesis that integration of vertex-wise cortical features can improve classification performance, we evaluated the classification of a DenseNet and a Support Vector Machine (SVM), with the expectation that the former would outperform the latter. We found that both classifiers exhibited close to chance performance (balanced accuracy DenseNet: 51%; SVM: 53%), when estimated on unseen sites. Slightly higher classification performance (balanced accuracy DenseNet: 58%; SVM: 55%) was found when the cross-validation folds contained subjects from all sites, indicating site effect. In conclusion, the integration of vertex-wise morphometric features and the use of the non-linear classifier did not lead to the differentiability between MDD and HC. Our results support the notion that MDD classification on this combination of such features and classifiers is unfeasible. Perhaps more sophisticated integration of multimodal information may lead to a higher performance in this diagnostic task. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2311.11282</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2311.11282</id><created>2023-11-19</created><updated>2025-01-24</updated><authors><author><keyname>Kim</keyname><forenames>Junsol</forenames></author><author><keyname>Wang</keyname><forenames>Zhao</forenames></author><author><keyname>Shi</keyname><forenames>Haohan</forenames></author><author><keyname>Ling</keyname><forenames>Hsin-Keng</forenames></author><author><keyname>Evans</keyname><forenames>James</forenames></author></authors><title>Differential impact from individual versus collective misinformation   tagging on the diversity of Twitter (X) information engagement and mobility</title><categories>cs.CY cs.HC cs.SI</categories><comments>This paper was published in Nature Communications. Supplementary   information is available at   https://www.nature.com/articles/s41467-025-55868-0#Sec19</comments><journal-ref>Nature Communications 16, 973 (2025)</journal-ref><doi>10.1038/s41467-025-55868-0</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fears about the destabilizing impact of misinformation online have motivated individuals and platforms to respond. Individuals have increasingly challenged others' online claims with fact-checks in pursuit of a healthier information ecosystem and to break down echo chambers of self-reinforcing opinion. Using Twitter (now X) data, here we show the consequences of individual misinformation tagging: tagged posters had explored novel political information and expanded topical interests immediately prior, but being tagged caused posters to retreat into information bubbles. These unintended consequences were softened by a collective verification system for misinformation moderation. In Twitter's new feature, Community Notes, misinformation tagging was peer-reviewed by other fact-checkers before revelation to the poster. With collective misinformation tagging, posters were less likely to retreat from diverse information engagement. Detailed comparison demonstrated differences in toxicity, sentiment, readability, and delay in individual versus collective misinformation tagging messages. These findings provide evidence for differential impacts from individual versus collective moderation strategies on the diversity of information engagement and mobility across the information ecosystem. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2311.11349</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2311.11349</id><created>2023-11-19</created><updated>2025-01-24</updated><authors><author><keyname>Bui</keyname><forenames>Ngoc</forenames></author><author><keyname>Nguyen</keyname><forenames>Duy</forenames></author><author><keyname>Yue</keyname><forenames>Man-Chung</forenames></author><author><keyname>Nguyen</keyname><forenames>Viet Anh</forenames></author></authors><title>Coverage-Validity-Aware Algorithmic Recourse</title><categories>cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic recourse emerges as a prominent technique to promote the explainability, transparency, and ethics of machine learning models. Existing algorithmic recourse approaches often assume an invariant predictive model; however, the predictive model is usually updated upon the arrival of new data. Thus, a recourse that is valid respective to the present model may become invalid for the future model. To resolve this issue, we propose a novel framework to generate a model-agnostic recourse that exhibits robustness to model shifts. Our framework first builds a coverage-validity-aware linear surrogate of the nonlinear (black-box) model; then, the recourse is generated with respect to the linear surrogate. We establish a theoretical connection between our coverage-validity-aware linear surrogate and the minimax probability machines (MPM). We then prove that by prescribing different covariance robustness, the proposed framework recovers popular regularizations for MPM, including the $\ell_2$-regularization and class-reweighting. Furthermore, we show that our surrogate pushes the approximate hyperplane intuitively, facilitating not only robust but also interpretable recourses. The numerical results demonstrate the usefulness and robustness of our framework. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2311.17621</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2311.17621</id><created>2023-11-29</created><authors><author><keyname>Nilsson</keyname><forenames>Adrian</forenames></author><author><keyname>Smith</keyname><forenames>Simon</forenames></author><author><keyname>Hagmar</keyname><forenames>Jonas</forenames></author><author><keyname>Önnheim</keyname><forenames>Magnus</forenames></author><author><keyname>Jirstrand</keyname><forenames>Mats</forenames></author></authors><title>The AutoSPADA Platform: User-Friendly Edge Computing for Distributed   Learning and Data Analytics in Connected Vehicles</title><categories>cs.DC cs.NI</categories><comments>14 pages, 4 figures, 3 tables, 1 algorithm, 1 code listing</comments><doi>10.1016/j.iot.2024.101480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary connected vehicles host numerous applications, such as diagnostics and navigation, and new software is continuously being developed. However, the development process typically requires offline batch processing of large data volumes. In an edge computing approach, data analysts and developers can instead process sensor data directly on computational resources inside vehicles. This enables rapid prototyping to shorten development cycles and reduce the time to create new business values or insights. This paper presents the design, implementation, and operation of the AutoSPADA edge computing platform for distributed data analytics. The platform's design follows scalability, reliability, resource efficiency, privacy, and security principles promoted through mature and industrially proven technologies. In AutoSPADA, computational tasks are general Python scripts, and we provide a library to, for example, read signals from the vehicle and publish results to the cloud. Hence, users only need Python knowledge to use the platform. Moreover, the platform is designed to be extended to support additional programming languages. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.01857</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.01857</id><created>2023-12-04</created><updated>2025-01-24</updated><authors><author><keyname>Prunet</keyname><forenames>Thibault</forenames></author><author><keyname>Absi</keyname><forenames>Nabil</forenames></author><author><keyname>Cattaruzza</keyname><forenames>Diego</forenames></author></authors><title>A note on the complexity of the picker routing problem in multi-block   warehouses and related problems</title><categories>cs.DS cs.CC math.OC</categories><doi>10.1007/s10479-025-06481-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Picker Routing Problem (PRP), which consists of finding a minimum-length tour between a set of storage locations in a warehouse, is one of the most important problems in the warehousing logistics literature. Despite its popularity, the tractability of the PRP in multi-block warehouses remains an open question. This technical note aims to fill this research gap by establishing that the problem is strongly NP-hard. As a corollary, the complexity status of other related problems is settled. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.03631</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.03631</id><created>2023-12-06</created><updated>2024-10-16</updated><authors><author><keyname>Ben-Kish</keyname><forenames>Assaf</forenames></author><author><keyname>Yanuka</keyname><forenames>Moran</forenames></author><author><keyname>Alper</keyname><forenames>Morris</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Averbuch-Elor</keyname><forenames>Hadar</forenames></author></authors><title>Mitigating Open-Vocabulary Caption Hallucinations</title><categories>cs.CV cs.AI</categories><comments>Website Link: https://assafbk.github.io/mocha/</comments><doi>10.18653/v1/2024.findings-acl.657</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  While recent years have seen rapid progress in image-conditioned text generation, image captioning still suffers from the fundamental issue of hallucinations, namely, the generation of spurious details that cannot be inferred from the given image. Existing methods largely use closed-vocabulary object lists to mitigate or evaluate hallucinations in image captioning, ignoring the long-tailed nature of hallucinations that occur in practice. To this end, we propose a framework for addressing hallucinations in image captioning in the open-vocabulary setting. Our framework includes a new benchmark, OpenCHAIR, that leverages generative foundation models to evaluate open-vocabulary object hallucinations for image captioning, surpassing the popular and similarly-sized CHAIR benchmark in both diversity and accuracy. Furthermore, to mitigate open-vocabulary hallucinations without using a closed object list, we propose MOCHa, an approach harnessing advancements in reinforcement learning. Our multi-objective reward function explicitly targets the trade-off between fidelity and adequacy in generations without requiring any strong supervision. MOCHa improves a large variety of image captioning models, as captured by our OpenCHAIR benchmark and other existing metrics. Code and models can be found at: https://github.com/assafbk/mocha_code </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.06254</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.06254</id><created>2023-12-11</created><updated>2025-01-24</updated><authors><author><keyname>Böther</keyname><forenames>Maximilian</forenames></author><author><keyname>Robroek</keyname><forenames>Ties</forenames></author><author><keyname>Gsteiger</keyname><forenames>Viktor</forenames></author><author><keyname>Holzinger</keyname><forenames>Robin</forenames></author><author><keyname>Ma</keyname><forenames>Xianzhe</forenames></author><author><keyname>Tözün</keyname><forenames>Pınar</forenames></author><author><keyname>Klimovic</keyname><forenames>Ana</forenames></author></authors><title>Modyn: Data-Centric Machine Learning Pipeline Orchestration</title><categories>cs.LG cs.AI cs.DB cs.DC stat.ML</categories><comments>final version published at SIGMOD'25; 30 pages</comments><doi>10.1145/3709705</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In real-world machine learning (ML) pipelines, datasets are continuously growing. Models must incorporate this new training data to improve generalization and adapt to potential distribution shifts. The cost of model retraining is proportional to how frequently the model is retrained and how much data it is trained on, which makes the naive approach of retraining from scratch each time impractical.   We present Modyn, a data-centric end-to-end machine learning platform. Modyn's ML pipeline abstraction enables users to declaratively describe policies for continuously training a model on a growing dataset. Modyn pipelines allow users to apply data selection policies (to reduce the number of data points) and triggering policies (to reduce the number of trainings). Modyn executes and orchestrates these continuous ML training pipelines. The system is open-source and comes with an ecosystem of benchmark datasets, models, and tooling. We formally discuss how to measure the performance of ML pipelines by introducing the concept of composite models, enabling fair comparison of pipelines with different data selection and triggering policies. We empirically analyze how various data selection and triggering policies impact model accuracy, and also show that Modyn enables high throughput training with sample-level data selection. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.10417</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.10417</id><created>2023-12-16</created><updated>2025-01-24</updated><authors><author><keyname>Zha</keyname><forenames>Zhiwei</forenames></author><author><keyname>Wang</keyname><forenames>Jiaan</forenames></author><author><keyname>Li</keyname><forenames>Zhixu</forenames></author><author><keyname>Zhu</keyname><forenames>Xiangru</forenames></author><author><keyname>Song</keyname><forenames>Wei</forenames></author><author><keyname>Xiao</keyname><forenames>Yanghua</forenames></author></authors><title>M^2ConceptBase: A Fine-Grained Aligned Concept-Centric Multimodal   Knowledge Base</title><categories>cs.AI</categories><comments>Accepted by CIKM2024. The code and data can be found at   https://github.com/AwellmanZha/M2ConceptBase</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal knowledge bases (MMKBs) provide cross-modal aligned knowledge crucial for multimodal tasks. However, the images in existing MMKBs are generally collected for entities in encyclopedia knowledge graphs. Therefore, detailed groundings of visual semantics with linguistic concepts are lacking, which are essential for the visual concept cognition ability of multimodal models. Addressing this gap, we introduce M^2ConceptBase, the first concept-centric MMKB. M^2ConceptBase models concepts as nodes with associated images and detailed textual descriptions. We propose a context-aware multimodal symbol grounding approach to align concept-image and concept-description pairs using context information from image-text datasets. Comprising 951K images and 152K concepts, M^2ConceptBase links each concept to an average of 6.27 images and a single description, ensuring comprehensive visual and textual semantics. Human studies confirm more than 95% alignment accuracy, underscoring its quality. Additionally, our experiments demonstrate that M^2ConceptBase significantly enhances VQA model performance on the OK-VQA task. M^2ConceptBase also substantially improves the fine-grained concept understanding capabilities of multimodal large language models through retrieval augmentation in two concept-related tasks, highlighting its value. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2312.13161</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2312.13161</id><created>2023-12-20</created><updated>2025-01-23</updated><authors><author><keyname>Falk</keyname><forenames>Richard S.</forenames></author><author><keyname>Winther</keyname><forenames>Ragnar</forenames></author></authors><title>Local space-preserving decompositions for the bubble transform</title><categories>math.NA cs.NA</categories><msc-class>65N30, 52-08</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The bubble transform is a procedure to decompose differential forms, which are piecewise smooth with respect to a given triangulation of the domain, into a sum of local bubbles. In this paper, an improved version of a construction in the setting of the de Rham complex previously proposed by the authors is presented. The major improvement in the decomposition is that unlike the previous results, in which the individual bubbles were rational functions with the property that groups of local bubbles summed up to preserve piecewise smoothness, the new decomposition is strictly space-preserving in the sense that each local bubble preserves piecewise smoothness. An important property of the transform is that the construction only depends on the given triangulation of the domain and is independent of any finite element space. On the other hand, all the standard piecewise polynomial spaces are invariant under the transform. Other key properties of the transform are that it commutes with the exterior derivative, is bounded in L^2, and satisfies the stable decomposition property. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.00766</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.00766</id><created>2024-01-01</created><updated>2025-01-24</updated><authors><author><keyname>Zhang</keyname><forenames>Zhilu</forenames></author><author><keyname>Zhang</keyname><forenames>Shuohao</forenames></author><author><keyname>Wu</keyname><forenames>Renlong</forenames></author><author><keyname>Yan</keyname><forenames>Zifei</forenames></author><author><keyname>Zuo</keyname><forenames>Wangmeng</forenames></author></authors><title>Exposure Bracketing Is All You Need For A High-Quality Image</title><categories>cs.CV eess.IV</categories><comments>ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is highly desired but challenging to acquire high-quality photos with clear content in low-light environments. Although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus on specific restoration or enhancement problems, and do not fully explore the potential of utilizing multiple images. Motivated by the fact that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize exposure bracketing photography to get a high-quality image by combining these tasks in this work. Due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. In particular, a temporally modulated recurrent network (TMRNet) and self-supervised adaptation method are proposed. Moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. Experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. Code and datasets are available at https://github.com/cszhilu1998/BracketIRE. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.02708</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.02708</id><created>2024-01-05</created><authors><author><keyname>Zhang</keyname><forenames>Liwen</forenames></author><author><keyname>Zhong</keyname><forenames>Lianzhen</forenames></author><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Dong</keyname><forenames>Di</forenames></author><author><keyname>Hui</keyname><forenames>Hui</forenames></author><author><keyname>Tian</keyname><forenames>Jie</forenames></author></authors><title>TripleSurv: Triplet Time-adaptive Coordinate Loss for Survival Analysis</title><categories>cs.LG cs.AI stat.ML</categories><comments>9 pages,6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A core challenge in survival analysis is to model the distribution of censored time-to-event data, where the event of interest may be a death, failure, or occurrence of a specific event. Previous studies have showed that ranking and maximum likelihood estimation (MLE)loss functions are widely-used for survival analysis. However, ranking loss only focus on the ranking of survival time and does not consider potential effect of samples for exact survival time values. Furthermore, the MLE is unbounded and easily subject to outliers (e.g., censored data), which may cause poor performance of modeling. To handle the complexities of learning process and exploit valuable survival time values, we propose a time-adaptive coordinate loss function, TripleSurv, to achieve adaptive adjustments by introducing the differences in the survival time between sample pairs into the ranking, which can encourage the model to quantitatively rank relative risk of pairs, ultimately enhancing the accuracy of predictions. Most importantly, the TripleSurv is proficient in quantifying the relative risk between samples by ranking ordering of pairs, and consider the time interval as a trade-off to calibrate the robustness of model over sample distribution. Our TripleSurv is evaluated on three real-world survival datasets and a public synthetic dataset. The results show that our method outperforms the state-of-the-art methods and exhibits good model performance and robustness on modeling various sophisticated data distributions with different censor rates. Our code will be available upon acceptance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.07494</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.07494</id><created>2024-01-15</created><updated>2025-01-24</updated><authors><author><keyname>Wang</keyname><forenames>Zihao</forenames></author><author><keyname>Wu</keyname><forenames>Zhe</forenames></author></authors><title>Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering   Tasks</title><categories>cs.LG cs.CE cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Computational efficiency and robustness are essential in process modeling, optimization, and control for real-world engineering applications. While neural network-based approaches have gained significant attention in recent years, conventional neural networks often fail to address these two critical aspects simultaneously or even independently. Inspired by natural physical systems and established literature, input convex architectures are known to enhance computational efficiency in optimization tasks, whereas Lipschitz-constrained architectures improve robustness. However, combining these properties within a single model requires careful review, as inappropriate methods for enforcing one property can undermine the other. To overcome this, we introduce a novel network architecture, termed Input Convex Lipschitz Recurrent Neural Networks (ICLRNNs). This architecture seamlessly integrates the benefits of convexity and Lipschitz continuity, enabling fast and robust neural network-based modeling and optimization. The ICLRNN outperforms existing recurrent units in both computational efficiency and robustness. Additionally, it has been successfully applied to practical engineering scenarios, such as modeling and control of chemical process and the modeling and real-world solar irradiance prediction for solar PV system planning at LHT Holdings in Singapore. Source code is available at https://github.com/killingbear999/ICLRNN. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.12231</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.12231</id><created>2024-01-18</created><updated>2025-01-24</updated><authors><author><keyname>Xiao</keyname><forenames>Zhenbang</forenames></author><author><keyname>Wang</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Shunyu</forenames></author><author><keyname>Hu</keyname><forenames>Bingde</forenames></author><author><keyname>Wang</keyname><forenames>Huiqiong</forenames></author><author><keyname>Song</keyname><forenames>Mingli</forenames></author><author><keyname>Zheng</keyname><forenames>Tongya</forenames></author></authors><title>Disentangled Condensation for Large-scale Graphs</title><categories>cs.SI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph condensation has emerged as an intriguing technique to save the expensive training costs of Graph Neural Networks (GNNs) by substituting a condensed small graph with the original graph. Despite the promising results achieved, previous methods usually employ an entangled paradigm of redundant parameters (nodes, edges, GNNs), which incurs complex joint optimization during condensation. This paradigm has considerably impeded the scalability of graph condensation, making it challenging to condense extremely large-scale graphs and generate high-fidelity condensed graphs. Therefore, we propose to disentangle the condensation process into a two-stage GNN-free paradigm, independently condensing nodes and generating edges while eliminating the need to optimize GNNs at the same time. The node condensation module avoids the complexity of GNNs by focusing on node feature alignment with anchors of the original graph, while the edge translation module constructs the edges of the condensed nodes by transferring the original structure knowledge with neighborhood anchors. This simple yet effective approach achieves at least 10 times faster than state-of-the-art methods with comparable accuracy on medium-scale graphs. Moreover, the proposed DisCo can successfully scale up to the Ogbn-papers100M graph containing over 100 million nodes with flexible reduction rates and improves performance on the second-largest Ogbn-products dataset by over 5%. Extensive downstream tasks and ablation study on five common datasets further demonstrate the effectiveness of the proposed DisCo framework. Our code is available at https://github.com/BangHonor/DisCo. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.14669</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.14669</id><created>2024-01-26</created><updated>2025-01-24</updated><authors><author><keyname>Fritz</keyname><forenames>Tobias</forenames></author><author><keyname>Klingler</keyname><forenames>Andreas</forenames></author><author><keyname>McNeely</keyname><forenames>Drew</forenames></author><author><keyname>Shah-Mohammed</keyname><forenames>Areeb</forenames></author><author><keyname>Wang</keyname><forenames>Yuwen</forenames></author></authors><title>Hidden Markov Models and the Bayes Filter in Categorical Probability</title><categories>math.ST cs.SY eess.SY math.CT stat.TH</categories><comments>v3: shortened to 55 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use Markov categories to generalize the basic theory of Markov chains and hidden Markov models to an abstract setting. This comprises characterizations of hidden Markov models in terms of conditional independences and algorithms for Bayesian filtering and smoothing applicable in all Markov categories with conditionals. When instantiated in appropriate Markov categories, these algorithms specialize to existing ones such as the Kalman filter, forward-backward algorithm, and the Rauch-Tung-Striebel smoother. We also prove that the sequence of outputs of our abstract Bayes filter is itself a Markov chain with a concrete formula for its transition maps.   There are two main features of this categorical framework. The first is its abstract generality, as manifested in our unified account of hidden Markov models and algorithms for filtering and smoothing in discrete probability, Gaussian probability, measure-theoretic probability, possibilistic nondeterminism and others at the same time. The second feature is the intuitive visual representation of information flow in terms of string diagrams. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.15344</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.15344</id><created>2024-01-27</created><authors><author><keyname>Li</keyname><forenames>Renwang</forenames></author><author><keyname>Shao</keyname><forenames>Xiaodan</forenames></author><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>IRS Aided Millimeter-Wave Sensing and Communication: Beam Scanning, Beam   Splitting, and Performance Analysis</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted to IEEE TWC</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 23, no. 12, pp.   19713-19727, Dec. 2024</journal-ref><doi>10.1109/TWC.2024.3486023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrated sensing and communication (ISAC) has attracted growing interests for enabling the future 6G wireless networks, due to its capability of sharing spectrum and hardware resources between communication and sensing systems. However, existing works on ISAC usually need to modify the communication protocol to cater for the new sensing performance requirement, which may be difficult to implement in practice. In this paper, we study a new intelligent reflecting surface (IRS) aided millimeter-wave (mmWave) ISAC system by exploiting the distinct beam scanning operation in mmWave communications to achieve efficient sensing at the same time. First, we propose a two-phase ISAC protocol aided by a semi-passive IRS, consisting of beam scanning and data transmission. Specifically, in the beam scanning phase, the IRS finds the optimal beam for reflecting signals from the base station to a communication user via its passive elements. Meanwhile, the IRS directly estimates the angle of a nearby target based on echo signals from the target using its equipped active sensing element. Then, in the data transmission phase, the sensing accuracy is further improved by leveraging the data signals via possible IRS beam splitting. Next, we derive the achievable rate of the communication user as well as the Cram\'er-Rao bound and the approximate mean square error of the target angle estimation Finally, extensive simulation results are provided to verify our analysis as well as the effectiveness of the proposed scheme. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.15578</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.15578</id><created>2024-01-28</created><updated>2025-01-24</updated><authors><author><keyname>Yuan</keyname><forenames>Shuai</forenames></author><author><keyname>Qin</keyname><forenames>Hanlin</forenames></author><author><keyname>Yan</keyname><forenames>Xiang</forenames></author><author><keyname>Yang</keyname><forenames>Shiqi</forenames></author><author><keyname>Yang</keyname><forenames>Shuowen</forenames></author><author><keyname>Akhtar</keyname><forenames>Naveed</forenames></author><author><keyname>Zhou</keyname><forenames>Huixin</forenames></author></authors><title>ASCNet: Asymmetric Sampling Correction Network for Infrared Image   Destriping</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a real-world infrared imaging system, effectively learning a consistent stripe noise removal model is essential. Most existing destriping methods cannot precisely reconstruct images due to cross-level semantic gaps and insufficient characterization of the global column features. To tackle this problem, we propose a novel infrared image destriping method, called Asymmetric Sampling Correction Network (ASCNet), that can effectively capture global column relationships and embed them into a U-shaped framework, providing comprehensive discriminative representation and seamless semantic connectivity. Our ASCNet consists of three core elements: Residual Haar Discrete Wavelet Transform (RHDWT), Pixel Shuffle (PS), and Column Non-uniformity Correction Module (CNCM). Specifically, RHDWT is a novel downsampler that employs double-branch modeling to effectively integrate stripe-directional prior knowledge and data-driven semantic interaction to enrich the feature representation. Observing the semantic patterns crosstalk of stripe noise, PS is introduced as an upsampler to prevent excessive apriori decoding and performing semantic-bias-free image reconstruction. After each sampling, CNCM captures the column relationships in long-range dependencies. By incorporating column, spatial, and self-dependence information, CNCM well establishes a global context to distinguish stripes from the scene's vertical structures. Extensive experiments on synthetic data, real data, and infrared small target detection tasks demonstrate that the proposed method outperforms state-of-the-art single-image destriping methods both visually and quantitatively. Our code will be made publicly available at https://github.com/xdFai/ASCNet. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2401.16610</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2401.16610</id><created>2024-01-29</created><updated>2025-01-23</updated><authors><author><keyname>Weld</keyname><forenames>Galen</forenames></author><author><keyname>Leibmann</keyname><forenames>Leon</forenames></author><author><keyname>Zhang</keyname><forenames>Amy X.</forenames></author><author><keyname>Althoff</keyname><forenames>Tim</forenames></author></authors><title>Perceptions of Moderators as a Large-Scale Measure of Online Community   Governance</title><categories>cs.SI cs.CY cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millions of online communities are governed by volunteer moderators, who shape their communities by setting and enforcing rules, recruiting additional moderators, and participating in the community themselves. These moderators must regularly make decisions about how to govern, yet measuring the 'success' of governance is complex and nuanced, making it challenging to determine what governance strategies are most successful. Furthermore, prior work has shown that communities have differing values, suggesting that 'one-size-fits-all' approaches to governance are unlikely to serve all communities well. In this work, we assess governance practices on reddit by classifying the sentiment of community members' public discussion of their own moderators. We label 1.89 million posts and comments made on reddit over an 18 month period. We relate these perceptions to characteristics of community governance, and to different actions that community moderators take. We identify types of communities where moderators are perceived particularly positively and negatively, and highlight promising strategies for moderator teams. Amongst other findings, we show that strict rule enforcement is linked to more favorable perceptions of moderators of communities dedicated to certain topics, such as news communities, than others. We investigate what kinds of moderators are associated with improved community perceptions upon their addition to a mod team, and find that moderators who are active community members before and during their mod tenures are seen more favorably. We make our models, anonymized datasets, and code public. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.03017</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.03017</id><created>2024-02-05</created><updated>2025-01-24</updated><authors><author><keyname>Tsoumplekas</keyname><forenames>Georgios</forenames></author><author><keyname>Li</keyname><forenames>Vladislav</forenames></author><author><keyname>Sarigiannidis</keyname><forenames>Panagiotis</forenames></author><author><keyname>Argyriou</keyname><forenames>Vasileios</forenames></author></authors><title>A Complete Survey on Contemporary Methods, Emerging Paradigms and Hybrid   Approaches for Few-Shot Learning</title><categories>cs.LG cs.AI</categories><comments>63 pages, 16 figures. Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the widespread success of deep learning, its intense requirements for vast amounts of data and extensive training make it impractical for various real-world applications where data is scarce. In recent years, Few-Shot Learning (FSL) has emerged as a learning paradigm that aims to address these limitations by leveraging prior knowledge to enable rapid adaptation to novel learning tasks. Due to its properties that highly complement deep learning's data-intensive needs, FSL has seen significant growth in the past few years. This survey provides a comprehensive overview of both well-established methods as well as recent advancements in the FSL field. The presented taxonomy extends previously proposed ones by incorporating emerging FSL paradigms, such as in-context learning, along with novel categories within the meta-learning paradigm for FSL, including neural processes and probabilistic meta-learning. Furthermore, a holistic overview of FSL is provided by discussing hybrid FSL approaches that extend FSL beyond the typically examined supervised learning setting. The survey also explores FSL's diverse applications across various domains. Finally, recent trends shaping the field, outstanding challenges, and promising future research directions are discussed. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.03245</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.03245</id><created>2024-02-05</created><authors><author><keyname>Montanari</keyname><forenames>Arthur N.</forenames></author><author><keyname>Duan</keyname><forenames>Chao</forenames></author><author><keyname>Motter</keyname><forenames>Adilson E.</forenames></author></authors><title>On the Popov-Belevitch-Hautus tests for functional observability and   output controllability</title><categories>math.OC cond-mat.dis-nn cs.SY eess.SY math.DS physics.soc-ph</categories><journal-ref>Automatica 174, 112122 (2025)</journal-ref><doi>10.1016/j.automatica.2025.112122</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional observability and output controllability are properties that establish the conditions respectively for the partial estimation and partial control of the system state. In the special case of full-state observability and controllability, the Popov-Belevitch-Hautus (PBH) tests provide conditions for the properties to hold based on the system eigenspace. Generalizations of the Popov-Belevitch-Hautus (PBH) test have been recently proposed for functional observability and output controllability but were proved to be valid only for diagonalizable systems thus far. Here, we rigorously establish a more general class of systems based on their Jordan decomposition under which a generalized PBH test for functional observability is valid. Likewise, we determine the class of systems under which the generalized PBH test is sufficient and necessary for output controllability. These results have immediate implications for observer and controller design, pole assignment, and optimal placement of sensors and drivers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.05048</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.05048</id><created>2024-02-07</created><updated>2025-01-24</updated><authors><author><keyname>Bezerra</keyname><forenames>Leonardo C. T.</forenames></author><author><keyname>Brownlee</keyname><forenames>Alexander E. I.</forenames></author><author><keyname>Alvarenga</keyname><forenames>Luana Ferraz</forenames></author><author><keyname>Moioli</keyname><forenames>Renan Cipriano</forenames></author><author><keyname>Batista</keyname><forenames>Thais Vasconcelos</forenames></author></authors><title>How VADER is your AI? Towards a definition of artificial intelligence   systems appropriate for regulation</title><categories>cs.AI</categories><acm-class>I.2.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Artificial intelligence (AI) has driven many information and communication technology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has expanded far beyond AI since the Turing test proposal. Critically, recent AI regulation proposals adopt AI definitions affecting ICT techniques, approaches, and systems that are not AI. In some cases, even works from mathematics, statistics, and engineering would be affected. Worryingly, AI misdefinitions are observed from Western societies to the Global South. In this paper, we propose a framework to score how validated as appropriately-defined for regulation (VADER) an AI definition is. Our online, publicly-available VADER framework scores the coverage of premises that should underlie AI definitions for regulation, which aim to (i) reproduce principles observed in other successful technology regulations, and (ii) include all AI techniques and approaches while excluding non-AI works. Regarding the latter, our score is based on a dataset of representative AI, non-AI ICT, and non-ICT examples. We demonstrate our contribution by reviewing the AI regulation proposals of key players, namely the United States, United Kingdom, European Union, and Brazil. Importantly, none of the proposals assessed achieve the appropriateness score, ranging from a revision need to a concrete risk to ICT systems and works from other fields. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.05347</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.05347</id><created>2024-02-07</created><updated>2025-01-23</updated><authors><author><keyname>Appelö</keyname><forenames>Daniel</forenames></author><author><keyname>Cheng</keyname><forenames>Yingda</forenames></author></authors><title>Robust Implicit Adaptive Low Rank Time-Stepping Methods for Matrix   Differential Equations</title><categories>math.NA cs.NA</categories><msc-class>65</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we develop implicit rank-adaptive schemes for time-dependent matrix differential equations. The dynamic low rank approximation (DLRA) is a well-known technique to capture the dynamic low rank structure based on Dirac-Frenkel time-dependent variational principle. In recent years, it has attracted a lot of attention due to its wide applicability. Our schemes are inspired by the three-step procedure used in the rank adaptive version of the unconventional robust integrator (the so called BUG integrator) for DLRA. First, a prediction (basis update) step is made computing the approximate column and row spaces at the next time level. Second, a Galerkin evolution step is invoked using a base implicit solve for the small core matrix. Finally, a truncation is made according to a prescribed error threshold. Since the DLRA is evolving the differential equation projected on to the tangent space of the low rank manifold, the error estimate of the BUG integrator contains the tangent projection (modeling) error which cannot be easily controlled by mesh refinement. This can cause convergence issue for equations with cross terms.   To address this issue, we propose a simple modification, consisting of merging the row and column spaces from the explicit step truncation method together with the BUG spaces in the prediction step. In addition, we propose an adaptive strategy where the BUG spaces are only computed if the residual for the solution obtained from the prediction space by explicit step truncation method, is too large. We prove stability and estimate the local truncation error of the schemes under assumptions. We benchmark the schemes in several tests, such as anisotropic diffusion, solid body rotation and the combination of the two, to show robust convergence properties. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.07782</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.07782</id><created>2024-02-12</created><updated>2025-01-24</updated><authors><author><keyname>Gaillard</keyname><forenames>Louis</forenames></author><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames></author></authors><title>Solving parameter-dependent semi-algebraic systems</title><categories>cs.SC math.AG</categories><comments>10 pages</comments><doi>10.1145/3666000.3669718</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider systems of polynomial equations and inequalities in $\mathbb{Q}[\boldsymbol{y}][\boldsymbol{x}]$ where $\boldsymbol{x} = (x_1, \ldots, x_n)$ and $\boldsymbol{y} = (y_1, \ldots,y_t)$. The $\boldsymbol{y}$ indeterminates are considered as parameters and we assume that when specialising them generically, the set of common complex solutions, to the obtained equations, is finite. We consider the problem of real root classification for such parameter-dependent problems, i.e. identifying the possible number of real solutions depending on the values of the parameters and computing a description of the regions of the space of parameters over which the number of real roots remains invariant.   We design an algorithm for solving this problem. The formulas it outputs enjoy a determinantal structure. Under genericity assumptions, we show that its arithmetic complexity is polynomial in both the maximum degree $d$ and the number $s$ of the input inequalities and exponential in $nt+t^2$. The output formulas consist of polynomials of degree bounded by $(2s+n)d^{n+1}$. This is the first algorithm with such a singly exponential complexity. We report on practical experiments showing that a first implementation of this algorithm can tackle examples which were previously out of reach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.09099</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.09099</id><created>2024-02-14</created><updated>2025-01-24</updated><authors><author><keyname>Xiao</keyname><forenames>Xiongye</forenames></author><author><keyname>Zhou</keyname><forenames>Chenyu</forenames></author><author><keyname>Ping</keyname><forenames>Heng</forenames></author><author><keyname>Cao</keyname><forenames>Defu</forenames></author><author><keyname>Li</keyname><forenames>Yaxing</forenames></author><author><keyname>Zhou</keyname><forenames>Yi-Zhuo</forenames></author><author><keyname>Li</keyname><forenames>Shixuan</forenames></author><author><keyname>Kanakaris</keyname><forenames>Nikos</forenames></author><author><keyname>Bogdan</keyname><forenames>Paul</forenames></author></authors><title>Neuron-based Multifractal Analysis of Neuron Interaction Dynamics in   Large Models</title><categories>cs.AI</categories><comments>ICLR 2025: https://openreview.net/forum?id=nt8gBX58Kh</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, there has been increasing attention on the capabilities of large models, particularly in handling complex tasks that small-scale models are unable to perform. Notably, large language models (LLMs) have demonstrated ``intelligent'' abilities such as complex reasoning and abstract language comprehension, reflecting cognitive-like behaviors. However, current research on emergent abilities in large models predominantly focuses on the relationship between model performance and size, leaving a significant gap in the systematic quantitative analysis of the internal structures and mechanisms driving these emergent abilities. Drawing inspiration from neuroscience research on brain network structure and self-organization, we propose (i) a general network representation of large models, (ii) a new analytical framework, called Neuron-based Multifractal Analysis (NeuroMFA), for structural analysis, and (iii) a novel structure-based metric as a proxy for emergent abilities of large models. By linking structural features to the capabilities of large models, NeuroMFA provides a quantitative framework for analyzing emergent phenomena in large models. Our experiments show that the proposed method yields a comprehensive measure of network's evolving heterogeneity and organization, offering theoretical foundations and a new perspective for investigating emergent abilities in large models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.12537</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.12537</id><created>2024-02-19</created><updated>2025-01-23</updated><authors><author><keyname>Ozkara</keyname><forenames>Kaan</forenames></author><author><keyname>Huang</keyname><forenames>Bruce</forenames></author><author><keyname>Zhou</keyname><forenames>Ruida</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>ADEPT: Hierarchical Bayes Approach to Personalized Federated   Unsupervised Learning</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Statistical heterogeneity of clients' local data is an important characteristic in federated learning, motivating personalized algorithms tailored to the local data statistics. Though there has been a plethora of algorithms proposed for personalized supervised learning, discovering the structure of local data through personalized unsupervised learning is less explored. We initiate a systematic study of such personalized unsupervised learning by developing algorithms based on optimization criteria inspired by a hierarchical Bayesian statistical framework. We develop adaptive algorithms that discover the balance between using limited local data and collaborative information. We do this in the context of two unsupervised learning tasks: personalized dimensionality reduction and personalized diffusion models. We develop convergence analyses for our adaptive algorithms which illustrate the dependence on problem parameters (e.g., heterogeneity, local sample size). We also develop a theoretical framework for personalized diffusion models, which shows the benefits of collaboration even under heterogeneity. We finally evaluate our proposed algorithms using synthetic and real data, demonstrating the effective sample amplification for personalized tasks, induced through collaboration, despite data heterogeneity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.14875</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.14875</id><created>2024-02-21</created><updated>2025-01-23</updated><authors><author><keyname>Salinas</keyname><forenames>Alejandro</forenames></author><author><keyname>Haim</keyname><forenames>Amit</forenames></author><author><keyname>Nyarko</keyname><forenames>Julian</forenames></author></authors><title>What's in a Name? Auditing Large Language Models for Race and Gender   Bias</title><categories>cs.CL cs.AI cs.CY cs.LG</categories><comments>62 pages, 34 tables, 16 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We employ an audit design to investigate biases in state-of-the-art large language models, including GPT-4. In our study, we prompt the models for advice involving a named individual across a variety of scenarios, such as during car purchase negotiations or election outcome predictions. We find that the advice systematically disadvantages names that are commonly associated with racial minorities and women. Names associated with Black women receive the least advantageous outcomes. The biases are consistent across 42 prompt templates and several models, indicating a systemic issue rather than isolated incidents. While providing numerical, decision-relevant anchors in the prompt can successfully counteract the biases, qualitative details have inconsistent effects and may even increase disparities. Our findings underscore the importance of conducting audits at the point of LLM deployment and implementation to mitigate their potential for harm against marginalized communities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.16201</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.16201</id><created>2024-02-25</created><updated>2025-01-23</updated><authors><author><keyname>Zhang</keyname><forenames>Yunqi</forenames></author><author><keyname>Venkatakrishnan</keyname><forenames>Shaileshh Bojja</forenames></author></authors><title>Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable   Random Walks</title><categories>cs.NI cs.CR cs.DC cs.DS cs.MA</categories><comments>29 pages; acmsmall-conf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and peer consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\geq50\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2402.18434</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2402.18434</id><created>2024-02-28</created><updated>2025-01-24</updated><authors><author><keyname>Mittal</keyname><forenames>Anshul</forenames></author><author><keyname>Mohan</keyname><forenames>Shikhar</forenames></author><author><keyname>Saini</keyname><forenames>Deepak</forenames></author><author><keyname>Asokan</keyname><forenames>Siddarth</forenames></author><author><keyname>Prabhu</keyname><forenames>Suchith C.</forenames></author><author><keyname>Kumar</keyname><forenames>Lakshya</forenames></author><author><keyname>Malhotra</keyname><forenames>Pankaj</forenames></author><author><keyname>jiao</keyname><forenames>Jain</forenames></author><author><keyname>Singh</keyname><forenames>Amit</forenames></author><author><keyname>Agarwal</keyname><forenames>Sumeet</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Soumen</forenames></author><author><keyname>Kar</keyname><forenames>Purushottam</forenames></author><author><keyname>Varma</keyname><forenames>Manik</forenames></author></authors><title>Graph Regularized Encoder Training for Extreme Classification</title><categories>cs.LG cs.IR</categories><comments>Accepted at TheWebConf</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep extreme classification (XC) aims to train an encoder architecture and an accompanying classifier architecture to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels for which the amount of training data is exceedingly small. Graph convolutional networks (GCN) present a convenient but computationally expensive way to leverage task metadata and enhance model accuracies in these settings. This paper formally establishes that in several use cases, the steep computational cost of GCNs is entirely avoidable by replacing GCNs with non-GCN architectures. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN is presented to utilize graph metadata in XC settings that offers significant performance boosts with zero increase in inference computational costs. RAMEN scales to datasets with up to 1M labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine. Code for RAMEN will be released publicly. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.01306</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.01306</id><created>2024-03-02</created><updated>2024-06-11</updated><authors><author><keyname>Yanuka</keyname><forenames>Moran</forenames></author><author><keyname>Alper</keyname><forenames>Morris</forenames></author><author><keyname>Averbuch-Elor</keyname><forenames>Hadar</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>ICC: Quantifying Image Caption Concreteness for Multimodal Dataset   Curation</title><categories>cs.LG cs.CV</categories><comments>Accepted to ACL 2024 (Finding). For Project webpage, see   https://moranyanuka.github.io/icc/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text. These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset. In this work, we propose a new metric, image caption concreteness, that evaluates caption text without an image reference to measure its concreteness and relevancy for use in multimodal learning. Our approach leverages strong foundation models for measuring visual-semantic information loss in multimodal representations. We demonstrate that this strongly correlates with human evaluation of concreteness in both single-word and sentence-level texts. Moreover, we show that curation using ICC complements existing approaches: It succeeds in selecting the highest quality samples from multimodal web-scale datasets to allow for efficient training in resource-constrained settings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.02317</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.02317</id><created>2024-03-04</created><updated>2025-01-23</updated><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Schecker</keyname><forenames>Conrad</forenames></author><author><keyname>Schewior</keyname><forenames>Kevin</forenames></author></authors><title>Designing Exploration Contracts</title><categories>cs.GT cs.DS</categories><comments>Accepted to STACS 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a natural application of contract design in the context of sequential exploration problems. In our principal-agent setting, a search task is delegated to an agent. The agent performs a sequential exploration of $n$ boxes, suffers the exploration cost for each inspected box, and selects the content (called the prize) of one inspected box as outcome. Agent and principal obtain an individual value based on the selected prize. To influence the search, the principal a-priori designs a contract with a non-negative payment to the agent for each potential prize. The goal of the principal is to maximize her expected reward, i.e., value minus payment. Interestingly, this natural contract scenario shares close relations with the Pandora's Box problem.   We show how to compute optimal contracts for the principal in several scenarios. A popular and important subclass is that of linear contracts, and we show how to compute optimal linear contracts in polynomial time. For general contracts, we obtain optimal contracts under the standard assumption that the agent suffers cost but obtains value only from the transfers by the principal. More generally, for general contracts with non-zero agent values for outcomes we show how to compute an optimal contract in two cases: (1) when each box has only one prize with non-zero value for principal and agent, (2) for i.i.d. boxes with a single prize with positive value for the principal. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.03024</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.03024</id><created>2024-03-05</created><updated>2025-01-24</updated><authors><author><keyname>Sejfia</keyname><forenames>Adriana</forenames></author><author><keyname>Das</keyname><forenames>Satyaki</forenames></author><author><keyname>Shafiq</keyname><forenames>Saad</forenames></author><author><keyname>Medvidović</keyname><forenames>Nenad</forenames></author></authors><title>Toward Improved Deep Learning-based Vulnerability Detection</title><categories>cs.SE</categories><doi>10.1145/3597503.3608141</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep learning (DL) has been a common thread across several recent techniques for vulnerability detection. The rise of large, publicly available datasets of vulnerabilities has fueled the learning process underpinning these techniques. While these datasets help the DL-based vulnerability detectors, they also constrain these detectors' predictive abilities. Vulnerabilities in these datasets have to be represented in a certain way, e.g., code lines, functions, or program slices within which the vulnerabilities exist. We refer to this representation as a base unit. The detectors learn how base units can be vulnerable and then predict whether other base units are vulnerable. We have hypothesized that this focus on individual base units harms the ability of the detectors to properly detect those vulnerabilities that span multiple base units (or MBU vulnerabilities). For vulnerabilities such as these, a correct detection occurs when all comprising base units are detected as vulnerable. Verifying how existing techniques perform in detecting all parts of a vulnerability is important to establish their effectiveness for other downstream tasks. To evaluate our hypothesis, we conducted a study focusing on three prominent DL-based detectors: ReVeal, DeepWukong, and LineVul. Our study shows that all three detectors contain MBU vulnerabilities in their respective datasets. Further, we observed significant accuracy drops when detecting these types of vulnerabilities. We present our study and a framework that can be used to help DL-based detectors toward the proper inclusion of MBU vulnerabilities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.06641</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.06641</id><created>2024-03-11</created><updated>2024-11-24</updated><authors><author><keyname>Liao</keyname><forenames>Yuan</forenames></author><author><keyname>Gil</keyname><forenames>Jorge</forenames></author><author><keyname>Yeh</keyname><forenames>Sonia</forenames></author><author><keyname>Pereira</keyname><forenames>Rafael H. M.</forenames></author><author><keyname>Alessandretti</keyname><forenames>Laura</forenames></author></authors><title>Socio-spatial segregation and human mobility: A review of empirical   evidence</title><categories>cs.SI</categories><doi>10.1016/j.compenvurbsys.2025.102250</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Socio-spatial segregation is the physical separation of different social, economic, or demographic groups within a geographic space, often resulting in unequal access to resources, services, and opportunities. The literature has traditionally focused on residential segregation, examining how individuals' residential locations are distributed differently across neighborhoods based on various social attributes, e.g., race, ethnicity, and income. However, this approach overlooks the complexity of spatial segregation in people's daily activities, which often extend far beyond residential areas. Since the 2010s, emerging mobility data sources have enabled a new understanding of socio-spatial segregation by considering daily activities such as work, school, shopping, and leisure visits. From traditional surveys to GPS trajectories, diverse data sources reveal that daily mobility can result in spatial segregation levels that differ from those observed in residential segregation. This literature review focuses on three critical questions: (a) What are the strengths and limitations of segregation research incorporating extensive mobility data? (b) How do human mobility patterns relate to individuals' residential vs. experienced segregation levels? and (c) What key factors explain the relationship between one's mobility patterns and experienced segregation? Our literature review enhances the understanding of socio-spatial segregation at the individual level and clarifies core concepts and methodological challenges in the field. Our review explores studies of key themes: segregation, activity space, co-presence, and the built environment. By synthesizing their findings, we aim to offer actionable insights for reducing segregation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.08378</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.08378</id><created>2024-03-13</created><updated>2025-01-24</updated><authors><author><keyname>Jiang</keyname><forenames>Lu</forenames></author><author><keyname>Wang</keyname><forenames>Qi</forenames></author><author><keyname>Chang</keyname><forenames>Yuhang</forenames></author><author><keyname>Song</keyname><forenames>Jianing</forenames></author><author><keyname>Fu</keyname><forenames>Haoyue</forenames></author><author><keyname>Yang</keyname><forenames>Xiaochun</forenames></author></authors><title>An Adaptive Cost-Sensitive Learning and Recursive Denoising Framework   for Imbalanced SVM Classification</title><categories>cs.CV</categories><comments>22 pages, 41 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Category imbalance is one of the most popular and important issues in the domain of classification. Emotion classification model trained on imbalanced datasets easily leads to unreliable prediction. The traditional machine learning method tends to favor the majority class, which leads to the lack of minority class information in the model. Moreover, most existing models will produce abnormal sensitivity issues or performance degradation. We propose a robust learning algorithm based on adaptive cost-sensitivity and recursive denoising, which is a generalized framework and can be incorporated into most stochastic optimization algorithms. The proposed method uses the dynamic kernel distance optimization model between the sample and the decision boundary, which makes full use of the sample's prior information. In addition, we also put forward an effective method to filter noise, the main idea of which is to judge the noise by finding the nearest neighbors of the minority class. In order to evaluate the strength of the proposed method, we not only carry out experiments on standard datasets but also apply it to emotional classification problems with different imbalance rates (IR). Experimental results show that the proposed general framework is superior to traditional methods in Accuracy, G-mean, Recall and F1-score. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.10144</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.10144</id><created>2024-03-15</created><updated>2025-01-24</updated><authors><author><keyname>Casadio</keyname><forenames>Marco</forenames></author><author><keyname>Dinkar</keyname><forenames>Tanvi</forenames></author><author><keyname>Komendantskaya</keyname><forenames>Ekaterina</forenames></author><author><keyname>Arnaboldi</keyname><forenames>Luca</forenames></author><author><keyname>Daggitt</keyname><forenames>Matthew L.</forenames></author><author><keyname>Isac</keyname><forenames>Omri</forenames></author><author><keyname>Katz</keyname><forenames>Guy</forenames></author><author><keyname>Rieser</keyname><forenames>Verena</forenames></author><author><keyname>Lemon</keyname><forenames>Oliver</forenames></author></authors><title>NLP Verification: Towards a General Methodology for Certifying   Robustness</title><categories>cs.CL cs.AI cs.LG cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Learning (ML) has exhibited substantial success in the field of Natural Language Processing (NLP). For example large language models have empirically proven to be capable of producing text of high complexity and cohesion. However, they are prone to inaccuracies and hallucinations. As these systems are increasingly integrated into real-world applications, ensuring their safety and reliability becomes a primary concern. There are safety critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Computer Vision had pioneered the use of formal verification of neural networks for such scenarios and developed common verification standards and pipelines, leveraging precise formal reasoning about geometric properties of data manifolds. In contrast, NLP verification methods have only recently appeared in the literature. While presenting sophisticated algorithms, these papers have not yet crystallised into a common methodology. They are often light on the pragmatical issues of NLP verification and the area remains fragmented. In this paper, we attempt to distil and evaluate general components of an NLP verification pipeline, that emerges from the progress in the field to date. Our contributions are two-fold. Firstly, we propose a general methodology to analyse the effect of the embedding gap, a problem that refers to the discrepancy between verification of geometric subspaces and the semantic meaning of sentences, which the geometric subspaces are supposed to represent. We propose a number of practical NLP methods that can help to quantify the effects of the embedding gap. Secondly, we give a general method for training and verification of neural networks that leverages a more precise geometric estimation of semantic similarity of sentences in the embedding space and helps to overcome the effects of the embedding gap in practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2403.14674</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2403.14674</id><created>2024-03-08</created><updated>2025-01-24</updated><authors><author><keyname>Runge</keyname><forenames>Julian</forenames></author><author><keyname>Skokan</keyname><forenames>Igor</forenames></author><author><keyname>Zhou</keyname><forenames>Gufeng</forenames></author><author><keyname>Pauwels</keyname><forenames>Koen</forenames></author></authors><title>Packaging Up Media Mix Modeling: An Introduction to Robyn's Open-Source   Approach</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As privacy-centric changes reshape the digital advertising landscape, deterministic attribution and measurement of advertising-related user behavior is increasingly constrained. In response, there has been a resurgence in the use of traditional probabilistic measurement techniques, such as media and marketing mix modeling (m/MMM), particularly among digital-first advertisers. However, small and midsize businesses often lack the resources to implement advanced proprietary modeling systems, which require specialized expertise and significant team investments. To address this gap, marketing data scientists at Meta have developed the open-source computational package Robyn, designed to facilitate the adoption of m/MMM for digital advertising measurement. This article explores the computational components and design choices that underpin Robyn, emphasizing how it "packages up" m/MMM to promote organizational acceptance and mitigate common biases. As a widely adopted and actively maintained open-source tool, Robyn is continually evolving. Consequently, the solutions described here should not be seen as definitive or conclusive but as an outline of the pathways that the Robyn community has embarked on. This article aims to provide a structured introduction to these evolving practices, encouraging feedback and dialogue to ensure that Robyn's development aligns with the needs of the broader data science community. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.02378</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.02378</id><created>2024-04-02</created><updated>2025-01-23</updated><authors><author><keyname>Mishkin</keyname><forenames>Aaron</forenames></author><author><keyname>Pilanci</keyname><forenames>Mert</forenames></author><author><keyname>Schmidt</keyname><forenames>Mark</forenames></author></authors><title>Faster Convergence of Stochastic Accelerated Gradient Descent under   Interpolation</title><categories>math.OC cs.LG</categories><comments>Warning: this preprint has a significant theoretical bug. We have   updated the text to point out the issue and clarify which results are valid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove new convergence rates for a generalized version of stochastic Nesterov acceleration under interpolation conditions. Unlike previous analyses, our approach accelerates any stochastic gradient method which makes sufficient progress in expectation. The proof, which proceeds using the estimating sequences framework, applies to both convex and strongly convex functions and is easily specialized to accelerated SGD under the strong growth condition. In this special case, our analysis reduces the dependence on the strong growth constant from $\rho$ to $\sqrt{\rho}$ as compared to prior work. This improvement is comparable to a square-root of the condition number in the worst case and address criticism that guarantees for stochastic acceleration could be worse than those for SGD. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.06814</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.06814</id><created>2024-04-10</created><updated>2025-01-24</updated><authors><author><keyname>Huang</keyname><forenames>Tianxin</forenames></author><author><keyname>Yan</keyname><forenames>Zhiwen</forenames></author><author><keyname>Zhao</keyname><forenames>Yuyang</forenames></author><author><keyname>Lee</keyname><forenames>Gim Hee</forenames></author></authors><title>ComPC: Completing a 3D Point Cloud with 2D Diffusion Priors</title><categories>cs.CV</categories><comments>Accepted by ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D point clouds directly collected from objects through sensors are often incomplete due to self-occlusion. Conventional methods for completing these partial point clouds rely on manually organized training sets and are usually limited to object categories seen during training. In this work, we propose a test-time framework for completing partial point clouds across unseen categories without any requirement for training. Leveraging point rendering via Gaussian Splatting, we develop techniques of Partial Gaussian Initialization, Zero-shot Fractal Completion, and Point Cloud Extraction that utilize priors from pre-trained 2D diffusion models to infer missing regions and extract uniform completed point clouds. Experimental results on both synthetic and real-world scanned point clouds demonstrate that our approach outperforms existing methods in completing a variety of objects. Our project page is at \url{https://tianxinhuang.github.io/projects/ComPC/}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.07517</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.07517</id><created>2024-04-11</created><updated>2025-01-23</updated><authors><author><keyname>Zhou</keyname><forenames>Xin</forenames></author><author><keyname>Lin</keyname><forenames>Chuang</forenames></author><author><keyname>Wang</keyname><forenames>Can</forenames></author><author><keyname>Peng</keyname><forenames>Xiaojiang</forenames></author></authors><title>sEMG-Based Joint Angle Estimation via Hierarchical Spiking Attentional   Feature Decomposition Network</title><categories>cs.HC</categories><comments>8 pages, 6 figures, IEEE Robotics and Automation Letters</comments><journal-ref>IEEE Robotics and Automation Letters ( Volume: 10, Issue: 3, pp   2176 - 2183, March 2025)</journal-ref><doi>10.1109/LRA.2025.3526447</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surface electromyography (sEMG) has demonstrated significant potential in simultaneous and proportional control (SPC). However, existing algorithms for predicting joint angles based onsEMGoften suffer fromhigh inference costs or are limited to specific subjects rather than multi-subject scenarios. To address these challenges, we introduced a hierarchical Spiking Attentional Feature Decomposition Network (SAFE-Net). This network initially compresses sEMG signals into neural spiking forms using a Spiking Sparse Attention Encoder (SSAE). Subsequently, the compressed features are decomposed into kinematic and biological features through a Spiking Attentional Feature Decomposition (SAFD) module. Finally, the kinematic and biological features are used to predict joint angles and identify subject identities, respectively. Our validation on two datasets and comparison with two existing methods, Informer and Spikformer, demonstrate that SSAE achieves significant power consumption savings of 39.1% and 37.5% respectively over them in terms of inference costs. Furthermore, SAFE-Net surpasses Informer and Spikformer in recognition accuracy on both datasets. This study underscores the potential of SAFE-Net to advance the field of SPC in lower limb rehabilitation exoskeleton robots. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.08003</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.08003</id><created>2024-04-09</created><updated>2025-01-23</updated><authors><author><keyname>Lan</keyname><forenames>Guangchen</forenames></author><author><keyname>Han</keyname><forenames>Dong-Jun</forenames></author><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Brinton</keyname><forenames>Christopher G.</forenames></author></authors><title>Asynchronous Federated Reinforcement Learning with Policy Gradient   Updates: Algorithm Design and Convergence Analysis</title><categories>cs.LG cs.DC cs.NI</categories><comments>Published as a conference paper at ICLR 2025</comments><acm-class>I.2.6; I.2.11</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  To improve the efficiency of reinforcement learning (RL), we propose a novel asynchronous federated reinforcement learning (FedRL) framework termed AFedPG, which constructs a global model through collaboration among $N$ agents using policy gradient (PG) updates. To address the challenge of lagged policies in asynchronous settings, we design a delay-adaptive lookahead technique \textit{specifically for FedRL} that can effectively handle heterogeneous arrival times of policy gradients. We analyze the theoretical global convergence bound of AFedPG, and characterize the advantage of the proposed algorithm in terms of both the sample complexity and time complexity. Specifically, our AFedPG method achieves $O(\frac{{\epsilon}^{-2.5}}{N})$ sample complexity for global convergence at each agent on average. Compared to the single agent setting with $O(\epsilon^{-2.5})$ sample complexity, it enjoys a linear speedup with respect to the number of agents. Moreover, compared to synchronous FedPG, AFedPG improves the time complexity from $O(\frac{t_{\max}}{N})$ to $O({\sum_{i=1}^{N} \frac{1}{t_{i}}})^{-1}$, where $t_{i}$ denotes the time consumption in each iteration at agent $i$, and $t_{\max}$ is the largest one. The latter complexity $O({\sum_{i=1}^{N} \frac{1}{t_{i}}})^{-1}$ is always smaller than the former one, and this improvement becomes significant in large-scale federated settings with heterogeneous computing powers ($t_{\max}\gg t_{\min}$). Finally, we empirically verify the improved performance of AFedPG in four widely used MuJoCo environments with varying numbers of agents. We also demonstrate the advantages of AFedPG in various computing heterogeneity scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.10642</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.10642</id><created>2024-04-16</created><updated>2025-01-24</updated><authors><author><keyname>Cheng</keyname><forenames>Pengyu</forenames></author><author><keyname>Hu</keyname><forenames>Tianhao</forenames></author><author><keyname>Xu</keyname><forenames>Han</forenames></author><author><keyname>Zhang</keyname><forenames>Zhisong</forenames></author><author><keyname>Yuan</keyname><forenames>Zheng</forenames></author><author><keyname>Dai</keyname><forenames>Yong</forenames></author><author><keyname>Han</keyname><forenames>Lei</forenames></author><author><keyname>Du</keyname><forenames>Nan</forenames></author><author><keyname>Li</keyname><forenames>Xiaolong</forenames></author></authors><title>Self-playing Adversarial Language Game Enhances LLM Reasoning</title><categories>cs.CL cs.LG</categories><comments>Accepted by NeurIPS 2024</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the potential of self-play training for large language models (LLMs) in a two-player adversarial language game called Adversarial Taboo. In this game, an attacker and a defender communicate around a target word only visible to the attacker. The attacker aims to induce the defender to speak the target word unconsciously, while the defender tries to infer the target word from the attacker's utterances. To win the game, both players must have sufficient knowledge about the target word and high-level reasoning ability to infer and express in this information-reserved conversation. Hence, we are curious about whether LLMs' reasoning ability can be further enhanced by Self-Playing this Adversarial language Game (SPAG). With this goal, we select several open-source LLMs and let each act as the attacker and play with a copy of itself as the defender on an extensive range of target words. Through reinforcement learning on the game outcomes, we observe that the LLMs' performances uniformly improve on a broad range of reasoning benchmarks. Furthermore, iteratively adopting this self-play process can continuously promote LLMs' reasoning abilities. The code is available at https://github.com/Linear95/SPAG. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.11314</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.11314</id><created>2024-04-17</created><updated>2025-01-24</updated><authors><author><keyname>Rivetti</keyname><forenames>Steven</forenames></author><author><keyname>Demir</keyname><forenames>Ozlem Tugfe</forenames></author><author><keyname>Bjornson</keyname><forenames>Emil</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Destructive and constructive RIS beamforming in an ISAC-multi-user MIMO   network</title><categories>cs.IT eess.SP math.IT</categories><comments>To be presented at IEEE ICC25</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Integrated sensing and communication (ISAC) has already established itself as a promising solution to the spectrum scarcity problem, even more so when paired with a reconfigurable intelligent surface (RIS), as RISs can shape the propagation environment by adjusting their phase-shift coefficients. Albeit the potential performance gain, a RIS is also a potential security threat to the system. In this paper, we explore both the positive and negative sides of having a RIS in a multi-user multiple-input multiple-output (MIMO) ISAC network. We first develop an alternating optimization algorithm, obtaining the active and passive beamforming vectors that maximize the sensing signal-to-noise ratio (SNR) under minimum signal-to-interference-plus-noise ratio (SINR) constraints for the communication users and finite power budget. We also investigate the destructive potential of the RIS by devising a RIS phase-shift optimization algorithm that minimizes the sensing SNR while preserving the same minimum communication SINR previously guaranteed by the system. We further investigate the impact of the RIS's individual element failures on the system performance. The simulation results show that the RIS performance-boosting potential is as good as its destructive one and that both of our optimization strategies are hindered by the investigated impairments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.12369</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.12369</id><created>2024-04-18</created><authors><author><keyname>Arazzi</keyname><forenames>Marco</forenames></author><author><keyname>Nicolazzo</keyname><forenames>Serena</forenames></author><author><keyname>Nocera</keyname><forenames>Antonino</forenames></author></authors><title>KDk: A Defense Mechanism Against Label Inference Attacks in Vertical   Federated Learning</title><categories>cs.LG cs.CR</categories><journal-ref>Neurocomputing 2025</journal-ref><doi>10.1016/j.neucom.2025.129476</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Vertical Federated Learning (VFL) is a category of Federated Learning in which models are trained collaboratively among parties with vertically partitioned data. Typically, in a VFL scenario, the labels of the samples are kept private from all the parties except for the aggregating server, that is the label owner. Nevertheless, recent works discovered that by exploiting gradient information returned by the server to bottom models, with the knowledge of only a small set of auxiliary labels on a very limited subset of training data points, an adversary can infer the private labels. These attacks are known as label inference attacks in VFL. In our work, we propose a novel framework called KDk, that combines Knowledge Distillation and k-anonymity to provide a defense mechanism against potential label inference attacks in a VFL scenario. Through an exhaustive experimental campaign we demonstrate that by applying our approach, the performance of the analyzed label inference attacks decreases consistently, even by more than 60%, maintaining the accuracy of the whole VFL almost unaltered. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.14332</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.14332</id><created>2024-04-22</created><updated>2025-01-23</updated><authors><author><keyname>Shmakov</keyname><forenames>Alexander</forenames></author><author><keyname>Greif</keyname><forenames>Kevin</forenames></author><author><keyname>Fenton</keyname><forenames>Michael James</forenames></author><author><keyname>Ghosh</keyname><forenames>Aishik</forenames></author><author><keyname>Baldi</keyname><forenames>Pierre</forenames></author><author><keyname>Whiteson</keyname><forenames>Daniel</forenames></author></authors><title>Full Event Particle-Level Unfolding with Variable-Length Latent   Variational Diffusion</title><categories>hep-ex cs.AI cs.LG hep-ph</categories><comments>Submission to SciPost</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The measurements performed by particle physics experiments must account for the imperfect response of the detectors used to observe the interactions. One approach, unfolding, statistically adjusts the experimental data for detector effects. Recently, generative machine learning models have shown promise for performing unbinned unfolding in a high number of dimensions. However, all current generative approaches are limited to unfolding a fixed set of observables, making them unable to perform full-event unfolding in the variable dimensional environment of collider data. A novel modification to the variational latent diffusion model (VLD) approach to generative unfolding is presented, which allows for unfolding of high- and variable-dimensional feature spaces. The performance of this method is evaluated in the context of semi-leptonic top quark pair production at the Large Hadron Collider. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.15354</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.15354</id><created>2024-04-15</created><updated>2025-01-24</updated><authors><author><keyname>Li</keyname><forenames>Guoming</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Liang</keyname><forenames>Shangsong</forenames></author><author><keyname>Luo</keyname><forenames>Dongsheng</forenames></author></authors><title>Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum of   Function Slices Approach</title><categories>eess.SP cs.AI cs.LG cs.NA math.NA</categories><comments>Accepted in ACM The Web Conference 2025, WWW 2025</comments><doi>10.1145/3696410.3714760</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Spectral graph neural networks are proposed to harness spectral information inherent in graph-structured data through the application of polynomial-defined graph filters, recently achieving notable success in graph-based web applications. Existing studies reveal that various polynomial choices greatly impact spectral GNN performance, underscoring the importance of polynomial selection. However, this selection process remains a critical and unresolved challenge. Although prior work suggests a connection between the approximation capabilities of polynomials and the efficacy of spectral GNNs, there is a lack of theoretical insights into this relationship, rendering polynomial selection a largely heuristic process.   To address the issue, this paper examines polynomial selection from an error-sum of function slices perspective. Inspired by the conventional signal decomposition, we represent graph filters as a sum of disjoint function slices. Building on this, we then bridge the polynomial capability and spectral GNN efficacy by proving that the construction error of graph convolution layer is bounded by the sum of polynomial approximation errors on function slices. This result leads us to develop an advanced filter based on trigonometric polynomials, a widely adopted option for approximating narrow signal slices. The proposed filter remains provable parameter efficiency, with a novel Taylor-based parameter decomposition that achieves streamlined, effective implementation. With this foundation, we propose TFGNN, a scalable spectral GNN operating in a decoupled paradigm. We validate the efficacy of TFGNN via benchmark node classification tasks, along with an example graph anomaly detection application to show its practical utility. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.15390</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.15390</id><created>2024-04-23</created><updated>2025-01-23</updated><authors><author><keyname>Catoni</keyname><forenames>Josefina</forenames></author><author><keyname>Martos</keyname><forenames>Domonkos</forenames></author><author><keyname>Csikor</keyname><forenames>Ferenc</forenames></author><author><keyname>Ferrante</keyname><forenames>Enzo</forenames></author><author><keyname>Milone</keyname><forenames>Diego H.</forenames></author><author><keyname>Meszéna</keyname><forenames>Balázs</forenames></author><author><keyname>Orbán</keyname><forenames>Gergő</forenames></author><author><keyname>Echeveste</keyname><forenames>Rodrigo</forenames></author></authors><title>Uncertainty in latent representations of variational autoencoders   optimized for visual tasks</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep Generative Models (DGMs) can learn flexible latent variable representations of images while avoiding intractable computations, common in Bayesian inference. However, investigating the properties of inference in Variational Autoencoders (VAEs), a major class of DGMs, reveals severe problems in their uncertainty representations. Here we draw inspiration from classical computer vision to introduce an inductive bias into the VAE by incorporating a global explaining-away latent variable, which remedies defective inference in VAEs. Unlike standard VAEs, the Explaing-Away VAE (EA-VAE) provides uncertainty estimates that align with normative requirements across a wide spectrum of perceptual tasks, including image corruption, interpolation, and out-of-distribution detection. We find that restored inference capabilities are delivered by developing a motif in the inference network (the encoder) which is widespread in biological neural networks: divisive normalization. Our results establish EA-VAEs as reliable tools to perform inference under deep generative models with appropriate estimates of uncertainty. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.16056</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.16056</id><created>2024-04-14</created><updated>2025-01-23</updated><authors><author><keyname>Goala</keyname><forenames>Sujata</forenames></author><author><keyname>Goswami</keyname><forenames>Mridu Prabal</forenames></author><author><keyname>Borkotokey</keyname><forenames>Surajit</forenames></author></authors><title>Intelligent Machines and Incomplete Information</title><categories>cs.GT econ.TH</categories><comments>35 pages</comments><msc-class>91A27</msc-class><acm-class>F.0</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The distribution of efficient individuals in the economy and the efforts that they will put in if they are hired, there are two important concerns for a technologically advanced firm. wants to open a new branch. The firm does not have information about the exact level of efficiency of an individual when she is hired. We call this situation incomplete information. The standard principal agent models assume that employees know their efficiency levels. Hence these models design incentive-compatible mechanisms. An incentive-compatible mechanism ensures that a participant does not have the incentive to misreport her efficiency level. This paper does not assume that employees know how efficient they are. This paper assumes that the production technology of the firm is intelligent, that is, the output of the machine reveals the efficiency levels of employees. Employees marginal contributions to the total output of the intelligent machine, the probability distribution of the levels of efficiency and employees costs of efforts together define a game of incomplete information. A characterization of ex-ante Nash Equilibrium is established. The results of the characterization formalize the relationship between the distribution of efficiency levels and the distribution of output. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.17342</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.17342</id><created>2024-04-26</created><updated>2025-01-24</updated><authors><author><keyname>Lynn</keyname><forenames>Teresa</forenames></author><author><keyname>Altakrori</keyname><forenames>Malik H.</forenames></author><author><keyname>Magdy</keyname><forenames>Samar Mohamed</forenames></author><author><keyname>Das</keyname><forenames>Rocktim Jyoti</forenames></author><author><keyname>Lyu</keyname><forenames>Chenyang</forenames></author><author><keyname>Nasr</keyname><forenames>Mohamed</forenames></author><author><keyname>Samih</keyname><forenames>Younes</forenames></author><author><keyname>Chirkunov</keyname><forenames>Kirill</forenames></author><author><keyname>Aji</keyname><forenames>Alham Fikri</forenames></author><author><keyname>Nakov</keyname><forenames>Preslav</forenames></author><author><keyname>Godbole</keyname><forenames>Shantanu</forenames></author><author><keyname>Roukos</keyname><forenames>Salim</forenames></author><author><keyname>Florian</keyname><forenames>Radu</forenames></author><author><keyname>Habash</keyname><forenames>Nizar</forenames></author></authors><title>From Multiple-Choice to Extractive QA: A Case Study for English and   Arabic</title><categories>cs.CL cs.AI</categories><comments>Paper 8 pages, Appendix 12 pages. Published at COLING2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The rapid evolution of Natural Language Processing (NLP) has favoured major languages such as English, leaving a significant gap for many others due to limited resources. This is especially evident in the context of data annotation, a task whose importance cannot be underestimated, but which is time-consuming and costly. Thus, any dataset for resource-poor languages is precious, in particular when it is task-specific. Here, we explore the feasibility of repurposing an existing multilingual dataset for a new NLP task: we repurpose a subset of the BELEBELE dataset (Bandarkar et al., 2023), which was designed for multiple-choice question answering (MCQA), to enable the more practical task of extractive QA (EQA) in the style of machine reading comprehension. We present annotation guidelines and a parallel EQA dataset for English and Modern Standard Arabic (MSA). We also present QA evaluation results for several monolingual and cross-lingual QA pairs including English, MSA, and five Arabic dialects. We aim to help others adapt our approach for the remaining 120 BELEBELE language variants, many of which are deemed under-resourced. We also provide a thorough analysis and share insights to deepen understanding of the challenges and opportunities in NLP task reformulation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2404.18887</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2404.18887</id><created>2024-04-29</created><updated>2025-01-24</updated><authors><author><keyname>Blackwell</keyname><forenames>Daniel</forenames></author><author><keyname>Clark</keyname><forenames>David</forenames></author></authors><title>PrescientFuzz: A more effective exploration approach for grey-box   fuzzing</title><categories>cs.SE cs.CR</categories><comments>12 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Since the advent of AFL, the use of mutational, feedback directed, grey-box fuzzers has become critical in the automated detection of security vulnerabilities. A great deal of research currently goes into their optimisation, including improving the rate at which they achieve branch coverage early in a campaign. We produce an augmented version of LibAFL's `fuzzbench' fuzzer, called PrescientFuzz, that makes use of semantic information from the target program's control flow graph (CFG). We develop an input corpus scheduler that prioritises the selection of inputs for mutation based on the proximity of their execution path to uncovered edges. Simple as this idea is, PrescientFuzz leads all fuzzers using the Google FuzzBench at the time of writing -- in both average code coverage and average ranking, across the benchmark SUTs. Whilst the existence of uncovered edges in the CFG does not guarantee their feasibility, the improvement in coverage over the state-of-the-art fuzzers suggests that this is not an issue in practice. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.09860</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.09860</id><created>2024-05-16</created><authors><author><keyname>Koyama</keyname><forenames>Marii</forenames></author><author><keyname>Yun</keyname><forenames>Claire</forenames></author><author><keyname>Taherkhani</keyname><forenames>Amin</forenames></author><author><keyname>Benchasattabuse</keyname><forenames>Naphan</forenames></author><author><keyname>Sane</keyname><forenames>Bernard Ousmane</forenames></author><author><keyname>Hajdušek</keyname><forenames>Michal</forenames></author><author><keyname>Nagayama</keyname><forenames>Shota</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>Optimal Switching Networks for Paired-Egress Bell State Analyzer Pools</title><categories>quant-ph cs.NI</categories><comments>11 pages, 8 figures, 1 table</comments><doi>10.1109/QCE60285.2024.00219</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To scale quantum computers to useful levels, we must build networks of quantum computational nodes that can share entanglement for use in distributed forms of quantum algorithms. In one proposed architecture, node-to-node entanglement is created when nodes emit photons entangled with stationary memories, with the photons routed through a switched interconnect to a shared pool of Bell state analyzers (BSAs). Designs that optimize switching circuits will reduce loss and crosstalk, raising entanglement rates and fidelity. We present optimal designs for switched interconnects constrained to planar layouts, appropriate for silicon waveguides and Mach-Zehnder interferometer (MZI) $2 \times 2$ switch points. The architectures for the optimal designs are scalable and algorithmically structured to pair any arbitrary inputs in a rearrangeable, non-blocking way. For pairing $N$ inputs, $N(N - 2)/4$ switches are required, which is less than half of number of switches required for full permutation switching networks. An efficient routing algorithm is also presented for each architecture. These designs can also be employed in reverse for entanglement generation using a shared pool of entangled paired photon sources. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.12114</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.12114</id><created>2024-05-20</created><updated>2025-01-24</updated><authors><author><keyname>Jia</keyname><forenames>Zhigang</forenames></author><author><keyname>Xiang</keyname><forenames>Yuelian</forenames></author><author><keyname>Zhao</keyname><forenames>Meixiang</forenames></author><author><keyname>Wu</keyname><forenames>Tingting</forenames></author><author><keyname>Ng</keyname><forenames>Michael K.</forenames></author></authors><title>A New Cross-Space Total Variation Regularization Model for Color Image   Restoration with Quaternion Blur Operator</title><categories>cs.CV cs.NA math.NA</categories><comments>15pages,14figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cross-channel deblurring problem in color image processing is difficult to solve due to the complex coupling and structural blurring of color pixels. Until now, there are few efficient algorithms that can reduce color artifacts in deblurring process. To solve this challenging problem, we present a novel cross-space total variation (CSTV) regularization model for color image deblurring by introducing a quaternion blur operator and a cross-color space regularization functional. The existence and uniqueness of the solution is proved and a new L-curve method is proposed to find a balance of regularization terms on different color spaces. The Euler-Lagrange equation is derived to show that CSTV has taken into account the coupling of all color channels and the local smoothing within each color channel. A quaternion operator splitting method is firstly proposed to enhance the ability of color artifacts reduction of the CSTV regularization model. This strategy also applies to the well-known color deblurring models. Numerical experiments on color image databases illustrate the efficiency and effectiveness of the new model and algorithms. The color images restored by them successfully maintain the color and spatial information and are of higher quality in terms of PSNR, SSIM, MSE and CIEde2000 than the restorations of the-state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.12121</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.12121</id><created>2024-05-20</created><updated>2025-01-24</updated><authors><author><keyname>Hänggi</keyname><forenames>Esther</forenames></author><author><keyname>Winkler</keyname><forenames>Severin</forenames></author></authors><title>Lower Bounds for Quantum Secure Function Evaluation Reductions</title><categories>quant-ph cs.CR</categories><comments>Completely rewritten. For better readability, we have separated the   two main results of the previous versions. arXiv:2405.12121 proves the   impossibility of quantum private queries. The current version builds upon the   main theorem of arXiv:2405.12121. It then proves lower bounds on secure   implementations of functions by quantum protocols</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-sided output secure function evaluation is a cryptographic primitive where the two mutually distrustful players, Alice and Bob, both have a private input to a bivariate function. Bob obtains the value of the function for the given inputs, while Alice receives no output. It is known that this primitive cannot be securely implemented if the two players only have access to noiseless classical and quantum communication. In this work, we first show that Bob can extract the function values for all his possible inputs from any implementation of a non-trivial function that is correct and preserves the privacy of Bob's input. Our result holds in the non-asymptotic setting where the players have finite resources and the error is a constant. Then we consider protocols for secure function evaluation in a setup where the two players have access to trusted distributed randomness as a resource. Building upon the first result, we prove a bound on the efficiency of such cryptographic reductions for any non-trivial function in terms of the conditional entropies of the trusted randomness. From this result, we can derive lower bounds on the number of instances of different variants of OT needed to securely implement a given function. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.14318</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.14318</id><created>2024-05-23</created><updated>2025-01-23</updated><authors><author><keyname>Chen</keyname><forenames>Haoran</forenames></author><author><keyname>Goldblum</keyname><forenames>Micah</forenames></author><author><keyname>Wu</keyname><forenames>Zuxuan</forenames></author><author><keyname>Jiang</keyname><forenames>Yu-Gang</forenames></author></authors><title>Adaptive Retention &amp; Correction: Test-Time Training for Continual   Learning</title><categories>cs.CV cs.LG</categories><comments>Accepted to ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continual learning, also known as lifelong learning or incremental learning, refers to the process by which a model learns from a stream of incoming data over time. A common problem in continual learning is the classification layer's bias towards the most recent task. Traditionally, methods have relied on incorporating data from past tasks during training to mitigate this issue. However, the recent shift in continual learning to memory-free environments has rendered these approaches infeasible. In this study, we propose a solution focused on the testing phase. We first introduce a simple Out-of-Task Detection method, OTD, designed to accurately identify samples from past tasks during testing. Leveraging OTD, we then propose: (1) an Adaptive Retention mechanism for dynamically tuning the classifier layer on past task data; (2) an Adaptive Correction mechanism for revising predictions when the model classifies data from previous tasks into classes from the current task. We name our approach Adaptive Retention &amp; Correction (ARC). While designed for memory-free environments, ARC also proves effective in memory-based settings. Extensive experiments show that our proposed method can be plugged in to virtually any existing continual learning approach without requiring any modifications to its training procedure. Specifically, when integrated with state-of-the-art approaches, ARC achieves an average performance increase of 2.7% and 2.6% on the CIFAR-100 and Imagenet-R datasets, respectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.14772</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.14772</id><created>2024-05-23</created><updated>2025-01-24</updated><authors><author><keyname>Blum</keyname><forenames>Maria</forenames></author><author><keyname>Döding</keyname><forenames>Christian</forenames></author><author><keyname>Henning</keyname><forenames>Patrick</forenames></author></authors><title>Vortex-capturing multiscale spaces for the Ginzburg-Landau equation</title><categories>math.NA cs.NA</categories><msc-class>65N12, 65N15, 65N30, 35Q56</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers minimizers of the Ginzburg-Landau energy functional in special multiscale spaces that are based on finite elements. The spaces are constructed by localized orthogonal decomposition techniques and their usage for solving the Ginzburg-Landau equation was first suggested in [D\"orich, Henning, SINUM 2024]. In this work we further explore their approximation properties and give an analytical explanation for why vortex structures of energy minimizers can be captured more accurately in these spaces. We quantify the necessary mesh resolution in terms of the Ginzburg-Landau parameter $\kappa$ and a stabilization parameter $\beta \ge 0$ that is used in the construction of the multiscale spaces. Furthermore, we analyze how $\kappa$ affects the necessary locality of the multiscale basis functions and we prove that the choice $\beta=0$ yields typically the highest accuracy. Our findings are supported by numerical experiments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.16361</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.16361</id><created>2024-05-25</created><updated>2025-01-23</updated><authors><author><keyname>Li</keyname><forenames>Kexin</forenames></author><author><keyname>Mehta</keyname><forenames>Aastha</forenames></author><author><keyname>Lie</keyname><forenames>David</forenames></author></authors><title>Noisy Data Meets Privacy: Training Local Models with Post-Processed   Remote Queries</title><categories>cs.LG cs.CR cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The adoption of large cloud-based models for inference in privacy-sensitive domains, such as homeless care systems and medical imaging, raises concerns about end-user data privacy. A common solution is adding locally differentially private (LDP) noise to queries before transmission, but this often reduces utility. LDPKiT, which stands for Local Differentially-Private and Utility-Preserving Inference via Knowledge Transfer, addresses the concern by generating a privacy-preserving inference dataset aligned with the private data distribution. This dataset is used to train a reliable local model for inference on sensitive inputs. LDPKiT employs a two-layer noise injection framework that leverages LDP and its post-processing property to create a privacy-protected inference dataset. The first layer ensures privacy, while the second layer helps to recover utility by creating a sufficiently large dataset for subsequent local model extraction using noisy labels returned from a cloud model on privacy-protected noisy inputs. Our experiments on Fashion-MNIST, SVHN and PathMNIST medical datasets demonstrate that LDPKiT effectively improves utility while preserving privacy. Moreover, the benefits of using LDPKiT increase at higher, more privacy-protective noise levels. For instance, on SVHN, LDPKiT achieves similar inference accuracy with $\epsilon=1.25$ as it does with $\epsilon=2.0$, providing stronger privacy guarantees with less than a 2% drop in accuracy. Furthermore, we perform extensive sensitivity analyses to evaluate the impact of dataset sizes on LDPKiT's effectiveness and systematically analyze the latent space representations to offer a theoretical explanation for its accuracy improvements. Lastly, we qualitatively and quantitatively demonstrate that the type of knowledge distillation performed by LDPKiT is ethical and fundamentally distinct from adversarial model extraction attacks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.18379</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.18379</id><created>2024-05-28</created><updated>2025-01-24</updated><authors><author><keyname>Zrnic</keyname><forenames>Tijana</forenames></author></authors><title>A Note on the Prediction-Powered Bootstrap</title><categories>stat.ML cs.LG stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce PPBoot: a bootstrap-based method for prediction-powered inference. PPBoot is applicable to arbitrary estimation problems and is very simple to implement, essentially only requiring one application of the bootstrap. Through a series of examples, we demonstrate that PPBoot often performs nearly identically to (and sometimes better than) the earlier PPI(++) method based on asymptotic normality$\unicode{x2013}$when the latter is applicable$\unicode{x2013}$without requiring any asymptotic characterizations. Given its versatility, PPBoot could simplify and expand the scope of application of prediction-powered inference to problems where central limit theorems are hard to prove. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2405.19019</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2405.19019</id><created>2024-05-29</created><authors><author><keyname>Chatzopoulos</keyname><forenames>Matthaios</forenames></author><author><keyname>Koutsourelakis</keyname><forenames>Phaedon-Stelios</forenames></author></authors><title>Physics-Aware Neural Implicit Solvers for multiscale, parametric PDEs   with applications in heterogeneous media</title><categories>stat.ML cs.LG</categories><journal-ref>Computer Methods in Applied Mechanics and Engineering, Volume 432,   Part A, 2024, 117342, ISSN 0045-7825</journal-ref><doi>10.1016/j.cma.2024.117342</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose Physics-Aware Neural Implicit Solvers (PANIS), a novel, data-driven framework for learning surrogates for parametrized Partial Differential Equations (PDEs). It consists of a probabilistic, learning objective in which weighted residuals are used to probe the PDE and provide a source of {\em virtual} data i.e. the actual PDE never needs to be solved. This is combined with a physics-aware implicit solver that consists of a much coarser, discretized version of the original PDE, which provides the requisite information bottleneck for high-dimensional problems and enables generalization in out-of-distribution settings (e.g. different boundary conditions). We demonstrate its capability in the context of random heterogeneous materials where the input parameters represent the material microstructure. We extend the framework to multiscale problems and show that a surrogate can be learned for the effective (homogenized) solution without ever solving the reference problem. We further demonstrate how the proposed framework can accommodate and generalize several existing learning objectives and architectures while yielding probabilistic surrogates that can quantify predictive uncertainty. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.00362</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.00362</id><created>2024-06-01</created><updated>2025-01-24</updated><authors><author><keyname>Muramatsu</keyname><forenames>Hisayoshi</forenames></author></authors><title>Quasiperiodic Disturbance Observer for Wideband Harmonic Suppression</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periodic disturbances composed of harmonics typically occur during periodic operations, impairing performance of mechanical and electrical systems. To improve the performance, control of periodic-disturbance suppression has been studied, such as repetitive control and periodic-disturbance observers. However, actual periodic disturbances are typically quasiperiodic owing to perturbations in each cycle, identification errors of the period, variations in the period, and/or aperiodic disturbances. For robustness against quasiperiodicity, although wideband harmonic suppression is expected, conventional methods have trade-offs among harmonic suppression bandwidth, amplification of aperiodic disturbances, and deviation of harmonic suppression frequencies. This paper proposes a quasiperiodic disturbance observer to compensate for quasiperiodic disturbances while simultaneously achieving the wideband harmonic suppression, non-amplification of aperiodic disturbances, and proper harmonic suppression frequencies. A quasiperiodic disturbance is defined as comprising harmonics and surrounding signals. On the basis of this definition, the quasiperiodic disturbance observer is designed using a periodic-pass filter of a first-order periodic/aperiodic separation filter for its Q-filter, time delay integrated with a zero-phase low-pass filter, and an inverse plant model with a first-order low-pass filter. The periodic-pass filter achieves the wideband harmonic suppression while the zero-phase and first-order low-pass filters prevent the amplification of aperiodic disturbances and deviation of harmonic suppression frequencies. For the implementation, the Q-filter is discretized by an exact mapping of the s-plane to the z-plane, and the inverse plant model is discretized by the backward Euler method. The experiments validated the frequency response and position-control precision of the proposed method. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.04772</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.04772</id><created>2024-06-07</created><updated>2025-01-24</updated><authors><author><keyname>Jeon</keyname><forenames>Sungho</forenames></author><author><keyname>Ma</keyname><forenames>Xinyue</forenames></author><author><keyname>Kim</keyname><forenames>Kwang In</forenames></author><author><keyname>Jeon</keyname><forenames>Myeongjae</forenames></author></authors><title>REP: Resource-Efficient Prompting for Rehearsal-Free Continual Learning</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent rehearsal-free methods, guided by prompts, generally excel in vision-related continual learning (CL) scenarios with continuously drifting data. To be deployable on real-world devices, these methods must contain high resource efficiency during training. In this paper, we introduce Resource-Efficient Prompting (REP), which targets improving the resource efficiency of prompt-based rehearsal-free methods. Our key focus is on avoiding catastrophic trade-offs with accuracy while trimming computational and memory costs during prompt learning. We achieve this by exploiting swift prompt selection that enhances input data using a carefully provisioned model, and by developing adaptive token merging (AToM) and layer dropping (ALD) algorithms for the prompt updating stage. AToM and ALD perform selective skipping across the data and model dimensions without compromising task-specific features while learning new tasks. We validate REP's superior resource efficiency over current state-of-the-art ViT- and CNN-based methods through extensive experiments on three image classification datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.08125</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.08125</id><created>2024-06-12</created><updated>2025-01-24</updated><authors><author><keyname>Giannakopoulos</keyname><forenames>Yiannis</forenames></author><author><keyname>Hahn</keyname><forenames>Johannes</forenames></author></authors><title>Discrete Single-Parameter Optimal Auction Design</title><categories>cs.GT cs.DM</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the classic single-item auction setting of Myerson, but under the assumption that the buyers' values for the item are distributed over finite supports. Using strong LP duality and polyhedral theory, we rederive various key results regarding the revenue-maximizing auction, including the characterization through virtual welfare maximization and the optimality of deterministic mechanisms, as well as a novel, generic equivalence between dominant-strategy and Bayesian incentive compatibility.   Inspired by this, we abstract our approach to handle more general auction settings, where the feasibility space can be given by arbitrary convex constraints, and the objective is a convex combination of revenue and social welfare. We characterize the optimal auctions of such systems as generalized virtual welfare maximizers, by making use of their KKT conditions, and we present an analogue of Myerson's payment formula for general discrete single-parameter auction settings. Additionally, we prove that total unimodularity of the feasibility space is a sufficient condition to guarantee the optimality of auctions with integral allocation rules.   Finally, we demonstrate this KKT approach by applying it to a setting where bidders are interested in buying feasible flows on trees with capacity constraints, and provide a combinatorial description of the (randomized, in general) optimal auction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.08627</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.08627</id><created>2024-06-12</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Haoxin</forenames></author><author><keyname>Xu</keyname><forenames>Shangqing</forenames></author><author><keyname>Zhao</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Kong</keyname><forenames>Lingkai</forenames></author><author><keyname>Kamarthi</keyname><forenames>Harshavardhan</forenames></author><author><keyname>Sasanur</keyname><forenames>Aditya B.</forenames></author><author><keyname>Sharma</keyname><forenames>Megha</forenames></author><author><keyname>Cui</keyname><forenames>Jiaming</forenames></author><author><keyname>Wen</keyname><forenames>Qingsong</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Prakash</keyname><forenames>B. Aditya</forenames></author></authors><title>Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis</title><categories>cs.LG cs.CL</categories><comments>Accepted by NeurIPS 2024 Datasets and Benchmarks Track</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Time series data are ubiquitous across a wide range of real-world domains. While real-world time series analysis (TSA) requires human experts to integrate numerical series data with multimodal domain-specific knowledge, most existing TSA models rely solely on numerical data, overlooking the significance of information beyond numerical series. This oversight is due to the untapped potential of textual series data and the absence of a comprehensive, high-quality multimodal dataset. To overcome this obstacle, we introduce Time-MMD, the first multi-domain, multimodal time series dataset covering 9 primary data domains. Time-MMD ensures fine-grained modality alignment, eliminates data contamination, and provides high usability. Additionally, we develop MM-TSFlib, the first-cut multimodal time-series forecasting (TSF) library, seamlessly pipelining multimodal TSF evaluations based on Time-MMD for in-depth analyses. Extensive experiments conducted on Time-MMD through MM-TSFlib demonstrate significant performance enhancements by extending unimodal TSF to multimodality, evidenced by over 15% mean squared error reduction in general, and up to 40% in domains with rich textual data. More importantly, our datasets and library revolutionize broader applications, impacts, research topics to advance TSA. The dataset is available at https://github.com/AdityaLab/Time-MMD. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.09116</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.09116</id><created>2024-06-13</created><updated>2025-01-24</updated><authors><author><keyname>Negri</keyname><forenames>Marcello Massimo</forenames></author><author><keyname>Aellen</keyname><forenames>Jonathan</forenames></author><author><keyname>Roth</keyname><forenames>Volker</forenames></author></authors><title>Injective flows for star-like manifolds</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Normalizing Flows (NFs) are powerful and efficient models for density estimation. When modeling densities on manifolds, NFs can be generalized to injective flows but the Jacobian determinant becomes computationally prohibitive. Current approaches either consider bounds on the log-likelihood or rely on some approximations of the Jacobian determinant. In contrast, we propose injective flows for star-like manifolds and show that for such manifolds we can compute the Jacobian determinant exactly and efficiently, with the same cost as NFs. This aspect is particularly relevant for variational inference settings, where no samples are available and only some unnormalized target is known. Among many, we showcase the relevance of modeling densities on star-like manifolds in two settings. Firstly, we introduce a novel Objective Bayesian approach for penalized likelihood models by interpreting level-sets of the penalty as star-like manifolds. Secondly, we consider probabilistic mixing models and introduce a general method for variational inference by defining the posterior of mixture weights on the probability simplex. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.09266</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.09266</id><created>2024-06-13</created><updated>2025-01-23</updated><authors><author><keyname>Patel</keyname><forenames>Radha</forenames></author><author><keyname>Ahrens</keyname><forenames>Willow</forenames></author><author><keyname>Amarasinghe</keyname><forenames>Saman</forenames></author></authors><title>SySTeC: A Symmetric Sparse Tensor Compiler</title><categories>cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetric and sparse tensors arise naturally in many domains including linear algebra, statistics, physics, chemistry, and graph theory. Symmetric tensors are equal to their transposes, so in the $n$-dimensional case we can save up to a factor of $n!$ by avoiding redundant operations. Sparse tensors, on the other hand, are mostly zero, and we can save asymptotically by processing only nonzeros. Unfortunately, specializing for both symmetry and sparsity at the same time is uniquely challenging. Optimizing for symmetry requires consideration of $n!$ transpositions of a triangular kernel, which can be complex and error prone. Considering multiple transposed iteration orders and triangular loop bounds also complicates iteration through intricate sparse tensor formats. Additionally, since each combination of symmetry and sparse tensor formats requires a specialized implementation, this leads to a combinatorial number of cases. A compiler is needed, but existing compilers cannot take advantage of both symmetry and sparsity within the same kernel. In this paper, we describe the first compiler which can automatically generate symmetry-aware code for sparse or structured tensor kernels. We introduce a taxonomy for symmetry in tensor kernels, and show how to target each kind of symmetry. Our implementation demonstrates significant speedups ranging from 1.36x for SSYMV to 30.4x for a 5-dimensional MTTKRP over the non-symmetric state of the art. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.09370</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.09370</id><created>2024-06-13</created><updated>2025-01-23</updated><authors><author><keyname>Friedman</keyname><forenames>Lior</forenames></author><author><keyname>Meir</keyname><forenames>Ron</forenames></author></authors><title>Data-dependent and Oracle Bounds on Forgetting in Continual Learning</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In continual learning, knowledge must be preserved and re-used between tasks, maintaining good transfer to future tasks and minimizing forgetting of previously learned ones. While several practical algorithms have been devised for this setting, there have been few theoretical works aiming to quantify and bound the degree of Forgetting in general settings. We provide both data-dependent and oracle upper bounds that apply regardless of model and algorithm choice, as well as bounds for Gibbs posteriors. We derive an algorithm based on our bounds and demonstrate empirically that our approach yields tight bounds on forgetting for several continual learning problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.11175</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.11175</id><created>2024-06-16</created><updated>2025-01-24</updated><authors><author><keyname>Sun</keyname><forenames>Zhihang</forenames></author><author><keyname>Li</keyname><forenames>Andong</forenames></author><author><keyname>Chen</keyname><forenames>Rilin</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Yu</keyname><forenames>Meng</forenames></author><author><keyname>Zhou</keyname><forenames>Yi</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>SMRU: Split-and-Merge Recurrent-based UNet for Acoustic Echo   Cancellation and Noise Suppression</title><categories>cs.SD eess.AS</categories><comments>8 pages, Accepted to SLT 2024</comments><journal-ref>2024 IEEE Spoken Language Technology Workshop (SLT), pp. 317-324,   2024</journal-ref><doi>10.1109/SLT61566.2024.10832279</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The proliferation of deep neural networks has spawned the rapid development of acoustic echo cancellation and noise suppression, and plenty of prior arts have been proposed, which yield promising performance. Nevertheless, they rarely consider the deployment generality in different processing scenarios, such as edge devices, and cloud processing. To this end, this paper proposes a general model, termed SMRU, to cover different application scenarios. The novelty lies in two-fold. First, a multi-scale band split layer and band merge layer are proposed to effectively fuse local frequency bands for lower complexity modeling. Besides, by simulating the multi-resolution feature modeling characteristic of the classical UNet structure, a novel recurrent-dominated UNet is devised. It consists of multiple variable frame rate blocks, each of which involves the causal time down-/up-sampling layer with varying compression ratios and the dual-path structure for inter- and intra-band modeling. The model is configured from 50 M/s to 6.8 G/s in terms of MACs, and the experimental results show that the proposed approach yields competitive or even better performance over existing baselines, and has the full potential to adapt to more general scenarios with varying complexity requirements. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.12334</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.12334</id><created>2024-06-18</created><updated>2025-01-24</updated><authors><author><keyname>Errica</keyname><forenames>Federico</forenames></author><author><keyname>Siracusano</keyname><forenames>Giuseppe</forenames></author><author><keyname>Sanvito</keyname><forenames>Davide</forenames></author><author><keyname>Bifulco</keyname><forenames>Roberto</forenames></author></authors><title>What Did I Do Wrong? Quantifying LLMs' Sensitivity and Consistency to   Prompt Engineering</title><categories>cs.LG cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large Language Models (LLMs) changed the way we design and interact with software systems. Their ability to process and extract information from text has drastically improved productivity in a number of routine tasks. Developers that want to include these models in their software stack, however, face a dreadful challenge: debugging LLMs' inconsistent behavior across minor variations of the prompt. We therefore introduce two metrics for classification tasks, namely sensitivity and consistency, which are complementary to task performance. First, sensitivity measures changes of predictions across rephrasings of the prompt, and does not require access to ground truth labels. Instead, consistency measures how predictions vary across rephrasings for elements of the same class. We perform an empirical comparison of these metrics on text classification tasks, using them as guideline for understanding failure modes of the LLM. Our hope is that sensitivity and consistency will be helpful to guide prompt engineering and obtain LLMs that balance robustness with performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.14117</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.14117</id><created>2024-06-20</created><updated>2025-01-24</updated><authors><author><keyname>Sun</keyname><forenames>Shuoqi</forenames></author><author><keyname>Zhuang</keyname><forenames>Shengyao</forenames></author><author><keyname>Wang</keyname><forenames>Shuai</forenames></author><author><keyname>Zuccon</keyname><forenames>Guido</forenames></author></authors><title>An Investigation of Prompt Variations for Zero-shot LLM-based Rankers</title><categories>cs.IR cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We provide a systematic understanding of the impact of specific components and wordings used in prompts on the effectiveness of rankers based on zero-shot Large Language Models (LLMs). Several zero-shot ranking methods based on LLMs have recently been proposed. Among many aspects, methods differ across (1) the ranking algorithm they implement, e.g., pointwise vs. listwise, (2) the backbone LLMs used, e.g., GPT3.5 vs. FLAN-T5, (3) the components and wording used in prompts, e.g., the use or not of role-definition (role-playing) and the actual words used to express this. It is currently unclear whether performance differences are due to the underlying ranking algorithm, or because of spurious factors such as better choice of words used in prompts. This confusion risks to undermine future research. Through our large-scale experimentation and analysis, we find that ranking algorithms do contribute to differences between methods for zero-shot LLM ranking. However, so do the LLM backbones -- but even more importantly, the choice of prompt components and wordings affect the ranking. In fact, in our experiments, we find that, at times, these latter elements have more impact on the ranker's effectiveness than the actual ranking algorithms, and that differences among ranking methods become more blurred when prompt variations are considered. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.14197</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.14197</id><created>2024-06-20</created><updated>2025-01-24</updated><authors><author><keyname>Nowak</keyname><forenames>Franz</forenames></author><author><keyname>Svete</keyname><forenames>Anej</forenames></author><author><keyname>Butoi</keyname><forenames>Alexandra</forenames></author><author><keyname>Cotterell</keyname><forenames>Ryan</forenames></author></authors><title>On the Representational Capacity of Neural Language Models with   Chain-of-Thought Reasoning</title><categories>cs.CL cs.FL</categories><comments>Published at ACL 2024</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of modern language models (LMs) has been improved by chain-of-thought (CoT) reasoning, i.e., the process of generating intermediate results that guide the model towards a final answer. A possible explanation for this improvement is that CoT reasoning extends an LM's computational power, as RNNs and transformers with additional scratch space are known to be Turing complete. Comparing LMs to Turing machines, however, introduces a category error - Turing machines decide language membership, whereas LMs define distributions over strings. To bridge this gap, we formalize CoT reasoning in a probabilistic setting. We present several results on the representational capacity of recurrent and transformer LMs with CoT reasoning, showing that they can represent the same family of distributions over strings as probabilistic Turing machines. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.15809</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.15809</id><created>2024-06-22</created><updated>2025-01-24</updated><authors><author><keyname>Chhikara</keyname><forenames>Garima</forenames></author><author><keyname>Sharma</keyname><forenames>Anurag</forenames></author><author><keyname>Gurucharan</keyname><forenames>V.</forenames></author><author><keyname>Ghosh</keyname><forenames>Kripabandhu</forenames></author><author><keyname>Chakraborty</keyname><forenames>Abhijnan</forenames></author></authors><title>LaMSUM: Amplifying Voices Against Harassment through LLM Guided   Extractive Summarization of User Incident Reports</title><categories>cs.CL cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Citizen reporting platforms like Safe City in India help the public and authorities stay informed about sexual harassment incidents. However, the high volume of data shared on these platforms makes reviewing each individual case challenging. Therefore, a summarization algorithm capable of processing and understanding various Indian code-mixed languages is essential. In recent years, Large Language Models (LLMs) have shown exceptional performance in NLP tasks, including summarization. LLMs inherently produce abstractive summaries by paraphrasing the original text, while the generation of extractive summaries - selecting specific subsets from the original text - through LLMs remains largely unexplored. Moreover, LLMs have a limited context window size, restricting the amount of data that can be processed at once. We tackle these challenge by introducing LaMSUM, a novel multi-level framework designed to generate extractive summaries for large collections of Safe City posts using LLMs. LaMSUM integrates summarization with different voting methods to achieve robust summaries. Extensive evaluation using three popular LLMs (Llama, Mistral and GPT-4o) demonstrates that LaMSUM outperforms state-of-the-art extractive summarization methods for Safe City posts. Overall, this work represents one of the first attempts to achieve extractive summarization through LLMs, and is likely to support stakeholders by offering a comprehensive overview and enabling them to develop effective policies to minimize incidents of unwarranted harassment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2406.18849</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2406.18849</id><created>2024-06-26</created><updated>2025-01-24</updated><authors><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Wang</keyname><forenames>Zhongqi</forenames></author><author><keyname>Lei</keyname><forenames>Mengqi</forenames></author><author><keyname>Yuan</keyname><forenames>Zheng</forenames></author><author><keyname>Yan</keyname><forenames>Bei</forenames></author><author><keyname>Shan</keyname><forenames>Shiguang</forenames></author><author><keyname>Chen</keyname><forenames>Xilin</forenames></author></authors><title>Dysca: A Dynamic and Scalable Benchmark for Evaluating Perception   Ability of LVLMs</title><categories>cs.CV</categories><comments>Accepted by ICLR2025</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Currently many benchmarks have been proposed to evaluate the perception ability of the Large Vision-Language Models (LVLMs). However, most benchmarks conduct questions by selecting images from existing datasets, resulting in the potential data leakage. Besides, these benchmarks merely focus on evaluating LVLMs on the realistic style images and clean scenarios, leaving the multi-stylized images and noisy scenarios unexplored. In response to these challenges, we propose a dynamic and scalable benchmark named Dysca for evaluating LVLMs by leveraging synthesis images. Specifically, we leverage Stable Diffusion and design a rule-based method to dynamically generate novel images, questions and the corresponding answers. We consider 51 kinds of image styles and evaluate the perception capability in 20 subtasks. Moreover, we conduct evaluations under 4 scenarios (i.e., Clean, Corruption, Print Attacking and Adversarial Attacking) and 3 question types (i.e., Multi-choices, True-or-false and Free-form). Thanks to the generative paradigm, Dysca serves as a scalable benchmark for easily adding new subtasks and scenarios. A total of 24 advanced open-source LVLMs and 2 close-source LVLMs are evaluated on Dysca, revealing the drawbacks of current LVLMs. The benchmark is released at \url{https://github.com/Robin-WZQ/Dysca}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.02810</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.02810</id><created>2024-07-03</created><updated>2025-01-24</updated><authors><author><keyname>Kirasur</keyname><forenames>Nayana</forenames></author><author><keyname>Jhaver</keyname><forenames>Shagun</forenames></author></authors><title>Understanding the Prevalence of Caste: A Critical Discourse Analysis of   Community Profiles on X</title><categories>cs.HC</categories><comments>34 pages, 11 figures, 1 table</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Despite decades of anti-caste efforts, sociocultural practices that marginalize lower-caste groups in India remain prevalent and have even proliferated with the use of social media. This paper examines how groups engaged in caste-based discrimination leverage platform affordances of the social media site X (formerly Twitter) to circulate and reinforce caste ideologies. Using a critical discourse analysis (CDA) approach, we examine the rhetorical and organizing strategies of 50 X profiles representing upper-caste collectives. We find that these profiles leverage platform affordances such as information control, bandwidth, visibility, searchability, and shareability to construct two main arguments: (1) that their upper caste culture deserves a superior status and (2) that they are the "true" victims of oppression in society. These profiles' digitally mediated discursive strategies contribute to the marginalization of lower castes by normalizing caste cultures, strengthening caste networks, reinforcing caste discrimination, and diminishing anti-caste measures. Our analysis builds upon previous HCI conceptualizations of online harms and safety to inform how to address caste-based marginalization. We offer theoretical and methodological suggestions for critical HCI research focused on studying the mechanisms of power along other social categories. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.07341</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.07341</id><created>2024-07-09</created><updated>2025-01-23</updated><authors><author><keyname>Sahu</keyname><forenames>Gaurav</forenames></author><author><keyname>Vechtomova</keyname><forenames>Olga</forenames></author><author><keyname>Laradji</keyname><forenames>Issam H.</forenames></author></authors><title>A Guide To Effectively Leveraging LLMs for Low-Resource Text   Summarization: Data Augmentation and Semi-supervised Approaches</title><categories>cs.CL cs.AI</categories><comments>Accepted to NAACL 2025 (Findings)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Existing approaches for low-resource text summarization primarily employ large language models (LLMs) like GPT-3 or GPT-4 at inference time to generate summaries directly; however, such approaches often suffer from inconsistent LLM outputs and are difficult to adapt to domain-specific data in low-resource scenarios. In this work, we propose two novel methods to effectively utilize LLMs for low-resource text summarization: 1) MixSumm, an LLM-based data augmentation regime that synthesizes high-quality documents (short and long) for few-shot text summarization, and 2) PPSL, a prompt-based pseudolabeling strategy for sample-efficient semi-supervised text summarization. Specifically, MixSumm leverages the open-source LLaMA-3-70b-Instruct model to generate new documents by mixing topical information derived from a small seed set, and PPSL leverages the LLaMA-3-70b-Instruct model to generate high-quality pseudo-labels in a semi-supervised learning setup. We evaluate our methods on the TweetSumm, WikiHow, and ArXiv/PubMed datasets and use L-Eval, a LLaMA-3-based evaluation metric, and ROUGE scores to measure the quality of generated summaries. Our experiments on extractive and abstractive summarization show that MixSumm and PPSL achieve competitive ROUGE scores as a fully supervised method with 5% of the labeled data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.11904</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.11904</id><created>2024-07-16</created><updated>2025-01-24</updated><authors><author><keyname>Andrews</keyname><forenames>Boris D.</forenames></author><author><keyname>Farrell</keyname><forenames>Patrick E.</forenames></author></authors><title>High-order conservative and accurately dissipative numerical integrators   via auxiliary variables</title><categories>math.NA cs.NA</categories><comments>54 pages, 13 figures</comments><msc-class>65M60 (Primary) 65L05, 65P10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical methods for the simulation of transient systems with structure-preserving properties are known to exhibit greater accuracy and physical reliability, in particular over long durations. However, there remain difficulties in devising geometric numerical integrators that preserve dissipation laws and conserve non-quadratic invariants. In this work, we propose a framework for the construction of timestepping schemes that preserve dissipation laws and conserve multiple general invariants. The framework employs finite elements in time and systematically introduces auxiliary variables; it extends to arbitrary order in time. We demonstrate the ideas by devising novel integrators that conserve (to machine precision) all known invariants of general conservative ODEs, energy-conserving finite-element discretisations of general Hamiltonian PDEs, and finite-element schemes for the compressible Navier-Stokes equations that conserve mass, momentum, and energy, and provably possess non-decreasing entropy. The approach generalises and unifies several existing ideas in the literature, including Gauss methods, the framework of Cohen &amp; Hairer, and the energy- and helicity-conserving scheme of Rebholz. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.14058</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.14058</id><created>2024-07-19</created><updated>2025-01-24</updated><authors><author><keyname>Wang</keyname><forenames>Jingyao</forenames></author><author><keyname>Zhao</keyname><forenames>Siyu</forenames></author><author><keyname>Qiang</keyname><forenames>Wenwen</forenames></author><author><keyname>Li</keyname><forenames>Jiangmeng</forenames></author><author><keyname>Sun</keyname><forenames>Fuchun</forenames></author><author><keyname>Xiong</keyname><forenames>Hui</forenames></author></authors><title>On the Causal Sufficiency and Necessity of Multi-Modal Representation   Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-Modal Learning (MML) aims to learn effective representations across modalities for accurate predictions. Existing methods typically focus on modality consistency and specificity to learn effective representations. However, from a causal perspective, they may lead to representations that contain insufficient and unnecessary information. To address this, we propose that effective MML representations should be causally sufficient and necessary. Considering practical issues like spurious correlations and modality conflicts, we relax the exogeneity and monotonicity assumptions prevalent in prior works and explore the concepts specific to MML, i.e., Causal Complete Cause (\(C^3\)). We begin by defining \(C^3\), which quantifies the probability of representations being causally sufficient and necessary. We then discuss the identifiability of \(C^3\) and introduce an instrumental variable to support identifying \(C^3\) with non-exogeneity and non-monotonicity. Building on this, we conduct the $C^3$ measurement, i.e., \(C^3\) risk. We propose a twin network to estimate it through (i) the real-world branch: utilizing the instrumental variable for sufficiency, and (ii) the hypothetical-world branch: applying gradient-based counterfactual modeling for necessity. Theoretical analyses confirm its reliability. Based on these results, we propose $C^3$ Regularization, a plug-and-play method that enforces the causal completeness of the learned representations by minimizing \(C^3\) risk. Extensive experiments demonstrate its effectiveness. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.16022</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.16022</id><created>2024-07-22</created><updated>2025-01-24</updated><authors><author><keyname>Scheidt</keyname><forenames>Benjamin</forenames></author><author><keyname>Schweikardt</keyname><forenames>Nicole</forenames></author></authors><title>Color Refinement for Relational Structures</title><categories>cs.DS cs.DM cs.LO</categories><comments>Added a new result: For every fixed finite relational signature, RCR   can be implemented to run on structures of that signature in time O(N log N),   where N denotes the number of tuples present in the structure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Color Refinement, also known as Naive Vertex Classification, is a classical method to distinguish graphs by iteratively computing a coloring of their vertices. While it is mainly used as an imperfect way to test for isomorphism, the algorithm permeated many other, seemingly unrelated, areas of computer science. The method is algorithmically simple, and it has a well-understood distinguishing power: It is logically characterized by Cai, F\"urer and Immerman (1992), who showed that it distinguishes precisely those graphs that can be distinguished by a sentence of first-order logic with counting quantifiers and only two variables. A combinatorial characterization is given by Dvo\v{r}\'ak (2010), who shows that it distinguishes precisely those graphs that can be distinguished by the number of homomorphisms from some tree.   In this paper, we introduce Relational Color Refinement (RCR, for short), a generalization of the Color Refinement method from graphs to arbitrary relational structures, whose distinguishing power admits the equivalent combinatorial and logical characterizations as Color Refinement has on graphs: We show that RCR distinguishes precisely those structures that can be distinguished by the number of homomorphisms from an acyclic relational structure. Further, we show that RCR distinguishes precisely those structures that can be distinguished by a sentence of the guarded fragment of first-order logic with counting quantifiers.   Additionally, we show that for every fixed finite relational signature, RCR can be implemented to run on structures of that signature in time $O(N\cdot \log N)$, where $N$ denotes the number of tuples present in the structure. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.16167</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.16167</id><created>2024-07-23</created><authors><author><keyname>Ahmed</keyname><forenames>Syed Adil</forenames></author><author><keyname>Shim</keyname><forenames>Taehyun</forenames></author></authors><title>Consideration of Vehicle Characteristics on the Motion Planner Algorithm</title><categories>cs.RO cs.SY eess.SY</categories><comments>This paper has been accepted for conference proceedings in MECC 2024,   Chicago under a Creative Commons License CC-BY-NC-ND</comments><journal-ref>IFAC-PapersOnLine, Vol 58, Num 28, 2024, pgs 444-449</journal-ref><doi>10.1016/j.ifacol.2025.01.086</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Autonomous vehicle control is generally divided in two main areas; trajectory planning and tracking. Currently, the trajectory planning is mostly done by particle or kinematic model-based optimization controllers. The output of these planners, since they do not consider CG height and its effects, is not unique for different vehicle types, especially for high CG vehicles. As a result, the tracking controller may have to work hard to avoid vehicle handling and comfort constraints while trying to realize these sub-optimal trajectories. This paper tries to address this problem by considering a planner with simplified double track model with estimation of lateral and roll based load transfer using steady state equations and a simplified tire model to reduce solver workload. The developed planner is compared with the widely used particle and kinematic model planners in collision avoidance scenarios in both high and low acceleration conditions and with different vehicle heights. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.16300</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.16300</id><created>2024-07-23</created><updated>2025-01-24</updated><authors><author><keyname>Assa</keyname><forenames>Gal</forenames></author><author><keyname>Bürgi</keyname><forenames>Lucas</forenames></author><author><keyname>Friedman</keyname><forenames>Michal</forenames></author><author><keyname>Lahav</keyname><forenames>Ori</forenames></author></authors><title>A Programming Model for Disaggregated Memory over CXL</title><categories>cs.DC cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CXL (Compute Express Link) is an emerging open industry-standard interconnect between processing and memory devices that is expected to revolutionize the way systems are designed in the near future. It enables cache-coherent shared memory pools in a disaggregated fashion at unprecedented scales, allowing algorithms to interact with a variety of storage devices using simple loads and stores. Alongside unleashing unique opportunities for a wide range of applications, CXL introduces new challenges of data management and crash consistency. Alas, CXL lacks an adequate programming model, which makes reasoning about the correctness and expected behaviors of algorithms and systems on top of it nearly impossible.   In this work, we present CXL0, the first programming model for concurrent programs running on top of CXL. We propose a high-level abstraction for CXL memory accesses and formally define operational semantics on top of that abstraction. We perform initial measurements that provide practical insight into CXL0. We provide a set of general transformations that adapt concurrent algorithms to the new disruptive technology. These transformations enhance linearizable algorithms with durability under a general partial-failure model. We provide an additional transformation for algorithms designed for persistent main memory and full-system crashes. We believe that this work will serve as a stepping stone for systems design and modeling on top of CXL, and support the development of future models as software and hardware evolve. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.17667</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.17667</id><created>2024-07-24</created><updated>2025-01-23</updated><authors><author><keyname>Barco</keyname><forenames>Gabriel Missael</forenames></author><author><keyname>Adam</keyname><forenames>Alexandre</forenames></author><author><keyname>Stone</keyname><forenames>Connor</forenames></author><author><keyname>Hezaveh</keyname><forenames>Yashar</forenames></author><author><keyname>Perreault-Levasseur</keyname><forenames>Laurence</forenames></author></authors><title>Tackling the Problem of Distributional Shifts: Correcting Misspecified,   High-Dimensional Data-Driven Priors for Inverse Problems</title><categories>astro-ph.IM astro-ph.CO cs.LG</categories><comments>20 pages, 15 figures. To be published in The Astrophysical Journal.   Added and updated references; fixed typos; extended discussions in some   sections. Results unchanged</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bayesian inference for inverse problems hinges critically on the choice of priors. In the absence of specific prior information, population-level distributions can serve as effective priors for parameters of interest. With the advent of machine learning, the use of data-driven population-level distributions (encoded, e.g., in a trained deep neural network) as priors is emerging as an appealing alternative to simple parametric priors in a variety of inverse problems. However, in many astrophysical applications, it is often difficult or even impossible to acquire independent and identically distributed samples from the underlying data-generating process of interest to train these models. In these cases, corrupted data or a surrogate, e.g. a simulator, is often used to produce training samples, meaning that there is a risk of obtaining misspecified priors. This, in turn, can bias the inferred posteriors in ways that are difficult to quantify, which limits the potential applicability of these models in real-world scenarios. In this work, we propose addressing this issue by iteratively updating the population-level distributions by retraining the model with posterior samples from different sets of observations, and we showcase the potential of this method on the problem of background image reconstruction in strong gravitational lensing when score-based models are used as data-driven priors. We show that, starting from a misspecified prior distribution, the updated distribution becomes progressively closer to the underlying population-level distribution, and the resulting posterior samples exhibit reduced bias after several updates. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2407.20479</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2407.20479</id><created>2024-07-29</created><authors><author><keyname>Varatalu</keyname><forenames>Ian Erik</forenames></author><author><keyname>Veanes</keyname><forenames>Margus</forenames></author><author><keyname>Ernits</keyname><forenames>Juhan-Peep</forenames></author></authors><title>RE#: High Performance Derivative-Based Regex Matching with Intersection,   Complement and Lookarounds</title><categories>cs.FL</categories><acm-class>F.4.3; I.1.3</acm-class><doi>10.1145/3704837</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a tool and theory RE# for regular expression matching that is built on symbolic derivatives, does not use backtracking, and, in addition to the classical operators, also supports complement, intersection and lookarounds. We develop the theory formally and show that the main matching algorithm has input-linear complexity both in theory as well as experimentally. We apply thorough evaluation on popular benchmarks that show that RE# is over 71% faster than the next fastest regex engine in Rust on the baseline, and outperforms all state-of-the-art engines on extensions of the benchmarks often by several orders of magnitude. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.01162</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.01162</id><created>2024-08-02</created><updated>2025-01-23</updated><authors><author><keyname>Wong</keyname><forenames>Bryan</forenames></author><author><keyname>Yi</keyname><forenames>Mun Yong</forenames></author></authors><title>PreMix: Addressing Label Scarcity in Whole Slide Image Classification   with Pre-trained Multiple Instance Learning Aggregators</title><categories>cs.CV</categories><comments>Under review for the Biomedical Signal Processing and Control journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple instance learning (MIL) has emerged as a powerful framework for weakly supervised whole slide image (WSI) classification, enabling slide-level predictions without requiring detailed patch-level annotations. However, a key limitation of MIL lies in the underexplored potential of pre-training the MIL aggregator. Most existing approaches train it from scratch, resulting in performance heavily dependent on the number of labeled WSIs, while overlooking the abundance of unlabeled WSIs available in real-world scenarios. To address this, we propose PreMix, a novel framework that leverages a non-contrastive pre-training method, Barlow Twins, augmented with the Slide Mixing approach to generate additional positive pairs and enhance feature learning, particularly under limited labeled WSI conditions. Fine-tuning with Mixup and Manifold Mixup further enhances robustness by effectively handling the diverse sizes of gigapixel WSIs. Experimental results demonstrate that integrating HIPT into PreMix achieves an average F1 improvement of 4.7% over the baseline HIPT across various WSI training datasets and label sizes. These findings underscore its potential to advance WSI classification with limited labeled data and its applicability to real-world histopathology practices. The code is available at https://anonymous.4open.science/r/PreMix </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.02935</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.02935</id><created>2024-08-05</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Zhihui</forenames></author></authors><title>Numerical Ergodicity of Stochastic Allen--Cahn Equation driven by   Multiplicative White Noise</title><categories>math.NA cs.NA math.PR</categories><comments>to appear at Commun. Math. Res</comments><msc-class>Primary 60H35, 60H15, 65M60</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We establish the unique ergodicity of a fully discrete scheme for monotone SPDEs with polynomial growth drift and bounded diffusion coefficients driven by multiplicative white noise. The main ingredient of our method depends on the satisfaction of a Lyapunov condition followed by a uniform moments' estimate, combined with the regularity property for the full discretization. We transform the original stochastic equation into an equivalent random equation where the discrete stochastic convolutions are uniformly controlled to derive the desired uniform moments' estimate. Applying the main result to the stochastic Allen--Cahn equation driven by multiplicative white noise indicates that this full discretization is uniquely ergodic for any interface thickness. Numerical experiments validate our theoretical results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.03274</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.03274</id><created>2024-08-06</created><authors><author><keyname>Boggust</keyname><forenames>Angie</forenames></author><author><keyname>Sivaraman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Assogba</keyname><forenames>Yannick</forenames></author><author><keyname>Ren</keyname><forenames>Donghao</forenames></author><author><keyname>Moritz</keyname><forenames>Dominik</forenames></author><author><keyname>Hohman</keyname><forenames>Fred</forenames></author></authors><title>Compress and Compare: Interactively Evaluating Efficiency and Behavior   Across ML Model Compression Experiments</title><categories>cs.HC cs.AI cs.LG</categories><comments>Accepted to VIS 2024</comments><doi>10.1109/TVCG.2024.3456371</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To deploy machine learning models on-device, practitioners use compression algorithms to shrink and speed up models while maintaining their high-quality output. A critical aspect of compression in practice is model comparison, including tracking many compression experiments, identifying subtle changes in model behavior, and negotiating complex accuracy-efficiency trade-offs. However, existing compression tools poorly support comparison, leading to tedious and, sometimes, incomplete analyses spread across disjoint tools. To support real-world comparative workflows, we develop an interactive visual system called Compress and Compare. Within a single interface, Compress and Compare surfaces promising compression strategies by visualizing provenance relationships between compressed models and reveals compression-induced behavior changes by comparing models' predictions, weights, and activations. We demonstrate how Compress and Compare supports common compression analysis tasks through two case studies, debugging failed compression on generative language models and identifying compression artifacts in image classification models. We further evaluate Compress and Compare in a user study with eight compression experts, illustrating its potential to provide structure to compression workflows, help practitioners build intuition about compression, and encourage thorough analysis of compression's effect on model behavior. Through these evaluations, we identify compression-specific challenges that future visual analytics tools should consider and Compress and Compare visualizations that may generalize to broader model comparison tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.03496</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.03496</id><created>2024-08-06</created><updated>2025-01-23</updated><authors><author><keyname>Pan</keyname><forenames>Yinxi</forenames></author><author><keyname>Ren</keyname><forenames>Kui</forenames></author><author><keyname>Tong</keyname><forenames>Shanyin</forenames></author></authors><title>A three-stage method for reconstructing multiple coefficients in coupled   photoacoustic and diffuse optical imaging</title><categories>math.NA cs.NA math.OC physics.comp-ph physics.med-ph</categories><msc-class>35J47, 35R30, 49M15, 65M32, 78A46, 78A60, 78A70, 80A23, 92C55, 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies inverse problems in quantitative photoacoustic tomography with additional optical current data supplemented from diffuse optical tomography. We propose a three-stage image reconstruction method for the simultaneous recovery of the absorption, diffusion, and Gr\"uneisen coefficients. We demonstrate, through numerical simulations, that: (i) when the Gr\"uneisen coefficient is known, the addition of the optical measurements allows a more accurate reconstruction of the scattering and absorption coefficients; and (ii) when the Gr\"uneisen coefficient is not known, the addition of optical current measurements allows us to reconstruct uniquely the Gr\"uneisen, the scattering and absorption coefficients. Numerical simulations based on synthetic data are presented to demonstrate the effectiveness of the proposed idea. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.03565</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.03565</id><created>2024-08-07</created><updated>2025-01-24</updated><authors><author><keyname>Brubeck</keyname><forenames>Pablo D.</forenames></author><author><keyname>Kirby</keyname><forenames>Robert C.</forenames></author><author><keyname>Laakmann</keyname><forenames>Fabian</forenames></author><author><keyname>Mitchell</keyname><forenames>Lawrence</forenames></author></authors><title>FIAT: improving performance and accuracy for high-order finite elements</title><categories>math.NA cs.NA</categories><msc-class>65N30, 65D05, 65D32</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  FIAT (the FInite element Automatic Tabulator) provides a powerful Python library for the generation and evaluation of finite element basis functions on a reference element. This release paper describes recent improvements to FIAT aimed at improving its run time and the accuracy and efficiency of code generated using FIAT-provided information. In the first category, we have greatly streamlined the implementation of orthogonal polynomials out of which finite element bases are built. The second category comprises several more advances. For one, we have built an interface to the $\texttt{recursivenodes}$ package to enable more accurate Lagrange bases at high order. We have also implemented integral-type degrees of freedom for $H(\mathrm{div})$ and $H(\mathrm{curl})$ elements, which match the mathematical definitions of the elements more closely and also avoid loss of accuracy in interpolation. More fundamentally, we have included families of simplicial quadrature rules that require many fewer quadrature points than the Stroud rules previously used in FIAT. Finally, FIAT now provides support for fast diagonalization methods, which enable fast solution algorithms at very high order. In each case, we describe the new features in FIAT and illustrate some of the gains obtained through simple numerical tests. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.04498</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.04498</id><created>2024-08-08</created><updated>2025-01-23</updated><authors><author><keyname>Cho</keyname><forenames>Jung-Hoon</forenames></author><author><keyname>Jayawardana</keyname><forenames>Vindula</forenames></author><author><keyname>Li</keyname><forenames>Sirui</forenames></author><author><keyname>Wu</keyname><forenames>Cathy</forenames></author></authors><title>Model-Based Transfer Learning for Contextual Reinforcement Learning</title><categories>cs.LG</categories><comments>38th Conference on Neural Information Processing Systems (NeurIPS   2024)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep reinforcement learning (RL) is a powerful approach to complex decision making. However, one issue that limits its practical application is its brittleness, sometimes failing to train in the presence of small changes in the environment. Motivated by the success of zero-shot transfer-where pre-trained models perform well on related tasks-we consider the problem of selecting a good set of training tasks to maximize generalization performance across a range of tasks. Given the high cost of training, it is critical to select training tasks strategically, but not well understood how to do so. We hence introduce Model-Based Transfer Learning (MBTL), which layers on top of existing RL methods to effectively solve contextual RL problems. MBTL models the generalization performance in two parts: 1) the performance set point, modeled using Gaussian processes, and 2) performance loss (generalization gap), modeled as a linear function of contextual similarity. MBTL combines these two pieces of information within a Bayesian optimization (BO) framework to strategically select training tasks. We show theoretically that the method exhibits sublinear regret in the number of training tasks and discuss conditions to further tighten regret bounds. We experimentally validate our methods using urban traffic and standard continuous control benchmarks. The experimental results suggest that MBTL can achieve up to 43x improved sample efficiency compared with canonical independent training and multi-task training. Further experiments demonstrate the efficacy of BO and the insensitivity to the underlying RL algorithm and hyperparameters. This work lays the foundations for investigating explicit modeling of generalization, thereby enabling principled yet effective methods for contextual RL. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.05006</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.05006</id><created>2024-08-09</created><updated>2025-01-24</updated><authors><author><keyname>Yang</keyname><forenames>Weiqing</forenames></author><author><keyname>Wang</keyname><forenames>Hanbin</forenames></author><author><keyname>Liu</keyname><forenames>Zhenghao</forenames></author><author><keyname>Li</keyname><forenames>Xinze</forenames></author><author><keyname>Yan</keyname><forenames>Yukun</forenames></author><author><keyname>Wang</keyname><forenames>Shuo</forenames></author><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Yu</keyname><forenames>Minghe</forenames></author><author><keyname>Liu</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Yu</keyname><forenames>Ge</forenames></author></authors><title>COAST: Enhancing the Code Debugging Ability of LLMs through   Communicative Agent Based Data Synthesis</title><categories>cs.SE cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code debugging is a vital stage of software development, essential for ensuring the reliability and performance of Large Language Models (LLMs) in code generation task. Human debugging typically follows a multi-stage process, which includes Bug Localization, Bug Identification, Code Repair, and Code Recognition. However, existing code debugging benchmarks predominantly focus on the Code Repair stage, which offers only a limited perspective on evaluating the debugging capabilities of LLMs. In this paper, we introduce DEBUGEVAL, a comprehensive benchmark for evaluating the debugging abilities of LLMs by emulating the multi-stage human debugging process. Through evaluating on DEBUGEVAL, we observe that 7B-scale models consistently underperform compared to their larger counterparts, highlighting their limitations in comprehending code semantics. In this case, we propose the COmmunicative Agent-based data SynThesis (COAST) framework, which employs a multi-agent system to generate high-quality training data for supervised fine-tuning (SFT). Experimental results demonstrate that COAST-generated data outperform human-curated and GPT-4-generated data, enabling 7B-scale LLMs to achieve debugging performance comparable to GPT-3.5. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.07245</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.07245</id><created>2024-08-13</created><updated>2025-01-24</updated><authors><author><keyname>Zhu</keyname><forenames>Lingwei</forenames></author><author><keyname>Shah</keyname><forenames>Haseeb</forenames></author><author><keyname>Wang</keyname><forenames>Han</forenames></author><author><keyname>Nagai</keyname><forenames>Yukie</forenames></author><author><keyname>White</keyname><forenames>Martha</forenames></author></authors><title>q-exponential family for policy optimization</title><categories>cs.LG</categories><comments>accepted by ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Policy optimization methods benefit from a simple and tractable policy parametrization, usually the Gaussian for continuous action spaces. In this paper, we consider a broader policy family that remains tractable: the $q$-exponential family. This family of policies is flexible, allowing the specification of both heavy-tailed policies ($q&gt;1$) and light-tailed policies ($q&lt;1$). This paper examines the interplay between $q$-exponential policies for several actor-critic algorithms conducted on both online and offline problems. We find that heavy-tailed policies are more effective in general and can consistently improve on Gaussian. In particular, we find the Student's t-distribution to be more stable than the Gaussian across settings and that a heavy-tailed $q$-Gaussian for Tsallis Advantage Weighted Actor-Critic consistently performs well in offline benchmark problems. Our code is available at \url{https://github.com/lingweizhu/qexp}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.07758</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.07758</id><created>2024-08-14</created><authors><author><keyname>Scanlon</keyname><forenames>John M.</forenames></author><author><keyname>Teoh</keyname><forenames>Eric R.</forenames></author><author><keyname>Kidd</keyname><forenames>David G.</forenames></author><author><keyname>Kusano</keyname><forenames>Kristofer D.</forenames></author><author><keyname>Bärgman</keyname><forenames>Jonas</forenames></author><author><keyname>Chi-Johnston</keyname><forenames>Geoffrey</forenames></author><author><keyname>Di Lillo</keyname><forenames>Luigi</forenames></author><author><keyname>Favaro</keyname><forenames>Francesca</forenames></author><author><keyname>Flannagan</keyname><forenames>Carol</forenames></author><author><keyname>Liers</keyname><forenames>Henrik</forenames></author><author><keyname>Lin</keyname><forenames>Bonnie</forenames></author><author><keyname>Lindman</keyname><forenames>Magdalena</forenames></author><author><keyname>McLaughlin</keyname><forenames>Shane</forenames></author><author><keyname>Perez</keyname><forenames>Miguel</forenames></author><author><keyname>Victor</keyname><forenames>Trent</forenames></author></authors><title>RAVE Checklist: Recommendations for Overcoming Challenges in   Retrospective Safety Studies of Automated Driving Systems</title><categories>cs.RO</categories><doi>10.1080/15389588.2024.2435620</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The public, regulators, and domain experts alike seek to understand the effect of deployed SAE level 4 automated driving system (ADS) technologies on safety. The recent expansion of ADS technology deployments is paving the way for early stage safety impact evaluations, whereby the observational data from both an ADS and a representative benchmark fleet are compared to quantify safety performance. In January 2024, a working group of experts across academia, insurance, and industry came together in Washington, DC to discuss the current and future challenges in performing such evaluations. A subset of this working group then met, virtually, on multiple occasions to produce this paper. This paper presents the RAVE (Retrospective Automated Vehicle Evaluation) checklist, a set of fifteen recommendations for performing and evaluating retrospective ADS performance comparisons. The recommendations are centered around the concepts of (1) quality and validity, (2) transparency, and (3) interpretation. Over time, it is anticipated there will be a large and varied body of work evaluating the observed performance of these ADS fleets. Establishing and promoting good scientific practices benefits the work of stakeholders, many of whom may not be subject matter experts. This working group's intentions are to: i) strengthen individual research studies and ii) make the at-large community more informed on how to evaluate this collective body of work. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.07911</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.07911</id><created>2024-08-14</created><updated>2025-01-24</updated><authors><author><keyname>Sun</keyname><forenames>Jinze</forenames></author><author><keyname>Sheng</keyname><forenames>Yongpan</forenames></author><author><keyname>He</keyname><forenames>Lirong</forenames></author><author><keyname>Qin</keyname><forenames>Yongbin</forenames></author><author><keyname>Liu</keyname><forenames>Ming</forenames></author><author><keyname>Jia</keyname><forenames>Tao</forenames></author></authors><title>CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework   for Temporal Knowledge Graph Reasoning</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Temporal knowledge graph reasoning (TKGR) is increasingly gaining attention for its ability to extrapolate new events from historical data, thereby enriching the inherently incomplete temporal knowledge graphs. Existing graph-based representation learning frameworks have made significant strides in developing evolving representations for both entities and relational embeddings. Despite these achievements, there's a notable tendency in these models to inadvertently learn biased data representations and mine spurious correlations, consequently failing to discern the causal relationships between events. This often leads to incorrect predictions based on these false correlations. To address this, we propose an innovative Causal Enhanced Graph Representation Learning framework for TKGR (named CEGRL-TKGR). This framework introduces causal structures in graph-based representation learning to unveil the essential causal relationships between events, ultimately enhancing the performance of the TKGR task. Specifically, we first disentangle the evolutionary representations of entities and relations in a temporal knowledge graph sequence into two distinct components, namely causal representations and confounding representations. Then, drawing on causal intervention theory, we advocate the utilization of causal representations for predictions, aiming to mitigate the effects of erroneous correlations caused by confounding features, thus achieving more robust and accurate predictions. Finally, extensive experimental results on six benchmark datasets demonstrate the superior performance of our model in the link prediction task. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.08270</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.08270</id><created>2024-08-15</created><updated>2025-01-24</updated><authors><author><keyname>Park</keyname><forenames>Chaesong</forenames></author><author><keyname>Seo</keyname><forenames>Eunbin</forenames></author><author><keyname>Lim</keyname><forenames>Jongwoo</forenames></author></authors><title>HeightLane: BEV Heightmap guided 3D Lane Detection</title><categories>cs.CV</categories><comments>10 pages, 6 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate 3D lane detection from monocular images presents significant challenges due to depth ambiguity and imperfect ground modeling. Previous attempts to model the ground have often used a planar ground assumption with limited degrees of freedom, making them unsuitable for complex road environments with varying slopes. Our study introduces HeightLane, an innovative method that predicts a height map from monocular images by creating anchors based on a multi-slope assumption. This approach provides a detailed and accurate representation of the ground. HeightLane employs the predicted heightmap along with a deformable attention-based spatial feature transform framework to efficiently convert 2D image features into 3D bird's eye view (BEV) features, enhancing spatial understanding and lane structure recognition. Additionally, the heightmap is used for the positional encoding of BEV features, further improving their spatial accuracy. This explicit view transformation bridges the gap between front-view perceptions and spatially accurate BEV representations, significantly improving detection performance. To address the lack of the necessary ground truth (GT) height map in the original OpenLane dataset, we leverage the Waymo dataset and accumulate its LiDAR data to generate a height map for the drivable area of each scene. The GT heightmaps are used to train the heightmap extraction module from monocular images. Extensive experiments on the OpenLane validation set show that HeightLane achieves state-of-the-art performance in terms of F-score, highlighting its potential in real-world applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.09150</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.09150</id><created>2024-08-17</created><updated>2025-01-24</updated><authors><author><keyname>Wang</keyname><forenames>Xinglin</forenames></author><author><keyname>Yuan</keyname><forenames>Peiwen</forenames></author><author><keyname>Feng</keyname><forenames>Shaoxiong</forenames></author><author><keyname>Li</keyname><forenames>Yiwei</forenames></author><author><keyname>Pan</keyname><forenames>Boyuan</forenames></author><author><keyname>Wang</keyname><forenames>Heda</forenames></author><author><keyname>Hu</keyname><forenames>Yao</forenames></author><author><keyname>Li</keyname><forenames>Kan</forenames></author></authors><title>CogLM: Tracking Cognitive Development of Large Language Models</title><categories>cs.CL cs.AI</categories><comments>NAACL2025 Main</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Piaget's Theory of Cognitive Development (PTC) posits that the development of cognitive levels forms the foundation for human learning across various abilities. As Large Language Models (LLMs) have recently shown remarkable abilities across a wide variety of tasks, we are curious about the cognitive levels of current LLMs: to what extent they have developed and how this development has been achieved. To this end, we construct a benchmark CogLM (Cognitive Ability Evaluation for Language Model) based on PTC to assess the cognitive levels of LLMs. CogLM comprises 1,220 questions spanning 10 cognitive abilities crafted by more than 20 human experts, providing a comprehensive testbed for the cognitive levels of LLMs. Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) Human-like cognitive abilities have emerged in advanced LLMs (GPT-4), comparable to those of a 20-year-old human. (2) The parameter size and optimization objective are two key factors affecting the cognitive levels of LLMs. (3) The performance on downstream tasks is positively correlated with the level of cognitive abilities. These findings fill the gap in research on the cognitive abilities of LLMs, tracing the development of LLMs from a cognitive perspective and guiding the future direction of their evolution. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.09688</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.09688</id><created>2024-08-18</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Jiaqing</forenames></author><author><keyname>Deng</keyname><forenames>Chong</forenames></author><author><keyname>Zhang</keyname><forenames>Qinglin</forenames></author><author><keyname>Zhou</keyname><forenames>Shilin</forenames></author><author><keyname>Chen</keyname><forenames>Qian</forenames></author><author><keyname>Yu</keyname><forenames>Hai</forenames></author><author><keyname>Wang</keyname><forenames>Wen</forenames></author></authors><title>Recording for Eyes, Not Echoing to Ears: Contextualized   Spoken-to-Written Conversion of ASR Transcripts</title><categories>cs.CL</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic Speech Recognition (ASR) transcripts exhibit recognition errors and various spoken language phenomena such as disfluencies, ungrammatical sentences, and incomplete sentences, hence suffering from poor readability. To improve readability, we propose a Contextualized Spoken-to-Written conversion (CoS2W) task to address ASR and grammar errors and also transfer the informal text into the formal style with content preserved, utilizing contexts and auxiliary information. This task naturally matches the in-context learning capabilities of Large Language Models (LLMs). To facilitate comprehensive comparisons of various LLMs, we construct a document-level Spoken-to-Written conversion of ASR Transcripts Benchmark (SWAB) dataset. Using SWAB, we study the impact of different granularity levels on the CoS2W performance, and propose methods to exploit contexts and auxiliary information to enhance the outputs. Experimental results reveal that LLMs have the potential to excel in the CoS2W task, particularly in grammaticality and formality, our methods achieve effective understanding of contexts and auxiliary information by LLMs. We further investigate the effectiveness of using LLMs as evaluators and find that LLM evaluators show strong correlations with human evaluations on rankings of faithfulness and formality, which validates the reliability of LLM evaluators for the CoS2W task. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.13074</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.13074</id><created>2024-08-23</created><updated>2025-01-23</updated><authors><author><keyname>Wei</keyname><forenames>Yuxiang</forenames></author><author><keyname>Abrol</keyname><forenames>Anees</forenames></author><author><keyname>Calhoun</keyname><forenames>Vince</forenames></author></authors><title>Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent advances in deep learning structured state space models, especially the Mamba architecture, have demonstrated remarkable performance improvements while maintaining linear complexity. In this study, we introduce functional spatiotemporal Mamba (FST-Mamba), a Mamba-based model designed for discovering neurological biomarkers using functional magnetic resonance imaging (fMRI). We focus on dynamic functional network connectivity (dFNC) derived from fMRI and propose a hierarchical spatiotemporal Mamba-based network that processes spatial and temporal information separately using Mamba-based encoders. Leveraging the topological uniqueness of the FNC matrix, we introduce a component-wise varied-scale aggregation (CVA) mechanism to aggregate connectivity across individual components within brain networks, enabling the model to capture component-level and network-level information. Additionally, we propose symmetric rotary position encoding (SymRope) to encode the relative positions of each functional connection while considering the symmetric nature of the FNC matrix. Experimental results demonstrate significant improvements in the proposed FST-Mamba model on various brain-based classification and regression tasks. We further show brain connectivities and dynamics that are crucial for the prediction. Our work reveals the substantial potential of attention-free sequence modeling in brain discovery. The codes are publicly available here: \url{https://github.com/yuxiangwei0808/FunctionalMamba/tree/main}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2408.13457</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2408.13457</id><created>2024-08-24</created><updated>2025-01-24</updated><authors><author><keyname>Wang</keyname><forenames>Xinglin</forenames></author><author><keyname>Feng</keyname><forenames>Shaoxiong</forenames></author><author><keyname>Li</keyname><forenames>Yiwei</forenames></author><author><keyname>Yuan</keyname><forenames>Peiwen</forenames></author><author><keyname>Zhang</keyname><forenames>Yueqi</forenames></author><author><keyname>Pan</keyname><forenames>Boyuan</forenames></author><author><keyname>Wang</keyname><forenames>Heda</forenames></author><author><keyname>Hu</keyname><forenames>Yao</forenames></author><author><keyname>Li</keyname><forenames>Kan</forenames></author></authors><title>Make Every Penny Count: Difficulty-Adaptive Self-Consistency for   Cost-Efficient Reasoning</title><categories>cs.CL cs.AI</categories><comments>NAACL2025 Findings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-consistency (SC), a widely used decoding strategy for chain-of-thought reasoning, shows significant gains across various multi-step reasoning tasks but comes with a high cost due to multiple sampling with the preset size. Its variants, Adaptive self-consistency (ASC) and Early-stopping self-consistency (ESC), dynamically adjust the number of samples based on the posterior distribution of a set of pre-samples, reducing the cost of SC with minimal impact on performance. Both methods, however, do not exploit the prior information about question difficulty. It often results in unnecessary repeated sampling for easy questions that could be accurately answered with just one attempt, wasting resources. To tackle this problem, we propose Difficulty-Adaptive Self-Consistency (DSC), which leverages the difficulty information from both prior and posterior perspectives to adaptively allocate inference resources, further reducing the cost of SC. To demonstrate the effectiveness of DSC, we conduct extensive experiments on three popular categories of reasoning tasks: arithmetic, commonsense and symbolic reasoning on six benchmarks. The empirical results show that DSC consistently surpasses the strong baseline ASC and ESC in terms of costs by a significant margin, while attaining comparable performances. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.00767</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.00767</id><created>2024-09-01</created><updated>2025-01-24</updated><authors><author><keyname>Dai</keyname><forenames>Xiaoying</forenames></author><author><keyname>Li</keyname><forenames>Yan</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author><author><keyname>Zhou</keyname><forenames>Aihui</forenames></author></authors><title>Numerical Analysis of the Parallel Orbital-Updating Approach for   Eigenvalue Problems</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parallel orbital-updating approach is an orbital/eigenfunction iteration based approach for solving eigenvalue problems when many eigenpairs are required. It has been proven to be efficient, for instance, in electronic structure calculations. In this paper, based on the investigation of a quasi-orthogonality, we present the numerical analysis of the parallel orbital-updating approach for linear eigenvalue problems, including convergence and error estimates of the numerical approximations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.06016</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.06016</id><created>2024-09-09</created><updated>2025-01-23</updated><authors><author><keyname>Etesam</keyname><forenames>Yasaman</forenames></author><author><keyname>Cheong</keyname><forenames>Hyunmin</forenames></author><author><keyname>Ataei</keyname><forenames>Mohammadmehdi</forenames></author><author><keyname>Jayaraman</keyname><forenames>Pradeep Kumar</forenames></author></authors><title>Deep Generative Model for Mechanical System Configuration Design</title><categories>cs.AI cs.LG</categories><comments>Accepted to AAAI-25</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Generative AI has made remarkable progress in addressing various design challenges. One prominent area where generative AI could bring significant value is in engineering design. In particular, selecting an optimal set of components and their interfaces to create a mechanical system that meets design requirements is one of the most challenging and time-consuming tasks for engineers. This configuration design task is inherently challenging due to its categorical nature, multiple design requirements a solution must satisfy, and the reliance on physics simulations for evaluating potential solutions. These characteristics entail solving a combinatorial optimization problem with multiple constraints involving black-box functions. To address this challenge, we propose a deep generative model to predict the optimal combination of components and interfaces for a given design problem. To demonstrate our approach, we solve a gear train synthesis problem by first creating a synthetic dataset using a grammar, a parts catalogue, and a physics simulator. We then train a Transformer using this dataset, named GearFormer, which can not only generate quality solutions on its own, but also augment search methods such as an evolutionary algorithm and Monte Carlo tree search. We show that GearFormer outperforms such search methods on their own in terms of satisfying the specified design requirements with orders of magnitude faster generation time. Additionally, we showcase the benefit of hybrid methods that leverage both GearFormer and search methods, which further improve the quality of the solutions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.06888</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.06888</id><created>2024-09-10</created><updated>2025-01-24</updated><authors><author><keyname>Qian</keyname><forenames>Cheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yulun</forenames></author><author><keyname>Bhatt</keyname><forenames>Varun</forenames></author><author><keyname>Fontaine</keyname><forenames>Matthew Christopher</forenames></author><author><keyname>Nikolaidis</keyname><forenames>Stefanos</forenames></author><author><keyname>Li</keyname><forenames>Jiaoyang</forenames></author></authors><title>A Quality Diversity Method to Automatically Generate Multi-Agent Path   Finding Benchmark Maps</title><categories>cs.MA</categories><comments>13 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the Quality Diversity (QD) algorithm with Neural Cellular Automata (NCA) to generate benchmark maps for Multi-Agent Path Finding (MAPF) algorithms. Previously, MAPF algorithms are tested using fixed, human-designed benchmark maps. However, such fixed benchmark maps have several problems. First, these maps may not cover all the potential failure scenarios for the algorithms. Second, when comparing different algorithms, fixed benchmark maps may introduce bias leading to unfair comparisons between algorithms. Third, since researchers test new algorithms on a small set of fixed benchmark maps, the design of the algorithms may overfit to the small set of maps. In this work, we take advantage of the QD algorithm to (1) generate maps with patterns to comprehensively understand the performance of MAPF algorithms, (2) be able to make fair comparisons between two MAPF algorithms, providing further information on the selection between two algorithms and on the design of the algorithms. Empirically, we employ this technique to generate diverse benchmark maps to evaluate and compare the behavior of different types of MAPF algorithms, including search-based, priority-based, rule-based, and learning-based algorithms. Through both single-algorithm experiments and comparisons between algorithms, we identify patterns where each algorithm excels and detect disparities in runtime or success rates between different algorithms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.07589</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.07589</id><created>2024-09-11</created><authors><author><keyname>Zhou</keyname><forenames>Xin</forenames></author><author><keyname>Peng</keyname><forenames>Xiaojing</forenames></author></authors><title>Multi-scale spatiotemporal representation learning for EEG-based emotion   recognition</title><categories>cs.HC eess.SP</categories><doi>10.1109/LRA.2025.3526447</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EEG-based emotion recognition holds significant potential in the field of brain-computer interfaces. A key challenge lies in extracting discriminative spatiotemporal features from electroencephalogram (EEG) signals. Existing studies often rely on domain-specific time-frequency features and analyze temporal dependencies and spatial characteristics separately, neglecting the interaction between local-global relationships and spatiotemporal dynamics. To address this, we propose a novel network called Multi-Scale Inverted Mamba (MS-iMamba), which consists of Multi-Scale Temporal Blocks (MSTB) and Temporal-Spatial Fusion Blocks (TSFB). Specifically, MSTBs are designed to capture both local details and global temporal dependencies across different scale subsequences. The TSFBs, implemented with an inverted Mamba structure, focus on the interaction between dynamic temporal dependencies and spatial characteristics. The primary advantage of MS-iMamba lies in its ability to leverage reconstructed multi-scale EEG sequences, exploiting the interaction between temporal and spatial features without the need for domain-specific time-frequency feature extraction. Experimental results on the DEAP, DREAMER, and SEED datasets demonstrate that MS-iMamba achieves classification accuracies of 94.86%, 94.94%, and 91.36%, respectively, using only four-channel EEG signals, outperforming state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.07613</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.07613</id><created>2024-09-11</created><updated>2025-01-24</updated><authors><author><keyname>Jajal</keyname><forenames>Purvish</forenames></author><author><keyname>Eliopoulos</keyname><forenames>Nick John</forenames></author><author><keyname>Chou</keyname><forenames>Benjamin Shiue-Hal</forenames></author><author><keyname>Thiruvathukal</keyname><forenames>George K.</forenames></author><author><keyname>Davis</keyname><forenames>James C.</forenames></author><author><keyname>Lu</keyname><forenames>Yung-Hsiang</forenames></author></authors><title>Token Turing Machines are Efficient Vision Models</title><categories>cs.CV cs.LG</categories><comments>Accepted to WACV 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose Vision Token Turing Machines (ViTTM), an efficient, low-latency, memory-augmented Vision Transformer (ViT). Our approach builds on Neural Turing Machines and Token Turing Machines, which were applied to NLP and sequential visual understanding tasks. ViTTMs are designed for non-sequential computer vision tasks such as image classification and segmentation. Our model creates two sets of tokens: process tokens and memory tokens; process tokens pass through encoder blocks and read-write from memory tokens at each encoder block in the network, allowing them to store and retrieve information from memory. By ensuring that there are fewer process tokens than memory tokens, we are able to reduce the inference time of the network while maintaining its accuracy. On ImageNet-1K, the state-of-the-art ViT-B has median latency of 529.5ms and 81.0% accuracy, while our ViTTM-B is 56% faster (234.1ms), with 2.4 times fewer FLOPs, with an accuracy of 82.9%. On ADE20K semantic segmentation, ViT-B achieves 45.65mIoU at 13.8 frame-per-second (FPS) whereas our ViTTM-B model acheives a 45.17 mIoU with 26.8 FPS (+94%). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.07796</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.07796</id><created>2024-09-12</created><updated>2025-01-24</updated><authors><author><keyname>Rastikerdar</keyname><forenames>Mohammad Mehdi</forenames></author><author><keyname>Huang</keyname><forenames>Jin</forenames></author><author><keyname>Guan</keyname><forenames>Hui</forenames></author><author><keyname>Ganesan</keyname><forenames>Deepak</forenames></author></authors><title>In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for   Efficient Adaptation</title><categories>cs.CV cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource-constrained IoT devices increasingly rely on deep learning models for inference tasks in remote environments. However, these models experience significant accuracy drops due to domain shifts when encountering variations in lighting, weather, and seasonal conditions. While cloud-based retraining can address this issue, many IoT deployments operate with limited connectivity and energy constraints, making traditional fine-tuning approaches impractical. We explore this challenge through the lens of wildlife ecology, where camera traps must maintain accurate species classification across changing seasons, weather, and habitats without reliable connectivity. We introduce WildFit, an autonomous in-situ adaptation framework that leverages the key insight that background scenes change more frequently than the visual characteristics of monitored species. WildFit combines background-aware synthesis to generate training samples on-device with drift-aware fine-tuning that triggers model updates only when necessary to conserve resources. Through extensive evaluation on multiple camera trap deployments, we demonstrate that WildFit significantly improves accuracy while greatly reducing adaptation overhead compared to traditional approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.08027</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.08027</id><created>2024-09-12</created><updated>2025-01-24</updated><authors><author><keyname>Swamy</keyname><forenames>Vinitra</forenames></author><author><keyname>Romano</keyname><forenames>Davide</forenames></author><author><keyname>Desikan</keyname><forenames>Bhargav Srinivasa</forenames></author><author><keyname>Camburu</keyname><forenames>Oana-Maria</forenames></author><author><keyname>Käser</keyname><forenames>Tanja</forenames></author></authors><title>iLLuMinaTE: An LLM-XAI Framework Leveraging Social Science Explanation   Theories Towards Actionable Student Performance Feedback</title><categories>cs.CY cs.HC cs.LG</categories><comments>Accepted at AAAI 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent advances in eXplainable AI (XAI) for education have highlighted a critical challenge: ensuring that explanations for state-of-the-art AI models are understandable for non-technical users such as educators and students. In response, we introduce iLLuMinaTE, a zero-shot, chain-of-prompts LLM-XAI pipeline inspired by Miller's cognitive model of explanation. iLLuMinaTE is designed to deliver theory-driven, actionable feedback to students in online courses. iLLuMinaTE navigates three main stages - causal connection, explanation selection, and explanation presentation - with variations drawing from eight social science theories (e.g. Abnormal Conditions, Pearl's Model of Explanation, Necessity and Robustness Selection, Contrastive Explanation). We extensively evaluate 21,915 natural language explanations of iLLuMinaTE extracted from three LLMs (GPT-4o, Gemma2-9B, Llama3-70B), with three different underlying XAI methods (LIME, Counterfactuals, MC-LIME), across students from three diverse online courses. Our evaluation involves analyses of explanation alignment to the social science theory, understandability of the explanation, and a real-world user preference study with 114 university students containing a novel actionability simulation. We find that students prefer iLLuMinaTE explanations over traditional explainers 89.52% of the time. Our work provides a robust, ready-to-use framework for effectively communicating hybrid XAI-driven insights in education, with significant generalization potential for other human-centric fields. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.09107</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.09107</id><created>2024-09-13</created><updated>2025-01-24</updated><authors><author><keyname>Houten</keyname><forenames>Kim van den</forenames></author><author><keyname>Planken</keyname><forenames>Léon</forenames></author><author><keyname>Freydell</keyname><forenames>Esteban</forenames></author><author><keyname>Tax</keyname><forenames>David M. J.</forenames></author><author><keyname>de Weerdt</keyname><forenames>Mathijs</forenames></author></authors><title>Proactive and Reactive Constraint Programming for Stochastic Project   Scheduling with Maximal Time-Lags</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This study investigates scheduling strategies for the stochastic resource-constrained project scheduling problem with maximal time lags (SRCPSP/max)). Recent advances in Constraint Programming (CP) and Temporal Networks have reinvoked interest in evaluating the advantages and drawbacks of various proactive and reactive scheduling methods. First, we present a new, CP-based fully proactive method. Second, we show how a reactive approach can be constructed using an online rescheduling procedure. A third contribution is based on partial order schedules and uses Simple Temporal Networks with Uncertainty (STNUs). Our statistical analysis shows that the STNU-based algorithm performs best in terms of solution quality, while also showing good relative offline and online computation time. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.09398</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.09398</id><created>2024-09-14</created><updated>2025-01-24</updated><authors><author><keyname>Ma</keyname><forenames>Hao</forenames></author><author><keyname>Peng</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Li</keyname><forenames>Xu</forenames></author><author><keyname>Li</keyname><forenames>Yukai</forenames></author><author><keyname>Shao</keyname><forenames>Mingjie</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Liu</keyname><forenames>Ju</forenames></author></authors><title>Language-Queried Target Sound Extraction Without Parallel Training Data</title><categories>eess.AS cs.SD</categories><comments>Accepted by ICASSP 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Language-queried target sound extraction (TSE) aims to extract specific sounds from mixtures based on language queries. Traditional fully-supervised training schemes require extensively annotated parallel audio-text data, which are labor-intensive. We introduce a parallel-data-free training scheme, requiring only unlabelled audio clips for TSE model training by utilizing the contrastive language-audio pre-trained model (CLAP). In a vanilla parallel-data-free training stage, target audio is encoded using the pre-trained CLAP audio encoder to form a condition embedding, while during testing, user language queries are encoded by CLAP text encoder as the condition embedding. This vanilla approach assumes perfect alignment between text and audio embeddings, which is unrealistic. Two major challenges arise from training-testing mismatch: the persistent modality gap between text and audio and the risk of overfitting due to the exposure of rich acoustic details in target audio embedding during training. To address this, we propose a retrieval-augmented strategy. Specifically, we create an embedding cache using audio captions generated by a large language model (LLM). During training, target audio embeddings retrieve text embeddings from this cache to use as condition embeddings, ensuring consistent modalities between training and testing and eliminating information leakage. Extensive experiment results show that our retrieval-augmented approach achieves consistent and notable performance improvements over existing state-of-the-art with better generalizability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.14596</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.14596</id><created>2024-09-22</created><updated>2025-01-24</updated><authors><author><keyname>Roy</keyname><forenames>Sayak Saha</forenames></author><author><keyname>Vafa</keyname><forenames>Elham Pourabbas</forenames></author><author><keyname>Khanmohammadi</keyname><forenames>Kobra</forenames></author><author><keyname>Nilizadeh</keyname><forenames>Shirin</forenames></author></authors><title>DarkGram: A Large-Scale Analysis of Cybercriminal Activity Channels on   Telegram</title><categories>cs.CR cs.CY cs.SI</categories><comments>To appear in USENIX Security 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present the first large-scale analysis of 339 cybercriminal activity channels (CACs). Followed by over 23.8 million users, these channels share a wide array of malicious and unethical content with their subscribers, including compromised credentials, pirated software and media, social media manipulation tools, and blackhat hacking resources such as malware, exploit kits, and social engineering scams. To evaluate these channels, we developed DarkGram, a BERT-based framework that automatically identifies malicious posts from the CACs with an accuracy of 96%. Using DarkGram, we conducted a quantitative analysis of 53,605 posts shared on these channels between February and May 2024, revealing key characteristics of the content. While much of this content is distributed for free, channel administrators frequently employ strategies such as promotions and giveaways to engage users and boost the sales of premium cybercriminal content. Interestingly, these channels sometimes pose significant risks to their own subscribers. Notably, 28.1% of the links shared in these channels contained phishing attacks, and 38% of executable files were bundled with malware. Analyzing how subscribers consume and positively react to the shared content paints a dangerous picture of the perpetuation of cybercriminal content at scale. We also found that the CACs can evade scrutiny or platform takedowns by quickly migrating to new channels with minimal subscriber loss, highlighting the resilience of this ecosystem. To counteract this, we utilized DarkGram to detect emerging channels and reported malicious content to Telegram and affected organizations. This resulted in the takedown of 196 channels over three months. Our findings underscore the urgent need for coordinated efforts to combat the growing threats posed by these channels. To aid this effort, we open-source our dataset and the DarkGram framework. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.15386</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.15386</id><created>2024-09-21</created><updated>2025-01-24</updated><authors><author><keyname>Fan</keyname><forenames>Zicheng</forenames></author><author><keyname>Feng</keyname><forenames>Chen-Chieh</forenames></author><author><keyname>Biljecki</keyname><forenames>Filip</forenames></author></authors><title>Coverage and Bias of Street View Imagery in Mapping the Urban   Environment</title><categories>cs.LG</categories><journal-ref>Computers, Environment and Urban Systems, 117: 102253 (2025)</journal-ref><doi>10.1016/j.compenvurbsys.2025.102253</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Street View Imagery (SVI) has emerged as a valuable data form in urban studies, enabling new ways to map and sense urban environments. However, fundamental concerns regarding the representativeness, quality, and reliability of SVI remain underexplored, e.g. to what extent can cities be captured by such data and do data gaps result in bias. This research, positioned at the intersection of spatial data quality and urban analytics, addresses these concerns by proposing a novel and effective method to estimate SVI's element-level coverage in the urban environment. The method integrates the positional relationships between SVI and target elements, as well as the impact of physical obstructions. Expanding the domain of data quality to SVI, we introduce an indicator system that evaluates the extent of coverage, focusing on the completeness and frequency dimensions. Taking London as a case study, three experiments are conducted to identify potential biases in SVI's ability to cover and represent urban environmental elements, using building facades as an example. It is found that despite their high availability along urban road networks, Google Street View covers only 62.4 % of buildings in the case study area. The average facade coverage per building is 12.4 %. SVI tends to over-represent non-residential buildings, thus possibly resulting in biased analyses, and its coverage of environmental elements is position-dependent. The research also highlights the variability of SVI coverage under different data acquisition practices and proposes an optimal sampling interval range of 50-60 m for SVI collection. The findings suggest that while SVI offers valuable insights, it is no panacea - its application in urban research requires careful consideration of data coverage and element-level representativeness to ensure reliable results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.17661</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.17661</id><created>2024-09-26</created><updated>2025-01-23</updated><authors><author><keyname>Jiang</keyname><forenames>Xiaowei</forenames></author><author><keyname>Ou</keyname><forenames>Liang</forenames></author><author><keyname>Chen</keyname><forenames>Yanan</forenames></author><author><keyname>Ao</keyname><forenames>Na</forenames></author><author><keyname>Chang</keyname><forenames>Yu-Cheng</forenames></author><author><keyname>Do</keyname><forenames>Thomas</forenames></author><author><keyname>Lin</keyname><forenames>Chin-Teng</forenames></author></authors><title>A Fuzzy-based Approach to Predict Human Interaction by Functional   Near-Infrared Spectroscopy</title><categories>cs.AI q-bio.NC</categories><doi>10.1109/TFUZZ.2025.3528376</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The paper introduces a Fuzzy-based Attention (Fuzzy Attention Layer) mechanism, a novel computational approach to enhance the interpretability and efficacy of neural models in psychological research. The proposed Fuzzy Attention Layer mechanism is integrated as a neural network layer within the Transformer Encoder model to facilitate the analysis of complex psychological phenomena through neural signals, such as those captured by functional Near-Infrared Spectroscopy (fNIRS). By leveraging fuzzy logic, the Fuzzy Attention Layer is capable of learning and identifying interpretable patterns of neural activity. This capability addresses a significant challenge when using Transformer: the lack of transparency in determining which specific brain activities most contribute to particular predictions. Our experimental results demonstrated on fNIRS data from subjects engaged in social interactions involving handholding reveal that the Fuzzy Attention Layer not only learns interpretable patterns of neural activity but also enhances model performance. Additionally, the learned patterns provide deeper insights into the neural correlates of interpersonal touch and emotional exchange. The application of our model shows promising potential in deciphering the subtle complexities of human social behaviors, thereby contributing significantly to the fields of social neuroscience and psychological AI. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2409.18592</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2409.18592</id><created>2024-09-27</created><updated>2025-01-24</updated><authors><author><keyname>Uecker</keyname><forenames>Marc</forenames></author><author><keyname>Zöllner</keyname><forenames>J. Marius</forenames></author></authors><title>From One to the Power of Many: Invariance to Multi-LiDAR Perception from   Single-Sensor Datasets</title><categories>cs.CV cs.RO</categories><comments>Accepted for publication at the ML4AD Workshop @ AAAI Conference 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently, LiDAR segmentation methods for autonomous vehicles, powered by deep neural networks, have experienced steep growth in performance on classic benchmarks, such as nuScenes and SemanticKITTI. However, there are still large gaps in performance when deploying models trained on such single-sensor setups to modern vehicles with multiple high-resolution LiDAR sensors. In this work, we introduce a new metric for feature-level invariance which can serve as a proxy to measure cross-domain generalization without requiring labeled data. Additionally, we propose two application-specific data augmentations, which facilitate better transfer to multi-sensor LiDAR setups, when trained on single-sensor datasets. We provide experimental evidence on both simulated and real data, that our proposed augmentations improve invariance across LiDAR setups, leading to improved generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.01021</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.01021</id><created>2024-10-01</created><updated>2025-01-24</updated><authors><author><keyname>Ehlers</keyname><forenames>Rüdiger</forenames></author><author><keyname>Khalimov</keyname><forenames>Ayrat</forenames></author></authors><title>A Naturally-Colored Translation from LTL to Parity and COCOA</title><categories>cs.FL</categories><comments>there was a bug in complexity estimate; 2exp -&gt; 3exp</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Chains of co-Buechi automata (COCOA) have recently been introduced as a new canonical representation of omega-regular languages. The co-Buechi automata in a chain assign to each omega-word its natural color, which depends only on the language itself and not on its automaton representation. The automata in such a chain can be minimized in polynomial time and are good-for-games, making the representation attractive for verification and reactive synthesis applications. However, since in such applications, a specification is usually given in linear temporal logic (LTL), to make COCOA useful, the specification first has to be translated into such a chain of automata. Currently, the only known translation procedure involves a detour through deterministic parity automata (LTL to DPW to COCOA), where the first step neglects the natural colors and requires intricate constructions by Safra or Esparza et al. This observation raises the question whether, by leveraging the definition of the natural color of words, these complex constructions can be avoided, leading to a more direct translation from LTL to COCOA.   In this paper, we present a surprisingly simple translation from LTL to COCOA, along with a variant that translates from LTL to DPW. Our procedure relies on standard operations on weak alternating automata, Miyano-Hayashi's breakpoint construction, an augmented subset construction, and simple graph algorithms. With weak alternating automata as a starting point, the procedure can also handle specifications in linear dynamic logic. Although the translation procedure runs in sub-optimal triply-exponential time (vs. doubly-exponential optimal), it constitutes a novel path for translating from LTL to DPW, avoiding the aforementioned intricate constructions entirely. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.01467</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.01467</id><created>2024-10-02</created><updated>2025-01-24</updated><authors><author><keyname>Yuan</keyname><forenames>Hao</forenames></author><author><keyname>Xie</keyname><forenames>Xiaoping</forenames></author></authors><title>A fast numerical scheme for fractional viscoelastic models of wave   propagation</title><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Due to the nonlocal feature of fractional differential operators, the numerical solution to fractional partial differential equations usually requires expensive memory and computation costs. This paper develops a fast scheme for fractional viscoelastic models of wave propagation.   We first apply the Laplace transform to convert the time-fractional constitutive equation into an integro-differential form that involves the Mittag-Leffler function as a convolution kernel. Then we construct an efficient sum-of-exponentials (SOE) approximation for the Mittag-Leffler function. We use mixed finite elements for the spatial discretization and the Newmark scheme for the temporal discretization of the second time-derivative of the displacement variable in the kinematical equation and finally obtain the fast algorithm. Compared with the traditional L1 scheme for time fractional derivative, our fast scheme reduces the memory complexity from $\mathcal O(N_sN) $ to $\mathcal O(N_sN_{exp})$ and the computation complexity from $\mathcal O(N_sN^2)$ to $\mathcal O(N_sN_{exp}N)$, where $N$ denotes the total number of temporal grid points, $N_{exp}$ is the number of exponentials in SOE, and $N_s$ represents the complexity of memory and computation related to the spatial discretization. Numerical experiments confirm the theoretical results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.01639</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.01639</id><created>2024-10-02</created><updated>2025-01-24</updated><authors><author><keyname>Tennant</keyname><forenames>Elizaveta</forenames></author><author><keyname>Hailes</keyname><forenames>Stephen</forenames></author><author><keyname>Musolesi</keyname><forenames>Mirco</forenames></author></authors><title>Moral Alignment for LLM Agents</title><categories>cs.LG cs.AI cs.CY</categories><comments>To appear at the 13th International Conference on Learning   Representations (ICLR'25), Singapore, Apr 2025</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Decision-making agents based on pre-trained Large Language Models (LLMs) are increasingly being deployed across various domains of human activity. While their applications are currently rather specialized, several research efforts are under way to develop more generalist agents. As LLM-based systems become more agentic, their influence on human activity will grow and the transparency of this will decrease. Consequently, developing effective methods for aligning them to human values is vital.   The prevailing practice in alignment often relies on human preference data (e.g., in RLHF or DPO), in which values are implicit and are essentially deduced from relative preferences over different model outputs. In this work, instead of relying on human feedback, we introduce the design of reward functions that explicitly encode core human values for Reinforcement Learning-based fine-tuning of foundation agent models. Specifically, we use intrinsic rewards for the moral alignment of LLM agents.   We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism, quantifying moral rewards for agents in terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD) environment. We also show how moral fine-tuning can be deployed to enable an agent to unlearn a previously developed selfish strategy. Finally, we find that certain moral strategies learned on the IPD game generalize to several other matrix game environments. In summary, we demonstrate that fine-tuning with intrinsic rewards is a promising general solution for aligning LLM agents to human values, and it might represent a more transparent and cost-effective alternative to currently predominant alignment techniques. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.02541</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.02541</id><created>2024-10-03</created><updated>2025-01-24</updated><authors><author><keyname>Biswas</keyname><forenames>Sayan</forenames></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames></author><author><keyname>Sharma</keyname><forenames>Rishi</forenames></author><author><keyname>Trinca</keyname><forenames>Thibaud</forenames></author><author><keyname>de Vos</keyname><forenames>Martijn</forenames></author></authors><title>Fair Decentralized Learning</title><categories>cs.LG cs.DC</categories><comments>To appear in the proceedings of "3rd IEEE Conference on Secure and   Trustworthy Machine Learning" (SatML'25)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decentralized learning (DL) is an emerging approach that enables nodes to collaboratively train a machine learning model without sharing raw data. In many application domains, such as healthcare, this approach faces challenges due to the high level of heterogeneity in the training data's feature space. Such feature heterogeneity lowers model utility and negatively impacts fairness, particularly for nodes with under-represented training data. In this paper, we introduce \textsc{Facade}, a clustering-based DL algorithm specifically designed for fair model training when the training data exhibits several distinct features. The challenge of \textsc{Facade} is to assign nodes to clusters, one for each feature, based on the similarity in the features of their local data, without requiring individual nodes to know apriori which cluster they belong to. \textsc{Facade} (1) dynamically assigns nodes to their appropriate clusters over time, and (2) enables nodes to collaboratively train a specialized model for each cluster in a fully decentralized manner. We theoretically prove the convergence of \textsc{Facade}, implement our algorithm, and compare it against three state-of-the-art baselines. Our experimental results on three datasets demonstrate the superiority of our approach in terms of model accuracy and fairness compared to all three competitors. Compared to the best-performing baseline, \textsc{Facade} on the CIFAR-10 dataset also reduces communication costs by 32.3\% to reach a target accuracy when cluster sizes are imbalanced. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.02705</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.02705</id><created>2024-10-03</created><updated>2025-01-24</updated><authors><author><keyname>Li</keyname><forenames>Zongming</forenames></author><author><keyname>Cheng</keyname><forenames>Tianheng</forenames></author><author><keyname>Chen</keyname><forenames>Shoufa</forenames></author><author><keyname>Sun</keyname><forenames>Peize</forenames></author><author><keyname>Shen</keyname><forenames>Haocheng</forenames></author><author><keyname>Ran</keyname><forenames>Longjin</forenames></author><author><keyname>Chen</keyname><forenames>Xiaoxin</forenames></author><author><keyname>Liu</keyname><forenames>Wenyu</forenames></author><author><keyname>Wang</keyname><forenames>Xinggang</forenames></author></authors><title>ControlAR: Controllable Image Generation with Autoregressive Models</title><categories>cs.CV</categories><comments>To appear in ICLR 2025. Work in progress</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Autoregressive (AR) models have reformulated image generation as next-token prediction, demonstrating remarkable potential and emerging as strong competitors to diffusion models. However, control-to-image generation, akin to ControlNet, remains largely unexplored within AR models. Although a natural approach, inspired by advancements in Large Language Models, is to tokenize control images into tokens and prefill them into the autoregressive model before decoding image tokens, it still falls short in generation quality compared to ControlNet and suffers from inefficiency. To this end, we introduce ControlAR, an efficient and effective framework for integrating spatial controls into autoregressive image generation models. Firstly, we explore control encoding for AR models and propose a lightweight control encoder to transform spatial inputs (e.g., canny edges or depth maps) into control tokens. Then ControlAR exploits the conditional decoding method to generate the next image token conditioned on the per-token fusion between control and image tokens, similar to positional encodings. Compared to prefilling tokens, using conditional decoding significantly strengthens the control capability of AR models but also maintains the model's efficiency. Furthermore, the proposed ControlAR surprisingly empowers AR models with arbitrary-resolution image generation via conditional decoding and specific controls. Extensive experiments can demonstrate the controllability of the proposed ControlAR for the autoregressive control-to-image generation across diverse inputs, including edges, depths, and segmentation masks. Furthermore, both quantitative and qualitative results indicate that ControlAR surpasses previous state-of-the-art controllable diffusion models, e.g., ControlNet++. Code, models, and demo will soon be available at https://github.com/hustvl/ControlAR. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.02888</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.02888</id><created>2024-10-03</created><updated>2025-01-23</updated><authors><author><keyname>Moradi</keyname><forenames>Pegah</forenames></author><author><keyname>Levy</keyname><forenames>Karen</forenames></author><author><keyname>Cheyre</keyname><forenames>Cristobal</forenames></author></authors><title>Pseudo-Automation: How Labor-Offsetting Technologies Reconfigure Roles   and Relationships in Frontline Retail Work</title><categories>cs.HC cs.CY</categories><comments>Pegah Moradi, Karen Levy, and Cristobal Cheyre. 2025.   Pseudo-Automation: How Labor-Offsetting Technologies Reconfigure Roles and   Relationships in Frontline Retail Work. Proc. ACM Hum.-Comput. Interact. 9,   2, Article CSCW153 (April 2025), 21 pages</comments><doi>10.1145/3711051</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Self-service machines are a form of pseudo-automation; rather than actually automate tasks, they offset them to unpaid customers. Typically implemented for customer convenience and to reduce labor costs, self-service is often criticized for worsening customer service and increasing loss and theft for retailers. Though millions of frontline service workers continue to interact with these technologies on a day-to-day basis, little is known about how these machines change the nature of frontline labor. Through interviews with current and former cashiers who work with self-checkout technologies, we investigate how technology that offsets labor from an employee to a customer can reconfigure frontline work. We find three changes to cashiering tasks as a result of self-checkout: (1) Working at self-checkout involved parallel demands from multiple customers, (2) self-checkout work was more problem-oriented (including monitoring and policing customers), and (3) traditional checkout began to become more demanding as easier transactions were filtered to self-checkout. As their interactions with customers became more focused on problem solving and rule enforcement, cashiers were often positioned as adversaries to customers at self-checkout. To cope with perceived adversarialism, cashiers engaged in a form of relational patchwork, using techniques like scapegoating the self-checkout machine and providing excessive customer service in order to maintain positive customer interactions in the face of potential conflict. Our findings highlight how even under pseudo-automation, workers must engage in relational work to manage and mend negative human-to-human interactions so that machines can be properly implemented in context. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.03252</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.03252</id><created>2024-10-04</created><updated>2025-01-24</updated><authors><author><keyname>Piccardi</keyname><forenames>Carlo</forenames></author></authors><title>An egonet-based approach to effective weighted network comparison</title><categories>cs.SI physics.data-an</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  With the impressive growth of network models in practically every scientific and technological area, we are often faced with the need to compare graphs, i.e., to quantify their (dis)similarity using appropriate metrics. This is necessary, for example, to identify networks with comparable characteristics or to spot anomalous instants in a time sequence of graphs. While a large number of metrics are available for binary networks, the set of comparison methods capable of handling weighted graphs is much smaller. Yet, the strength of connections is often a key ingredient of the model, and ignoring this information could lead to misleading results. In this paper we introduce a family of dissimilarity measures to compare undirected weighted networks. They fall into the class of alignment-free metrics: as such, they do not require the correspondence of the nodes between the two graphs and can also compare networks of different sizes. In short, they are based on the distributions, on the graph, of a few egonet features which are easily defined and computed: the distance between two graphs is then the distance between the corresponding distributions. On a properly defined testbed with a pool of weighted network models with diversified characteristics, the proposed metrics are shown to achieve state-of-the-art performance in the model classification task. The effectiveness and applicability of the proposed metrics are then demonstrated on two examples. In the first, some "filtering" schemes -- designed to eliminate non-significant links while maintaining most of the total weight -- are evaluated in their ability to produce as output a graph faithful to the original, in terms of the local structure around nodes. In the second example, analyzing a timeline of stock market correlation graphs highlights anomalies associated with periods of financial instability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.04080</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.04080</id><created>2024-10-05</created><updated>2025-01-23</updated><authors><author><keyname>Huang</keyname><forenames>Ruiyuan</forenames></author><author><keyname>Huang</keyname><forenames>Zengfeng</forenames></author></authors><title>High Probability Bound for Cross-Learning Contextual Bandits with   Unknown Context Distributions</title><categories>cs.LG</categories><comments>Restructured the manuscript to improve readability</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Motivated by applications in online bidding and sleeping bandits, we examine the problem of contextual bandits with cross learning, where the learner observes the loss associated with the action across all possible contexts, not just the current round's context. Our focus is on a setting where losses are chosen adversarially, and contexts are sampled i.i.d. from a specific distribution. This problem was first studied by Balseiro et al. (2019), who proposed an algorithm that achieves near-optimal regret under the assumption that the context distribution is known in advance. However, this assumption is often unrealistic. To address this issue, Schneider and Zimmert (2023) recently proposed a new algorithm that achieves nearly optimal expected regret. It is well-known that expected regret can be significantly weaker than high-probability bounds. In this paper, we present a novel, in-depth analysis of their algorithm and demonstrate that it actually achieves near-optimal regret with high probability. There are steps in the original analysis by Schneider and Zimmert (2023) that lead only to an expected bound by nature. In our analysis, we introduce several new insights. Specifically, we make extensive use of the weak dependency structure between different epochs, which was overlooked in previous analyses. Additionally, standard martingale inequalities are not directly applicable, so we refine martingale inequalities to complete our analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.04850</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.04850</id><created>2024-10-07</created><updated>2025-01-24</updated><authors><author><keyname>Ulander</keyname><forenames>Johan</forenames></author></authors><title>Artificial Barriers for stochastic differential equations and for   construction of boundary-preserving schemes</title><categories>math.NA cs.NA math.PR</categories><comments>32 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We develop the novel method of artificial barriers for scalar stochastic differential equations (SDEs) and use it to construct boundary-preserving numerical schemes for strong approximations of scalar SDEs, possibly with non-globally Lipschitz drift and diffusion coefficients, whose state-space is either bounded or half-bounded. The idea of artificial barriers is to augment the SDE with artificial barriers outside the state-space to not change the solution process, and then apply a boundary-preserving numerical scheme to the resulting reflected SDE (RSDE). This enables us to construct boundary-preserving numerical schemes with the same strong convergence rate as the strong convergence rate of the numerical scheme for the corresponding RSDE. Based on the method of artificial barriers, we construct two boundary-preserving schemes that we call the Artificial Barriers Euler--Maruyama (ABEM) scheme and the Artificial Barriers Euler--Peano (ABEP) scheme, respectively. We provide numerical experiments for the ABEM scheme and the numerical results agree with the obtained theoretical results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.05604</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.05604</id><created>2024-10-07</created><updated>2025-01-14</updated><authors><author><keyname>Musa</keyname><forenames>Md Rajib Khan</forenames></author><author><keyname>Qian</keyname><forenames>Yichen</forenames></author><author><keyname>Peng</keyname><forenames>Jie</forenames></author><author><keyname>Cereceda</keyname><forenames>David</forenames></author></authors><title>Accelerating the discovery of low-energy structure configurations: a   computational approach that integrates first-principles calculations, Monte   Carlo sampling, and Machine Learning</title><categories>cond-mat.mtrl-sci cs.LG</categories><comments>added changes made during revision of manuscript</comments><doi>10.1016/j.scriptamat.2024.116535</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Finding Minimum Energy Configurations (MECs) is essential in fields such as physics, chemistry, and materials science, as they represent the most stable states of the systems. In particular, identifying such MECs in multi-component alloys considered candidate PFMs is key because it determines the most stable arrangement of atoms within the alloy, directly influencing its phase stability, structural integrity, and thermo-mechanical properties. However, since the search space grows exponentially with the number of atoms considered, obtaining such MECs using computationally expensive first-principles DFT calculations often results in a cumbersome task. To escape the above compromise between physical fidelity and computational efficiency, we have developed a novel physics-based data-driven approach that combines Monte Carlo sampling, first-principles DFT calculations, and Machine Learning to accelerate the discovery of MECs in multi-component alloys. More specifically, we have leveraged well-established Cluster Expansion (CE) techniques with Local Outlier Factor models to establish strategies that enhance the reliability of the CE method. In this work, we demonstrated the capabilities of the proposed approach for the particular case of a tungsten-based quaternary high-entropy alloy. However, the method is applicable to other types of alloys and enables a wide range of applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.08007</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.08007</id><created>2024-10-10</created><updated>2025-01-24</updated><authors><author><keyname>De Toni</keyname><forenames>Giovanni</forenames></author><author><keyname>Teso</keyname><forenames>Stefano</forenames></author><author><keyname>Lepri</keyname><forenames>Bruno</forenames></author><author><keyname>Passerini</keyname><forenames>Andrea</forenames></author></authors><title>Time Can Invalidate Algorithmic Recourse</title><categories>cs.LG cs.CY</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Algorithmic Recourse (AR) aims to provide users with actionable steps to overturn unfavourable decisions made by machine learning predictors. However, these actions often take time to implement (e.g., getting a degree can take years), and their effects may vary as the world evolves. Thus, it is natural to ask for recourse that remains valid in a dynamic environment. In this paper, we study the robustness of algorithmic recourse over time by casting the problem through the lens of causality. We demonstrate theoretically and empirically that (even robust) causal AR methods can fail over time except in the -- unlikely -- case that the world is stationary. Even more critically, unless the world is fully deterministic, counterfactual AR cannot be solved optimally. To account for this, we propose a simple yet effective algorithm for temporal AR that explicitly accounts for time under the assumption of having access to an estimator approximating the stochastic process. Our simulations on synthetic and realistic datasets show how considering time produces more resilient solutions to potential trends in the data distribution. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.08706</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.08706</id><created>2024-10-11</created><updated>2025-01-24</updated><authors><author><keyname>Ari</keyname><forenames>Cagri</forenames></author><author><keyname>Shisher</keyname><forenames>Md Kamran Chowdhury</forenames></author><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Uysal</keyname><forenames>Elif</forenames></author></authors><title>Goal-Oriented Status Updating for Real-time Remote Inference over   Networks with Two-Way Delay</title><categories>cs.NI eess.SP</categories><comments>13 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a setting where an intelligent model (e.g., a pre-trained neural network) predicts the real-time value of a target signal using data samples transmitted from a remote source according to a scheduling policy. The scheduler decides on i) the age of the samples to be sent, ii) when to send them, and iii) the length of each packet (i.e., the number of samples contained in each packet). The dependence of inference quality on the Age of Information (AoI) for a given packet length is modeled by a general relationship. Previous work assumed i.i.d. transmission delays with immediate feedback or were restricted to the case where inference performance degrades as the input data ages. Our formulation, in addition to capturing non-monotone age dependence, also covers Markovian delay on both forward and feedback links. We model this as an infinite-horizon average-cost Semi-Markov Decision Process. We obtain a closed-form solution that decides on (i) and (ii) for any constant packet length. The solution for when to send is an index-based threshold policy, where the index function is expressed in terms of the delay state and AoI at the receiver. The age of the packet selected is a function of the delay state. We separately optimize the value of the constant length. We also develop an index-based threshold policy for the variable length case, which allows a complexity reduction. In simulation results, we observe that our goal-oriented scheduler drops inference error down to one sixth with respect to age-based scheduling of unit-length packets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.10989</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.10989</id><created>2024-10-14</created><updated>2025-01-23</updated><authors><author><keyname>Hsu</keyname><forenames>Pin-Lun</forenames></author><author><keyname>Dai</keyname><forenames>Yun</forenames></author><author><keyname>Kothapalli</keyname><forenames>Vignesh</forenames></author><author><keyname>Song</keyname><forenames>Qingquan</forenames></author><author><keyname>Tang</keyname><forenames>Shao</forenames></author><author><keyname>Zhu</keyname><forenames>Siyu</forenames></author><author><keyname>Shimizu</keyname><forenames>Steven</forenames></author><author><keyname>Sahni</keyname><forenames>Shivam</forenames></author><author><keyname>Ning</keyname><forenames>Haowen</forenames></author><author><keyname>Chen</keyname><forenames>Yanning</forenames></author></authors><title>Liger Kernel: Efficient Triton Kernels for LLM Training</title><categories>cs.LG cs.AI cs.CL cs.DC</categories><comments>17 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Training Large Language Models (LLMs) efficiently at scale presents a formidable challenge, driven by their ever-increasing computational demands and the need for enhanced performance. In this work, we introduce Liger-Kernel, an open-sourced set of Triton kernels developed specifically for LLM training. With kernel optimization techniques like kernel operation fusing and input chunking, our kernels achieve on average a 20% increase in training throughput and a 60% reduction in GPU memory usage for popular LLMs compared to HuggingFace implementations. In addition, Liger-Kernel is designed with modularity, accessibility, and adaptability in mind, catering to both casual and expert users. Comprehensive benchmarks and integration tests are built in to ensure compatibility, performance, correctness, and convergence across diverse computing environments and model architectures.   The source code is available under a permissive license at: github.com/linkedin/Liger-Kernel. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.10994</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.10994</id><created>2024-10-14</created><updated>2025-01-24</updated><authors><author><keyname>Bhattacharjee</keyname><forenames>Aditya</forenames></author><author><keyname>Singh</keyname><forenames>Shubhr</forenames></author><author><keyname>Benetos</keyname><forenames>Emmanouil</forenames></author></authors><title>GraFPrint: A GNN-Based Approach for Audio Identification</title><categories>cs.SD cs.IR eess.AS</categories><comments>Submitted to IEEE International Conference on Acoustics, Speech, and   Signal Processing (ICASSP 2025)</comments><acm-class>H.5.5; I.2.6</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces GraFPrint, an audio identification framework that leverages the structural learning capabilities of Graph Neural Networks (GNNs) to create robust audio fingerprints. Our method constructs a k-nearest neighbor (k-NN) graph from time-frequency representations and applies max-relative graph convolutions to encode local and global information. The network is trained using a self-supervised contrastive approach, which enhances resilience to ambient distortions by optimizing feature representation. GraFPrint demonstrates superior performance on large-scale datasets at various levels of granularity, proving to be both lightweight and scalable, making it suitable for real-world applications with extensive reference databases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.11290</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.11290</id><created>2024-10-15</created><updated>2025-01-24</updated><authors><author><keyname>Yang</keyname><forenames>Jirui</forenames></author><author><keyname>Chen</keyname><forenames>Peng</forenames></author><author><keyname>Lu</keyname><forenames>Zhihui</forenames></author><author><keyname>Deng</keyname><forenames>Ruijun</forenames></author><author><keyname>Duan</keyname><forenames>Qiang</forenames></author><author><keyname>Zeng</keyname><forenames>Jianping</forenames></author></authors><title>Backdoor Attack on Vertical Federated Graph Neural Network Learning</title><categories>cs.LG cs.AI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Federated Graph Neural Network (FedGNN) integrate federated learning (FL) with graph neural networks (GNNs) to enable privacy-preserving training on distributed graph data. Vertical Federated Graph Neural Network (VFGNN), a key branch of FedGNN, handles scenarios where data features and labels are distributed among participants. Despite the robust privacy-preserving design of VFGNN, we have found that it still faces the risk of backdoor attacks, even in situations where labels are inaccessible. This paper proposes BVG, a novel backdoor attack method that leverages multi-hop triggers and backdoor retention, requiring only four target-class nodes to execute effective attacks. Experimental results demonstrate that BVG achieves nearly 100% attack success rates across three commonly used datasets and three GNN models, with minimal impact on the main task accuracy. We also evaluated various defense methods, and the BVG method maintained high attack effectiveness even under existing defenses. This finding highlights the need for advanced defense mechanisms to counter sophisticated backdoor attacks in practical VFGNN applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.11610</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.11610</id><created>2024-10-15</created><updated>2025-01-24</updated><authors><author><keyname>Das</keyname><forenames>Dabbrata</forenames></author><author><keyname>Das</keyname><forenames>Argho Deb</forenames></author><author><keyname>Sadaf</keyname><forenames>Farhan</forenames></author></authors><title>Enhanced Encoder-Decoder Architecture for Accurate Monocular Depth   Estimation</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating depth from a single 2D image is a challenging task due to the lack of stereo or multi-view data, which are typically required for depth perception. In state-of-the-art architectures, the main challenge is to efficiently capture complex objects and fine-grained details, which are often difficult to predict. This paper introduces a novel deep learning-based approach using an enhanced encoder-decoder architecture, where the Inception-ResNet-v2 model serves as the encoder. This is the first instance of utilizing Inception-ResNet-v2 as an encoder for monocular depth estimation, demonstrating improved performance over previous models. It incorporates multi-scale feature extraction to enhance depth prediction accuracy across various object sizes and distances. We propose a composite loss function comprising depth loss, gradient edge loss, and Structural Similarity Index Measure (SSIM) loss, with fine-tuned weights to optimize the weighted sum, ensuring a balance across different aspects of depth estimation. Experimental results on the KITTI dataset show that our model achieves a significantly faster inference time of 0.019 seconds, outperforming vision transformers in efficiency while maintaining good accuracy. On the NYU Depth V2 dataset, the model establishes state-of-the-art performance, with an Absolute Relative Error (ARE) of 0.064, a Root Mean Square Error (RMSE) of 0.228, and an accuracy of 89.3% for $\delta$ &lt; 1.25. These metrics demonstrate that our model can accurately and efficiently predict depth even in challenging scenarios, providing a practical solution for real-time applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.12853</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.12853</id><created>2024-10-10</created><updated>2025-01-23</updated><authors><author><keyname>Hegazy</keyname><forenames>Mahmood</forenames></author></authors><title>Diversity of Thought Elicits Stronger Reasoning Capabilities in   Multi-Agent Debate Frameworks</title><categories>cs.CL cs.AI cs.LG</categories><comments>11 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Large language models (LLMs) excel in natural language generation but often confidently produce incorrect responses, especially in tasks like mathematical reasoning. Chain-of-thought prompting, self-verification, and multi-agent debate are among the strategies proposed to improve the reasoning and factual accuracy of LLMs. Building on Du et al.'s multi-agent debate framework, we find that multi-agent debate helps at any model scale, and that diversity of thought elicits stronger reasoning in debating LLMs. Across various model sizes, performance on mathematical reasoning tasks benefits most when diverse trained models are used. Remarkably, after 4 rounds of debate, a diverse set of medium-capacity models (Gemini-Pro, Mixtral 7BX8, and PaLM 2-M) outperforms GPT-4 on the GSM-8K benchmark, scoring 91% accuracy. By comparison, when 3 instances of Gemini-Pro are used, performance only reaches 82%. Finally, this diverse set of medium-capacity models sets a new state-of-the-art performance on the ASDiv benchmark (94%). These results underscore the idea that the future of AI is agentic, with diverse cooperating agents yielding emergent capabilities beyond even the most powerful individual models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.12880</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.12880</id><created>2024-10-15</created><updated>2025-01-24</updated><authors><author><keyname>Banerjee</keyname><forenames>Somnath</forenames></author><author><keyname>Layek</keyname><forenames>Sayan</forenames></author><author><keyname>Shrawgi</keyname><forenames>Hari</forenames></author><author><keyname>Mandal</keyname><forenames>Rajarshi</forenames></author><author><keyname>Halder</keyname><forenames>Avik</forenames></author><author><keyname>Kumar</keyname><forenames>Shanu</forenames></author><author><keyname>Basu</keyname><forenames>Sagnik</forenames></author><author><keyname>Agrawal</keyname><forenames>Parag</forenames></author><author><keyname>Hazra</keyname><forenames>Rima</forenames></author><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author></authors><title>Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to   Sensitivity in Large Language Models</title><categories>cs.CL cs.AI cs.CY</categories><comments>Accepted at NAACL 2025 (Main track). [Project   Page](https://neuralsentinel.github.io/KaleidoCulture/)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As LLMs are increasingly deployed in global applications, the importance of cultural sensitivity becomes paramount, ensuring that users from diverse backgrounds feel respected and understood. Cultural harm can arise when these models fail to align with specific cultural norms, resulting in misrepresentations or violations of cultural values. This work addresses the challenges of ensuring cultural sensitivity in LLMs, especially in small-parameter models that often lack the extensive training data needed to capture global cultural nuances. We present two key contributions: (1) A cultural harm test dataset, created to assess model outputs across different cultural contexts through scenarios that expose potential cultural insensitivities, and (2) A culturally aligned preference dataset, aimed at restoring cultural sensitivity through fine-tuning based on feedback from diverse annotators. These datasets facilitate the evaluation and enhancement of LLMs, ensuring their ethical and safe deployment across different cultural landscapes. Our results show that integrating culturally aligned feedback leads to a marked improvement in model behavior, significantly reducing the likelihood of generating culturally insensitive or harmful content. Ultimately, this work paves the way for more inclusive and respectful AI systems, fostering a future where LLMs can safely and ethically navigate the complexities of diverse cultural landscapes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.13147</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.13147</id><created>2024-10-16</created><updated>2025-01-23</updated><authors><author><keyname>Le</keyname><forenames>Khiem</forenames></author><author><keyname>Chawla</keyname><forenames>Nitesh V.</forenames></author></authors><title>Utilizing Large Language Models in an iterative paradigm with domain   feedback for zero-shot molecule optimization</title><categories>cs.LG cs.AI cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Molecule optimization is a critical task in drug discovery to optimize desired properties of a given molecule. Despite Large Language Models (LLMs) holding the potential to efficiently simulate this task by using natural language to direct the optimization, straightforwardly utilizing them shows limited performance. In this work, we facilitate utilizing LLMs in an iterative paradigm by proposing a simple yet effective domain feedback provider, namely $\text{Re}^2$DF. In detail, $\text{Re}^2$DF harnesses an external toolkit, RDKit, to handle the molecule hallucination, if the modified molecule is chemically invalid. Otherwise, $\text{Re}^2$DF verifies whether the modified molecule meets the objective, if not, its desired properties are computed and compared to the original one, establishing reliable domain feedback with correct direction and distance towards the objective to explicitly guide the LLM to refine the modified molecule. We conduct experiments across both single- and multi-property objectives with 2 thresholds, where $\text{Re}^2$DF shows significant improvements. Notably, for 20 single-property objectives, $\text{Re}^2$DF enhances Hit ratio by 16.96% and 20.76% under loose (\texttt{l}) and strict (\texttt{s}) thresholds, respectively. For 32 multi-property objectives, $\text{Re}^2$DF enhances Hit ratio by 6.04% and 5.25%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.13267</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.13267</id><created>2024-10-17</created><updated>2025-01-23</updated><authors><author><keyname>Wu</keyname><forenames>Shangda</forenames></author><author><keyname>Wang</keyname><forenames>Yashan</forenames></author><author><keyname>Yuan</keyname><forenames>Ruibin</forenames></author><author><keyname>Guo</keyname><forenames>Zhancheng</forenames></author><author><keyname>Tan</keyname><forenames>Xu</forenames></author><author><keyname>Zhang</keyname><forenames>Ge</forenames></author><author><keyname>Zhou</keyname><forenames>Monan</forenames></author><author><keyname>Chen</keyname><forenames>Jing</forenames></author><author><keyname>Mu</keyname><forenames>Xuefeng</forenames></author><author><keyname>Gao</keyname><forenames>Yuejie</forenames></author><author><keyname>Dong</keyname><forenames>Yuanliang</forenames></author><author><keyname>Liu</keyname><forenames>Jiafeng</forenames></author><author><keyname>Li</keyname><forenames>Xiaobing</forenames></author><author><keyname>Yu</keyname><forenames>Feng</forenames></author><author><keyname>Sun</keyname><forenames>Maosong</forenames></author></authors><title>CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages   Using Large Language Models</title><categories>cs.SD cs.CL eess.AS</categories><comments>17 pages, 10 figures, 4 tables, accepted by NAACL 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Challenges in managing linguistic diversity and integrating various musical modalities are faced by current music information retrieval systems. These limitations reduce their effectiveness in a global, multimodal music environment. To address these issues, we introduce CLaMP 2, a system compatible with 101 languages that supports both ABC notation (a text-based musical notation format) and MIDI (Musical Instrument Digital Interface) for music information retrieval. CLaMP 2, pre-trained on 1.5 million ABC-MIDI-text triplets, includes a multilingual text encoder and a multimodal music encoder aligned via contrastive learning. By leveraging large language models, we obtain refined and consistent multilingual descriptions at scale, significantly reducing textual noise and balancing language distribution. Our experiments show that CLaMP 2 achieves state-of-the-art results in both multilingual semantic search and music classification across modalities, thus establishing a new standard for inclusive and global music information retrieval. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.13387</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.13387</id><created>2024-10-17</created><updated>2025-01-23</updated><authors><author><keyname>Chen</keyname><forenames>Chaoran</forenames></author><author><keyname>Zhou</keyname><forenames>Daodao</forenames></author><author><keyname>Ye</keyname><forenames>Yanfang</forenames></author><author><keyname>Li</keyname><forenames>Toby Jia-jun</forenames></author><author><keyname>Yao</keyname><forenames>Yaxing</forenames></author></authors><title>CLEAR: Towards Contextual LLM-Empowered Privacy Policy Analysis and Risk   Generation for Large Language Model Applications</title><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The rise of end-user applications powered by large language models (LLMs), including both conversational interfaces and add-ons to existing graphical user interfaces (GUIs), introduces new privacy challenges. However, many users remain unaware of the risks. This paper explores methods to increase user awareness of privacy risks associated with LLMs in end-user applications. We conducted five co-design workshops to uncover user privacy concerns and their demand for contextual privacy information within LLMs. Based on these insights, we developed CLEAR (Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation), a just-in-time contextual assistant designed to help users identify sensitive information, summarize relevant privacy policies, and highlight potential risks when sharing information with LLMs. We evaluated the usability and usefulness of CLEAR across two example domains: ChatGPT and the Gemini plugin in Gmail. Our findings demonstrated that CLEAR is easy to use and improves users' understanding of data practices and privacy risks. We also discussed LLM's duality in posing and mitigating privacy risks, offering design and policy implications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.13415</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.13415</id><created>2024-10-17</created><updated>2025-01-24</updated><authors><author><keyname>Rinkinen</keyname><forenames>Mikael</forenames></author><author><keyname>Koskinen</keyname><forenames>Lauri</forenames></author><author><keyname>Silven</keyname><forenames>Olli</forenames></author><author><keyname>Safarpour</keyname><forenames>Mehdi</forenames></author></authors><title>Shavette: Low Power Neural Network Acceleration via Algorithm-level   Error Detection and Undervolting</title><categories>cs.AR cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Reduced voltage operation is an effective technique for substantial energy efficiency improvement in digital circuits. This brief introduces a simple approach for enabling reduced voltage operation of Deep Neural Network (DNN) accelerators by mere software modifications. Conventional approaches for enabling reduced voltage operation e.g., Timing Error Detection (TED) systems, incur significant development costs and overheads, while not being applicable to the off-the-shelf components. Contrary to those, the solution proposed in this paper relies on algorithm-based error detection, and hence, is implemented with low development costs, does not require any circuit modifications, and is even applicable to commodity devices. By showcasing the solution through experimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we demonstrate 18% to 25% energy saving with no accuracy loss of the models and negligible throughput compromise (&lt; 3.9%), considering the overheads from integration of the error detection schemes into the DNN. The integration of presented algorithmic solution into the design is simpler when compared conventional TED based techniques that require extensive circuit-level modifications, cell library characterizations or special support from the design tools. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.13549</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.13549</id><created>2024-10-17</created><updated>2025-01-24</updated><authors><author><keyname>Arad</keyname><forenames>Itai</forenames></author><author><keyname>Santha</keyname><forenames>Miklos</forenames></author></authors><title>Quasi-quantum states and the quasi-quantum PCP theorem</title><categories>quant-ph cs.CC</categories><comments>50 pages, 17 figures, comments are welcome. Updated version with   improved exposition (results are the same)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce $k$-local quasi-quantum states: a superset of the regular quantum states, defined by relaxing the positivity constraint. We show that a $k$-local quasi-quantum state on $n$ qubits can be 1-1 mapped to a distribution of assignments over $n$ variables with an alphabet of size $4$, which is subject to non-linear constraints over its $k$-local marginals. Therefore, solving the $k$-local Hamiltonian over the quasi-quantum states is equivalent to optimizing a distribution of assignment over a classical $k$-local CSP. We show that this optimization problem is essentially classical by proving it is NP-complete. Crucially, just as ordinary quantum states, these distributions lack a simple tensor-product structure and are therefore not determined straightforwardly by their local marginals. Consequently, our classical optimization problem shares some unique aspects of Hamiltonian complexity: it lacks an easy search-to-decision reduction, and it is not clear that its 1D version can be solved with dynamical programming (i.e., it could remain NP-hard).   Our main result is a PCP theorem for the $k$-local Hamiltonian over the quasi-quantum states in the form of a hardness-of-approximation result. The proof suggests the existence of a subtle promise-gap amplification procedure in a model that shares many similarities with the quantum local Hamiltonian problem, thereby providing insights on the quantum PCP conjecture. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.17647</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.17647</id><created>2024-10-23</created><updated>2025-01-24</updated><authors><author><keyname>Thompson</keyname><forenames>Isaac Symes</forenames></author><author><keyname>Caron</keyname><forenames>Alberto</forenames></author><author><keyname>Hicks</keyname><forenames>Chris</forenames></author><author><keyname>Mavroudis</keyname><forenames>Vasilios</forenames></author></authors><title>Entity-based Reinforcement Learning for Autonomous Cyber Defence</title><categories>cs.LG cs.CR</categories><comments>Material also appearing in the proceedings of the 1st International   Workshop on Autonomous Cybersecurity at ACM CCS 2024</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant challenge for autonomous cyber defence is ensuring a defensive agent's ability to generalise across diverse network topologies and configurations. This capability is necessary for agents to remain effective when deployed in dynamically changing environments, such as an enterprise network where devices may frequently join and leave. Standard approaches to deep reinforcement learning, where policies are parameterised using a fixed-input multi-layer perceptron (MLP) expect fixed-size observation and action spaces. In autonomous cyber defence, this makes it hard to develop agents that generalise to environments with network topologies different from those trained on, as the number of nodes affects the natural size of the observation and action spaces. To overcome this limitation, we reframe the problem of autonomous network defence using entity-based reinforcement learning, where the observation and action space of an agent are decomposed into a collection of discrete entities. This framework enables the use of policy parameterisations specialised in compositional generalisation. We train a Transformer-based policy on the Yawning Titan cyber-security simulation environment and test its generalisation capabilities across various network topologies. We demonstrate that this approach significantly outperforms an MLP-based policy when training across fixed-size networks of varying topologies, and matches performance when training on a single network. We also demonstrate the potential for zero-shot generalisation to networks of a different size to those seen in training. These findings highlight the potential for entity-based reinforcement learning to advance the field of autonomous cyber defence by providing more generalisable policies capable of handling variations in real-world network environments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.17878</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.17878</id><created>2024-10-23</created><updated>2025-01-24</updated><authors><author><keyname>Elhag</keyname><forenames>Ahmed A.</forenames></author><author><keyname>Rusch</keyname><forenames>T. Konstantin</forenames></author><author><keyname>Di Giovanni</keyname><forenames>Francesco</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael</forenames></author></authors><title>Relaxed Equivariance via Multitask Learning</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Incorporating equivariance as an inductive bias into deep learning architectures to take advantage of the data symmetry has been successful in multiple applications, such as chemistry and dynamical systems. In particular, roto-translations are crucial for effectively modeling geometric graphs and molecules, where understanding the 3D structures enhances generalization. However, equivariant models often pose challenges due to their high computational complexity. In this paper, we introduce REMUL, a training procedure for approximating equivariance with multitask learning. We show that unconstrained models (which do not build equivariance into the architecture) can learn approximate symmetries by minimizing an additional simple equivariance loss. By formulating equivariance as a new learning objective, we can control the level of approximate equivariance in the model. Our method achieves competitive performance compared to equivariant baselines while being $10 \times$ faster at inference and $2.5 \times$ at training. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.18944</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.18944</id><created>2024-10-24</created><updated>2025-01-23</updated><authors><author><keyname>Huang</keyname><forenames>Tianyu</forenames></author><author><keyname>Ling</keyname><forenames>Jingwang</forenames></author><author><keyname>Zhao</keyname><forenames>Shuang</forenames></author><author><keyname>Xu</keyname><forenames>Feng</forenames></author></authors><title>Guiding-Based Importance Sampling for Walk on Stars</title><categories>cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Walk on stars (WoSt) has shown its power in being applied to Monte Carlo methods for solving partial differential equations, but the sampling techniques in WoSt are not satisfactory, leading to high variance. We propose a guiding-based importance sampling method to reduce the variance of WoSt. Drawing inspiration from path guiding in rendering, we approximate the directional distribution of the recursive term of WoSt using online-learned parametric mixture distributions, decoded by a lightweight neural field. This adaptive approach enables importance sampling the recursive term, which lacks shape information before computation. We introduce a reflection technique to represent guiding distributions at Neumann boundaries and incorporate multiple importance sampling with learnable selection probabilities to further reduce variance. We also present a practical GPU implementation of our method. Experiments show that our method effectively reduces variance compared to the original WoSt, given the same time or the same sample budget. Code and data will be released. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.21422</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.21422</id><created>2024-10-28</created><updated>2025-01-23</updated><authors><author><keyname>Cai</keyname><forenames>Feiyang</forenames></author><author><keyname>Hanna</keyname><forenames>Katelin</forenames></author><author><keyname>Zhu</keyname><forenames>Tianyu</forenames></author><author><keyname>Tzeng</keyname><forenames>Tzuen-Rong</forenames></author><author><keyname>Duan</keyname><forenames>Yongping</forenames></author><author><keyname>Liu</keyname><forenames>Ling</forenames></author><author><keyname>Pilla</keyname><forenames>Srikanth</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Luo</keyname><forenames>Feng</forenames></author></authors><title>A Foundation Model for Chemical Design and Property Prediction</title><categories>cs.CE</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Artificial intelligence (AI) has significantly advanced computational chemistry research in various tasks. However, traditional AI methods often rely on task-specific model designs and training, which constrain both the scalability of model size and generalization across different tasks. Here, we introduce ChemFM, a large foundation model specifically developed for chemicals. ChemFM comprises 3 billion parameters and is pre-trained on 178 million molecules using self-supervised causal language modeling to extract generalizable molecular representations. This model can be adapted to diverse downstream chemical applications using either full-parameter or parameter-efficient fine-tuning methods. ChemFM consistently outperforms state-of-the-art task-specific AI models across all tested tasks. Notably, it achieves up to 67.48% performance improvement across 34 property prediction benchmarks, up to 33.80% reduction in mean average deviation between conditioned and actual properties of generated molecules in conditional molecular generation tasks, and up to 3.7% top-1 accuracy improvement across 4 reaction prediction datasets. Moreover, ChemFM demonstrates its superior performance in predicting antibiotic activity and cytotoxicity, highlighting its potential to advance the discovery of novel antibiotics. We anticipate that ChemFM will significantly advance chemistry research by providing a foundation model capable of effectively generalizing across a broad range of tasks with minimal additional training. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.22948</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.22948</id><created>2024-10-30</created><updated>2025-01-24</updated><authors><author><keyname>Rønning</keyname><forenames>Ola</forenames></author><author><keyname>Nalisnick</keyname><forenames>Eric</forenames></author><author><keyname>Ley</keyname><forenames>Christophe</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author><author><keyname>Hamelryck</keyname><forenames>Thomas</forenames></author></authors><title>ELBOing Stein: Variational Bayes with Stein Mixture Inference</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Stein variational gradient descent (SVGD) [Liu and Wang, 2016] performs approximate Bayesian inference by representing the posterior with a set of particles. However, SVGD suffers from variance collapse, i.e. poor predictions due to underestimating uncertainty [Ba et al., 2021], even for moderately-dimensional models such as small Bayesian neural networks (BNNs). To address this issue, we generalize SVGD by letting each particle parameterize a component distribution in a mixture model. Our method, Stein Mixture Inference (SMI), optimizes a lower bound to the evidence (ELBO) and introduces user-specified guides parameterized by particles. SMI extends the Nonlinear SVGD framework [Wang and Liu, 2019] to the case of variational Bayes. SMI effectively avoids variance collapse, judging by a previously described test developed for this purpose, and performs well on standard data sets. In addition, SMI requires considerably fewer particles than SVGD to accurately estimate uncertainty for small BNNs. The synergistic combination of NSVGD, ELBO optimization and user-specified guides establishes a promising approach towards variational Bayesian inference in the case of tall and wide data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2410.23085</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2410.23085</id><created>2024-10-30</created><updated>2025-01-24</updated><authors><author><keyname>Wozniak</keyname><forenames>Maciej K.</forenames></author><author><keyname>Govindarajan</keyname><forenames>Hariprasath</forenames></author><author><keyname>Klingner</keyname><forenames>Marvin</forenames></author><author><keyname>Maurice</keyname><forenames>Camille</forenames></author><author><keyname>Kiran</keyname><forenames>B Ravi</forenames></author><author><keyname>Yogamani</keyname><forenames>Senthil</forenames></author></authors><title>S3PT: Scene Semantics and Structure Guided Clustering to Boost   Self-Supervised Pre-Training for Autonomous Driving</title><categories>cs.CV cs.AI cs.RO</categories><comments>Accepted for WACV 2025 (Oral)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent self-supervised clustering-based pre-training techniques like DINO and Cribo have shown impressive results for downstream detection and segmentation tasks. However, real-world applications such as autonomous driving face challenges with imbalanced object class and size distributions and complex scene geometries. In this paper, we propose S3PT a novel scene semantics and structure guided clustering to provide more scene-consistent objectives for self-supervised training. Specifically, our contributions are threefold: First, we incorporate semantic distribution consistent clustering to encourage better representation of rare classes such as motorcycles or animals. Second, we introduce object diversity consistent spatial clustering, to handle imbalanced and diverse object sizes, ranging from large background areas to small objects such as pedestrians and traffic signs. Third, we propose a depth-guided spatial clustering to regularize learning based on geometric information of the scene, thus further refining region separation on the feature level. Our learned representations significantly improve performance in downstream semantic segmentation and 3D object detection tasks on the nuScenes, nuImages, and Cityscapes datasets and show promising domain translation properties. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.00067</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.00067</id><created>2024-10-31</created><updated>2025-01-23</updated><authors><author><keyname>Norga</keyname><forenames>Quinten</forenames></author><author><keyname>Kundu</keyname><forenames>Suparna</forenames></author><author><keyname>Ojha</keyname><forenames>Uttam Kumar</forenames></author><author><keyname>Ganguly</keyname><forenames>Anindya</forenames></author><author><keyname>Karmakar</keyname><forenames>Angshuman</forenames></author><author><keyname>Verbauwhede</keyname><forenames>Ingrid</forenames></author></authors><title>Masking Gaussian Elimination at Arbitrary Order, with Application to   Multivariate- and Code-Based PQC</title><categories>cs.CR</categories><comments>31 pages, 9 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Digital signature schemes based on multivariate- and code-based hard problems are promising alternatives for lattice-based signature schemes, due to their small signature size. Gaussian Elimination (GE) is a critical operation in the signing procedure of these schemes. In this paper, we provide a masking scheme for GE with back substitution to defend against first- and higher-order attacks. To the best of our knowledge, this work is the first to analyze and propose masking techniques for multivariate- or code-based DS algorithms. We propose a masked algorithm for transforming a system of linear equations into row-echelon form. This is realized by introducing techniques for efficiently making leading (pivot) elements one while avoiding costly conversions between Boolean and multiplicative masking at all orders. We also propose a technique for efficient masked back substitution, which eventually enables a secure unmasking of the public output. All novel gadgets are proven secure in the $t$-probing model. Additionally, we evaluate the overhead of our countermeasure for several post-quantum candidates and their different security levels at first-, second-, and third-order, including UOV, MAYO, SNOVA, QR-UOV, and MQ-Sign. Notably, the operational cost of first-, second-, and third-order masked GE is 2.3$\times$ higher, and the randomness cost is 1.2$\times$ higher in MAYO compared to UOV for security levels III and V. In contrast, these costs are similar in UOV and MAYO for one version of level I. We also show detailed performance results for masked GE implementations for all three security versions of UOV on the Arm Cortex-M4 and compare them with unmasked results. Our masked implementation targeting UOV parameters has an overhead of factor 15.1$\times$, 15.2$\times$, and 15.4$\times$ compared to the unprotected implementation for NIST security level I, III, and V. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.00124</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.00124</id><created>2024-10-31</created><updated>2025-01-23</updated><authors><author><keyname>Kaplan</keyname><forenames>Berkay</forenames></author></authors><title>Globalping: A Community-Driven, Open-Source Platform for Scalable,   Real-Time Network Measurements</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present Globalping, an open-source, community-driven platform for scalable, real-time global network measurements. It democratizes access to network diagnostics by offering every user, including non-technicals, technicals, and companies, the ability to perform ping, traceroute, and DNS lookups from a globally distributed network of user-hosted probes using either the intuitive Globalping front-end or REST API. Unlike solutions like RIPE Atlas, official integrations with other platforms, such as Slack and GitHub, make Globalping even more effective in real-time monitoring and collaboration. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.03654</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.03654</id><created>2024-11-05</created><updated>2025-01-23</updated><authors><author><keyname>Kaplan</keyname><forenames>Berkay</forenames></author><author><keyname>Li</keyname><forenames>Buhe</forenames></author></authors><title>PyroGuardian: An IoT-Enabled System for Health and Location Monitoring   in High-Risk Firefighting Environments</title><categories>cs.NI cs.CY cs.HC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  First responders risk their lives to reduce property damage and prevent injuries during disasters. Among first responders, firefighters work with fires in residential properties, forests, or other locations where fire occurs. We built the PyroGuardian system that uses wearable modules to transmit unit information over Long Range (LoRa) to an Android tablet. The tablet runs our application, PyroPortal, to assign each firefighter's stats, such as body temperature, heart rate, and GPS location. PyroPortal displays this information on unit dashboards, and markers on Google Maps represent the firefighter's location and the direction they are facing. These dashboards can help the incident commander (IC) make more informed decisions on mission control operations and remove specific units whose health stats, such as oximeter and pulse, passed certain thresholds. PyroGuardian completes all these tasks at an affordable cost and in an impressive maximum range between the units and IC. In addition, PyroGuardian has various application scenarios, such as law enforcement and military operations, besides firefighting. We also conducted a sample mission inside a burning building while real firefighters watched. After the demonstration, they completed a survey on system usability and PyroGuardian's potential to meet their requirements. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.06560</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.06560</id><created>2024-11-10</created><updated>2025-01-23</updated><authors><author><keyname>Gorka</keyname><forenames>Joe</forenames></author><author><keyname>Rhodes</keyname><forenames>Noah</forenames></author><author><keyname>Roald</keyname><forenames>Line</forenames></author></authors><title>ElectricityEmissions.jl: A Framework for the Comparison of Carbon   Intensity Signals</title><categories>eess.SY cs.SY</categories><comments>Accepted to ACM e-Energy 2025</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  An increasing number of individuals, companies and organizations are interested in computing and minimizing the carbon emissions associated with their real-time electricity consumption. To achieve this, they require a carbon signal, i.e. a metric that defines the real-time carbon intensity of their electricity supply. Unfortunately, in a grid with multiple generation sources and multiple consumers, the physics of the system do not provide an unambiguous way to trace electricity from source to sink. As a result, there are a multitude of proposed carbon signals, each of which has a distinct set of properties and method of calculation. It remains unclear which signal best quantifies the carbon footprint of electricity. This paper seeks to inform the discussion about which carbon signal is better or more suitable for two important use cases, namely carbon-informed load shifting and carbon accounting. We do this by developing a new software package ElectricityEmissions$.$jl, that computes several established and newly proposed carbon emission metrics for standard electric grid test cases. We also demonstrate how the package can be used to investigate the effects of using these metrics to guide load shifting. Our results affirm previous research, which showed that the choice of carbon emission metric has significant impact on shifting results and associated carbon emission reductions. In addition, we demonstrate the impact of load shifting on both the consumers that perform the shifting and consumers that do not. Disconcertingly, we observe that shifting according to common metrics such as average carbon emissions can reduce the amount of emissions allocated to the consumer doing the shifting, while increasing the total emissions of the power system. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.07072</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.07072</id><created>2024-11-11</created><updated>2025-01-24</updated><authors><author><keyname>Eckert</keyname><forenames>Dominik</forenames></author><author><keyname>Ritschl</keyname><forenames>Ludwig</forenames></author><author><keyname>Syben</keyname><forenames>Christopher</forenames></author><author><keyname>Hümmer</keyname><forenames>Christian</forenames></author><author><keyname>Wicklein</keyname><forenames>Julia</forenames></author><author><keyname>Beister</keyname><forenames>Marcel</forenames></author><author><keyname>Kappler</keyname><forenames>Steffen</forenames></author><author><keyname>Stober</keyname><forenames>Sebastian</forenames></author></authors><title>An Interpretable X-ray Style Transfer via Trainable Local Laplacian   Filter</title><categories>cs.CV cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiologists have preferred visual impressions or 'styles' of X-ray images that are manually adjusted to their needs to support their diagnostic performance. In this work, we propose an automatic and interpretable X-ray style transfer by introducing a trainable version of the Local Laplacian Filter (LLF). From the shape of the LLF's optimized remap function, the characteristics of the style transfer can be inferred and reliability of the algorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray style features by replacing the remap function with a Multi-Layer Perceptron (MLP) and adding a trainable normalization layer. We demonstrate the effectiveness of the proposed method by transforming unprocessed mammographic X-ray images into images that match the style of target mammograms and achieve a Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline LLF style transfer method from Aubry et al. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.09018</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.09018</id><created>2024-11-13</created><updated>2025-01-24</updated><authors><author><keyname>Yanuka</keyname><forenames>Moran</forenames></author><author><keyname>Kish</keyname><forenames>Assaf Ben</forenames></author><author><keyname>Bitton</keyname><forenames>Yonatan</forenames></author><author><keyname>Szpektor</keyname><forenames>Idan</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>Bridging the Visual Gap: Fine-Tuning Multimodal Models with   Knowledge-Adapted Captions</title><categories>cs.CV cs.CL cs.LG</categories><comments>Accepted to NAACL 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent research increasingly focuses on training vision-language models (VLMs) with long, detailed image captions. However, small-scale VLMs often struggle to balance the richness of these captions with the risk of hallucinating content during fine-tuning. In this paper, we explore how well VLMs adapt to such captions. To quantify caption quality, we propose Decomposed NLI (DNLI), an evaluation framework that breaks down generated captions into individual propositions, assessing each in isolation. This fine-grained analysis reveals a critical balance between capturing descriptive details and preventing hallucinations. Our findings show that simply reducing caption complexity or employing standard data curation techniques does not effectively resolve this issue. To tackle this challenge, we introduce Knowledge Adapted (KnowAda) fine-tuning, a data-centric approach that automatically adapts training data with the model's existing knowledge and visual understanding. KnowAda minimizes hallucinations while preserving high descriptiveness. We validate this approach across several small-scale VLMs (up to 7B parameters) and dense caption datasets, demonstrating that KnowAda effectively balances hallucination reduction and descriptiveness. Our results show that KnowAda outperforms various baselines in both automatic metrics and human evaluations. We will release our code and models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.11081</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.11081</id><created>2024-11-17</created><updated>2025-01-24</updated><authors><author><keyname>Horych</keyname><forenames>Tomas</forenames></author><author><keyname>Mandl</keyname><forenames>Christoph</forenames></author><author><keyname>Ruas</keyname><forenames>Terry</forenames></author><author><keyname>Greiner-Petter</keyname><forenames>Andre</forenames></author><author><keyname>Gipp</keyname><forenames>Bela</forenames></author><author><keyname>Aizawa</keyname><forenames>Akiko</forenames></author><author><keyname>Spinde</keyname><forenames>Timo</forenames></author></authors><title>The Promises and Pitfalls of LLM Annotations in Dataset Labeling: a Case   Study on Media Bias Detection</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  High annotation costs from hiring or crowdsourcing complicate the creation of large, high-quality datasets needed for training reliable text classifiers. Recent research suggests using Large Language Models (LLMs) to automate the annotation process, reducing these costs while maintaining data quality. LLMs have shown promising results in annotating downstream tasks like hate speech detection and political framing. Building on the success in these areas, this study investigates whether LLMs are viable for annotating the complex task of media bias detection and whether a downstream media bias classifier can be trained on such data. We create annolexical, the first large-scale dataset for media bias classification with over 48000 synthetically annotated examples. Our classifier, fine-tuned on this dataset, surpasses all of the annotator LLMs by 5-9 percent in Matthews Correlation Coefficient (MCC) and performs close to or outperforms the model trained on human-labeled data when evaluated on two media bias benchmark datasets (BABE and BASIL). This study demonstrates how our approach significantly reduces the cost of dataset creation in the media bias domain and, by extension, the development of classifiers, while our subsequent behavioral stress-testing reveals some of its current limitations and trade-offs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.12692</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.12692</id><created>2024-11-19</created><updated>2025-01-24</updated><authors><author><keyname>Shin</keyname><forenames>Jiho</forenames></author><author><keyname>Yang</keyname><forenames>Hoeseok</forenames></author><author><keyname>Yi</keyname><forenames>Youngmin</forenames></author></authors><title>SparseInfer: Training-free Prediction of Activation Sparsity for Fast   LLM Inference</title><categories>cs.PF</categories><comments>7 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Leveraging sparsity is crucial for optimizing large language model inference. however, modern LLMs employing SiLU as their activation function exhibit minimal activation sparsity. Recent research has proposed replacing SiLU with ReLU to induce significant activation sparsity and showed no downstream task accuracy degradation through fine tuning. However, taking full advantage of it required training a predictor to estimate this sparsity. In this paper, we introduce SparseInfer, a simple, light weight, and training free predictor for activation sparsity of ReLU field LLMs, in which activation sparsity is predicted by comparing only the sign bits of inputs and weights. To compensate for possible prediction inaccuracy, an adaptive tuning of the predictor's conservativeness is enabled, which can also serve as a control knob for optimizing LLM inference. The proposed method achieves approximately faster inference speed over the state of the art, with negligible accuracy loss of within 1%p. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.12724</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.12724</id><created>2024-11-19</created><updated>2025-01-24</updated><authors><author><keyname>Nguyen</keyname><forenames>Huy Thong</forenames></author><author><keyname>Chu</keyname><forenames>En-Hung</forenames></author><author><keyname>Melvix</keyname><forenames>Lenord</forenames></author><author><keyname>Jiao</keyname><forenames>Jazon</forenames></author><author><keyname>Wen</keyname><forenames>Chunglin</forenames></author><author><keyname>Louie</keyname><forenames>Benjamin</forenames></author></authors><title>Heuristic-Free Multi-Teacher Learning</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Teacher2Task, a novel framework for multi-teacher learning that eliminates the need for manual aggregation heuristics. Existing multi-teacher methods typically rely on such heuristics to combine predictions from multiple teachers, often resulting in sub-optimal aggregated labels and the propagation of aggregation errors. Teacher2Task addresses these limitations by introducing teacher-specific input tokens and reformulating the training process. Instead of relying on aggregated labels, the framework transforms the training data, consisting of ground truth labels and annotations from N teachers, into N+1 distinct tasks: N auxiliary tasks that predict the labeling styles of the N individual teachers, and one primary task that focuses on the ground truth labels. This approach, drawing upon principles from multiple learning paradigms, demonstrates strong empirical results across a range of architectures, modalities, and tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.14288</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.14288</id><created>2024-11-21</created><updated>2025-01-23</updated><authors><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author><author><keyname>Cesa</keyname><forenames>Gabriele</forenames></author></authors><title>On the Sample Complexity of One Hidden Layer Networks with Equivariance,   Locality and Weight Sharing</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>48 pages, TMLR accepted</comments><msc-class>68T07</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks. However, it is not clear how each one of these design choices contributes to the generalization error. Through the lens of statistical learning theory, we aim to provide insight into this question by characterizing the relative impact of each choice on the sample complexity. We obtain lower and upper sample complexity bounds for a class of single hidden layer networks. For a large class of activation functions, the bounds depend merely on the norm of filters and are dimension-independent. We also provide bounds for max-pooling and an extension to multi-layer networks, both with mild dimension dependence. We provide a few takeaways from the theoretical results. It can be shown that depending on the weight-sharing mechanism, the non-equivariant weight-sharing can yield a similar generalization bound as the equivariant one. We show that locality has generalization benefits, however the uncertainty principle implies a trade-off between locality and expressivity. We conduct extensive experiments and highlight some consistent trends for these models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.17241</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.17241</id><created>2024-11-26</created><updated>2025-01-24</updated><authors><author><keyname>George</keyname><forenames>Ian</forenames></author><author><keyname>Zheng</keyname><forenames>Alice</forenames></author><author><keyname>Bansal</keyname><forenames>Akshay</forenames></author></authors><title>Divergence Inequalities with Applications in Ergodic Theory</title><categories>cs.IT math.IT quant-ph</categories><comments>Updated a few statements in a generalizing form, added more   references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The data processing inequality is central to information theory and motivates the study of monotonic divergences. However, it is not clear operationally we need to consider all such divergences. We establish a simple method for Pinsker inequalities as well as general bounds in terms of $\chi^{2}$-divergences for twice-differentiable $f$-divergences. These tools imply new relations for input-dependent contraction coefficients. We use these relations to show for many $f$-divergences the rate of contraction of a time homogeneous Markov chain is characterized by the input-dependent contraction coefficient of the $\chi^{2}$-divergence. This is efficient to compute and the fastest it could converge for a class of divergences. We show similar ideas hold for mixing times. Moreover, we extend these results to the Petz $f$-divergences in quantum information theory, albeit without any guarantee of efficient computation. These tools may have applications in other settings where iterative data processing is relevant. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2411.19377</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2411.19377</id><created>2024-11-28</created><authors><author><keyname>Nortmann</keyname><forenames>Benita</forenames></author><author><keyname>Sassano</keyname><forenames>Mario</forenames></author><author><keyname>Mylvaganam</keyname><forenames>Thulasi</forenames></author></authors><title>Feedback Nash equilibria for scalar N-player linear quadratic dynamic   games</title><categories>math.OC cs.SY eess.SY</categories><doi>10.1016/j.automatica.2025.112133</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Considering infinite-horizon, discrete-time, linear quadratic, N-player dynamic games with scalar dynamics, a graphical representation of feedback Nash equilibrium solutions is provided. This representation is utilised to derive conditions for the number and properties of different feedback Nash equilibria a game may admit. The results are illustrated via a numerical example. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.00430</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.00430</id><created>2024-11-30</created><updated>2025-01-23</updated><authors><author><keyname>Shen</keyname><forenames>Tingjia</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Wu</keyname><forenames>Chuhan</forenames></author><author><keyname>Chin</keyname><forenames>Jin Yao</forenames></author><author><keyname>Guo</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Yong</forenames></author><author><keyname>Guo</keyname><forenames>Huifeng</forenames></author><author><keyname>Lian</keyname><forenames>Defu</forenames></author><author><keyname>Tang</keyname><forenames>Ruiming</forenames></author><author><keyname>Chen</keyname><forenames>Enhong</forenames></author></authors><title>Optimizing Sequential Recommendation Models with Scaling Laws and   Approximate Entropy</title><categories>cs.AI cs.IR</categories><comments>12 pages, 5 figures</comments><msc-class>68P20</msc-class><acm-class>H.3.4; I.2.6</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scaling Laws have emerged as a powerful framework for understanding how model performance evolves as they increase in size, providing valuable insights for optimizing computational resources. In the realm of Sequential Recommendation (SR), which is pivotal for predicting users' sequential preferences, these laws offer a lens through which to address the challenges posed by the scalability of SR models. However, the presence of structural and collaborative issues in recommender systems prevents the direct application of the Scaling Law (SL) in these systems. In response, we introduce the Performance Law for SR models, which aims to theoretically investigate and model the relationship between model performance and data quality. Specifically, we first fit the HR and NDCG metrics to transformer-based SR models. Subsequently, we propose Approximate Entropy (ApEn) to assess data quality, presenting a more nuanced approach compared to traditional data quantity metrics. Our method enables accurate predictions across various dataset scales and model sizes, demonstrating a strong correlation in large SR models and offering insights into achieving optimal performance for any given model configuration. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.00532</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.00532</id><created>2024-11-30</created><updated>2025-01-23</updated><authors><author><keyname>Kasmaee</keyname><forenames>Ali Shiraee</forenames></author><author><keyname>Khodadad</keyname><forenames>Mohammad</forenames></author><author><keyname>Saloot</keyname><forenames>Mohammad Arshi</forenames></author><author><keyname>Sherck</keyname><forenames>Nicholas</forenames></author><author><keyname>Dokas</keyname><forenames>Stephen</forenames></author><author><keyname>Mahyar</keyname><forenames>Hamidreza</forenames></author><author><keyname>Samiee</keyname><forenames>Soheila</forenames></author></authors><title>ChemTEB: Chemical Text Embedding Benchmark, an Overview of Embedding   Models Performance &amp; Efficiency on a Specific Domain</title><categories>cs.CL</categories><journal-ref>Proceedings of The 4th NeurIPS Efficient Natural Language and   Speech Processing Workshop, PMLR 262:512-531 (2024)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent advancements in language models have started a new era of superior information retrieval and content generation, with embedding models playing an important role in optimizing data representation efficiency and performance. While benchmarks like the Massive Text Embedding Benchmark (MTEB) have standardized the evaluation of general domain embedding models, a gap remains in specialized fields such as chemistry, which require tailored approaches due to domain-specific challenges. This paper introduces a novel benchmark, the Chemical Text Embedding Benchmark (ChemTEB), designed specifically for the chemical sciences. ChemTEB addresses the unique linguistic and semantic complexities of chemical literature and data, offering a comprehensive suite of tasks on chemical domain data. Through the evaluation of 34 open-source and proprietary models using this benchmark, we illuminate the strengths and weaknesses of current methodologies in processing and understanding chemical information. Our work aims to equip the research community with a standardized, domain-specific evaluation framework, promoting the development of more precise and efficient NLP models for chemistry-related applications. Furthermore, it provides insights into the performance of generic models in a domain-specific context. ChemTEB comes with open-source code and data, contributing further to its accessibility and utility. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.01476</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.01476</id><created>2024-12-02</created><updated>2025-01-24</updated><authors><author><keyname>Jiang</keyname><forenames>RuiZhe</forenames></author><author><keyname>Lei</keyname><forenames>Haotian</forenames></author></authors><title>ConsistentFeature: A Plug-and-Play Component for Neural Network   Regularization</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Over-parameterized neural network models often lead to significant performance discrepancies between training and test sets, a phenomenon known as overfitting. To address this, researchers have proposed numerous regularization techniques tailored to various tasks and model architectures. In this paper, we introduce a simple perspective on overfitting: models learn different representations in different i.i.d. datasets. Based on this viewpoint, we propose an adaptive method, ConsistentFeature, that regularizes the model by constraining feature differences across random subsets of the same training set. Due to minimal prior assumptions, this approach is applicable to almost any architecture and task. Our experiments show that it effectively reduces overfitting, with low sensitivity to hyperparameters and minimal computational cost. It demonstrates particularly strong memory suppression and promotes normal convergence, even when the model has already started to overfit. Even in the absence of significant overfitting, our method consistently improves accuracy and reduces validation loss. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.05074</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.05074</id><created>2024-12-06</created><updated>2025-01-23</updated><authors><author><keyname>Zhao</keyname><forenames>Zijian</forenames></author><author><keyname>Chen</keyname><forenames>Tingwei</forenames></author><author><keyname>Meng</keyname><forenames>Fanyi</forenames></author><author><keyname>Cai</keyname><forenames>Zhijie</forenames></author><author><keyname>Li</keyname><forenames>Hang</forenames></author><author><keyname>Li</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Zhu</keyname><forenames>Guangxu</forenames></author></authors><title>LoFi: Vision-Aided Label Generator for Wi-Fi Localization and Tracking</title><categories>cs.CV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven Wi-Fi localization and tracking have shown great promise due to their lower reliance on specialized hardware compared to model-based methods. However, most existing data collection techniques provide only coarse-grained ground truth or a limited number of labeled points, significantly hindering the advancement of data-driven approaches. While systems like lidar can deliver precise ground truth, their high costs make them inaccessible to many users. To address these challenges, we propose LoFi, a vision-aided label generator for Wi-Fi localization and tracking. LoFi can generate ground truth position coordinates solely from 2D images, offering high precision, low cost, and ease of use. Utilizing our method, we have compiled a Wi-Fi tracking and localization dataset using the ESP32-S3 and a webcam, which will be open-sourced along with the code upon publication. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.06394</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.06394</id><created>2024-12-09</created><updated>2025-01-23</updated><authors><author><keyname>Hu</keyname><forenames>Lanxiang</forenames></author><author><keyname>Li</keyname><forenames>Qiyu</forenames></author><author><keyname>Xie</keyname><forenames>Anze</forenames></author><author><keyname>Jiang</keyname><forenames>Nan</forenames></author><author><keyname>Stoica</keyname><forenames>Ion</forenames></author><author><keyname>Jin</keyname><forenames>Haojian</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author></authors><title>GameArena: Evaluating LLM Reasoning through Live Computer Games</title><categories>cs.AI cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluating the reasoning abilities of large language models (LLMs) is challenging. Existing benchmarks often depend on static datasets, which are vulnerable to data contamination and may get saturated over time, or on binary live human feedback that conflates reasoning with other abilities. As the most prominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in real-world settings, but lacks the granularity in assessing specific reasoning capabilities. We introduce GameArena, a dynamic benchmark designed to evaluate LLM reasoning capabilities through interactive gameplay with humans. GameArena consists of three games designed to test specific reasoning capabilities (e.g., deductive and inductive reasoning), while keeping participants entertained and engaged. We analyze the gaming data retrospectively to uncover the underlying reasoning processes of LLMs and measure their fine-grained reasoning capabilities. We collect over 2000 game sessions and provide detailed assessments of various reasoning capabilities for five state-of-the-art LLMs. Our user study with 100 participants suggests that GameArena improves user engagement compared to Chatbot Arena. For the first time, GameArena enables the collection of step-by-step LLM reasoning data in the wild. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.06695</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.06695</id><created>2024-12-09</created><updated>2025-01-24</updated><authors><author><keyname>McGuire</keyname><forenames>Niall</forenames></author><author><keyname>Moshfeghi</keyname><forenames>Yashar</forenames></author></authors><title>DEEPER: Dense Electroencephalography Passage Retrieval</title><categories>cs.IR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A fundamental challenge in Information Retrieval (IR) is the cognitive burden of translating internal information needs into explicit textual queries. This translation barrier particularly affects users with undefined information needs or those who face physical constraints in traditional text input methods. While Brain-Machine Interfaces (BMIs) have emerged as a potential solution for direct neural query interpretation, existing approaches that attempt to convert brain signals into text queries have demonstrated limited success in capturing the complexity of neural semantic patterns. This paper introduces DEEPER Dense EEG Passage Retrieval, a novel framework that bypasses the need for explicit query translation by directly mapping electroencephalography (EEG) signals to relevant text passages. Our approach employs dense retrieval architectures to create a unified semantic space where both EEG signals and text passages can be effectively compared. Experimental evaluation on the ZuCo dataset shows that DEEPER substantially outperforms current EEG-to-text baselines, achieving nearly 5x improvement in retrieval precision while demonstrating robust performance across a diverse set of 30 participants. Through detailed ablation analysis, we identify key architectural components, including specialized neural encoders and strategic negative sampling techniques, that enable effective cross-modal semantic alignment. Our findings demonstrate the feasibility of direct EEG passage retrieval and suggest new possibilities for developing IR systems that can more naturally interface with users' cognitive processes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.09299</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.09299</id><created>2024-12-12</created><updated>2024-12-14</updated><authors><author><keyname>Sakuma</keyname><forenames>Daisuke</forenames></author><author><keyname>Taherkhani</keyname><forenames>Amin</forenames></author><author><keyname>Tsuno</keyname><forenames>Tomoki</forenames></author><author><keyname>Sasaki</keyname><forenames>Toshihiko</forenames></author><author><keyname>Shimizu</keyname><forenames>Hikaru</forenames></author><author><keyname>Teramoto</keyname><forenames>Kentaro</forenames></author><author><keyname>Todd</keyname><forenames>Andrew</forenames></author><author><keyname>Ueno</keyname><forenames>Yosuke</forenames></author><author><keyname>Hajdušek</keyname><forenames>Michal</forenames></author><author><keyname>Ikuta</keyname><forenames>Rikizo</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author><author><keyname>Nagayama</keyname><forenames>Shota</forenames></author></authors><title>An Optical Interconnect for Modular Quantum Computers</title><categories>quant-ph cs.AR</categories><comments>14 pages, 11 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much like classical supercomputers, scaling up quantum computers requires an optical interconnect. However, signal attenuation leads to irreversible qubit loss, making quantum interconnect design guidelines and metrics different from conventional computing. Inspired by the classical Dragonfly topology, we propose a multi-group structure where the group switch routes photons emitted by computational end nodes to the group's shared pool of Bell state analyzers (which conduct the entanglement swapping that creates end-to-end entanglement) or across a low-diameter path to another group. We present a full-stack analysis of system performance, a combination of distributed and centralized protocols, and a resource scheduler that plans qubit placement and communications for large-scale, fault-tolerant systems. We implement a prototype three-node switched interconnect and create two-hop entanglement with fidelities of at least 0.6. Our design emphasizes reducing network hops and optical components to simplify system stabilization while flexibly adjusting optical path lengths. Based on evaluated loss and infidelity budgets, we find that moderate-radix switches enable systems meeting expected near-term needs, and large systems are feasible. Our design is expected to be effective for a variety of quantum computing technologies, including ion traps and superconducting qubits with appropriate wavelength transduction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.09460</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.09460</id><created>2024-12-12</created><updated>2025-01-24</updated><authors><author><keyname>de la Rosa</keyname><forenames>Javier</forenames></author><author><keyname>Mikhailov</keyname><forenames>Vladislav</forenames></author><author><keyname>Zhang</keyname><forenames>Lemei</forenames></author><author><keyname>Wetjen</keyname><forenames>Freddy</forenames></author><author><keyname>Samuel</keyname><forenames>David</forenames></author><author><keyname>Liu</keyname><forenames>Peng</forenames></author><author><keyname>Braaten</keyname><forenames>Rolv-Arild</forenames></author><author><keyname>Mæhlum</keyname><forenames>Petter</forenames></author><author><keyname>Birkenes</keyname><forenames>Magnus Breder</forenames></author><author><keyname>Kutuzov</keyname><forenames>Andrey</forenames></author><author><keyname>Enstad</keyname><forenames>Tita</forenames></author><author><keyname>Farsethås</keyname><forenames>Hans Christian</forenames></author><author><keyname>Brygfjeld</keyname><forenames>Svein Arne</forenames></author><author><keyname>Gulla</keyname><forenames>Jon Atle</forenames></author><author><keyname>Oepen</keyname><forenames>Stephan</forenames></author><author><keyname>Velldal</keyname><forenames>Erik</forenames></author><author><keyname>Østgulen</keyname><forenames>Wilfred</forenames></author><author><keyname>Øvrelid</keyname><forenames>Liljia</forenames></author><author><keyname>Myhre</keyname><forenames>Aslak Sira</forenames></author></authors><title>The Impact of Copyrighted Material on Large Language Models: A Norwegian   Perspective</title><categories>cs.CL</categories><comments>17 pages, 5 figures, 8 tables. Accepted at NoDaLiDa/Baltic-HLT 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of copyrighted materials in training language models raises critical legal and ethical questions. This paper presents a framework for and the results of empirically assessing the impact of publisher-controlled copyrighted corpora on the performance of generative large language models (LLMs) for Norwegian. When evaluated on a diverse set of tasks, we found that adding both books and newspapers to the data mixture of LLMs tend to improve their performance, while the addition of fiction works seems to be detrimental. Our experiments could inform the creation of a compensation scheme for authors whose works contribute to AI development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.10381</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.10381</id><created>2024-11-27</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Jingxin</forenames></author><author><keyname>Gao</keyname><forenames>Xiang</forenames></author><author><keyname>Li</keyname><forenames>Yisha</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Lu</keyname><forenames>Haiyang</forenames></author><author><keyname>Wang</keyname><forenames>Ben</forenames></author></authors><title>Supervised Learning-enhanced Multi-Group Actor Critic for Live Stream   Allocation in Feed</title><categories>cs.IR cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reinforcement Learning (RL) has been widely applied in recommendation systems to capture long-term user engagement, thus improving dwelling time and improving user retention. In the context of a short video &amp; live stream mixed recommendation scenario, the live stream recommendation system (RS) decides whether to inject at most one live stream into the video feed for each user request. To maximize long-term user engagement, it is crucial to determine an optimal live stream injection policy for accurate live stream allocation. However, traditional RL algorithms often face divergence and instability problems, and these issues may cause too many live stream allocation, which interrupts user's short video interest and leads to a decrease in the user's app usage duration. To address these challenges, we propose a novel Supervised Learning-enhanced Multi-Group Actor Critic algorithm (SL-MGAC). Specifically, we introduce a supervised learning-enhanced actor-critic framework that incorporates variance reduction techniques, where multi-task reward learning helps restrict bootstrapping error accumulation during critic learning. Additionally, we design a multi-group state decomposition module for both actor and critic networks to reduce prediction variance and improve model stability. We also propose a novel reward function to prevent overly greedy live stream allocation. Empirically, we evaluate the SL-MGAC algorithm using offline policy evaluation (OPE) and online A/B testing. Experimental results demonstrate that the proposed method not only outperforms baseline methods under the platform-level constraints but also exhibits enhanced stability in online recommendation scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.12612</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.12612</id><created>2024-12-17</created><updated>2025-01-24</updated><authors><author><keyname>Tiwari</keyname><forenames>Aman</forenames></author><author><keyname>Malay</keyname><forenames>Shiva Krishna Reddy</forenames></author><author><keyname>Yadav</keyname><forenames>Vikas</forenames></author><author><keyname>Hashemi</keyname><forenames>Masoud</forenames></author><author><keyname>Madhusudhan</keyname><forenames>Sathwik Tejaswi</forenames></author></authors><title>Auto-Cypher: Improving LLMs on Cypher generation via LLM-supervised   generation-verification framework</title><categories>cs.CL cs.AI cs.IR cs.LG</categories><comments>Accepted at NAACL 2025 main conference</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Graph databases like Neo4j are gaining popularity for handling complex, interconnected data, over traditional relational databases in modeling and querying relationships. While translating natural language into SQL queries is well-researched, generating Cypher queries for Neo4j remains relatively underexplored. In this work, we present an automated, LLM-Supervised, pipeline to generate high-quality synthetic data for Text2Cypher. Our Cypher data generation pipeline introduces LLM-As-Database-Filler, a novel strategy for ensuring Cypher query correctness, thus resulting in high quality generations. Using our pipeline, we generate high quality Text2Cypher data - SynthCypher containing 29.8k instances across various domains and queries with varying complexities. Training open-source LLMs like LLaMa-3.1-8B, Mistral-7B, and QWEN-7B on SynthCypher results in performance gains of up to 40% on the Text2Cypher test split and 30% on the SPIDER benchmark, adapted for graph databases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.13012</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.13012</id><created>2024-12-17</created><authors><author><keyname>Kaplan</keyname><forenames>Daniel</forenames></author><author><keyname>Zhang</keyname><forenames>Adam</forenames></author><author><keyname>Blawat</keyname><forenames>Joanna</forenames></author><author><keyname>Jin</keyname><forenames>Rongying</forenames></author><author><keyname>Cava</keyname><forenames>Robert J.</forenames></author><author><keyname>Oudovenko</keyname><forenames>Viktor</forenames></author><author><keyname>Kotliar</keyname><forenames>Gabriel</forenames></author><author><keyname>Sengupta</keyname><forenames>Anirvan M.</forenames></author><author><keyname>Xie</keyname><forenames>Weiwei</forenames></author></authors><title>Deep Learning Based Superconductivity: Prediction and Experimental Tests</title><categories>cs.LG cond-mat.mtrl-sci cond-mat.str-el</categories><comments>14 pages + 2 appendices + references. EPJ submission</comments><journal-ref>Eur. Phys. J. Plus (2025) 140:58</journal-ref><doi>10.1140/epjp/s13360-024-05947-w</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discovery of novel superconducting materials is a longstanding challenge in materials science, with a wealth of potential for applications in energy, transportation, and computing. Recent advances in artificial intelligence (AI) have enabled expediting the search for new materials by efficiently utilizing vast materials databases. In this study, we developed an approach based on deep learning (DL) to predict new superconducting materials. We have synthesized a compound derived from our DL network and confirmed its superconducting properties in agreement with our prediction. Our approach is also compared to previous work based on random forests (RFs). In particular, RFs require knowledge of the chem-ical properties of the compound, while our neural net inputs depend solely on the chemical composition. With the help of hints from our network, we discover a new ternary compound $\textrm{Mo}_{20}\textrm{Re}_{6}\textrm{Si}_{4}$, which becomes superconducting below 5.4 K. We further discuss the existing limitations and challenges associated with using AI to predict and, along with potential future research directions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.14063</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.14063</id><created>2024-12-18</created><updated>2025-01-23</updated><authors><author><keyname>Thompson</keyname><forenames>Kyle</forenames></author><author><keyname>Saavedra</keyname><forenames>Nuno</forenames></author><author><keyname>Carrott</keyname><forenames>Pedro</forenames></author><author><keyname>Fisher</keyname><forenames>Kevin</forenames></author><author><keyname>Sanchez-Stern</keyname><forenames>Alex</forenames></author><author><keyname>Brun</keyname><forenames>Yuriy</forenames></author><author><keyname>Ferreira</keyname><forenames>João F.</forenames></author><author><keyname>Lerner</keyname><forenames>Sorin</forenames></author><author><keyname>First</keyname><forenames>Emily</forenames></author></authors><title>Rango: Adaptive Retrieval-Augmented Proving for Automated Software   Verification</title><categories>cs.SE cs.AI</categories><comments>In Proceedings of the 47th International Conference on Software   Engineering (ICSE), Ottawa, ON, Canada, April 2025</comments><acm-class>D.2.4; I.2.7; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal verification using proof assistants, such as Coq, enables the creation of high-quality software. However, the verification process requires significant expertise and manual effort to write proofs. Recent work has explored automating proof synthesis using machine learning and large language models (LLMs). This work has shown that identifying relevant premises, such as lemmas and definitions, can aid synthesis. We present Rango, a fully automated proof synthesis tool for Coq that automatically identifies relevant premises and also similar proofs from the current project and uses them during synthesis. Rango uses retrieval augmentation at every step of the proof to automatically determine which proofs and premises to include in the context of its fine-tuned LLM. In this way, Rango adapts to the project and to the evolving state of the proof. We create a new dataset, CoqStoq, of 2,226 open-source Coq projects and 196,929 theorems from GitHub, which includes both training data and a curated evaluation benchmark of well-maintained projects. On this benchmark, Rango synthesizes proofs for 32.0% of the theorems, which is 29% more theorems than the prior state-of-the-art tool Tactician. Our evaluation also shows that Rango adding relevant proofs to its context leads to a 47% increase in the number of theorems proven. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.14809</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.14809</id><created>2024-12-19</created><updated>2025-01-24</updated><authors><author><keyname>Tu</keyname><forenames>Zeao</forenames></author><author><keyname>Meng</keyname><forenames>Xiangdi</forenames></author><author><keyname>He</keyname><forenames>Yu</forenames></author><author><keyname>Yao</keyname><forenames>Zihan</forenames></author><author><keyname>Qi</keyname><forenames>Tianyu</forenames></author><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>ResoFilter: Fine-grained Synthetic Data Filtering for Large Language   Models through Data-Parameter Resonance Analysis</title><categories>cs.CL</categories><comments>Accepted by NAACL 2025 Findings</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large language models (LLMs) have shown remarkable effectiveness across various domains, with data augmentation methods utilizing GPT for synthetic data generation becoming prevalent. However, the quality and utility of augmented data remain questionable, and current methods lack clear metrics for evaluating data characteristics. To address these challenges, we propose ResoFilter, a novel method that integrates models, data, and tasks to refine datasets. ResoFilter leverages the fine-tuning process to obtain Data-Parameter features for data selection, offering improved interpretability by representing data characteristics through model weights. Our experiments demonstrate that ResoFilter achieves comparable results to full-scale fine-tuning using only half the data in mathematical tasks and exhibits strong generalization across different models and domains. This method provides valuable insights for constructing synthetic datasets and evaluating high-quality data, offering a promising solution for enhancing data augmentation techniques and improving training dataset quality for LLMs. For reproducibility, we will release our code and data upon acceptance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.15799</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.15799</id><created>2024-12-20</created><updated>2025-01-24</updated><authors><author><keyname>Lieb</keyname><forenames>Alexander</forenames></author><author><keyname>Göttmann</keyname><forenames>Hendrik</forenames></author><author><keyname>Luthmann</keyname><forenames>Lars</forenames></author><author><keyname>Lochau</keyname><forenames>Malte</forenames></author><author><keyname>Schürr</keyname><forenames>Andy</forenames></author></authors><title>Checking Timed Bisimilarity with Virtual Clocks</title><categories>cs.FL</categories><comments>50 main pages, 128 pages appendix</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timed automata are a widely used formalism for specifying the discrete-state/continuous-time behavior of time-critical reactive systems. For the fundamental verification problem of comparing two timed automata, it has been shown that timed trace equivalence is undecidable, while timed bisimulation is decidable. The corresponding decidability proof uses region graphs, a finite but space-consuming characterization of timed automata semantics. Most verification tools use zone graphs instead, a symbolic and, on average, more space-efficient representation of timed automata semantics. However, zone graphs provide correct results only for those verification tasks that are reducible to reachability problems, and are too imprecise for timed bisimilarity checking. To the best of our knowledge, there is currently no practical tool for automated timed bisimilarity checking. In this paper, we propose a new representation of timed automata semantics that extends zone graphs by so-called virtual clocks. Our zone-based construction is, on average, significantly smaller than the corresponding region graph representation. We also present experimental results obtained by applying our tool implementation to timed automata models, which are often used to evaluate timed automata analysis techniques. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.16006</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.16006</id><created>2024-12-20</created><updated>2025-01-24</updated><authors><author><keyname>Deniau</keyname><forenames>Laurent</forenames></author></authors><title>MAD-NG, a standalone multiplatform tool for linear and non-linear optics   design and optimisation</title><categories>cs.CE</categories><comments>13 pages, to be published in "Appears in the proceedings of the 14th   International Computational Accelerator Physics Conference (ICAP 24), 2-5   October 2024, Germany"</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The paper will provide an overview of the capabilities of the Methodical Accelerator Design Next Generation (MAD-NG) tool. MAD-NG is a standalone, all-in-one, multi-platform tool well-suited for linear and nonlinear optics design and optimization, and has already been used in large-scale studies such as HiLumi-LHC or FCC-ee. It embeds LuaJIT, an extremely fast tracing just-in-time compiler for the Lua programming language, delivering exceptional versatility and performance for the forefront of computational physics. The core of MAD-NG relies on the fast Generalized Truncated Power Series Algebra (GTPSA) library, which has been specially developed to handle many parameters and high-order differential algebra, including Lie map operators. This ecosystem offers powerful features for the analysis and optimization of linear and nonlinear optics, thanks to the fast parametric nonlinear normal forms and the polyvalent matching command. A few examples and results will complete this overview of the MAD-NG application. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.17094</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.17094</id><created>2024-12-22</created><updated>2025-01-24</updated><authors><author><keyname>Akib</keyname><forenames>Md. Ahnaf</forenames></author><author><keyname>Mazumder</keyname><forenames>Md. Muktadir</forenames></author><author><keyname>Ahsan</keyname><forenames>Salman</forenames></author></authors><title>Analysis on LLMs Performance for Code Summarization</title><categories>cs.SE cs.AI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Code summarization aims to generate concise natural language descriptions for source code. Deep learning has been used more and more recently in software engineering, particularly for tasks like code creation and summarization. Specifically, it appears that the most current Large Language Models with coding perform well on these tasks. Large Language Models (LLMs) have significantly advanced the field of code summarization, providing sophisticated methods for generating concise and accurate summaries of source code. This study aims to perform a comparative analysis of several open-source LLMs, namely LLaMA-3, Phi-3, Mistral, and Gemma. These models' performance is assessed using important metrics such as BLEU\textsubscript{3.1} and ROUGE\textsubscript{3.2}.   Through this analysis, we seek to identify the strengths and weaknesses of each model, offering insights into their applicability and effectiveness in code summarization tasks. Our findings contribute to the ongoing development and refinement of LLMs, supporting their integration into tools that enhance software development and maintenance processes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.17640</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.17640</id><created>2024-12-23</created><updated>2025-01-24</updated><authors><author><keyname>Spurio</keyname><forenames>Federico</forenames></author><author><keyname>Bahrami</keyname><forenames>Emad</forenames></author><author><keyname>Francesca</keyname><forenames>Gianpiero</forenames></author><author><keyname>Gall</keyname><forenames>Juergen</forenames></author></authors><title>Hierarchical Vector Quantization for Unsupervised Action Segmentation</title><categories>cs.CV</categories><comments>To be published in Conference on Artificial Intelligence (AAAI) 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we address unsupervised temporal action segmentation, which segments a set of long, untrimmed videos into semantically meaningful segments that are consistent across videos. While recent approaches combine representation learning and clustering in a single step for this task, they do not cope with large variations within temporal segments of the same class. To address this limitation, we propose a novel method, termed Hierarchical Vector Quantization (HVQ), that consists of two subsequent vector quantization modules. This results in a hierarchical clustering where the additional subclusters cover the variations within a cluster. We demonstrate that our approach captures the distribution of segment lengths much better than the state of the art. To this end, we introduce a new metric based on the Jensen-Shannon Distance (JSD) for unsupervised temporal action segmentation. We evaluate our approach on three public datasets, namely Breakfast, YouTube Instructional and IKEA ASM. Our approach outperforms the state of the art in terms of F1 score, recall and JSD. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.18180</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.18180</id><created>2024-12-24</created><updated>2025-01-24</updated><authors><author><keyname>Nanmo</keyname><forenames>Hisayoshi</forenames></author><author><keyname>Kuroki</keyname><forenames>Manabu</forenames></author></authors><title>PCM Selector: Penalized Covariate-Mediator Selection Operator for   Evaluating Linear Causal Effects</title><categories>stat.ME cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  For a data-generating process for random variables that can be described with a linear structural equation model, we consider a situation in which (i) a set of covariates satisfying the back-door criterion cannot be observed or (ii) such a set can be observed, but standard statistical estimation methods cannot be applied to estimate causal effects because of multicollinearity/high-dimensional data problems. We propose a novel two-stage penalized regression approach, the penalized covariate-mediator selection operator (PCM Selector), to estimate the causal effects in such scenarios. Unlike existing penalized regression analyses, when a set of intermediate variables is available, PCM Selector provides a consistent or less biased estimator of the causal effect. In addition, PCM Selector provides a variable selection procedure for intermediate variables to obtain better estimation accuracy of the causal effects than does the back-door criterion. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.18442</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.18442</id><created>2024-12-24</created><updated>2025-01-24</updated><authors><author><keyname>Schröer</keyname><forenames>Saskia Laura</forenames></author><author><keyname>Apruzzese</keyname><forenames>Giovanni</forenames></author><author><keyname>Human</keyname><forenames>Soheil</forenames></author><author><keyname>Laskov</keyname><forenames>Pavel</forenames></author><author><keyname>Anderson</keyname><forenames>Hyrum S.</forenames></author><author><keyname>Bernroider</keyname><forenames>Edward W. N.</forenames></author><author><keyname>Fass</keyname><forenames>Aurore</forenames></author><author><keyname>Nassi</keyname><forenames>Ben</forenames></author><author><keyname>Rimmer</keyname><forenames>Vera</forenames></author><author><keyname>Roli</keyname><forenames>Fabio</forenames></author><author><keyname>Salam</keyname><forenames>Samer</forenames></author><author><keyname>Shen</keyname><forenames>Ashley</forenames></author><author><keyname>Sunyaev</keyname><forenames>Ali</forenames></author><author><keyname>Wadhwa-Brown</keyname><forenames>Tim</forenames></author><author><keyname>Wagner</keyname><forenames>Isabel</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author></authors><title>SoK: On the Offensive Potential of AI</title><categories>cs.CR cs.AI cs.CY cs.LG</categories><comments>Systematization of Knowledge (SoK) paper. Accepted to the 3rd IEEE   Conference on Secure and Trustworthy Machine Learning (SaTML'25)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Our society increasingly benefits from Artificial Intelligence (AI). Unfortunately, more and more evidence shows that AI is also used for offensive purposes. Prior works have revealed various examples of use cases in which the deployment of AI can lead to violation of security and privacy objectives. No extant work, however, has been able to draw a holistic picture of the offensive potential of AI. In this SoK paper we seek to lay the ground for a systematic analysis of the heterogeneous capabilities of offensive AI. In particular we (i) account for AI risks to both humans and systems while (ii) consolidating and distilling knowledge from academic literature, expert opinions, industrial venues, as well as laypeople -- all of which being valuable sources of information on offensive AI.   To enable alignment of such diverse sources of knowledge, we devise a common set of criteria reflecting essential technological factors related to offensive AI. With the help of such criteria, we systematically analyze: 95 research papers; 38 InfoSec briefings (from, e.g., BlackHat); the responses of a user study (N=549) entailing individuals with diverse backgrounds and expertise; and the opinion of 12 experts. Our contributions not only reveal concerning ways (some of which overlooked by prior work) in which AI can be offensively used today, but also represent a foothold to address this threat in the years to come. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.19289</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.19289</id><created>2024-12-26</created><updated>2025-01-24</updated><authors><author><keyname>Kim</keyname><forenames>Taewhan</forenames></author><author><keyname>Lee</keyname><forenames>Soeun</forenames></author><author><keyname>Kim</keyname><forenames>Si-Woo</forenames></author><author><keyname>Kim</keyname><forenames>Dong-Jin</forenames></author></authors><title>ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image   Captioning</title><categories>cs.CV cs.AI cs.CL cs.LG</categories><comments>Accepted to AAAI 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent lightweight image captioning models using retrieved data mainly focus on text prompts. However, previous works only utilize the retrieved text as text prompts, and the visual information relies only on the CLIP visual embedding. Because of this issue, there is a limitation that the image descriptions inherent in the prompt are not sufficiently reflected in the visual embedding space. To tackle this issue, we propose ViPCap, a novel retrieval text-based visual prompt for lightweight image captioning. ViPCap leverages the retrieved text with image information as visual prompts to enhance the ability of the model to capture relevant visual information. By mapping text prompts into the CLIP space and generating multiple randomized Gaussian distributions, our method leverages sampling to explore randomly augmented distributions and effectively retrieves the semantic features that contain image information. These retrieved features are integrated into the image and designated as the visual prompt, leading to performance improvements on the datasets such as COCO, Flickr30k, and NoCaps. Experimental results demonstrate that ViPCap significantly outperforms prior lightweight captioning models in efficiency and effectiveness, demonstrating the potential for a plug-and-play solution. The source code is available at https://github.com/taewhankim/VIPCAP. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2412.20211</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2412.20211</id><created>2024-12-28</created><updated>2025-01-24</updated><authors><author><keyname>Ma</keyname><forenames>Hongxu</forenames></author><author><keyname>Tian</keyname><forenames>Kai</forenames></author><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Xuefeng</forenames></author><author><keyname>Chen</keyname><forenames>Chunjie</forenames></author><author><keyname>Li</keyname><forenames>Han</forenames></author><author><keyname>Guan</keyname><forenames>Jihong</forenames></author><author><keyname>Zhou</keyname><forenames>Shuigeng</forenames></author></authors><title>Sequence Generation Modeling for Continuous Value Prediction</title><categories>cs.LG cs.IR</categories><comments>10 pages, 5 figures, conference or other essential info</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous value prediction (CVP) plays a crucial role in short video recommendation, capturing user preferences through precise numerical estimations. However, traditional regression-based methods often struggle with challenges like wide value ranges and imbalanced data, leading to prediction bias. While ordinal classification approaches have been introduced to address these issues, their reliance on discretization reduces accuracy and overlooks inherent relationships between intervals. To overcome these limitations, we introduce a novel Generative Regression (GR) framework for CVP, inspired by sequence generation techniques in language modeling. Our method transforms numerical values into token sequences through structural discretization, preserving original data fidelity while improving prediction precision. Leveraging a carefully crafted vocabulary and label encoding, GR employs curriculum learning with an embedding mixup strategy to bridge training-inference gaps. Experimental evaluations on four public datasets and one large-scale industrial dataset validate the superiority of GR over existing methods. Real-world A/B tests on Kuaishou, a leading video platform, further demonstrate its practical effectiveness. Additionally, GR proves adaptable to other regression tasks, such as Lifetime Value (LTV) prediction, showcasing its potential as a robust solution for diverse CVP challenges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.01720</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.01720</id><created>2025-01-03</created><updated>2025-01-23</updated><authors><author><keyname>Zhang</keyname><forenames>Guosheng</forenames></author><author><keyname>Wang</keyname><forenames>Keyao</forenames></author><author><keyname>Yue</keyname><forenames>Haixiao</forenames></author><author><keyname>Liu</keyname><forenames>Ajian</forenames></author><author><keyname>Zhang</keyname><forenames>Gang</forenames></author><author><keyname>Yao</keyname><forenames>Kun</forenames></author><author><keyname>Ding</keyname><forenames>Errui</forenames></author><author><keyname>Wang</keyname><forenames>Jingdong</forenames></author></authors><title>Interpretable Face Anti-Spoofing: Enhancing Generalization with   Multimodal Large Language Models</title><categories>cs.CV</categories><comments>Accepted to AAAI2025(Oral)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Face Anti-Spoofing (FAS) is essential for ensuring the security and reliability of facial recognition systems. Most existing FAS methods are formulated as binary classification tasks, providing confidence scores without interpretation. They exhibit limited generalization in out-of-domain scenarios, such as new environments or unseen spoofing types. In this work, we introduce a multimodal large language model (MLLM) framework for FAS, termed Interpretable Face Anti-Spoofing (I-FAS), which transforms the FAS task into an interpretable visual question answering (VQA) paradigm. Specifically, we propose a Spoof-aware Captioning and Filtering (SCF) strategy to generate high-quality captions for FAS images, enriching the model's supervision with natural language interpretations. To mitigate the impact of noisy captions during training, we develop a Lopsided Language Model (L-LM) loss function that separates loss calculations for judgment and interpretation, prioritizing the optimization of the former. Furthermore, to enhance the model's perception of global visual features, we design a Globally Aware Connector (GAC) to align multi-level visual representations with the language model. Extensive experiments on standard and newly devised One to Eleven cross-domain benchmarks, comprising 12 public datasets, demonstrate that our method significantly outperforms state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.03833</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.03833</id><created>2025-01-07</created><updated>2025-01-24</updated><authors><author><keyname>Song</keyname><forenames>Wentu</forenames></author><author><keyname>Cai</keyname><forenames>Kui</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author></authors><title>Sequence Reconstruction for the Single-Deletion Single-Substitution   Channel</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The central problem in sequence reconstruction is to find the minimum number of distinct channel outputs required to uniquely reconstruct the transmitted sequence. According to Levenshtein's work in 2001, this number is determined by the size of the maximum intersection between the error balls of any two distinct input sequences of the channel. In this work, we study the sequence reconstruction problem for single-deletion single-substitution channel, assuming that the transmitted sequence belongs to a $q$-ary code with minimum Hamming distance at least $2$, where $q\geq 2$ is any fixed integer. Specifically, we prove that for any two $q$-ary sequences of length $n$ and with Hamming distance $d\geq 2$, the size of the intersection of their error balls is upper bounded by $2qn-3q-2-\delta_{q,2}$, where $\delta_{i,j}$ is the Kronecker delta. We also prove the tightness of this bound by constructing two sequences the intersection size of whose error balls achieves this bound. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.05094</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.05094</id><created>2025-01-09</created><updated>2025-01-24</updated><authors><author><keyname>Zou</keyname><forenames>Jiayang</forenames></author><author><keyname>Fan</keyname><forenames>Luyao</forenames></author><author><keyname>Gao</keyname><forenames>Jiayang</forenames></author><author><keyname>Wang</keyname><forenames>Jia</forenames></author></authors><title>Convexity of Mutual Information along the Fokker-Planck Flow</title><categories>cs.IT math.IT</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the convexity of mutual information as a function of time along the Fokker-Planck flow. The results are generalizations of that along heat flow and Ornstein-Ulenbeck flow, which were established by A. Wibisono and V. Jog. We prove the existence and uniqueness of the classical solutions to a class of Fokker-Planck equations and then we obtain the second derivative of mutual information along the Fokker-Planck equation. If the initial distribution is sufficiently strongly log-concave compared to the steady state, then mutual information always preserves convexity under suitable conditions. In particular, if there exists some time point at which the distribution is sufficiently strongly log-concave, then mutual information will preserve convexity after that time. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.05240</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.05240</id><created>2025-01-09</created><updated>2025-01-24</updated><authors><author><keyname>Schöpf</keyname><forenames>Jonas</forenames></author><author><keyname>Middeldorp</keyname><forenames>Aart</forenames></author></authors><title>Automated Analysis of Logically Constrained Rewrite Systems using crest</title><categories>cs.LO</categories><comments>Accepted at the 31st International Conference on Tools and Algorithms   for the Construction and Analysis of Systems (TACAS) 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present crest, a tool for automatically proving (non-)confluence and termination of logically constrained rewrite systems. We compare crest to other tools for logically constrained rewriting. Extensive experiments demonstrate the promise of crest. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06252</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06252</id><created>2025-01-08</created><updated>2025-01-23</updated><authors><author><keyname>Sun</keyname><forenames>Qi</forenames></author><author><keyname>Cetin</keyname><forenames>Edoardo</forenames></author><author><keyname>Tang</keyname><forenames>Yujin</forenames></author></authors><title>Transformer-Squared: Self-adaptive LLMs</title><categories>cs.LG cs.AI cs.CL</categories><comments>To appear at the 13th International Conference on Learning   Representations (ICLR 2025)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce Transformer-Squared, a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting only the singular components of their weight matrices. During inference, Transformer-Squared employs a two-pass mechanism: first, a dispatch system identifies the task properties, and then task-specific 'expert' vectors, trained using reinforcement learning, are dynamically mixed to obtain targeted behavior for the incoming prompt. Our method consistently outperforms ubiquitous approaches such as LoRA, with fewer parameters and greater efficiency. Furthermore, Transformer-Squared demonstrates versatility across different LLM architectures and modalities, including vision-language tasks. Transformer-Squared represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06261</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06261</id><created>2025-01-09</created><authors><author><keyname>Cai</keyname><forenames>Huaiguang</forenames></author></authors><title>CAMs as Shapley Value-based Explainers</title><categories>cs.CV cs.GT</categories><comments>Accepted by The Visual Computer (2025)</comments><doi>10.1007/s00371-025-03803-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Class Activation Mapping (CAM) methods are widely used to visualize neural network decisions, yet their underlying mechanisms remain incompletely understood. To enhance the understanding of CAM methods and improve their explainability, we introduce the Content Reserved Game-theoretic (CRG) Explainer. This theoretical framework clarifies the theoretical foundations of GradCAM and HiResCAM by modeling the neural network prediction process as a cooperative game. Within this framework, we develop ShapleyCAM, a new method that leverages gradients and the Hessian matrix to provide more precise and theoretically grounded visual explanations. Due to the computational infeasibility of exact Shapley value calculation, ShapleyCAM employs a second-order Taylor expansion of the cooperative game's utility function to derive a closed-form expression. Additionally, we propose the Residual Softmax Target-Class (ReST) utility function to address the limitations of pre-softmax and post-softmax scores. Extensive experiments across 12 popular networks on the ImageNet validation set demonstrate the effectiveness of ShapleyCAM and its variants. Our findings not only advance CAM explainability but also bridge the gap between heuristic-driven CAM methods and compute-intensive Shapley value-based methods. The code is available at \url{https://github.com/caihuaiguang/pytorch-shapley-cam}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06605</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06605</id><created>2025-01-11</created><updated>2025-01-24</updated><authors><author><keyname>Chen</keyname><forenames>Zixuan</forenames></author><author><keyname>Huo</keyname><forenames>Jing</forenames></author><author><keyname>Chen</keyname><forenames>Yangtao</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author></authors><title>RoboHorizon: An LLM-Assisted Multi-View World Model for Long-Horizon   Robotic Manipulation</title><categories>cs.RO</categories><comments>Under review</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Efficient control in long-horizon robotic manipulation is challenging due to complex representation and policy learning requirements. Model-based visual reinforcement learning (RL) has shown great potential in addressing these challenges but still faces notable limitations, particularly in handling sparse rewards and complex visual features in long-horizon environments. To address these limitations, we propose the Recognize-Sense-Plan-Act (RSPA) pipeline for long-horizon tasks and further introduce RoboHorizon, an LLM-assisted multi-view world model tailored for long-horizon robotic manipulation. In RoboHorizon, pre-trained LLMs generate dense reward structures for multi-stage sub-tasks based on task language instructions, enabling robots to better recognize long-horizon tasks. Keyframe discovery is then integrated into the multi-view masked autoencoder (MAE) architecture to enhance the robot's ability to sense critical task sequences, strengthening its multi-stage perception of long-horizon processes. Leveraging these dense rewards and multi-view representations, a robotic world model is constructed to efficiently plan long-horizon tasks, enabling the robot to reliably act through RL algorithms. Experiments on two representative benchmarks, RLBench and FurnitureBench, show that RoboHorizon outperforms state-of-the-art visual model-based RL methods, achieving a 23.35% improvement in task success rates on RLBench's 4 short-horizon tasks and a 29.23% improvement on 6 long-horizon tasks from RLBench and 3 furniture assembly tasks from FurnitureBench. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06764</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06764</id><created>2025-01-12</created><updated>2025-01-24</updated><authors><author><keyname>Yan</keyname><forenames>Kaiying</forenames></author><author><keyname>Liu</keyname><forenames>Moyang</forenames></author><author><keyname>Liu</keyname><forenames>Yukun</forenames></author><author><keyname>Fu</keyname><forenames>Ruibo</forenames></author><author><keyname>Wen</keyname><forenames>Zhengqi</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author><author><keyname>Liu</keyname><forenames>Xuefei</forenames></author><author><keyname>Li</keyname><forenames>Guanjun</forenames></author></authors><title>MTPareto: A MultiModal Targeted Pareto Framework for Fake News Detection</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal fake news detection is essential for maintaining the authenticity of Internet multimedia information. Significant differences in form and content of multimodal information lead to intensified optimization conflicts, hindering effective model training as well as reducing the effectiveness of existing fusion methods for bimodal. To address this problem, we propose the MTPareto framework to optimize multimodal fusion, using a Targeted Pareto(TPareto) optimization algorithm for fusion-level-specific objective learning with a certain focus. Based on the designed hierarchical fusion network, the algorithm defines three fusion levels with corresponding losses and implements all-modal-oriented Pareto gradient integration for each. This approach accomplishes superior multimodal fusion by utilizing the information obtained from intermediate fusion to provide positive effects to the entire process. Experiment results on FakeSV and FVC datasets show that the proposed framework outperforms baselines and the TPareto optimization algorithm achieves 2.40% and 1.89% accuracy improvement respectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.06781</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.06781</id><created>2025-01-12</created><updated>2025-01-23</updated><authors><author><keyname>Walters</keyname><forenames>Shaw</forenames></author><author><keyname>Gao</keyname><forenames>Sam</forenames></author><author><keyname>Nerd</keyname><forenames>Shakker</forenames></author><author><keyname>Da</keyname><forenames>Feng</forenames></author><author><keyname>Williams</keyname><forenames>Warren</forenames></author><author><keyname>Meng</keyname><forenames>Ting-Chien</forenames></author><author><keyname>Chow</keyname><forenames>Amie</forenames></author><author><keyname>Han</keyname><forenames>Hunter</forenames></author><author><keyname>He</keyname><forenames>Frank</forenames></author><author><keyname>Zhang</keyname><forenames>Allen</forenames></author><author><keyname>Wu</keyname><forenames>Ming</forenames></author><author><keyname>Shen</keyname><forenames>Timothy</forenames></author><author><keyname>Hu</keyname><forenames>Maxwell</forenames></author><author><keyname>Yan</keyname><forenames>Jerry</forenames></author></authors><title>Eliza: A Web3 friendly AI Agent Operating System</title><categories>cs.AI</categories><comments>20 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  AI Agent, powered by large language models (LLMs) as its cognitive core, is an intelligent agentic system capable of autonomously controlling and determining the execution paths under user's instructions. With the burst of capabilities of LLMs and various plugins, such as RAG, text-to-image/video/3D, etc., the potential of AI Agents has been vastly expanded, with their capabilities growing stronger by the day. However, at the intersection between AI and web3, there is currently no ideal agentic framework that can seamlessly integrate web3 applications into AI agent functionalities. In this paper, we propose Eliza, the first open-source web3-friendly Agentic framework that makes the deployment of web3 applications effortless. We emphasize that every aspect of Eliza is a regular Typescript program under the full control of its user, and it seamlessly integrates with web3 (i.e., reading and writing blockchain data, interacting with smart contracts, etc.). Furthermore, we show how stable performance is achieved through the pragmatic implementation of the key components of Eliza's runtime. Our code is publicly available at https://github.com/ai16z/eliza. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.07888</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.07888</id><created>2025-01-14</created><updated>2025-01-24</updated><authors><author><keyname>Yuan</keyname><forenames>Liping</forenames></author><author><keyname>Wang</keyname><forenames>Jiawei</forenames></author><author><keyname>Sun</keyname><forenames>Haomiao</forenames></author><author><keyname>Zhang</keyname><forenames>Yuchen</forenames></author><author><keyname>Lin</keyname><forenames>Yuan</forenames></author></authors><title>Tarsier2: Advancing Large Vision-Language Models from Detailed Video   Description to Comprehensive Video Understanding</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM) designed for generating detailed and accurate video descriptions, while also exhibiting superior general video understanding capabilities. Tarsier2 achieves significant advancements through three key upgrades: (1) Scaling pre-training data from 11M to 40M video-text pairs, enriching both volume and diversity; (2) Performing fine-grained temporal alignment during supervised fine-tuning; (3) Using model-based sampling to automatically construct preference data and applying DPO training for optimization. Extensive experiments show that Tarsier2-7B consistently outperforms leading proprietary models, including GPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K benchmark, Tarsier2-7B improves F1 by 2.8% over GPT-4o and 5.8% over Gemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6% performance advantage over GPT-4o and +24.9% over Gemini-1.5-Pro. Tarsier2-7B also sets new state-of-the-art results across 15 public benchmarks, spanning tasks such as video question-answering, video grounding, hallucination test, and embodied question-answering, demonstrating its versatility as a robust generalist vision-language model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.08738</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.08738</id><created>2025-01-15</created><updated>2025-01-24</updated><authors><author><keyname>Garnier</keyname><forenames>Paul</forenames></author><author><keyname>Lannelongue</keyname><forenames>Vincent</forenames></author><author><keyname>Viquerat</keyname><forenames>Jonathan</forenames></author><author><keyname>Hachem</keyname><forenames>Elie</forenames></author></authors><title>MeshMask: Physics-Based Simulations with Masked Graph Neural Networks</title><categories>cs.LG physics.flu-dyn</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a novel masked pre-training technique for graph neural networks (GNNs) applied to computational fluid dynamics (CFD) problems. By randomly masking up to 40\% of input mesh nodes during pre-training, we force the model to learn robust representations of complex fluid dynamics. We pair this masking strategy with an asymmetric encoder-decoder architecture and gated multi-layer perceptrons to further enhance performance. The proposed method achieves state-of-the-art results on seven CFD datasets, including a new challenging dataset of 3D intracranial aneurysm simulations with over 250,000 nodes per mesh. Moreover, it significantly improves model performance and training efficiency across such diverse range of fluid simulation tasks. We demonstrate improvements of up to 60\% in long-term prediction accuracy compared to previous best models, while maintaining similar computational costs. Notably, our approach enables effective pre-training on multiple datasets simultaneously, significantly reducing the time and data required to achieve high performance on new tasks. Through extensive ablation studies, we provide insights into the optimal masking ratio, architectural choices, and training strategies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.09362</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.09362</id><created>2025-01-16</created><updated>2025-01-24</updated><authors><author><keyname>Zou</keyname><forenames>Jiayang</forenames></author><author><keyname>Fan</keyname><forenames>Luyao</forenames></author><author><keyname>Gao</keyname><forenames>Jiayang</forenames></author><author><keyname>Wang</keyname><forenames>Jia</forenames></author></authors><title>A Revisit to Rate-distortion Theory via Optimal Weak Transport</title><categories>cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper revisits the rate-distortion theory from the perspective of optimal weak transport, as recently introduced by Gozlan et al. While the conditions for optimality and the existence of solutions are well-understood in the case of discrete alphabets, the extension to abstract alphabets requires more intricate analysis. Within the framework of weak transport problems, we derive a parametric representation of the rate-distortion function, thereby connecting the rate-distortion function with the Schr\"odinger bridge problem, and establish necessary conditions for its optimality. As a byproduct of our analysis, we reproduce K. Rose's conclusions regarding the achievability of Shannon lower bound concisely, without reliance on variational calculus. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10243</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10243</id><created>2025-01-17</created><updated>2025-01-24</updated><authors><author><keyname>Vieira</keyname><forenames>Bruno Salezze</forenames></author><author><keyname>Silva</keyname><forenames>Eduardo Machado</forenames></author><author><keyname>Chaves</keyname><forenames>Antonio Augusto</forenames></author></authors><title>Random-Key Algorithms for Optimizing Integrated Operating Room   Scheduling</title><categories>cs.NE cs.AI math.CO</categories><comments>38 pages, Preprint submitted to Applied Soft Computing</comments><acm-class>F.2.2; I.2.7; I.2.8</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Efficient surgery room scheduling is essential for hospital efficiency, patient satisfaction, and resource utilization. This study addresses this challenge by introducing a novel concept of Random-Key Optimizer (RKO), rigorously tested on literature and new, real-world inspired instances. Our combinatorial optimization problem incorporates multi-room scheduling, equipment scheduling, and complex availability constraints for rooms, patients, and surgeons, facilitating rescheduling and enhancing operational flexibility. The RKO approach represents solutions as points in a continuous space, which are then mapped in the problem solution space via a deterministic function known as a decoder. The core idea is to operate metaheuristics and heuristics in the random-key space, unaware of the original solution space. We design the Biased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and Iterated Local Search for use within an RKO framework, employing a single decoder function. The proposed metaheuristics are complemented by lower-bound formulations, providing optimal gaps for evaluating the effectiveness of the heuristic results. Our results demonstrate significant lower and upper bounds improvements for the literature instances, notably proving one optimal result. Furthermore, the best-proposed metaheuristic efficiently generates schedules for the newly introduced instances, even in highly constrained scenarios. This research offers valuable insights and practical solutions for improving surgery scheduling processes, offering tangible benefits to hospitals by optimising resource allocation, reducing patient wait times, and enhancing overall operational efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10321</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10321</id><created>2025-01-17</created><updated>2025-01-24</updated><authors><author><keyname>Saveliev</keyname><forenames>Evgeny</forenames></author><author><keyname>Liu</keyname><forenames>Jiashuo</forenames></author><author><keyname>Seedat</keyname><forenames>Nabeel</forenames></author><author><keyname>Boyd</keyname><forenames>Anders</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Towards Human-Guided, Data-Centric LLM Co-Pilots</title><categories>cs.LG stat.ML</categories><comments>Saveliev, Liu &amp; Seedat contributed equally</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Machine learning (ML) has the potential to revolutionize various domains, but its adoption is often hindered by the disconnect between the needs of domain experts and translating these needs into robust and valid ML tools. Despite recent advances in LLM-based co-pilots to democratize ML for non-technical domain experts, these systems remain predominantly focused on model-centric aspects while overlooking critical data-centric challenges. This limitation is problematic in complex real-world settings where raw data often contains complex issues, such as missing values, label noise, and domain-specific nuances requiring tailored handling. To address this we introduce CliMB-DC, a human-guided, data-centric framework for LLM co-pilots that combines advanced data-centric tools with LLM-driven reasoning to enable robust, context-aware data processing. At its core, CliMB-DC introduces a novel, multi-agent reasoning system that combines a strategic coordinator for dynamic planning and adaptation with a specialized worker agent for precise execution. Domain expertise is then systematically incorporated to guide the reasoning process using a human-in-the-loop approach. To guide development, we formalize a taxonomy of key data-centric challenges that co-pilots must address. Thereafter, to address the dimensions of the taxonomy, we integrate state-of-the-art data-centric tools into an extensible, open-source architecture, facilitating the addition of new tools from the research community. Empirically, using real-world healthcare datasets we demonstrate CliMB-DC's ability to transform uncurated datasets into ML-ready formats, significantly outperforming existing co-pilot baselines for handling data-centric challenges. CliMB-DC promises to empower domain experts from diverse domains -- healthcare, finance, social sciences and more -- to actively participate in driving real-world impact using ML. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10348</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10348</id><created>2025-01-17</created><updated>2025-01-23</updated><authors><author><keyname>Zhang</keyname><forenames>Zizhou</forenames></author><author><keyname>Li</keyname><forenames>Xinshi</forenames></author><author><keyname>Cheng</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Zhenrui</forenames></author><author><keyname>Liu</keyname><forenames>Qianying</forenames></author></authors><title>Credit Risk Identification in Supply Chains Using Generative Adversarial   Networks</title><categories>cs.LG</categories><comments>The paper will be published and indexed by IEEE at 2025 8th   International Conference on Advanced Algorithms and Control Engineering   (ICAACE 2025)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Credit risk management within supply chains has emerged as a critical research area due to its significant implications for operational stability and financial sustainability. The intricate interdependencies among supply chain participants mean that credit risks can propagate across networks, with impacts varying by industry. This study explores the application of Generative Adversarial Networks (GANs) to enhance credit risk identification in supply chains. GANs enable the generation of synthetic credit risk scenarios, addressing challenges related to data scarcity and imbalanced datasets. By leveraging GAN-generated data, the model improves predictive accuracy while effectively capturing dynamic and temporal dependencies in supply chain data. The research focuses on three representative industries-manufacturing (steel), distribution (pharmaceuticals), and services (e-commerce) to assess industry-specific credit risk contagion. Experimental results demonstrate that the GAN-based model outperforms traditional methods, including logistic regression, decision trees, and neural networks, achieving superior accuracy, recall, and F1 scores. The findings underscore the potential of GANs in proactive risk management, offering robust tools for mitigating financial disruptions in supply chains. Future research could expand the model by incorporating external market factors and supplier relationships to further enhance predictive capabilities. Keywords- Generative Adversarial Networks (GANs); Supply Chain Risk; Credit Risk Identification; Machine Learning; Data Augmentation </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10388</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10388</id><created>2024-12-19</created><updated>2025-01-23</updated><authors><author><keyname>Sanabria</keyname><forenames>Jordi Montes</forenames></author><author><keyname>Vecino</keyname><forenames>Pol Alvarez</forenames></author></authors><title>Beyond the Sum: Unlocking AI Agents Potential Through Market Forces</title><categories>cs.CY cs.AI cs.CL cs.GT cs.MA</categories><comments>20 pages, 5 figures</comments><acm-class>I.2.2; I.2.7; I.2.11; J.4; K.4.4</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The emergence of Large Language Models has fundamentally transformed the capabilities of AI agents, enabling a new class of autonomous agents capable of interacting with their environment through dynamic code generation and execution. These agents possess the theoretical capacity to operate as independent economic actors within digital markets, offering unprecedented potential for value creation through their distinct advantages in operational continuity, perfect replication, and distributed learning capabilities. However, contemporary digital infrastructure, architected primarily for human interaction, presents significant barriers to their participation.   This work presents a systematic analysis of the infrastructure requirements necessary for AI agents to function as autonomous participants in digital markets. We examine four key areas - identity and authorization, service discovery, interfaces, and payment systems - to show how existing infrastructure actively impedes agent participation. We argue that addressing these infrastructure challenges represents more than a technical imperative; it constitutes a fundamental step toward enabling new forms of economic organization. Much as traditional markets enable human intelligence to coordinate complex activities beyond individual capability, markets incorporating AI agents could dramatically enhance economic efficiency through continuous operation, perfect information sharing, and rapid adaptation to changing conditions. The infrastructure challenges identified in this work represent key barriers to realizing this potential. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.10455</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.10455</id><created>2025-01-14</created><updated>2025-01-24</updated><authors><author><keyname>Yu</keyname><forenames>Boyang</forenames></author><author><keyname>Cordier</keyname><forenames>Frederic</forenames></author><author><keyname>Seo</keyname><forenames>Hyewon</forenames></author></authors><title>PhyDeformer: High-Quality Non-Rigid Garment Registration with   Physics-Awareness</title><categories>cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present PhyDeformer, a new deformation method for high-quality garment mesh registration. It operates in two phases: In the first phase, a garment grading is performed to achieve a coarse 3D alignment between the mesh template and the target mesh, accounting for proportional scaling and fit (e.g. length, size). Then, the graded mesh is refined to align with the fine-grained details of the 3D target through an optimization coupled with the Jacobian-based deformation framework. Both quantitative and qualitative evaluations on synthetic and real garments highlight the effectiveness of our method. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11139</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11139</id><created>2025-01-19</created><updated>2025-01-23</updated><authors><author><keyname>Jin</keyname><forenames>Dian</forenames></author><author><keyname>Zhang</keyname><forenames>Yuqian</forenames></author><author><keyname>Zhang</keyname><forenames>Qiaosheng</forenames></author></authors><title>Community Detection for Contextual-LSBM: Theoretical Limitations of   Misclassification Rate and Efficient Algorithms</title><categories>stat.ML cs.LG</categories><comments>online version for Isit-25 submission</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The integration of network information and node attribute information has recently gained significant attention in the community detection literature. In this work, we consider community detection in the Contextual Labeled Stochastic Block Model (CLSBM), where the network follows an LSBM and node attributes follow a Gaussian Mixture Model (GMM). Our primary focus is the misclassification rate, which measures the expected number of nodes misclassified by community detection algorithms. We first establish a lower bound on the optimal misclassification rate that holds for any algorithm. When we specialize our setting to the LSBM (which preserves only network information) or the GMM (which preserves only node attribute information), our lower bound recovers prior results. Moreover, we present an efficient spectral-based algorithm tailored for the CLSBM and derive an upper bound on its misclassification rate. Although the algorithm does not attain the lower bound, it serves as a reliable starting point for designing more accurate community detection algorithms (as many algorithms use spectral method as an initial step, followed by refinement procedures to enhance accuracy). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11430</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11430</id><created>2025-01-20</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Jing</forenames></author><author><keyname>Ma</keyname><forenames>Zhenchao</forenames></author><author><keyname>Wang</keyname><forenames>Zepu</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Zehua</forenames></author><author><keyname>Sun</keyname><forenames>Peng</forenames></author><author><keyname>Song</keyname><forenames>Liang</forenames></author><author><keyname>Hu</keyname><forenames>Bo</forenames></author><author><keyname>Boukerche</keyname><forenames>Azzedine</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>A Survey on Diffusion Models for Anomaly Detection</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion models (DMs) have emerged as a powerful class of generative AI models, showing remarkable potential in anomaly detection (AD) tasks across various domains, such as cybersecurity, fraud detection, healthcare, and manufacturing. The intersection of these two fields, termed diffusion models for anomaly detection (DMAD), offers promising solutions for identifying deviations in increasingly complex and high-dimensional data. In this survey, we review recent advances in DMAD research. We begin by presenting the fundamental concepts of AD and DMs, followed by a comprehensive analysis of classic DM architectures including DDPMs, DDIMs, and Score SDEs. We further categorize existing DMAD methods into reconstruction-based, density-based, and hybrid approaches, providing detailed examinations of their methodological innovations. We also explore the diverse tasks across different data modalities, encompassing image, time series, video, and multimodal data analysis. Furthermore, we discuss critical challenges and emerging research directions, including computational efficiency, model interpretability, robustness enhancement, edge-cloud collaboration, and integration with large language models. The collection of DMAD research papers and resources is available at https://github.com/fdjingliu/DMAD. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11477</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11477</id><created>2025-01-20</created><updated>2025-01-23</updated><authors><author><keyname>Singh</keyname><forenames>Akhilesh Kumar</forenames></author><author><keyname>Hiremath</keyname><forenames>Kirankumar R.</forenames></author></authors><title>QGAIC: Quantum Inspired Genetic Algorithm for Image Classification</title><categories>cs.NE</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This study uses two meta-heuristics methodologies to introduce two novel quantum-inspired meta heuristic approaches: quantum-inspired genetic algorithm (QIGA1) and quantum-inspired genetic algorithm with dynamic approach (QIGA2). The two suggested methods combine a classical and quantum genetic algorithm approach. Both approaches use The correlation coefficient as an assessment function to identify the best (optimal) values for binary image. In quantum computing, they use simple ideas like qubits and state superposition. Due to these characteristics, parallelism which uses the time discreteness of quantum mechanical systems, is exhibited. For five distinct MNIST datasets, the performance of all participating algorithms has been assessed by comparing the suggested approaches first with their traditional approach counterparts and then with the proposed methods QIGA1 and QIGA2. Each method's ideal threshold value, associated fitness value (best and average), loss, and accuracy for each MNIST dataset have all been published. The outcomes demonstrate the superior efficiency of the suggested approaches over their traditional equivalents. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11740</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11740</id><created>2025-01-20</created><updated>2025-01-24</updated><authors><author><keyname>Elimelech</keyname><forenames>Or</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author></authors><title>PIR Over Wireless Channels: Achieving Privacy With Public Responses</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of Private Information Retrieval (PIR) over a public Additive White Gaussian Noise (AWGN) channel. In such a setup, the server's responses are visible to other servers. Thus, a curious server can listen to the other responses, compromising the user's privacy. Indeed, previous works on PIR over a shared medium assumed the servers cannot instantaneously listen to other responses. To address this gap, we present a novel randomized lattice -- PIR coding scheme that jointly codes for privacy, channel noise, and curious servers which may listen to other responses. We demonstrate that a positive PIR rate is achievable even in cases where the channel to the curious server is stronger than the channel to the user. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11747</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11747</id><created>2025-01-20</created><updated>2025-01-23</updated><authors><author><keyname>Held</keyname><forenames>William</forenames></author><author><keyname>Paranjape</keyname><forenames>Bhargavi</forenames></author><author><keyname>Koura</keyname><forenames>Punit Singh</forenames></author><author><keyname>Lewis</keyname><forenames>Mike</forenames></author><author><keyname>Zhang</keyname><forenames>Frank</forenames></author><author><keyname>Mihaylov</keyname><forenames>Todor</forenames></author></authors><title>Optimizing Pretraining Data Mixtures with LLM-Estimated Utility</title><categories>cs.CL cs.AI</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large Language Models improve with increasing amounts of high-quality training data. However, leveraging larger datasets requires balancing quality, quantity, and diversity across sources. After evaluating nine baseline methods under both compute- and data-constrained scenarios, we find token-count heuristics outperform manual and learned mixes, indicating that simple approaches accounting for dataset size and diversity are surprisingly effective. Building on this insight, we propose two complementary approaches: UtiliMax, which extends token-based heuristics by incorporating utility estimates from reduced-scale ablations, achieving up to a 10.6x speedup over manual baselines; and Model Estimated Data Utility (MEDU), which leverages LLMs to estimate data utility from small samples, matching ablation-based performance while reducing computational requirements by $\sim$200x. Together, these approaches establish a new framework for automated, compute-efficient data mixing that is robust across training regimes. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11801</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11801</id><created>2025-01-20</created><updated>2025-01-24</updated><authors><author><keyname>Meinhardt</keyname><forenames>Luca-Maxim</forenames></author><author><keyname>Wilke</keyname><forenames>Lina</forenames></author><author><keyname>Elhaidary</keyname><forenames>Maryam</forenames></author><author><keyname>von Abel</keyname><forenames>Julia</forenames></author><author><keyname>Fink</keyname><forenames>Paul</forenames></author><author><keyname>Rietzler</keyname><forenames>Michael</forenames></author><author><keyname>Colley</keyname><forenames>Mark</forenames></author><author><keyname>Rukzio</keyname><forenames>Enrico</forenames></author></authors><title>Light My Way: Developing and Exploring a Multimodal Interface to Assist   People With Visual Impairments to Exit Highly Automated Vehicles</title><categories>cs.HC</categories><doi>10.1145/3706598.3713454</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The introduction of Highly Automated Vehicles (HAVs) has the potential to increase the independence of blind and visually impaired people (BVIPs). However, ensuring safety and situation awareness when exiting these vehicles in unfamiliar environments remains challenging. To address this, we conducted an interactive workshop with N=5 BVIPs to identify their information needs when exiting an HAV and evaluated three prior-developed low-fidelity prototypes. The insights from this workshop guided the development of PathFinder, a multimodal interface combining visual, auditory, and tactile modalities tailored to BVIP's unique needs. In a three-factorial within-between-subject study with N=16 BVIPs, we evaluated PathFinder against an auditory-only baseline in urban and rural scenarios. PathFinder significantly reduced mental demand and maintained high perceived safety in both scenarios, while the auditory baseline led to lower perceived safety in the urban scenario compared to the rural one. Qualitative feedback further supported PathFinder's effectiveness in providing spatial orientation during exiting. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11814</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11814</id><created>2025-01-20</created><updated>2025-01-24</updated><authors><author><keyname>Meinhardt</keyname><forenames>Luca-Maxim</forenames></author><author><keyname>Elhaidary</keyname><forenames>Maryam</forenames></author><author><keyname>Colley</keyname><forenames>Mark</forenames></author><author><keyname>Rietzler</keyname><forenames>Michael</forenames></author><author><keyname>Rixen</keyname><forenames>Jan Ole</forenames></author><author><keyname>Purohit</keyname><forenames>Aditya Kumar</forenames></author><author><keyname>Rukzio</keyname><forenames>Enrico</forenames></author></authors><title>Scrolling in the Deep: Analysing Contextual Influences on Intervention   Effectiveness during Infinite Scrolling on Social Media</title><categories>cs.HC</categories><doi>10.1145/3706598.3713187</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Infinite scrolling on social media platforms is designed to encourage prolonged engagement, leading users to spend more time than desired, which can provoke negative emotions. Interventions to mitigate infinite scrolling have shown initial success, yet users become desensitized due to the lack of contextual relevance. Understanding how contextual factors influence intervention effectiveness remains underexplored. We conducted a 7-day user study (N=72) investigating how these contextual factors affect users' reactance and responsiveness to interventions during infinite scrolling. Our study revealed an interplay, with contextual factors such as being at home, sleepiness, and valence playing significant roles in the intervention's effectiveness. Low valence coupled with being at home slows down the responsiveness to interventions, and sleepiness lowers reactance towards interventions, increasing user acceptance of the intervention. Overall, our work contributes to a deeper understanding of user responses toward interventions and paves the way for developing more effective interventions during infinite scrolling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11829</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11829</id><created>2025-01-20</created><updated>2025-01-24</updated><authors><author><keyname>Meinhardt</keyname><forenames>Luca-Maxim</forenames></author><author><keyname>Schramm</keyname><forenames>Clara</forenames></author><author><keyname>Jansen</keyname><forenames>Pascal</forenames></author><author><keyname>Colley</keyname><forenames>Mark</forenames></author><author><keyname>Rukzio</keyname><forenames>Enrico</forenames></author></authors><title>Fly Away: Evaluating the Impact of Motion Fidelity on Optimized User   Interface Design via Bayesian Optimization in Automated Urban Air Mobility   Simulations</title><categories>cs.HC</categories><doi>10.1145/3706598.3713288</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automated Urban Air Mobility (UAM) can improve passenger transportation and reduce congestion, but its success depends on passenger trust. While initial research addresses passengers' information needs, questions remain about how to simulate air taxi flights and how these simulations impact users and interface requirements. We conducted a between-subjects study (N=40), examining the influence of motion fidelity in Virtual-Reality-simulated air taxi flights on user effects and interface design. Our study compared simulations with and without motion cues using a 3-Degrees-of-Freedom motion chair. Optimizing the interface design across six objectives, such as trust and mental demand, we used multi-objective Bayesian optimization to determine the most effective design trade-offs. Our results indicate that motion fidelity decreases users' trust, understanding, and acceptance, highlighting the need to consider motion fidelity in future UAM studies to approach realism. However, minimal evidence was found for differences or equality in the optimized interface designs, suggesting personalized interface designs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.11881</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.11881</id><created>2025-01-20</created><updated>2025-01-24</updated><authors><author><keyname>Takahashi</keyname><forenames>Koki</forenames></author><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author></authors><title>Channel Resolvability Using Multiplicative Weight Update Algorithm</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the channel resolvability problem, which is used to prove strong converse of identification via channel. Channel resolvability has been solved by only random coding in the literature. We prove channel resolvability using the multiplicative weight update algorithm. This is the first approach to channel resolvability using non-random coding. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12032</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12032</id><created>2025-01-21</created><updated>2025-01-24</updated><authors><author><keyname>Zhu</keyname><forenames>Yu</forenames></author><author><keyname>Jiang</keyname><forenames>Wenqi</forenames></author><author><keyname>Alonso</keyname><forenames>Gustavo</forenames></author></authors><title>Multi-Tenant SmartNICs for In-Network Preprocessing of Recommender   Systems</title><categories>cs.AR cs.DC cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Keeping ML-based recommender models up-to-date as data drifts and evolves is essential to maintain accuracy. As a result, online data preprocessing plays an increasingly important role in serving recommender systems. Existing solutions employ multiple CPU workers to saturate the input bandwidth of a single training node. Such an approach results in high deployment costs and energy consumption. For instance, a recent report from industrial deployments shows that data storage and ingestion pipelines can account for over 60\% of the power consumption in a recommender system. In this paper, we tackle the issue from a hardware perspective by introducing Piper, a flexible and network-attached accelerator that executes data loading and preprocessing pipelines in a streaming fashion. As part of the design, we define MiniPipe, the smallest pipeline unit enabling multi-pipeline implementation by executing various data preprocessing tasks across the single board, giving Piper the ability to be reconfigured at runtime. Our results, using publicly released commercial pipelines, show that Piper, prototyped on a power-efficient FPGA, achieves a 39$\sim$105$\times$ speedup over a server-grade, 128-core CPU and 3$\sim$17$\times$ speedup over GPUs like RTX 3090 and A100 in multiple pipelines. The experimental analysis demonstrates that Piper provides advantages in both latency and energy efficiency for preprocessing tasks in recommender systems, providing an alternative design point for systems that today are in very high demand. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12104</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12104</id><created>2025-01-21</created><updated>2025-01-24</updated><authors><author><keyname>Song</keyname><forenames>Shixuan</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Hu</keyname><forenames>Shu</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Hu</keyname><forenames>Jinrong</forenames></author><author><keyname>Wu</keyname><forenames>Xi</forenames></author></authors><title>Teacher Encoder-Student Decoder Denoising Guided Segmentation Network   for Anomaly Detection</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual anomaly detection is a highly challenging task, often categorized as a one-class classification and segmentation problem. Recent studies have demonstrated that the student-teacher (S-T) framework effectively addresses this challenge. However, most S-T frameworks rely solely on pre-trained teacher networks to guide student networks in learning multi-scale similar features, overlooking the potential of the student networks to enhance learning through multi-scale feature fusion. In this study, we propose a novel model named PFADSeg, which integrates a pre-trained teacher network, a denoising student network with multi-scale feature fusion, and a guided anomaly segmentation network into a unified framework. By adopting a unique teacher-encoder and student-decoder denoising mode, the model improves the student network's ability to learn from teacher network features. Furthermore, an adaptive feature fusion mechanism is introduced to train a self-supervised segmentation network that synthesizes anomaly masks autonomously, significantly increasing detection performance. Evaluated on the MVTec AD dataset, PFADSeg achieves state-of-the-art results with an image-level AUC of 98.9%, a pixel-level mean precision of 76.4%, and an instance-level mean precision of 78.7%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12323</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12323</id><created>2025-01-21</created><updated>2025-01-24</updated><authors><author><keyname>Lv</keyname><forenames>Jiaqi</forenames></author><author><keyname>Antonowicz</keyname><forenames>Stefan S</forenames></author><author><keyname>Raza</keyname><forenames>Shan E Ahmed</forenames></author></authors><title>Deep Learning Based Segmentation of Blood Vessels from H&amp;E Stained   Oesophageal Adenocarcinoma Whole-Slide Images</title><categories>eess.IV cs.CV</categories><comments>Accepted by ISBI 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Blood vessels (BVs) play a critical role in the Tumor Micro-Environment (TME), potentially influencing cancer progression and treatment response. However, manually quantifying BVs in Hematoxylin and Eosin (H&amp;E) stained images is challenging and labor-intensive due to their heterogeneous appearances. We propose a novel approach of constructing guiding maps to improve the performance of state-of-the-art segmentation models for BV segmentation, the guiding maps encourage the models to learn representative features of BVs. This is particularly beneficial for computational pathology, where labeled training data is often limited and large models are prone to overfitting. We have quantitative and qualitative results to demonstrate the efficacy of our approach in improving segmentation accuracy. In future, we plan to validate this method to segment BVs across various tissue types and investigate the role of cellular structures in relation to BVs in the TME. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12558</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12558</id><created>2025-01-21</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Jianchuan</forenames></author><author><keyname>Chen</keyname><forenames>Tao</forenames></author><author><keyname>Mao</keyname><forenames>Sheng</forenames></author><author><keyname>Chen</keyname><forenames>Mohan</forenames></author></authors><title>Structural and mechanical properties of W-Cu compounds characterized by   a neural-network-based potential</title><categories>cond-mat.mtrl-sci cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tungsten-copper (W-Cu) compounds are widely utilized in various industrial fields due to their exceptional mechanical properties. In this study, we have developed a neural-network-based deep potential (DP) model that covers a wide range of temperatures, ranging from 0 to 3,000 K, and pressures, varying from 0 to 10 GPa. This study presents a model trained using density functional theory data for full concentration CuxW100-x compounds. Through this model, we systematically investigate the structural and mechanical properties of W-Cu alloys and have the following findings. First, the bulk modulus (B) and Young's modulus (E) of W-Cu alloys exhibit a linear decline as the Cu content increases, indicating a softening trend in the CuxW100-x compounds as the Cu concentration rises. Second, a higher Cu content results in higher critical strain and lower critical stress for these compounds. A brittle-to-ductile transition in the deformation mode predicted is predicted at around 37.5 at. % Cu content. Third, tensile loading tests in the W-Cu gradient structure reveal that Cu-poor region serves as a barrier, hindering shear band propagation while promoting new shear band formation in the Cu-rich region. The above results from the DP model are anticipated to aid in exploring the physical mechanisms underlying the complex phenomena of W-Cu systems and contribute to the advancement of methodologies for materials simulation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12588</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12588</id><created>2025-01-21</created><updated>2025-01-23</updated><authors><author><keyname>Ravi</keyname><forenames>Aditya Narayan</forenames></author><author><keyname>Shomorony</keyname><forenames>Ilan</forenames></author></authors><title>Fundamental Limits of Non-Adaptive Group Testing with Markovian   Correlation</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study a correlated group testing model where items are infected according to a Markov chain, which creates bursty binfection patterns. Focusing on a very sparse infections regime, we propose a non adaptive testing strategy with an efficient decoding scheme that is nearly optimal. Specifically, it achieves asymptotically vanishing error with a number of tests that is within a $1/\ln(2) \approx 1.44$ multiplicative factor of the fundamental entropy bound a result that parallels the independent group testing setting. We show that the number of tests reduces with an increase in the expected burst length of infected items, quantifying the advantage of exploiting correlation in test design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12603</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12603</id><created>2025-01-21</created><updated>2025-01-24</updated><authors><author><keyname>Grzeszczuk</keyname><forenames>Maciej</forenames></author><author><keyname>Skorupska</keyname><forenames>Kinga</forenames></author><author><keyname>Wojcik</keyname><forenames>Grzegorz Marcin</forenames></author></authors><title>Bridging the Digital Divide: Approach to Documenting Early Computing   Artifacts Using Established Standards for Cross-Collection Knowledge   Integration Ontology</title><categories>cs.HC</categories><comments>8 pages, 1 table, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the challenges of documenting early digital artifacts in collections built to offer historical context for future generations. Through insights from active community members (N=20), we examine current archival needs and obstacles. We assess the potential of the CIDOC Conceptual Reference Model (CRM) for categorizing fragmented digital data. Despite its complexity, CIDOC-CRM proves logical, human-readable, and adaptable, enabling archivists to select minimal yet effective building blocks set to empower community-led heritage projects. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12783</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12783</id><created>2025-01-22</created><updated>2025-01-23</updated><authors><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Guan</keyname><forenames>Peiyuan</forenames></author><author><keyname>Chen</keyname><forenames>Ziru</forenames></author><author><keyname>Taherkordi</keyname><forenames>Amir</forenames></author><author><keyname>Hou</keyname><forenames>Fen</forenames></author><author><keyname>Cai</keyname><forenames>Lin X.</forenames></author></authors><title>Cost Optimization for Serverless Edge Computing with Budget Constraints   using Deep Reinforcement Learning</title><categories>cs.NI</categories><comments>This paper has been accepted by IEEE ICC 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Serverless computing adopts a pay-as-you-go billing model where applications are executed in stateless and shortlived containers triggered by events, resulting in a reduction of monetary costs and resource utilization. However, existing platforms do not provide an upper bound for the billing model which makes the overall cost unpredictable, precluding many organizations from managing their budgets. Due to the diverse ranges of serverless functions and the heterogeneous capacity of edge devices, it is challenging to receive near-optimal solutions for deployment cost in a polynomial time. In this paper, we investigated the function scheduling problem with a budget constraint for serverless computing in wireless networks. Users and IoT devices are sending requests to edge nodes, improving the latency perceived by users. We propose two online scheduling algorithms based on reinforcement learning, incorporating several important characteristics of serverless functions. Via extensive simulations, we justify the superiority of the proposed algorithm by comparing with an ILP solver (Midaco). Our results indicate that the proposed algorithms efficiently approximate the results of Midaco within a factor of 1.03 while our decision-making time is 5 orders of magnitude less than that of Midaco. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12880</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12880</id><created>2025-01-22</created><authors><author><keyname>Tzach</keyname><forenames>Yarden</forenames></author><author><keyname>Meir</keyname><forenames>Yuval</forenames></author><author><keyname>Gross</keyname><forenames>Ronit D.</forenames></author><author><keyname>Tevet</keyname><forenames>Ofek</forenames></author><author><keyname>Koresh</keyname><forenames>Ella</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author></authors><title>Advanced deep architecture pruning using single filter performance</title><categories>cs.LG cs.CV</categories><comments>22 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Pruning the parameters and structure of neural networks reduces the computational complexity, energy consumption, and latency during inference. Recently, a novel underlying mechanism for successful deep learning (DL) was presented based on a method that quantitatively measures the single filter performance in each layer of a DL architecture, and a new comprehensive mechanism of how deep learning works was presented. Herein, we demonstrate how this understanding paves the path to highly dilute the convolutional layers of deep architectures without affecting their overall accuracy using applied filter cluster connections (AFCC). AFCC is exemplified on VGG-11 and EfficientNet-B0 architectures trained on CIFAR-100, and its high pruning outperforms other techniques using the same pruning magnitude. Additionally, this technique is broadened to single nodal performance and highly pruning of fully connected layers, suggesting a possible implementation to considerably reduce the complexity of over-parameterized AI tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.12883</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.12883</id><created>2025-01-22</created><updated>2025-01-24</updated><authors><author><keyname>Shepherd</keyname><forenames>Carlton</forenames></author></authors><title>Generative AI Misuse Potential in Cyber Security Education: A Case Study   of a UK Degree Program</title><categories>cs.CR cs.CY</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Recent advances in generative artificial intelligence (AI), such as ChatGPT, Google Gemini, and other large language models (LLMs), pose significant challenges to upholding academic integrity in higher education. This paper investigates the susceptibility of a Master's-level cyber security degree program at a UK Russell Group university, accredited by a leading national body, to LLM misuse. Through the application and extension of a quantitative assessment framework, we identify a high exposure to misuse, particularly in independent project- and report-based assessments. Contributing factors, including block teaching and a predominantly international cohort, are highlighted as potential amplifiers of these vulnerabilities. To address these challenges, we discuss the adoption of LLM-resistant assessments, detection tools, and the importance of fostering an ethical learning environment. These approaches aim to uphold academic standards while preparing students for the complexities of real-world cyber security. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13223</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13223</id><created>2025-01-22</created><updated>2025-01-24</updated><authors><author><keyname>Sahili</keyname><forenames>Zahraa Al</forenames></author><author><keyname>Patras</keyname><forenames>Ioannis</forenames></author><author><keyname>Purver</keyname><forenames>Matthew</forenames></author></authors><title>Scaling for Fairness? Analyzing Model Size, Data Composition, and   Multilinguality in Vision-Language Bias</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  As large scale vision language models become increasingly central to modern AI applications, understanding and mitigating social biases in these systems has never been more critical. We investigate how dataset composition, model size, and multilingual training affect gender and racial bias in a popular VLM, CLIP, and its open source variants. In particular, we systematically evaluate models trained on varying dataset scales and architectures, as well as multilingual versions encompassing English along with Persian, Turkish, and Finnish,languages with minimal gender marking. To assess social perception bias, we measure the zero-shot performance on face images featuring socially charged terms rooted in the psychological constructs of communion and agency, and demographic labeling bias using both the FairFace and PATA datasets.   Our findings reveal three key insights. First, while larger training datasets can mitigate some biases, they may also introduce or amplify others when the data composition is imbalanced. Second, although increasing model size generally improves performance, it does not consistently reduce bias and can, in certain cases, exacerbate it. Finally, while multilingual training broadens linguistic coverage, it does not inherently neutralize bias and can transfer or intensify inequities across languages. Taken together, these results highlight the necessity of inclusive, carefully curated training data to foster fairness rather than relying solely on model scaling or language expansion. We provide a systematic evaluation for vision language bias across diverse demographics, underscoring the urgent need for intentional bias mitigation strategies in next-generation AI systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13291</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13291</id><created>2025-01-22</created><updated>2025-01-24</updated><authors><author><keyname>Das</keyname><forenames>Satyaki</forenames></author><author><keyname>Fabiha</keyname><forenames>Syeda Tasnim</forenames></author><author><keyname>Shafiq</keyname><forenames>Saad</forenames></author><author><keyname>Medvidovic</keyname><forenames>Nenad</forenames></author></authors><title>Are We Learning the Right Features? A Framework for Evaluating DL-Based   Software Vulnerability Detection Solutions</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has revealed that the reported results of an emerging body of DL-based techniques for detecting software vulnerabilities are not reproducible, either across different datasets or on unseen samples. This paper aims to provide the foundation for properly evaluating the research in this domain. We do so by analyzing prior work and existing vulnerability datasets for the syntactic and semantic features of code that contribute to vulnerability, as well as features that falsely correlate with vulnerability. We provide a novel, uniform representation to capture both sets of features, and use this representation to detect the presence of both vulnerability and spurious features in code. To this end, we design two types of code perturbations: feature preserving perturbations (FPP) ensure that the vulnerability feature remains in a given code sample, while feature eliminating perturbations (FEP) eliminate the feature from the code sample. These perturbations aim to measure the influence of spurious and vulnerability features on the predictions of a given vulnerability detection solution. To evaluate how the two classes of perturbations influence predictions, we conducted a large-scale empirical study on five state-of-the-art DL-based vulnerability detectors. Our study shows that, for vulnerability features, only ~2% of FPPs yield the undesirable effect of a prediction changing among the five detectors on average. However, on average, ~84% of FEPs yield the undesirable effect of retaining the vulnerability predictions. For spurious features, we observed that FPPs yielded a drop in recall up to 29% for graph-based detectors. We present the reasons underlying these results and suggest strategies for improving DNN-based vulnerability detectors. We provide our perturbation-based evaluation framework as a public resource to enable independent future evaluation of vulnerability detectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13341</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13341</id><created>2025-01-22</created><updated>2025-01-24</updated><authors><author><keyname>Lee</keyname><forenames>Taegyeong</forenames></author><author><keyname>Bang</keyname><forenames>Jinsik</forenames></author><author><keyname>Kwon</keyname><forenames>Soyeong</forenames></author><author><keyname>Kim</keyname><forenames>Taehwan</forenames></author></authors><title>Multi-aspect Knowledge Distillation with Large Language Model</title><categories>cs.CV</categories><comments>Preprint</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Recent advancements in deep learning have significantly improved performance on computer vision tasks. Previous image classification methods primarily modify model architectures or add features, and they optimize models using cross-entropy loss on class logits. Since they focus on classifying images with considering class labels, these methods may struggle to learn various \emph{aspects} of classes (e.g., natural positions and shape changes). Rethinking the previous approach from a novel view, we propose a multi-aspect knowledge distillation method using Multimodal Large Language Models (MLLMs). Our approach involves: 1) querying Large Language Model with multi-aspect questions relevant to the knowledge we want to transfer to the model, 2) extracting corresponding logits from MLLM, and 3) expanding the model's output dimensions to distill these multi-aspect logits. We then apply cross-entropy loss to class logits and binary cross-entropy loss to multi-aspect logits. Through our method, the model can learn not only the knowledge about visual aspects but also the abstract and complex aspects that require a deeper understanding. We primarily apply our method to image classification, and to explore the potential for extending our model, we expand it to other tasks, such as object detection. In all experimental results, our method improves the performance of the baselines. Additionally, we analyze the effect of multi-aspect knowledge distillation. These results demonstrate that our method can transfer knowledge about various aspects to the model and the aspect knowledge can enhance model performance in computer vision tasks. This paper demonstrates the great potential of multi-aspect knowledge distillation, and we believe it offers a promising direction for future research in computer vision and beyond. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13397</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13397</id><created>2025-01-23</created><updated>2025-01-24</updated><authors><author><keyname>Zheng</keyname><forenames>Kangjie</forenames></author><author><keyname>Yang</keyname><forenames>Junwei</forenames></author><author><keyname>Liang</keyname><forenames>Siyue</forenames></author><author><keyname>Feng</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Zequn</forenames></author><author><keyname>Ju</keyname><forenames>Wei</forenames></author><author><keyname>Xiao</keyname><forenames>Zhiping</forenames></author><author><keyname>Zhang</keyname><forenames>Ming</forenames></author></authors><title>ExLM: Rethinking the Impact of [MASK] Tokens in Masked Language Models</title><categories>cs.CL cs.LG</categories><comments>29 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Masked Language Models (MLMs) have achieved remarkable success in many self-supervised representation learning tasks. MLMs are trained by randomly replacing some tokens in the input sentences with [MASK] tokens and predicting the original tokens based on the remaining context. This paper explores the impact of [MASK] tokens on MLMs. Analytical studies show that masking tokens can introduce the corrupted semantics problem, wherein the corrupted context may convey multiple, ambiguous meanings. This problem is also a key factor affecting the performance of MLMs on downstream tasks. Based on these findings, we propose a novel enhanced-context MLM, ExLM. Our approach expands [MASK] tokens in the input context and models the dependencies between these expanded states. This expansion increases context capacity and enables the model to capture richer semantic information, effectively mitigating the corrupted semantics problem during pre-training. Experimental results demonstrate that ExLM achieves significant performance improvements in both text modeling and SMILES modeling tasks. Further analysis confirms that ExLM enhances semantic representations through context enhancement, and effectively reduces the multimodality problem commonly observed in MLMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13462</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13462</id><created>2025-01-23</created><updated>2025-01-24</updated><authors><author><keyname>Fujii</keyname><forenames>Naoki</forenames></author></authors><title>Generalized graph codes and thier minimum distances</title><categories>math.CO cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph code is a linear code obtained from linear codes $C$ and a certain bipartite graph G. In this paper, I propose an expansion of the definition of graph code to general $l$-partite, and give its lower bound of minimum distance. I also give an example of generalized graph code and calculate its parameters $[n, k, d]$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13554</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13554</id><created>2025-01-23</created><updated>2025-01-24</updated><authors><author><keyname>Liu</keyname><forenames>Tao</forenames></author><author><keyname>Wang</keyname><forenames>Kai</forenames></author><author><keyname>Li</keyname><forenames>Senmao</forenames></author><author><keyname>van de Weijer</keyname><forenames>Joost</forenames></author><author><keyname>Khan</keyname><forenames>Fahad Shahbaz</forenames></author><author><keyname>Yang</keyname><forenames>Shiqi</forenames></author><author><keyname>Wang</keyname><forenames>Yaxing</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Cheng</keyname><forenames>Ming-Ming</forenames></author></authors><title>One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation   Using a Single Prompt</title><categories>cs.CV cs.AI cs.LG</categories><comments>28 pages, 22 figures, ICLR2025 conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Text-to-image generation models can create high-quality images from input prompts. However, they struggle to support the consistent generation of identity-preserving requirements for storytelling. Existing approaches to this problem typically require extensive training in large datasets or additional modifications to the original model architectures. This limits their applicability across different domains and diverse diffusion model configurations. In this paper, we first observe the inherent capability of language models, coined context consistency, to comprehend identity through context with a single prompt. Drawing inspiration from the inherent context consistency, we propose a novel training-free method for consistent text-to-image (T2I) generation, termed "One-Prompt-One-Story" (1Prompt1Story). Our approach 1Prompt1Story concatenates all prompts into a single input for T2I diffusion models, initially preserving character identities. We then refine the generation process using two novel techniques: Singular-Value Reweighting and Identity-Preserving Cross-Attention, ensuring better alignment with the input description for each frame. In our experiments, we compare our method against various existing consistent T2I generation approaches to demonstrate its effectiveness through quantitative metrics and qualitative assessments. Code is available at https://github.com/byliutao/1Prompt1Story. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13584</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13584</id><created>2025-01-23</created><updated>2025-01-24</updated><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Xia</keyname><forenames>Mingxuan</forenames></author><author><keyname>Yao</keyname><forenames>Chang</forenames></author><author><keyname>Feng</keyname><forenames>Lei</forenames></author><author><keyname>Zhao</keyname><forenames>Junbo</forenames></author><author><keyname>Chen</keyname><forenames>Gang</forenames></author><author><keyname>Wang</keyname><forenames>Haobo</forenames></author></authors><title>Towards Robust Incremental Learning under Ambiguous Supervision</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional Incremental Learning (IL) targets to handle sequential fully-supervised learning problems where novel classes emerge from time to time. However, due to inherent annotation uncertainty and ambiguity, collecting high-quality annotated data in a dynamic learning system can be extremely expensive. To mitigate this problem, we propose a novel weakly-supervised learning paradigm called Incremental Partial Label Learning (IPLL), where the sequentially arrived data relate to a set of candidate labels rather than the ground truth. Technically, we develop the Prototype-Guided Disambiguation and Replay Algorithm (PGDR) which leverages the class prototypes as a proxy to mitigate two intertwined challenges in IPLL, i.e., label ambiguity and catastrophic forgetting. To handle the former, PGDR encapsulates a momentum-based pseudo-labeling algorithm along with prototype-guided initialization, resulting in a balanced perception of classes. To alleviate forgetting, we develop a memory replay technique that collects well-disambiguated samples while maintaining representativeness and diversity. By jointly distilling knowledge from curated memory data, our framework exhibits a great disambiguation ability for samples of new tasks and achieves less forgetting of knowledge. Extensive experiments demonstrate that PGDR achieves superior </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13597</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13597</id><created>2025-01-23</created><updated>2025-01-24</updated><authors><author><keyname>Berahmand</keyname><forenames>Kamal</forenames></author><author><keyname>Saberi-Movahed</keyname><forenames>Farid</forenames></author><author><keyname>Sheikhpour</keyname><forenames>Razieh</forenames></author><author><keyname>Li</keyname><forenames>Yuefeng</forenames></author><author><keyname>Jalili</keyname><forenames>Mahdi</forenames></author></authors><title>A Comprehensive Survey on Spectral Clustering with Graph Structure   Learning</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Spectral clustering is a powerful technique for clustering high-dimensional data, utilizing graph-based representations to detect complex, non-linear structures and non-convex clusters. The construction of a similarity graph is essential for ensuring accurate and effective clustering, making graph structure learning (GSL) central for enhancing spectral clustering performance in response to the growing demand for scalable solutions. Despite advancements in GSL, there is a lack of comprehensive surveys specifically addressing its role within spectral clustering. To bridge this gap, this survey presents a comprehensive review of spectral clustering methods, emphasizing on the critical role of GSL. We explore various graph construction techniques, including pairwise, anchor, and hypergraph-based methods, in both fixed and adaptive settings. Additionally, we categorize spectral clustering approaches into single-view and multi-view frameworks, examining their applications within one-step and two-step clustering processes. We also discuss multi-view information fusion techniques and their impact on clustering data. By addressing current challenges and proposing future research directions, this survey provides valuable insights for advancing spectral clustering methodologies and highlights the pivotal role of GSL in tackling large-scale and high-dimensional data clustering tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13648</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13648</id><created>2025-01-23</created><updated>2025-01-24</updated><authors><author><keyname>Sakaue</keyname><forenames>Shinsaku</forenames></author><author><keyname>Bao</keyname><forenames>Han</forenames></author><author><keyname>Tsuchiya</keyname><forenames>Taira</forenames></author></authors><title>Revisiting Online Learning Approach to Inverse Linear Optimization: A   Fenchel$-$Young Loss Perspective and Gap-Dependent Regret Analysis</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper revisits the online learning approach to inverse linear optimization studied by B\"armann et al. (2017), where the goal is to infer an unknown linear objective function of an agent from sequential observations of the agent's input-output pairs. First, we provide a simple understanding of the online learning approach through its connection to online convex optimization of \emph{Fenchel--Young losses}. As a byproduct, we present an offline guarantee on the \emph{suboptimality loss}, which measures how well predicted objectives explain the agent's choices, without assuming the optimality of the agent's choices. Second, assuming that there is a gap between optimal and suboptimal objective values in the agent's decision problems, we obtain an upper bound independent of the time horizon $T$ on the sum of suboptimality and \emph{estimate losses}, where the latter measures the quality of solutions recommended by predicted objectives. Interestingly, our gap-dependent analysis achieves a faster rate than the standard $O(\sqrt{T})$ regret bound by exploiting structures specific to inverse linear optimization, even though neither the loss functions nor their domains enjoy desirable properties, such as strong convexity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13935</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13935</id><created>2025-01-10</created><authors><author><keyname>Dzhenzher</keyname><forenames>S.</forenames></author><author><keyname>Garaev</keyname><forenames>T.</forenames></author><author><keyname>Nikitenko</keyname><forenames>O.</forenames></author><author><keyname>Petukhov</keyname><forenames>A.</forenames></author><author><keyname>Skopenkov</keyname><forenames>A.</forenames></author><author><keyname>Voropaev</keyname><forenames>A.</forenames></author></authors><title>Low rank matrix completion and realization of graphs: results and   problems</title><categories>math.HO cs.DM cs.LG math.CO math.GT</categories><comments>21 pages, 6 figures</comments><msc-class>15-02, 15A83, 57-02, 57M15, 57Q35, 05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Netflix problem (from machine learning) asks the following. Given a ratings matrix in which each entry $(i,j)$ represents the rating of movie $j$ by customer $i$, if customer $i$ has watched movie $j$, and is otherwise missing, we would like to predict the remaining entries in order to make good recommendations to customers on what to watch next. The remaining entries are predicted so as to minimize the {\it rank} of the completed matrix.   In this survey we study a more general problem, in which instead of knowing specific matrix elements, we know linear relations on such elements. We describe applications of these results to embeddings of graphs in surfaces (more precisely, embeddings with rotation systems, and embeddings modulo 2). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13936</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13936</id><created>2025-01-13</created><authors><author><keyname>Malghan</keyname><forenames>Arjun R.</forenames></author></authors><title>Evaluating Computational Accuracy of Large Language Models in Numerical   Reasoning Tasks for Healthcare Applications</title><categories>cs.AI cs.CL cs.LG</categories><comments>13 pages, 1 figure, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large Language Models (LLMs) have emerged as transformative tools in the healthcare sector, demonstrating remarkable capabilities in natural language understanding and generation. However, their proficiency in numerical reasoning, particularly in high-stakes domains like in clinical applications, remains underexplored. Numerical reasoning is critical in healthcare applications, influencing patient outcomes, treatment planning, and resource allocation. This study investigates the computational accuracy of LLMs in numerical reasoning tasks within healthcare contexts. Using a curated dataset of 1,000 numerical problems, encompassing real-world scenarios such as dosage calculations and lab result interpretations, the performance of a refined LLM based on the GPT-3 architecture was evaluated. The methodology includes prompt engineering, integration of fact-checking pipelines, and application of regularization techniques to enhance model accuracy and generalization. Key metrics such as precision, recall, and F1-score were utilized to assess the model's efficacy. The results indicate an overall accuracy of 84.10%, with improved performance in straightforward numerical tasks and challenges in multi-step reasoning. The integration of a fact-checking pipeline improved accuracy by 11%, underscoring the importance of validation mechanisms. This research highlights the potential of LLMs in healthcare numerical reasoning and identifies avenues for further refinement to support critical decision-making in clinical environments. The findings aim to contribute to the development of reliable, interpretable, and contextually relevant AI tools for healthcare. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13941</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13941</id><created>2025-01-17</created><authors><author><keyname>Block</keyname><forenames>Adam</forenames></author><author><keyname>Sekhari</keyname><forenames>Ayush</forenames></author><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author></authors><title>GaussMark: A Practical Approach for Structural Watermarking of Language   Models</title><categories>cs.CR cs.AI cs.CL cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent advances in Large Language Models (LLMs) have led to significant improvements in natural language processing tasks, but their ability to generate human-quality text raises significant ethical and operational concerns in settings where it is important to recognize whether or not a given text was generated by a human. Thus, recent work has focused on developing techniques for watermarking LLM-generated text, i.e., introducing an almost imperceptible signal that allows a provider equipped with a secret key to determine if given text was generated by their model. Current watermarking techniques are often not practical due to concerns with generation latency, detection time, degradation in text quality, or robustness. Many of these drawbacks come from the focus on token-level watermarking, which ignores the inherent structure of text. In this work, we introduce a new scheme, GaussMark, that is simple and efficient to implement, has formal statistical guarantees on its efficacy, comes at no cost in generation latency, and embeds the watermark into the weights of the model itself, providing a structural watermark. Our approach is based on Gaussian independence testing and is motivated by recent empirical observations that minor additive corruptions to LLM weights can result in models of identical (or even improved) quality. We show that by adding a small amount of Gaussian noise to the weights of a given LLM, we can watermark the model in a way that is statistically detectable by a provider who retains the secret key. We provide formal statistical bounds on the validity and power of our procedure. Through an extensive suite of experiments, we demonstrate that GaussMark is reliable, efficient, and relatively robust to corruptions such as insertions, deletions, substitutions, and roundtrip translations and can be instantiated with essentially no loss in model quality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13942</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13942</id><created>2025-01-17</created><authors><author><keyname>Duan</keyname><forenames>Zhihua</forenames></author><author><keyname>Wang</keyname><forenames>Jialin</forenames></author></authors><title>Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in   Large Models</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of large models in the field of artificial intelligence, how to enhance their application capabilities in handling complex problems in the field of scientific research remains a challenging problem to be solved. This study proposes an improved Monte Carlo Tree Search (MCTS) method based on prompt words. In the simulation search stage, it introduces dynamic adjustment of exploration parameters and adaptive selection strategies, which can better balance exploration and exploitation, thereby reducing the hallucination phenomenon. This paper takes the four subsets of the SciEval dataset as the test objects, and compares the Glm-4-flash+Improved MCTS method with the methods of several existing models. The results show that the Improved MCTS method performs better, providing new ideas and methods for the application of large models in the field of scientific research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13943</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13943</id><created>2025-01-17</created><authors><author><keyname>Liu</keyname><forenames>Shuo</forenames></author><author><keyname>Zhou</keyname><forenames>Zihan</forenames></author><author><keyname>Liu</keyname><forenames>Yuanhao</forenames></author><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Qian</keyname><forenames>Hong</forenames></author></authors><title>Language Representation Favored Zero-Shot Cross-Domain Cognitive   Diagnosis</title><categories>cs.CL cs.AI cs.CY cs.LG</categories><journal-ref>KDD 2025</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive diagnosis aims to infer students' mastery levels based on their historical response logs. However, existing cognitive diagnosis models (CDMs), which rely on ID embeddings, often have to train specific models on specific domains. This limitation may hinder their directly practical application in various target domains, such as different subjects (e.g., Math, English and Physics) or different education platforms (e.g., ASSISTments, Junyi Academy and Khan Academy). To address this issue, this paper proposes the language representation favored zero-shot cross-domain cognitive diagnosis (LRCD). Specifically, LRCD first analyzes the behavior patterns of students, exercises and concepts in different domains, and then describes the profiles of students, exercises and concepts using textual descriptions. Via recent advanced text-embedding modules, these profiles can be transformed to vectors in the unified language space. Moreover, to address the discrepancy between the language space and the cognitive diagnosis space, we propose language-cognitive mappers in LRCD to learn the mapping from the former to the latter. Then, these profiles can be easily and efficiently integrated and trained with existing CDMs. Extensive experiments show that training LRCD on real-world datasets can achieve commendable zero-shot performance across different target domains, and in some cases, it can even achieve competitive performance with some classic CDMs trained on the full response data on target domains. Notably, we surprisingly find that LRCD can also provide interesting insights into the differences between various subjects (such as humanities and sciences) and sources (such as primary and secondary education). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13944</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13944</id><created>2025-01-18</created><authors><author><keyname>Fanar Team</keyname></author><author><keyname>Abbas</keyname><forenames>Ummar</forenames></author><author><keyname>Ahmad</keyname><forenames>Mohammad Shahmeer</forenames></author><author><keyname>Alam</keyname><forenames>Firoj</forenames></author><author><keyname>Altinisik</keyname><forenames>Enes</forenames></author><author><keyname>Asgari</keyname><forenames>Ehsannedin</forenames></author><author><keyname>Boshmaf</keyname><forenames>Yazan</forenames></author><author><keyname>Boughorbel</keyname><forenames>Sabri</forenames></author><author><keyname>Chawla</keyname><forenames>Sanjay</forenames></author><author><keyname>Chowdhury</keyname><forenames>Shammur</forenames></author><author><keyname>Dalvi</keyname><forenames>Fahim</forenames></author><author><keyname>Darwish</keyname><forenames>Kareem</forenames></author><author><keyname>Durrani</keyname><forenames>Nadir</forenames></author><author><keyname>Elfeky</keyname><forenames>Mohamed</forenames></author><author><keyname>Elmagarmid</keyname><forenames>Ahmed</forenames></author><author><keyname>Eltabakh</keyname><forenames>Mohamed</forenames></author><author><keyname>Fatehkia</keyname><forenames>Masoomali</forenames></author><author><keyname>Fragkopoulos</keyname><forenames>Anastasios</forenames></author><author><keyname>Hasanain</keyname><forenames>Maram</forenames></author><author><keyname>Hawasly</keyname><forenames>Majd</forenames></author><author><keyname>Husaini</keyname><forenames>Mus'ab</forenames></author><author><keyname>Jung</keyname><forenames>Soon-Gyo</forenames></author><author><keyname>Lucas</keyname><forenames>Ji Kim</forenames></author><author><keyname>Magdy</keyname><forenames>Walid</forenames></author><author><keyname>Messaoud</keyname><forenames>Safa</forenames></author><author><keyname>Mohamed</keyname><forenames>Abubakr</forenames></author><author><keyname>Mohiuddin</keyname><forenames>Tasnim</forenames></author><author><keyname>Mousi</keyname><forenames>Basel</forenames></author><author><keyname>Mubarak</keyname><forenames>Hamdy</forenames></author><author><keyname>Musleh</keyname><forenames>Ahmad</forenames></author><author><keyname>Naeem</keyname><forenames>Zan</forenames></author><author><keyname>Ouzzani</keyname><forenames>Mourad</forenames></author><author><keyname>Popovic</keyname><forenames>Dorde</forenames></author><author><keyname>Sadeghi</keyname><forenames>Amin</forenames></author><author><keyname>Sencar</keyname><forenames>Husrev Taha</forenames></author><author><keyname>Shinoy</keyname><forenames>Mohammed</forenames></author><author><keyname>Sinan</keyname><forenames>Omar</forenames></author><author><keyname>Zhang</keyname><forenames>Yifan</forenames></author><author><keyname>Ali</keyname><forenames>Ahmed</forenames></author><author><keyname>Kheir</keyname><forenames>Yassine El</forenames></author><author><keyname>Ma</keyname><forenames>Xiaosong</forenames></author><author><keyname>Ruan</keyname><forenames>Chaoyi</forenames></author></authors><title>Fanar: An Arabic-Centric Multimodal Generative AI Platform</title><categories>cs.CL cs.AI</categories><acm-class>I.2.0; D.2.0</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present Fanar, a platform for Arabic-centric multimodal generative AI systems, that supports language, speech and image generation tasks. At the heart of Fanar are Fanar Star and Fanar Prime, two highly capable Arabic Large Language Models (LLMs) that are best in the class on well established benchmarks for similar sized models. Fanar Star is a 7B (billion) parameter model that was trained from scratch on nearly 1 trillion clean and deduplicated Arabic, English and Code tokens. Fanar Prime is a 9B parameter model continually trained on the Gemma-2 9B base model on the same 1 trillion token set. Both models are concurrently deployed and designed to address different types of prompts transparently routed through a custom-built orchestrator. The Fanar platform provides many other capabilities including a customized Islamic Retrieval Augmented Generation (RAG) system for handling religious prompts, a Recency RAG for summarizing information about current or recent events that have occurred after the pre-training data cut-off date. The platform provides additional cognitive capabilities including in-house bilingual speech recognition that supports multiple Arabic dialects, voice and image generation that is fine-tuned to better reflect regional characteristics. Finally, Fanar provides an attribution service that can be used to verify the authenticity of fact based generated content.   The design, development, and implementation of Fanar was entirely undertaken at Hamad Bin Khalifa University's Qatar Computing Research Institute (QCRI) and was sponsored by Qatar's Ministry of Communications and Information Technology to enable sovereign AI technology development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13945</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13945</id><created>2025-01-18</created><authors><author><keyname>Basappa</keyname><forenames>Rhea</forenames></author><author><keyname>Tekman</keyname><forenames>Mustafa</forenames></author><author><keyname>Lu</keyname><forenames>Hong</forenames></author><author><keyname>Faught</keyname><forenames>Benjamin</forenames></author><author><keyname>Kakar</keyname><forenames>Sandeep</forenames></author><author><keyname>Goel</keyname><forenames>Ashok K.</forenames></author></authors><title>Self-Explanation in Social AI Agents</title><categories>cs.CL cs.AI cs.CY</categories><comments>Extended version of the paper published in International Conference   on Intelligent Tutoring Systems, pages 351-360, 2024, Springer. Images   corrected, and live deployment, ablation, and precision study results added</comments><doi>10.1007/978-3-031-63028-6_29</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Social AI agents interact with members of a community, thereby changing the behavior of the community. For example, in online learning, an AI social assistant may connect learners and thereby enhance social interaction. These social AI assistants too need to explain themselves in order to enhance transparency and trust with the learners. We present a method of self-explanation that uses introspection over a self-model of an AI social assistant. The self-model is captured as a functional model that specifies how the methods of the agent use knowledge to achieve its tasks. The process of generating self-explanations uses Chain of Thought to reflect on the self-model and ChatGPT to provide explanations about its functioning. We evaluate the self-explanation of the AI social assistant for completeness and correctness. We also report on its deployment in a live class. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13946</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13946</id><created>2025-01-19</created><authors><author><keyname>Gosmar</keyname><forenames>Diego</forenames></author><author><keyname>Dahl</keyname><forenames>Deborah A.</forenames></author></authors><title>Hallucination Mitigation using Agentic AI Natural Language-Based   Frameworks</title><categories>cs.CL cs.AI cs.MA</categories><comments>18 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Hallucinations remain a significant challenge in current Generative AI models, undermining trust in AI systems and their reliability. This study investigates how orchestrating multiple specialized Artificial Intelligent Agents can help mitigate such hallucinations, with a focus on systems leveraging Natural Language Processing (NLP) to facilitate seamless agent interactions. To achieve this, we design a pipeline that introduces over three hundred prompts, purposefully crafted to induce hallucinations, into a front-end agent. The outputs are then systematically reviewed and refined by second- and third-level agents, each employing distinct large language models and tailored strategies to detect unverified claims, incorporate explicit disclaimers, and clarify speculative content. Additionally, we introduce a set of novel Key Performance Indicators (KPIs) specifically designed to evaluate hallucination score levels. A dedicated fourth-level AI agent is employed to evaluate these KPIs, providing detailed assessments and ensuring accurate quantification of shifts in hallucination-related behaviors. A core component of this investigation is the use of the OVON (Open Voice Network) framework, which relies on universal NLP-based interfaces to transfer contextual information among agents. Through structured JSON messages, each agent communicates its assessment of the hallucination likelihood and the reasons underlying questionable content, thereby enabling the subsequent stage to refine the text without losing context. The results demonstrate that employing multiple specialized agents capable of interoperating with each other through NLP-based agentic frameworks can yield promising outcomes in hallucination mitigation, ultimately bolstering trust within the AI community. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13947</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13947</id><created>2025-01-19</created><authors><author><keyname>Some</keyname><forenames>Lilian</forenames></author><author><keyname>Yang</keyname><forenames>Wenli</forenames></author><author><keyname>Bain</keyname><forenames>Michael</forenames></author><author><keyname>Kang</keyname><forenames>Byeong</forenames></author></authors><title>A Comprehensive Survey on Integrating Large Language Models with   Knowledge-Based Methods</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of artificial intelligence has brought about substantial advancements in the field. One promising direction is the integration of Large Language Models (LLMs) with structured knowledge-based systems. This approach aims to enhance AI capabilities by combining the generative language understanding of LLMs with the precise knowledge representation of structured systems. This survey explores the synergy between LLMs and knowledge bases, focusing on real-world applications and addressing associated technical, operational, and ethical challenges. Through a comprehensive literature review, the study identifies critical issues and evaluates existing solutions. The paper highlights the benefits of integrating generative AI with knowledge bases, including improved data contextualization, enhanced model accuracy, and better utilization of knowledge resources. The findings provide a detailed overview of the current state of research, identify key gaps, and offer actionable recommendations. These insights contribute to advancing AI technologies and support their practical deployment across various sectors. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13948</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13948</id><created>2025-01-19</created><authors><author><keyname>Chandra</keyname><forenames>Rohitash</forenames></author><author><keyname>Ren</keyname><forenames>Guoxiang</forenames></author><author><keyname>Group-H</keyname></author></authors><title>Longitudinal Abuse and Sentiment Analysis of Hollywood Movie Dialogues   using LLMs</title><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Over the past decades, there has been an increasing concern about the prevalence of abusive and violent content in Hollywood movies. This study uses Large Language Models (LLMs) to explore the longitudinal abuse and sentiment analysis of Hollywood Oscar and blockbuster movie dialogues from 1950 to 2024. By employing fine-tuned LLMs, we analyze subtitles for over a thousand movies categorised into four genres to examine the trends and shifts in emotional and abusive content over the past seven decades. Our findings reveal significant temporal changes in movie dialogues, which reflect broader social and cultural influences. Overall, the emotional tendencies in the films are diverse, and the detection of abusive content also exhibits significant fluctuations. The results show a gradual rise in abusive content in recent decades, reflecting social norms and regulatory policy changes. Genres such as thrillers still present a higher frequency of abusive content that emphasises the ongoing narrative role of violence and conflict. At the same time, underlying positive emotions such as humour and optimism remain prevalent in most of the movies. Furthermore, the gradual increase of abusive content in movie dialogues has been significant over the last two decades, where Oscar-nominated movies overtook the top ten blockbusters. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13949</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13949</id><created>2025-01-19</created><authors><author><keyname>Srinivasan</keyname><forenames>Sahana</forenames></author><author><keyname>Ai</keyname><forenames>Xuguang</forenames></author><author><keyname>Zou</keyname><forenames>Minjie</forenames></author><author><keyname>Zou</keyname><forenames>Ke</forenames></author><author><keyname>Kim</keyname><forenames>Hyunjae</forenames></author><author><keyname>Lo</keyname><forenames>Thaddaeus Wai Soon</forenames></author><author><keyname>Pushpanathan</keyname><forenames>Krithi</forenames></author><author><keyname>Kong</keyname><forenames>Yiming</forenames></author><author><keyname>Li</keyname><forenames>Anran</forenames></author><author><keyname>Singer</keyname><forenames>Maxwell</forenames></author><author><keyname>Jin</keyname><forenames>Kai</forenames></author><author><keyname>Antaki</keyname><forenames>Fares</forenames></author><author><keyname>Chen</keyname><forenames>David Ziyou</forenames></author><author><keyname>Liu</keyname><forenames>Dianbo</forenames></author><author><keyname>Adelman</keyname><forenames>Ron A.</forenames></author><author><keyname>Chen</keyname><forenames>Qingyu</forenames></author><author><keyname>Tham</keyname><forenames>Yih Chung</forenames></author></authors><title>Can OpenAI o1 Reason Well in Ophthalmology? A 6,990-Question   Head-to-Head Evaluation Study</title><categories>cs.CL cs.AI</categories><comments>44 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Question: What is the performance and reasoning ability of OpenAI o1 compared to other large language models in addressing ophthalmology-specific questions?   Findings: This study evaluated OpenAI o1 and five LLMs using 6,990 ophthalmological questions from MedMCQA. O1 achieved the highest accuracy (0.88) and macro-F1 score but ranked third in reasoning capabilities based on text-generation metrics. Across subtopics, o1 ranked first in ``Lens'' and ``Glaucoma'' but second to GPT-4o in ``Corneal and External Diseases'', ``Vitreous and Retina'' and ``Oculoplastic and Orbital Diseases''. Subgroup analyses showed o1 performed better on queries with longer ground truth explanations.   Meaning: O1's reasoning enhancements may not fully extend to ophthalmology, underscoring the need for domain-specific refinements to optimize performance in specialized fields like ophthalmology. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13950</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13950</id><created>2025-01-19</created><authors><author><keyname>Chappa</keyname><forenames>Naga VS Raviteja</forenames></author><author><keyname>Shepard</keyname><forenames>Matthew</forenames></author><author><keyname>McCurtain</keyname><forenames>Connor</forenames></author><author><keyname>McCormick</keyname><forenames>Charlotte</forenames></author><author><keyname>Dobbs</keyname><forenames>Page Daniel</forenames></author><author><keyname>Luu</keyname><forenames>Khoa</forenames></author></authors><title>DEFEND: A Large-scale 1M Dataset and Foundation Model for Tobacco   Addiction Prevention</title><categories>cs.CV</categories><comments>11 pages, 5 figures, 5 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While tobacco advertising innovates at unprecedented speed, traditional surveillance methods remain frozen in time, especially in the context of social media. The lack of large-scale, comprehensive datasets and sophisticated monitoring systems has created a widening gap between industry advancement and public health oversight. This paper addresses this critical challenge by introducing Tobacco-1M, a comprehensive dataset of one million tobacco product images with hierarchical labels spanning 75 product categories, and DEFEND, a novel foundation model for tobacco product understanding. Our approach integrates a Feature Enhancement Module for rich multimodal representation learning, a Local-Global Visual Coherence mechanism for detailed feature discrimination, and an Enhanced Image-Text Alignment strategy for precise product characterization. Experimental results demonstrate DEFEND's superior performance, achieving 83.1% accuracy in product classification and 73.8% in visual question-answering tasks, outperforming existing methods by significant margins. Moreover, the model exhibits robust zero-shot learning capabilities with 45.6% accuracy on novel product categories. This work provides regulatory bodies and public health researchers with powerful tools for monitoring emerging tobacco products and marketing strategies, potentially revolutionizing approaches to tobacco control and public health surveillance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13951</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13951</id><created>2025-01-19</created><authors><author><keyname>Tang</keyname><forenames>Jinwen</forenames></author><author><keyname>Guo</keyname><forenames>Qiming</forenames></author><author><keyname>Sun</keyname><forenames>Wenbo</forenames></author><author><keyname>Shang</keyname><forenames>Yi</forenames></author></authors><title>A Layered Multi-Expert Framework for Long-Context Mental Health   Assessments</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long-form mental health assessments pose unique challenges for large language models (LLMs), which often exhibit hallucinations or inconsistent reasoning when handling extended, domain-specific contexts. We introduce Stacked Multi-Model Reasoning (SMMR), a layered framework that leverages multiple LLMs and specialized smaller models as coequal 'experts'. Early layers isolate short, discrete subtasks, while later layers integrate and refine these partial outputs through more advanced long-context models. We evaluate SMMR on the DAIC-WOZ depression-screening dataset and 48 curated case studies with psychiatric diagnoses, demonstrating consistent improvements over single-model baselines in terms of accuracy, F1-score, and PHQ-8 error reduction. By harnessing diverse 'second opinions', SMMR mitigates hallucinations, captures subtle clinical nuances, and enhances reliability in high-stakes mental health assessments. Our findings underscore the value of multi-expert frameworks for more trustworthy AI-driven screening. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13952</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13952</id><created>2025-01-20</created><authors><author><keyname>Zhang</keyname><forenames>Yiyi</forenames></author><author><keyname>Chen</keyname><forenames>Xingyu</forenames></author><author><keyname>Chen</keyname><forenames>Kexin</forenames></author><author><keyname>Du</keyname><forenames>Yuyang</forenames></author><author><keyname>Dang</keyname><forenames>Xilin</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author></authors><title>The Dual-use Dilemma in LLMs: Do Empowering Ethical Capacities Make a   Degraded Utility?</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed extensive efforts to enhance Large Language Models (LLMs) across various domains, alongside growing attention to their ethical implications. However, a critical challenge remains largely overlooked: LLMs must balance between rejecting harmful requests for safety and accommodating legitimate ones for utility. This paper presents a Direct Preference Optimization (DPO) based alignment framework that achieves better overall performance by addressing this ethical-utility trade-off, using chemical domain applications as a proof-of-concept. Our alignment pipeline starts with a GPT-assisted three-phase data generation scheme, in which we create LibraChemQA, a chemical question-answering dataset comprising 31.6k triplet instances. By incorporating an innovative balanced seed in the data generation process, our framework systematically considers both legitimate and illegitimate requests. The framework also introduces a rephrasing mechanism for efficient data augmentation that enhances the model's chemical comprehension. We further develop a novel hybrid evaluation scheme with LLM judges for precise assessment of both safety and utility. Experimental results demonstrate our model's substantial improvements in overall performance where both safety and utility are considered - our resulting model, LibraChem, outperforms leading LLMs including Claude-3, GPT-4o, and LLaMA-3 by margins of 13.44%, 7.16%, and 7.10% respectively on our released benchmark. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13953</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13953</id><created>2025-01-20</created><authors><author><keyname>Zhang</keyname><forenames>Zicheng</forenames></author><author><keyname>Zhao</keyname><forenames>Xiangyu</forenames></author><author><keyname>Fang</keyname><forenames>Xinyu</forenames></author><author><keyname>Li</keyname><forenames>Chunyi</forenames></author><author><keyname>Liu</keyname><forenames>Xiaohong</forenames></author><author><keyname>Min</keyname><forenames>Xiongkuo</forenames></author><author><keyname>Duan</keyname><forenames>Haodong</forenames></author><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Zhai</keyname><forenames>Guangtao</forenames></author></authors><title>Redundancy Principles for MLLMs Benchmarks</title><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the rapid iteration of Multi-modality Large Language Models (MLLMs) and the evolving demands of the field, the number of benchmarks produced annually has surged into the hundreds. The rapid growth has inevitably led to significant redundancy among benchmarks. Therefore, it is crucial to take a step back and critically assess the current state of redundancy and propose targeted principles for constructing effective MLLM benchmarks. In this paper, we focus on redundancy from three key perspectives: 1) Redundancy of benchmark capability dimensions, 2) Redundancy in the number of test questions, and 3) Cross-benchmark redundancy within specific domains. Through the comprehensive analysis over hundreds of MLLMs' performance across more than 20 benchmarks, we aim to quantitatively measure the level of redundancy lies in existing MLLM evaluations, provide valuable insights to guide the future development of MLLM benchmarks, and offer strategies to refine and address redundancy issues effectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13954</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13954</id><created>2025-01-20</created><authors><author><keyname>Huang</keyname><forenames>Long</forenames></author><author><keyname>Zhao</keyname><forenames>Ming</forenames></author><author><keyname>Xiao</keyname><forenames>Limin</forenames></author><author><keyname>Zhang</keyname><forenames>Xiujun</forenames></author><author><keyname>Hu</keyname><forenames>Jungang</forenames></author></authors><title>Chat3GPP: An Open-Source Retrieval-Augmented Generation Framework for   3GPP Documents</title><categories>cs.CL cs.AI cs.DC cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3rd Generation Partnership Project (3GPP) documents is key standards in global telecommunications, while posing significant challenges for engineers and researchers in the telecommunications field due to the large volume and complexity of their contents as well as the frequent updates. Large language models (LLMs) have shown promise in natural language processing tasks, but their general-purpose nature limits their effectiveness in specific domains like telecommunications. To address this, we propose Chat3GPP, an open-source retrieval-augmented generation (RAG) framework tailored for 3GPP specifications. By combining chunking strategies, hybrid retrieval and efficient indexing methods, Chat3GPP can efficiently retrieve relevant information and generate accurate responses to user queries without requiring domain-specific fine-tuning, which is both flexible and scalable, offering significant potential for adapting to other technical standards beyond 3GPP. We evaluate Chat3GPP on two telecom-specific datasets and demonstrate its superior performance compared to existing methods, showcasing its potential for downstream tasks like protocol generation and code automation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13955</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13955</id><created>2025-01-20</created><authors><author><keyname>Tzachristas</keyname><forenames>Ioannis</forenames></author><author><keyname>Narayanan</keyname><forenames>Santhanakrishnan</forenames></author><author><keyname>Antoniou</keyname><forenames>Constantinos</forenames></author></authors><title>Guided Persona-based AI Surveys: Can we replicate personal mobility   preferences at scale using LLMs?</title><categories>cs.CL cs.AI cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This study explores the potential of Large Language Models (LLMs) to generate artificial surveys, with a focus on personal mobility preferences in Germany. By leveraging LLMs for synthetic data creation, we aim to address the limitations of traditional survey methods, such as high costs, inefficiency and scalability challenges. A novel approach incorporating "Personas" - combinations of demographic and behavioural attributes - is introduced and compared to five other synthetic survey methods, which vary in their use of real-world data and methodological complexity. The MiD 2017 dataset, a comprehensive mobility survey in Germany, serves as a benchmark to assess the alignment of synthetic data with real-world patterns. The results demonstrate that LLMs can effectively capture complex dependencies between demographic attributes and preferences while offering flexibility to explore hypothetical scenarios. This approach presents valuable opportunities for transportation planning and social science research, enabling scalable, cost-efficient and privacy-preserving data generation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13956</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13956</id><created>2025-01-20</created><authors><author><keyname>Rasmussen</keyname><forenames>Preston</forenames></author><author><keyname>Paliychuk</keyname><forenames>Pavlo</forenames></author><author><keyname>Beauvais</keyname><forenames>Travis</forenames></author><author><keyname>Ryan</keyname><forenames>Jack</forenames></author><author><keyname>Chalef</keyname><forenames>Daniel</forenames></author></authors><title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title><categories>cs.CL cs.AI cs.IR</categories><comments>12 pages, 3 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark. Additionally, Zep excels in more comprehensive and challenging evaluations than DMR that better reflect real-world enterprise use cases. While existing retrieval-augmented generation (RAG) frameworks for large language model (LLM)-based agents are limited to static document retrieval, enterprise applications demand dynamic knowledge integration from diverse sources including ongoing conversations and business data. Zep addresses this fundamental limitation through its core component Graphiti -- a temporally-aware knowledge graph engine that dynamically synthesizes both unstructured conversational data and structured business data while maintaining historical relationships. In the DMR benchmark, which the MemGPT team established as their primary evaluation metric, Zep demonstrates superior performance (94.8% vs 93.4%). Beyond DMR, Zep's capabilities are further validated through the more challenging LongMemEval benchmark, which better reflects enterprise use cases through complex temporal reasoning tasks. In this evaluation, Zep achieves substantial results with accuracy improvements of up to 18.5% while simultaneously reducing response latency by 90% compared to baseline implementations. These results are particularly pronounced in enterprise-critical tasks such as cross-session information synthesis and long-term context maintenance, demonstrating Zep's effectiveness for deployment in real-world applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13957</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13957</id><created>2025-01-20</created><authors><author><keyname>Geathers</keyname><forenames>Jadon</forenames></author><author><keyname>Hicke</keyname><forenames>Yann</forenames></author><author><keyname>Chan</keyname><forenames>Colleen</forenames></author><author><keyname>Rajashekar</keyname><forenames>Niroop</forenames></author><author><keyname>Sewell</keyname><forenames>Justin</forenames></author><author><keyname>Cornes</keyname><forenames>Susannah</forenames></author><author><keyname>Kizilcec</keyname><forenames>Rene</forenames></author><author><keyname>Shung</keyname><forenames>Dennis</forenames></author></authors><title>Benchmarking Generative AI for Scoring Medical Student Interviews in   Objective Structured Clinical Examinations (OSCEs)</title><categories>cs.CL cs.AI</categories><comments>11 pages, 4 figures (+3 figures in supplementary appendix)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Introduction. Objective Structured Clinical Examinations (OSCEs) are widely used to assess medical students' communication skills, but scoring interview-based assessments is time-consuming and potentially subject to human bias. This study explored the potential of large language models (LLMs) to automate OSCE evaluations using the Master Interview Rating Scale (MIRS).   Methods. We compared the performance of four state-of-the-art LLMs (GPT-4o, Claude 3.5, Llama 3.1, and Gemini 1.5 Pro) in evaluating OSCE transcripts across all 28 items of the MIRS under the conditions of zero-shot, chain-of-thought (CoT), few-shot, and multi-step prompting. The models were benchmarked against a dataset of 10 OSCE cases with 174 expert consensus scores available. Model performance was measured using three accuracy metrics (exact, off-by-one, thresholded).   Results. Averaging across all MIRS items and OSCE cases, LLMs performed with low exact accuracy (0.27 to 0.44), and moderate to high off-by-one accuracy (0.67 to 0.87) and thresholded accuracy (0.75 to 0.88). A zero temperature parameter ensured high intra-rater reliability ($\alpha = 0.98$ for GPT-4o). CoT, few-shot, and multi-step techniques proved valuable when tailored to specific assessment items. The performance was consistent across MIRS items independent of encounter phases and communication domains.   Conclusion. We demonstrated the feasibility of AI-assisted OSCE evaluation and provided benchmarking of multiple LLMs across multiple prompt techniques. Our work provides a baseline performance assessment for LLMs that lays a foundation for future research in automated assessment of clinical communication skills. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13958</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13958</id><created>2025-01-21</created><authors><author><keyname>Zhang</keyname><forenames>Qinggang</forenames></author><author><keyname>Chen</keyname><forenames>Shengyuan</forenames></author><author><keyname>Bei</keyname><forenames>Yuanchen</forenames></author><author><keyname>Yuan</keyname><forenames>Zheng</forenames></author><author><keyname>Zhou</keyname><forenames>Huachi</forenames></author><author><keyname>Hong</keyname><forenames>Zijin</forenames></author><author><keyname>Dong</keyname><forenames>Junnan</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Chang</keyname><forenames>Yi</forenames></author><author><keyname>Huang</keyname><forenames>Xiao</forenames></author></authors><title>A Survey of Graph Retrieval-Augmented Generation for Customized Large   Language Models</title><categories>cs.CL cs.AI cs.IR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large language models (LLMs) have demonstrated remarkable capabilities in a wide range of tasks, yet their application to specialized domains remains challenging due to the need for deep expertise. Retrieval-augmented generation (RAG) has emerged as a promising solution to customize LLMs for professional fields by seamlessly integrating external knowledge bases, enabling real-time access to domain-specific expertise during inference. Despite its potential, traditional RAG systems, based on flat text retrieval, face three critical challenges: (i) complex query understanding in professional contexts, (ii) difficulties in knowledge integration across distributed sources, and (iii) system efficiency bottlenecks at scale. This survey presents a systematic analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new paradigm that revolutionizes domain-specific LLM applications. GraphRAG addresses traditional RAG limitations through three key innovations: (i) graph-structured knowledge representation that explicitly captures entity relationships and domain hierarchies, (ii) efficient graph-based retrieval techniques that enable context-preserving knowledge retrieval with multihop reasoning ability, and (iii) structure-aware knowledge integration algorithms that leverage retrieved knowledge for accurate and logical coherent generation of LLMs. In this survey, we systematically analyze the technical foundations of GraphRAG and examine current implementations across various professional domains, identifying key technical challenges and promising research directions. All the related resources of GraphRAG, including research papers, open-source data, and projects, are collected for the community in \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13959</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13959</id><created>2025-01-21</created><authors><author><keyname>Tao</keyname><forenames>Yicheng</forenames></author><author><keyname>Liu</keyname><forenames>Haotian</forenames></author><author><keyname>Wang</keyname><forenames>Shanwen</forenames></author><author><keyname>Xu</keyname><forenames>Hongteng</forenames></author></authors><title>Assisting Mathematical Formalization with A Learning-based Premise   Retriever</title><categories>cs.CL cs.AI cs.IR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Premise selection is a crucial yet challenging step in mathematical formalization, especially for users with limited experience. Due to the lack of available formalization projects, existing approaches that leverage language models often suffer from data scarcity. In this work, we introduce an innovative method for training a premise retriever to support the formalization of mathematics. Our approach employs a BERT model to embed proof states and premises into a shared latent space. The retrieval model is trained within a contrastive learning framework and incorporates a domain-specific tokenizer along with a fine-grained similarity computation method. Experimental results show that our model is highly competitive compared to existing baselines, achieving strong performance while requiring fewer computational resources. Performance is further enhanced through the integration of a re-ranking module. To streamline the formalization process, we will release a search engine that enables users to query Mathlib theorems directly using proof states, significantly improving accessibility and efficiency. Codes are available at https://github.com/ruc-ai4math/Premise-Retrieval. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13960</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13960</id><created>2025-01-21</created><authors><author><keyname>Páez-Ubieta</keyname><forenames>Ignacio de Loyola</forenames></author><author><keyname>Velasco-Sánchez</keyname><forenames>Edison P.</forenames></author><author><keyname>Puente</keyname><forenames>Santiago T.</forenames></author></authors><title>LiCAR: pseudo-RGB LiDAR image for CAR segmentation</title><categories>eess.IV cs.CV cs.RO</categories><comments>This is a preprint version of the work accepted at 5th International   Conference on Robotics, Computer Vision and Intelligent Systems (ROBOVIS   2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the advancement of computing resources, an increasing number of Neural Networks (NNs) are appearing for image detection and segmentation appear. However, these methods usually accept as input a RGB 2D image. On the other side, Light Detection And Ranging (LiDAR) sensors with many layers provide images that are similar to those obtained from a traditional low resolution RGB camera. Following this principle, a new dataset for segmenting cars in pseudo-RGB images has been generated. This dataset combines the information given by the LiDAR sensor into a Spherical Range Image (SRI), concretely the reflectivity, near infrared and signal intensity 2D images. These images are then fed into instance segmentation NNs. These NNs segment the cars that appear in these images, having as result a Bounding Box (BB) and mask precision of 88% and 81.5% respectively with You Only Look Once (YOLO)-v8 large. By using this segmentation NN, some trackers have been applied so as to follow each car segmented instance along a video feed, having great performance in real world experiments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13961</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13961</id><created>2025-01-21</created><authors><author><keyname>Pramanik</keyname><forenames>Aniket</forenames></author><author><keyname>Rahman</keyname><forenames>Obaidullah</forenames></author><author><keyname>Venkatakrishnan</keyname><forenames>Singanallur V.</forenames></author><author><keyname>Ziabari</keyname><forenames>Amirkoushyar</forenames></author></authors><title>A Fast, Scalable, and Robust Deep Learning-based Iterative   Reconstruction Framework for Accelerated Industrial Cone-beam X-ray Computed   Tomography</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cone-beam X-ray Computed Tomography (XCT) with large detectors and corresponding large-scale 3D reconstruction plays a pivotal role in micron-scale characterization of materials and parts across various industries. In this work, we present a novel deep neural network-based iterative algorithm that integrates an artifact reduction-trained CNN as a prior model with automated regularization parameter selection, tailored for large-scale industrial cone-beam XCT data. Our method achieves high-quality 3D reconstructions even for extremely dense thick metal parts - which traditionally pose challenges to industrial CT images - in just a few iterations. Furthermore, we show the generalizability of our approach to out-of-distribution scans obtained under diverse scanning conditions. Our method effectively handles significant noise and streak artifacts, surpassing state-of-the-art supervised learning methods trained on the same data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13962</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13962</id><created>2025-01-21</created><authors><author><keyname>Gueriani</keyname><forenames>Afrah</forenames></author><author><keyname>Kheddar</keyname><forenames>Hamza</forenames></author><author><keyname>Mazari</keyname><forenames>Ahmed Cherif</forenames></author></authors><title>Adaptive Cyber-Attack Detection in IIoT Using Attention-Based LSTM-CNN   Models</title><categories>cs.CR cs.AI cs.LG cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The rapid expansion of the industrial Internet of things (IIoT) has introduced new challenges in securing critical infrastructures against sophisticated cyberthreats. This study presents the development and evaluation of an advanced Intrusion detection (IDS) based on a hybrid LSTM-convolution neural network (CNN)-Attention architecture, specifically designed to detect and classify cyberattacks in IIoT environments. The research focuses on two key classification tasks: binary and multi-class classification. The proposed models was rigorously tested using the Edge-IIoTset dataset. To mitigate the class imbalance in the dataset, the synthetic minority over-sampling technique (SMOTE) was employed to generate synthetic samples for the underrepresented classes. This ensured that the model could learn effectively from all classes, thereby improving the overall classification performance. Through systematic experimentation, various deep learning (DL) models were compared, ultimately demonstrating that the LSTM-CNN-Attention model consistently outperformed others across key performance metrics. In binary classification, the model achieved near-perfect accuracy, while in multi-class classification, it maintained a high accuracy level (99.04%), effectively categorizing different attack types with a loss value of 0.0220%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13963</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13963</id><created>2025-01-21</created><authors><author><keyname>Hadadi</keyname><forenames>Mozhgan</forenames></author><author><keyname>Saraeian</keyname><forenames>Mehdi</forenames></author><author><keyname>Godbersen</keyname><forenames>Jackson</forenames></author><author><keyname>Jubery</keyname><forenames>Talukder</forenames></author><author><keyname>Li</keyname><forenames>Yawei</forenames></author><author><keyname>Attigala</keyname><forenames>Lakshmi</forenames></author><author><keyname>Balu</keyname><forenames>Aditya</forenames></author><author><keyname>Sarkar</keyname><forenames>Soumik</forenames></author><author><keyname>Schnable</keyname><forenames>Patrick S.</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Adarsh</forenames></author><author><keyname>Ganapathysubramanian</keyname><forenames>Baskar</forenames></author></authors><title>Procedural Generation of 3D Maize Plant Architecture from LIDAR Data</title><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This study introduces a robust framework for generating procedural 3D models of maize (Zea mays) plants from LiDAR point cloud data, offering a scalable alternative to traditional field-based phenotyping. Our framework leverages Non-Uniform Rational B-Spline (NURBS) surfaces to model the leaves of maize plants, combining Particle Swarm Optimization (PSO) for an initial approximation of the surface and a differentiable programming framework for precise refinement of the surface to fit the point cloud data. In the first optimization phase, PSO generates an approximate NURBS surface by optimizing its control points, aligning the surface with the LiDAR data, and providing a reliable starting point for refinement. The second phase uses NURBS-Diff, a differentiable programming framework, to enhance the accuracy of the initial fit by refining the surface geometry and capturing intricate leaf details. Our results demonstrate that, while PSO establishes a robust initial fit, the integration of differentiable NURBS significantly improves the overall quality and fidelity of the reconstructed surface. This hierarchical optimization strategy enables accurate 3D reconstruction of maize leaves across diverse genotypes, facilitating the subsequent extraction of complex traits like phyllotaxy. We demonstrate our approach on diverse genotypes of field-grown maize plants. All our codes are open-source to democratize these phenotyping approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13964</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13964</id><created>2025-01-21</created><authors><author><keyname>Duan</keyname><forenames>Lin</forenames></author><author><keyname>Xiu</keyname><forenames>Yanming</forenames></author><author><keyname>Gorlatova</keyname><forenames>Maria</forenames></author></authors><title>Advancing the Understanding and Evaluation of AR-Generated Scenes: When   Vision-Language Models Shine and Stumble</title><categories>cs.CV cs.AI cs.HC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Augmented Reality (AR) enhances the real world by integrating virtual content, yet ensuring the quality, usability, and safety of AR experiences presents significant challenges. Could Vision-Language Models (VLMs) offer a solution for the automated evaluation of AR-generated scenes? Could Vision-Language Models (VLMs) offer a solution for the automated evaluation of AR-generated scenes? In this study, we evaluate the capabilities of three state-of-the-art commercial VLMs -- GPT, Gemini, and Claude -- in identifying and describing AR scenes. For this purpose, we use DiverseAR, the first AR dataset specifically designed to assess VLMs' ability to analyze virtual content across a wide range of AR scene complexities. Our findings demonstrate that VLMs are generally capable of perceiving and describing AR scenes, achieving a True Positive Rate (TPR) of up to 93\% for perception and 71\% for description. While they excel at identifying obvious virtual objects, such as a glowing apple, they struggle when faced with seamlessly integrated content, such as a virtual pot with realistic shadows. Our results highlight both the strengths and the limitations of VLMs in understanding AR scenarios. We identify key factors affecting VLM performance, including virtual content placement, rendering quality, and physical plausibility. This study underscores the potential of VLMs as tools for evaluating the quality of AR experiences. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13965</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13965</id><created>2025-01-21</created><authors><author><keyname>Roy</keyname><forenames>Bidhan</forenames></author><author><keyname>Potash</keyname><forenames>Peter</forenames></author><author><keyname>Villagra</keyname><forenames>Marcos</forenames></author></authors><title>ZKLoRA: Efficient Zero-Knowledge Proofs for LoRA Verification</title><categories>cs.CR cs.AI cs.LG</categories><comments>7 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Low-Rank Adaptation (LoRA) is a widely adopted method for customizing large-scale language models. In distributed, untrusted training environments, an open source base model user may want to use LoRA weights created by an external contributor, leading to two requirements: (1) the base model user must confirm that the LoRA weights are effective when paired with the intended base model, and (2) the LoRA contributor must keep their proprietary weights private until compensation is assured.   We present ZKLoRA, a zero-knowledge verification protocol that relies on succinct proofs and our novel Multi-Party Inference procedure to verify LoRA-base model compatibility without exposing LoRA weights. ZKLoRA produces deterministic correctness guarantees and validates each LoRA module in only 1-2 seconds on state-of-the-art large language models. This low-latency approach enables nearly real-time verification and promotes secure collaboration among geographically decentralized teams and contract-based training pipelines. The protocol ensures that the delivered LoRA module works as claimed, safeguarding the contributor's intellectual property while providing the base model user with verification of compatibility and lineage. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13967</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13967</id><created>2025-01-22</created><authors><author><keyname>Che</keyname><forenames>Haoxuan</forenames></author><author><keyname>Wu</keyname><forenames>Yifei</forenames></author><author><keyname>Jin</keyname><forenames>Haibo</forenames></author><author><keyname>Xia</keyname><forenames>Yong</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author></authors><title>FedDAG: Federated Domain Adversarial Generation Towards Generalizable   Medical Image Analysis</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Federated domain generalization aims to train a global model from multiple source domains and ensure its generalization ability to unseen target domains. {Due to the target domain being with unknown domain shifts, attempting to approximate these gaps by source domains may be the key to improving model generalization capability.} Existing works mainly focus on sharing and recombining local domain-specific attributes to increase data diversity and simulate potential domain shifts. {However, these methods may be insufficient since only the local attribute recombination can be hard to touch the out-of-distribution of global data.} In this paper, we propose a simple-yet-efficient framework named Federated Domain Adversarial Generation (FedDAG). {It aims to simulate the domain shift and improve the model generalization by adversarially generating novel domains different from local and global source domains.} Specifically, it generates novel-style images by maximizing the instance-level feature discrepancy between original and generated images and trains a generalizable task model by minimizing their feature discrepancy. {Further, we observed that FedDAG could cause different performance improvements for local models. It may be due to inherent data isolation and heterogeneity among clients, exacerbating the imbalance in their generalization contributions to the global model.} {Ignoring this imbalance can lead the global model's generalization ability to be sub-optimal, further limiting the novel domain generation procedure. } Thus, to mitigate this imbalance, FedDAG hierarchically aggregates local models at the within-client and across-client levels by using the sharpness concept to evaluate client model generalization contributions. {Extensive experiments across four medical benchmarks demonstrate FedDAG's ability to enhance generalization in federated medical scenarios.} </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13968</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13968</id><created>2025-01-22</created><authors><author><keyname>Uesugi</keyname><forenames>Kenta</forenames></author><author><keyname>Saito</keyname><forenames>Naoki</forenames></author><author><keyname>Maeda</keyname><forenames>Keisuke</forenames></author><author><keyname>Ogawa</keyname><forenames>Takahiro</forenames></author><author><keyname>Haseyama</keyname><forenames>Miki</forenames></author></authors><title>Triplet Synthesis For Enhancing Composed Image Retrieval via   Counterfactual Image Generation</title><categories>cs.CV cs.LG eess.IV</categories><comments>4 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Composed Image Retrieval (CIR) provides an effective way to manage and access large-scale visual data. Construction of the CIR model utilizes triplets that consist of a reference image, modification text describing desired changes, and a target image that reflects these changes. For effectively training CIR models, extensive manual annotation to construct high-quality training datasets, which can be time-consuming and labor-intensive, is required. To deal with this problem, this paper proposes a novel triplet synthesis method by leveraging counterfactual image generation. By controlling visual feature modifications via counterfactual image generation, our approach automatically generates diverse training triplets without any manual intervention. This approach facilitates the creation of larger and more expressive datasets, leading to the improvement of CIR model's performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13969</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13969</id><created>2025-01-22</created><authors><author><keyname>Zhang</keyname><forenames>Yunfan</forenames></author><author><keyname>Xiong</keyname><forenames>Zhiwei</forenames></author><author><keyname>Shen</keyname><forenames>Zhiqi</forenames></author><author><keyname>Lin</keyname><forenames>Guosheng</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Vun</keyname><forenames>Nicolas</forenames></author></authors><title>InsTex: Indoor Scenes Stylized Texture Synthesis</title><categories>cs.CV cs.GR cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Generating high-quality textures for 3D scenes is crucial for applications in interior design, gaming, and augmented/virtual reality (AR/VR). Although recent advancements in 3D generative models have enhanced content creation, significant challenges remain in achieving broad generalization and maintaining style consistency across multiple viewpoints. Current methods, such as 2D diffusion models adapted for 3D texturing, suffer from lengthy processing times and visual artifacts, while approaches driven by 3D data often fail to generalize effectively. To overcome these challenges, we introduce InsTex, a two-stage architecture designed to generate high-quality, style-consistent textures for 3D indoor scenes. InsTex utilizes depth-to-image diffusion priors in a coarse-to-fine pipeline, first generating multi-view images with a pre-trained 2D diffusion model and subsequently refining the textures for consistency. Our method supports both textual and visual prompts, achieving state-of-the-art results in visual quality and quantitative metrics, and demonstrates its effectiveness across various 3D texturing applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13970</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13970</id><created>2025-01-22</created><authors><author><keyname>Al-Saih</keyname><forenames>Khaled</forenames></author><author><keyname>Al-Shargie</keyname><forenames>Fares</forenames></author><author><keyname>Al-hiyali</keyname><forenames>Mohammed Isam</forenames></author><author><keyname>Alhejaili</keyname><forenames>Reham</forenames></author></authors><title>Patch-Based and Non-Patch-Based inputs Comparison into Deep Neural   Models: Application for the Segmentation of Retinal Diseases on Optical   Coherence Tomography Volumes</title><categories>eess.IV cs.CV cs.LG</categories><comments>6 pages, 1 figures, 2 tables, submitted to 15th IEEE Symposium on   Computer Applications &amp; Industrial Electronics</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Worldwide, sight loss is commonly occurred by retinal diseases, with age-related macular degeneration (AMD) being a notable facet that affects elderly patients. Approaching 170 million persons wide-ranging have been spotted with AMD, a figure anticipated to rise to 288 million by 2040. For visualizing retinal layers, optical coherence tomography (OCT) dispenses the most compelling non-invasive method. Frequent patient visits have increased the demand for automated analysis of retinal diseases, and deep learning networks have shown promising results in both image and pixel-level 2D scan classification. However, when relying solely on 2D data, accuracy may be impaired, especially when localizing fluid volume diseases. The goal of automatic techniques is to outperform humans in manually recognizing illnesses in medical data. In order to further understand the benefit of deep learning models, we studied the effects of the input size. The dice similarity coefficient (DSC) metric showed a human performance score of 0.71 for segmenting various retinal diseases. Yet, the deep models surpassed human performance to establish a new era of advancement of segmenting the diseases on medical images. However, to further improve the performance of the models, overlapping patches enhanced the performance of the deep models compared to feeding the full image. The highest score for a patch-based model in the DSC metric was 0.88 in comparison to the score of 0.71 for the same model in non-patch-based for SRF fluid segmentation. The objective of this article is to show a fair comparison between deep learning models in relation to the input (Patch-Based vs. NonPatch-Based). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13971</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13971</id><created>2025-01-22</created><authors><author><keyname>Jiang</keyname><forenames>Junzhe</forenames></author><author><keyname>Gu</keyname><forenames>Chun</forenames></author><author><keyname>Chen</keyname><forenames>Yurui</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>GS-LiDAR: Generating Realistic LiDAR Point Clouds with Panoramic   Gaussian Splatting</title><categories>cs.CV cs.GR eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LiDAR novel view synthesis (NVS) has emerged as a novel task within LiDAR simulation, offering valuable simulated point cloud data from novel viewpoints to aid in autonomous driving systems. However, existing LiDAR NVS methods typically rely on neural radiance fields (NeRF) as their 3D representation, which incurs significant computational costs in both training and rendering. Moreover, NeRF and its variants are designed for symmetrical scenes, making them ill-suited for driving scenarios. To address these challenges, we propose GS-LiDAR, a novel framework for generating realistic LiDAR point clouds with panoramic Gaussian splatting. Our approach employs 2D Gaussian primitives with periodic vibration properties, allowing for precise geometric reconstruction of both static and dynamic elements in driving scenarios. We further introduce a novel panoramic rendering technique with explicit ray-splat intersection, guided by panoramic LiDAR supervision. By incorporating intensity and ray-drop spherical harmonic (SH) coefficients into the Gaussian primitives, we enhance the realism of the rendered point clouds. Extensive experiments on KITTI-360 and nuScenes demonstrate the superiority of our method in terms of quantitative metrics, visual quality, as well as training and rendering efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13972</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13972</id><created>2025-01-22</created><authors><author><keyname>Altalib</keyname><forenames>Alzahra</forenames></author><author><keyname>McGregor</keyname><forenames>Scott</forenames></author><author><keyname>Li</keyname><forenames>Chunhui</forenames></author><author><keyname>Perelli</keyname><forenames>Alessandro</forenames></author></authors><title>Synthetic CT image generation from CBCT: A Systematic Review</title><categories>eess.IV cs.CV</categories><comments>21 pages, 14 Figures, Accepted in the IEEE Transactions on Radiation   and Plasma Medical Sciences</comments><msc-class>68T07</msc-class><acm-class>J.2</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The generation of synthetic CT (sCT) images from cone-beam CT (CBCT) data using deep learning methodologies represents a significant advancement in radiation oncology. This systematic review, following PRISMA guidelines and using the PICO model, comprehensively evaluates the literature from 2014 to 2024 on the generation of sCT images for radiation therapy planning in oncology. A total of 35 relevant studies were identified and analyzed, revealing the prevalence of deep learning approaches in the generation of sCT. This review comprehensively covers synthetic CT generation based on CBCT and proton-based studies. Some of the commonly employed architectures explored are convolutional neural networks (CNNs), generative adversarial networks (GANs), transformers, and diffusion models. Evaluation metrics including mean absolute error (MAE), root mean square error (RMSE), peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) consistently demonstrate the comparability of sCT images with gold-standard planning CTs (pCT), indicating their potential to improve treatment precision and patient outcomes. Challenges such as field-of-view (FOV) disparities and integration into clinical workflows are discussed, along with recommendations for future research and standardization efforts. In general, the findings underscore the promising role of sCT-based approaches in personalized treatment planning and adaptive radiation therapy, with potential implications for improved oncology treatment delivery and patient care. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13973</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13973</id><created>2025-01-22</created><authors><author><keyname>Long</keyname><forenames>Juncen</forenames></author><author><keyname>Bardaro</keyname><forenames>Gianluca</forenames></author><author><keyname>Mentasti</keyname><forenames>Simone</forenames></author><author><keyname>Matteucci</keyname><forenames>Matteo</forenames></author></authors><title>A Spatio-temporal Graph Network Allowing Incomplete Trajectory Input for   Pedestrian Trajectory Prediction</title><categories>cs.CV cs.AI cs.LG cs.RO</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Pedestrian trajectory prediction is important in the research of mobile robot navigation in environments with pedestrians. Most pedestrian trajectory prediction algorithms require the input historical trajectories to be complete. If a pedestrian is unobservable in any frame in the past, then its historical trajectory become incomplete, the algorithm will not predict its future trajectory. To address this limitation, we propose the STGN-IT, a spatio-temporal graph network allowing incomplete trajectory input, which can predict the future trajectories of pedestrians with incomplete historical trajectories. STGN-IT uses the spatio-temporal graph with an additional encoding method to represent the historical trajectories and observation states of pedestrians. Moreover, STGN-IT introduces static obstacles in the environment that may affect the future trajectories as nodes to further improve the prediction accuracy. A clustering algorithm is also applied in the construction of spatio-temporal graphs. Experiments on public datasets show that STGN-IT outperforms state of the art algorithms on these metrics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13974</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13974</id><created>2025-01-22</created><authors><author><keyname>Hoffert</keyname><forenames>Antonio</forenames></author></authors><title>Absolute Governance: A Framework for Synchronization and Certification   of the Corporate Contractual State</title><categories>cs.CR cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This dissertation addresses the challenge of ensuring transactional integrity and reducing costs in corporate governance through blockchain technology. We propose an on-chain methodology for certifying, registering, and querying institutional transactional status. Our decentralized governance approach utilizes consensus mechanisms and smart contracts to automate and enforce business rules. The framework aims to reduce the transaction costs associated with contractual measurement reports and enhance overall transactional integrity. We provide a detailed exploration of how blockchain technology can be effectively harnessed to offer a robust solution to these challenges, setting the stage for our proposed solution and its potential impact on corporate governance. The application of the methodology resulted in as average of 2% overbilling reduction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13975</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13975</id><created>2025-01-22</created><authors><author><keyname>Lan</keyname><forenames>Lei</forenames></author><author><keyname>Shao</keyname><forenames>Tianjia</forenames></author><author><keyname>Lu</keyname><forenames>Zixuan</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Jiang</keyname><forenames>Chenfanfu</forenames></author><author><keyname>Yang</keyname><forenames>Yin</forenames></author></authors><title>3DGS$^2$: Near Second-order Converging 3D Gaussian Splatting</title><categories>cs.CV cs.GR</categories><comments>11 pages, submit on SIGGRAPH 2025</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  3D Gaussian Splatting (3DGS) has emerged as a mainstream solution for novel view synthesis and 3D reconstruction. By explicitly encoding a 3D scene using a collection of Gaussian kernels, 3DGS achieves high-quality rendering with superior efficiency. As a learning-based approach, 3DGS training has been dealt with the standard stochastic gradient descent (SGD) method, which offers at most linear convergence. Consequently, training often requires tens of minutes, even with GPU acceleration. This paper introduces a (near) second-order convergent training algorithm for 3DGS, leveraging its unique properties. Our approach is inspired by two key observations. First, the attributes of a Gaussian kernel contribute independently to the image-space loss, which endorses isolated and local optimization algorithms. We exploit this by splitting the optimization at the level of individual kernel attributes, analytically constructing small-size Newton systems for each parameter group, and efficiently solving these systems on GPU threads. This achieves Newton-like convergence per training image without relying on the global Hessian. Second, kernels exhibit sparse and structured coupling across input images. This property allows us to effectively utilize spatial information to mitigate overshoot during stochastic training. Our method converges an order faster than standard GPU-based 3DGS training, requiring over $10\times$ fewer iterations while maintaining or surpassing the quality of the compared with the SGD-based 3DGS reconstructions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13976</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13976</id><created>2025-01-22</created><authors><author><keyname>Bonagiri</keyname><forenames>Akash</forenames></author><author><keyname>Li</keyname><forenames>Lucen</forenames></author><author><keyname>Oak</keyname><forenames>Rajvardhan</forenames></author><author><keyname>Babar</keyname><forenames>Zeerak</forenames></author><author><keyname>Wojcieszak</keyname><forenames>Magdalena</forenames></author><author><keyname>Chhabra</keyname><forenames>Anshuman</forenames></author></authors><title>Towards Safer Social Media Platforms: Scalable and Performant Few-Shot   Harmful Content Moderation Using Large Language Models</title><categories>cs.CL cs.AI cs.CY cs.SI</categories><comments>This paper is in submission and under peer review</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The prevalence of harmful content on social media platforms poses significant risks to users and society, necessitating more effective and scalable content moderation strategies. Current approaches rely on human moderators, supervised classifiers, and large volumes of training data, and often struggle with scalability, subjectivity, and the dynamic nature of harmful content (e.g., violent content, dangerous challenge trends, etc.). To bridge these gaps, we utilize Large Language Models (LLMs) to undertake few-shot dynamic content moderation via in-context learning. Through extensive experiments on multiple LLMs, we demonstrate that our few-shot approaches can outperform existing proprietary baselines (Perspective and OpenAI Moderation) as well as prior state-of-the-art few-shot learning methods, in identifying harm. We also incorporate visual information (video thumbnails) and assess if different multimodal techniques improve model performance. Our results underscore the significant benefits of employing LLM based methods for scalable and dynamic harmful content moderation online. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13977</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13977</id><created>2025-01-22</created><authors><author><keyname>Oak</keyname><forenames>Rajvardhan</forenames></author><author><keyname>Haroon</keyname><forenames>Muhammad</forenames></author><author><keyname>Jo</keyname><forenames>Claire</forenames></author><author><keyname>Wojcieszak</keyname><forenames>Magdalena</forenames></author><author><keyname>Chhabra</keyname><forenames>Anshuman</forenames></author></authors><title>Re-ranking Using Large Language Models for Mitigating Exposure to   Harmful Content on Social Media Platforms</title><categories>cs.CL cs.AI cs.CY cs.SI</categories><comments>This paper is under peer review</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement, which can result in inadvertent exposure to harmful content. Current moderation efforts, reliant on classifiers trained with extensive human-annotated data, struggle with scalability and adapting to new forms of harm. To address these challenges, we propose a novel re-ranking approach using Large Language Models (LLMs) in zero-shot and few-shot settings. Our method dynamically assesses and re-ranks content sequences, effectively mitigating harmful content exposure without requiring extensive labeled data. Alongside traditional ranking metrics, we also introduce two new metrics to evaluate the effectiveness of re-ranking in reducing exposure to harmful content. Through experiments on three datasets, three models and across three configurations, we demonstrate that our LLM-based approach significantly outperforms existing proprietary moderation approaches, offering a scalable and adaptable solution for harm mitigation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13978</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13978</id><created>2025-01-22</created><authors><author><keyname>Yeo</keyname><forenames>Sangyeop</forenames></author><author><keyname>Hwang</keyname><forenames>Seung-won</forenames></author><author><keyname>Ma</keyname><forenames>Yu-Seung</forenames></author></authors><title>Chain of Grounded Objectives: Bridging Process and Goal-oriented   Prompting for Code Generation</title><categories>cs.CL cs.AI cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of Large Language Models (LLMs) for code generation has gained significant attention in recent years. Existing methods often aim to improve the quality of generated code by incorporating additional contextual information or guidance into input prompts. Many of these approaches adopt sequential reasoning strategies, mimicking human-like step-by-step thinking. However, such strategies may constrain flexibility, as they do not always align with the structured characteristics of programming languages. This paper introduces the Chain of Grounded Objectives (CGO), a method that embeds functional objectives into input prompts to enhance code generation. By leveraging appropriately structured objectives as input and avoiding explicit sequential procedures, CGO adapts effectively to the structured nature of programming tasks. Empirical evaluations demonstrate that CGO effectively enhances code generation, addressing limitations of existing approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13981</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13981</id><created>2025-01-22</created><authors><author><keyname>Zuguo</keyname><forenames>Chen</forenames></author><author><keyname>Aowei</keyname><forenames>Kuang</forenames></author><author><keyname>Yi</keyname><forenames>Huang</forenames></author><author><keyname>Jie</keyname><forenames>Jin</forenames></author></authors><title>Enhanced PEC-YOLO for Detecting Improper Safety Gear Wearing Among Power   Line Workers</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To address the high risks associated with improper use of safety gear in complex power line environments, where target occlusion and large variance are prevalent, this paper proposes an enhanced PEC-YOLO object detection algorithm. The method integrates deep perception with multi-scale feature fusion, utilizing PConv and EMA attention mechanisms to enhance feature extraction efficiency and minimize model complexity. The CPCA attention mechanism is incorporated into the SPPF module, improving the model's ability to focus on critical information and enhance detection accuracy, particularly in challenging conditions. Furthermore, the introduction of the BiFPN neck architecture optimizes the utilization of low-level and high-level features, enhancing feature representation through adaptive fusion and context-aware mechanism. Experimental results demonstrate that the proposed PEC-YOLO achieves a 2.7% improvement in detection accuracy compared to YOLOv8s, while reducing model parameters by 42.58%. Under identical conditions, PEC-YOLO outperforms other models in detection speed, meeting the stringent accuracy requirements for safety gear detection in construction sites. This study contributes to the development of efficient and accurate intelligent monitoring systems for ensuring worker safety in hazardous environments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13982</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13982</id><created>2025-01-23</created><authors><author><keyname>Cai</keyname><forenames>Chengyi</forenames></author><author><keyname>Ye</keyname><forenames>Zesheng</forenames></author><author><keyname>Feng</keyname><forenames>Lei</forenames></author><author><keyname>Qi</keyname><forenames>Jianzhong</forenames></author><author><keyname>Liu</keyname><forenames>Feng</forenames></author></authors><title>Attribute-based Visual Reprogramming for Image Classification with CLIP</title><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Visual reprogramming (VR) reuses pre-trained vision models for downstream image classification tasks by adding trainable noise patterns to inputs. When applied to vision-language models (e.g., CLIP), existing VR approaches follow the same pipeline used in vision models (e.g., ResNet, ViT), where ground-truth class labels are inserted into fixed text templates to guide the optimization of VR patterns. This label-based approach, however, overlooks the rich information and diverse attribute-guided textual representations that CLIP can exploit, which may lead to the misclassification of samples. In this paper, we propose Attribute-based Visual Reprogramming (AttrVR) for CLIP, utilizing descriptive attributes (DesAttrs) and distinctive attributes (DistAttrs), which respectively represent common and unique feature descriptions for different classes. Besides, as images of the same class may reflect different attributes after VR, AttrVR iteratively refines patterns using the $k$-nearest DesAttrs and DistAttrs for each image sample, enabling more dynamic and sample-specific optimization. Theoretically, AttrVR is shown to reduce intra-class variance and increase inter-class separation. Empirically, it achieves superior performance in 12 downstream tasks for both ViT-based and ResNet-based CLIP. The success of AttrVR facilitates more effective integration of VR from unimodal vision models into vision-language models. Our code is available at https://github.com/tmlr-group/AttrVR. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13983</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13983</id><created>2025-01-23</created><authors><author><keyname>Fan</keyname><forenames>Yang</forenames></author></authors><title>AdEval: Alignment-based Dynamic Evaluation to Mitigate Data   Contamination in Large Language Models</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the issue of data contamination has become increasingly severe, leading to potential overestimation of model performance during evaluation. To address this, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data evaluation method aimed at mitigating the impact of data contamination on evaluation reliability. AdEval extracts key knowledge points and main ideas to align dynamically generated questions with static data's core concepts. It also leverages online search to provide detailed explanations of related knowledge points, thereby creating high-quality evaluation samples with robust knowledge support. Furthermore, AdEval incorporates mechanisms to control the number and complexity of questions, enabling dynamic alignment and flexible adjustment. This ensures that the generated questions align with the complexity of static data while supporting varied complexity levels. Based on Bloom's taxonomy, AdEval conducts a multi-dimensional evaluation of LLMs across six cognitive levels: remembering, understanding, applying, analyzing, evaluating, and creating. Experimental results on multiple datasets demonstrate that AdEval effectively reduces the impact of data contamination on evaluation outcomes, enhancing both the fairness and reliability of the evaluation process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13984</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13984</id><created>2025-01-23</created><authors><author><keyname>Gupta</keyname><forenames>Bhumika</forenames></author><author><keyname>Ta</keyname><forenames>Pralaypati</forenames></author><author><keyname>Ram</keyname><forenames>Keerthi</forenames></author><author><keyname>Sivaprakasam</keyname><forenames>Mohanasankar</forenames></author></authors><title>Comprehensive Modeling and Question Answering of Cancer Clinical   Practice Guidelines using LLMs</title><categories>cs.CL cs.AI cs.LG</categories><doi>10.1109/CIBCB58642.2024.10702112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The updated recommendations on diagnostic procedures and treatment pathways for a medical condition are documented as graphical flows in Clinical Practice Guidelines (CPGs). For effective use of the CPGs in helping medical professionals in the treatment decision process, it is necessary to fully capture the guideline knowledge, particularly the contexts and their relationships in the graph. While several existing works have utilized these guidelines to create rule bases for Clinical Decision Support Systems, limited work has been done toward directly capturing the full medical knowledge contained in CPGs. This work proposes an approach to create a contextually enriched, faithful digital representation of National Comprehensive Cancer Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and node &amp; relationship classification. We also implement semantic enrichment of the model by using Large Language Models (LLMs) for node classification, achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot learning, respectively. Additionally, we introduce a methodology for answering natural language questions with constraints to guideline text by leveraging LLMs to extract the relevant subgraph from the guideline knowledge base. By generating natural language answers based on subgraph paths and semantic information, we mitigate the risk of incorrect answers and hallucination associated with LLMs, ensuring factual accuracy in medical domain Question Answering. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13985</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13985</id><created>2025-01-23</created><authors><author><keyname>Xiong</keyname><forenames>Baochen</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoshan</forenames></author><author><keyname>Song</keyname><forenames>Yaguang</forenames></author><author><keyname>Wang</keyname><forenames>Yaowei</forenames></author><author><keyname>Xu</keyname><forenames>Changsheng</forenames></author></authors><title>Pilot: Building the Federated Multimodal Instruction Tuning Framework</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore a novel federated multimodal instruction tuning task(FedMIT), which is significant for collaboratively fine-tuning MLLMs on different types of multimodal instruction data on distributed devices. To solve the new task, we propose a federated multimodal instruction tuning framework(Pilot). Our framework integrates two stages of "adapter on adapter" into the connector of the vision encoder and the LLM. In stage 1, we extract task-specific features and client-specific features from visual information. In stage 2, we build the cross-task Mixture-of-Adapters(CT-MoA) module to perform cross-task interaction. Each client can not only capture personalized information of local data and learn task-related multimodal information, but also learn general knowledge from other tasks. In addition, we introduce an adaptive parameter aggregation strategy for text training parameters, which optimizes parameter aggregation by calculating weights based on the euclidean distance between parameters, so that parameter aggregation can benefit from positive effects to the greatest extent while effectively reducing negative effects. Our framework can collaboratively exploit distributed data from different local clients to learn cross-task knowledge without being affected by the task heterogeneity during instruction tuning. The effectiveness of our method is verified in two different cross-task scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13986</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13986</id><created>2025-01-23</created><authors><author><keyname>Bharadwaj</keyname><forenames>Vivek</forenames></author><author><keyname>Glover</keyname><forenames>Austin Scott</forenames></author><author><keyname>Buluc</keyname><forenames>Aydin</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author></authors><title>An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks</title><categories>cs.LG cs.AI</categories><comments>12 pages, 9 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Rotation equivariant graph neural networks, i.e., networks designed to guarantee certain geometric relations between their inputs and outputs, yield state-of-the-art performance on spatial deep learning tasks. They exhibit high data efficiency during training and significantly reduced inference time for interatomic potential calculations compared to classical approaches. Key to these models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts two dense feature vectors with a highly structured sparse tensor to produce a dense output vector. The operation, which may be repeated millions of times for typical equivariant models, is a costly and inefficient bottleneck. We introduce a GPU sparse kernel generator for the CG tensor product that provides significant speedup over the best existing open and closed-source implementations. Our implementation achieves high performance by carefully managing GPU shared memory through static analysis at model compile-time, minimizing reads and writes to global memory. We break the tensor product into a series of kernels with operands that fit entirely into registers, enabling us to emit long arithmetic instruction streams that maximize instruction-level parallelism. By fusing the CG tensor product with a subsequent graph convolution, we reduce both intermediate storage and global memory traffic over naive approaches that duplicate input data. We also provide optimized kernels for the gradient of the CG tensor product and a novel identity for the higher partial derivatives required to predict interatomic forces. Our fused kernels offer up to 4.5x speedup for the forward pass and 3x for the backward pass over NVIDIA cuEquivariance, as well as &gt;10x speedup over the widely-used e3nn package. We offer up to 5.3x inference-time speedup for the MACE chemistry foundation model over the original unoptimized version. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13987</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13987</id><created>2025-01-23</created><authors><author><keyname>Hu</keyname><forenames>Xing</forenames></author><author><keyname>Cheng</keyname><forenames>Yuan</forenames></author><author><keyname>Yang</keyname><forenames>Dawei</forenames></author><author><keyname>Xu</keyname><forenames>Zukang</forenames></author><author><keyname>Yuan</keyname><forenames>Zhihang</forenames></author><author><keyname>Yu</keyname><forenames>Jiangyong</forenames></author><author><keyname>Xu</keyname><forenames>Chen</forenames></author><author><keyname>Jiang</keyname><forenames>Zhe</forenames></author><author><keyname>Zhou</keyname><forenames>Sifan</forenames></author></authors><title>OstQuant: Refining Large Language Model Quantization with Orthogonal and   Scaling Transformations for Better Distribution Fitting</title><categories>cs.LG cs.AI</categories><comments>10 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Post-training quantization (PTQ) has emerged as a widely adopted technique for compressing and accelerating Large Language Models (LLMs). The major challenge in LLM quantization is that uneven and heavy-tailed data distributions can expand the quantization range, thereby reducing bit precision for most values. Recent methods attempt to eliminate outliers and balance inter-channel differences by employing linear transformations; however, they remain heuristic and are often overlook optimizing the data distribution across the entire quantization space.In this paper, we introduce Quantization Space Utilization Rate (QSUR), a novel metric that effectively assesses the quantizability of transformed data by measuring the space utilization of the data in the quantization space. We complement QSUR with mathematical derivations that examine the effects and limitations of various transformations, guiding our development of Orthogonal and Scaling Transformation-based Quantization (OSTQuant). OSQuant employs a learnable equivalent transformation, consisting of an orthogonal transformation and a scaling transformation, to optimize the distributions of weights and activations across the entire quantization space. Futhermore, we propose the KL-Top loss function, designed to mitigate noise during optimization while retaining richer semantic information within the limited calibration data imposed by PTQ. OSTQuant outperforms existing work on various LLMs and benchmarks. In the W4-only setting, it retains 99.5\% of the floating-point accuracy. In the more challenging W4A4KV4 configuration, OSTQuant reduces the performance gap by 32\% on the LLaMA-3-8B model compared to state-of-the-art methods. \href{https://github.com/BrotherHappy/OSTQuant}{https://github.com/BrotherHappy/OSTQuant}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13988</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13988</id><created>2025-01-23</created><authors><author><keyname>Yang</keyname><forenames>Yi</forenames></author><author><keyname>Zhang</keyname><forenames>Zhang</forenames></author><author><keyname>Wang</keyname><forenames>Liang</forenames></author></authors><title>MCRL4OR: Multimodal Contrastive Representation Learning for Off-Road   Environmental Perception</title><categories>cs.RO cs.AI cs.CV</categories><comments>Github repository: https://github.com/1uciusy/MCRL4OR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most studies on environmental perception for autonomous vehicles (AVs) focus on urban traffic environments, where the objects/stuff to be perceived are mainly from man-made scenes and scalable datasets with dense annotations can be used to train supervised learning models. By contrast, it is hard to densely annotate a large-scale off-road driving dataset manually due to the inherently unstructured nature of off-road environments. In this paper, we propose a Multimodal Contrastive Representation Learning approach for Off-Road environmental perception, namely MCRL4OR. This approach aims to jointly learn three encoders for processing visual images, locomotion states, and control actions by aligning the locomotion states with the fused features of visual images and control actions within a contrastive learning framework. The causation behind this alignment strategy is that the inertial locomotion state is the result of taking a certain control action under the current landform/terrain condition perceived by visual sensors. In experiments, we pre-train the MCRL4OR with a large-scale off-road driving dataset and adopt the learned multimodal representations for various downstream perception tasks in off-road driving scenarios. The superior performance in downstream tasks demonstrates the advantages of the pre-trained multimodal representations. The codes can be found in \url{https://github.com/1uciusy/MCRL4OR}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13989</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13989</id><created>2025-01-23</created><authors><author><keyname>Yue</keyname><forenames>Wenzhen</forenames></author><author><keyname>Liu</keyname><forenames>Yong</forenames></author><author><keyname>Ying</keyname><forenames>Xianghua</forenames></author><author><keyname>Xing</keyname><forenames>Bowei</forenames></author><author><keyname>Guo</keyname><forenames>Ruohao</forenames></author><author><keyname>Shi</keyname><forenames>Ji</forenames></author></authors><title>FreEformer: Frequency Enhanced Transformer for Multivariate Time Series   Forecasting</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents \textbf{FreEformer}, a simple yet effective model that leverages a \textbf{Fre}quency \textbf{E}nhanced Trans\textbf{former} for multivariate time series forecasting. Our work is based on the assumption that the frequency spectrum provides a global perspective on the composition of series across various frequencies and is highly suitable for robust representation learning. Specifically, we first convert time series into the complex frequency domain using the Discrete Fourier Transform (DFT). The Transformer architecture is then applied to the frequency spectra to capture cross-variate dependencies, with the real and imaginary parts processed independently. However, we observe that the vanilla attention matrix exhibits a low-rank characteristic, thus limiting representation diversity. This could be attributed to the inherent sparsity of the frequency domain and the strong-value-focused nature of Softmax in vanilla attention. To address this, we enhance the vanilla attention mechanism by introducing an additional learnable matrix to the original attention matrix, followed by row-wise L1 normalization. Theoretical analysis~demonstrates that this enhanced attention mechanism improves both feature diversity and gradient flow. Extensive experiments demonstrate that FreEformer consistently outperforms state-of-the-art models on eighteen real-world benchmarks covering electricity, traffic, weather, healthcare and finance. Notably, the enhanced attention mechanism also consistently improves the performance of state-of-the-art Transformer-based forecasters. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13991</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13991</id><created>2025-01-23</created><authors><author><keyname>Zhou</keyname><forenames>Zhi</forenames></author><author><keyname>Tan</keyname><forenames>Hao-Zhe</forenames></author><author><keyname>Song</keyname><forenames>Peng-Xiao</forenames></author><author><keyname>Guo</keyname><forenames>Lan-Zhe</forenames></author></authors><title>CGI: Identifying Conditional Generative Models with Example Images</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Generative models have achieved remarkable performance recently, and thus model hubs have emerged. Existing model hubs typically assume basic text matching is sufficient to search for models. However, in reality, due to different abstractions and the large number of models in model hubs, it is not easy for users to review model descriptions and example images, choosing which model best meets their needs. Therefore, it is necessary to describe model functionality wisely so that future users can efficiently search for the most suitable model for their needs. Efforts to address this issue remain limited. In this paper, we propose Conditional Generative Model Identification (CGI), which aims to provide an effective way to identify the most suitable model using user-provided example images rather than requiring users to manually review a large number of models with example images. To address this problem, we propose the PromptBased Model Identification (PMI) , which can adequately describe model functionality and precisely match requirements with specifications. To evaluate PMI approach and promote related research, we provide a benchmark comprising 65 models and 9100 identification tasks. Extensive experimental and human evaluation results demonstrate that PMI is effective. For instance, 92% of models are correctly identified with significantly better FID scores when four example images are provided. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13992</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13992</id><created>2025-01-23</created><authors><author><keyname>Nguyen</keyname><forenames>Hy</forenames></author><author><keyname>Nguyen</keyname><forenames>Nguyen Hung</forenames></author><author><keyname>Nguyen</keyname><forenames>Nguyen Linh Bao</forenames></author><author><keyname>Thudumu</keyname><forenames>Srikanth</forenames></author><author><keyname>Du</keyname><forenames>Hung</forenames></author><author><keyname>Vasa</keyname><forenames>Rajesh</forenames></author><author><keyname>Mouzakis</keyname><forenames>Kon</forenames></author></authors><title>Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Hierarchical Navigable Small World (HNSW) algorithm is widely used for approximate nearest neighbor (ANN) search, leveraging the principles of navigable small-world graphs. However, it faces some limitations. The first is the local optima problem, which arises from the algorithm's greedy search strategy, selecting neighbors based solely on proximity at each step. This often leads to cluster disconnections. The second limitation is that HNSW frequently fails to achieve logarithmic complexity, particularly in high-dimensional datasets, due to the exhaustive traversal through each layer. To address these limitations, we propose a novel algorithm that mitigates local optima and cluster disconnections while enhancing the construction speed, maintaining inference speed. The first component is a dual-branch HNSW structure with LID-based insertion mechanisms, enabling traversal from multiple directions. This improves outlier node capture, enhances cluster connectivity, accelerates construction speed and reduces the risk of local minima. The second component incorporates a bridge-building technique that bypasses redundant intermediate layers, maintaining inference and making up the additional computational overhead introduced by the dual-branch structure. Experiments on various benchmarks and datasets showed that our algorithm outperforms the original HNSW in both accuracy and speed. We evaluated six datasets across Computer Vision (CV), and Natural Language Processing (NLP), showing recall improvements of 18\% in NLP, and up to 30\% in CV tasks while reducing the construction time by up to 20\% and maintaining the inference speed. We did not observe any trade-offs in our algorithm. Ablation studies revealed that LID-based insertion had the greatest impact on performance, followed by the dual-branch structure and bridge-building components. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13993</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13993</id><created>2025-01-23</created><authors><author><keyname>Landolsi</keyname><forenames>Hamza</forenames></author><author><keyname>Letaief</keyname><forenames>Kais</forenames></author><author><keyname>Taghouti</keyname><forenames>Nizar</forenames></author><author><keyname>Abdeljaoued-Tej</keyname><forenames>Ines</forenames></author></authors><title>CAPRAG: A Large Language Model Solution for Customer Service and   Automatic Reporting using Vector and Graph Retrieval-Augmented Generation</title><categories>cs.CL cs.AI cs.IR</categories><comments>14 pages, 5 Figures, 3 Tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The introduction of new features and services in the banking sector often overwhelms customers, creating an opportunity for banks to enhance user experience through financial chatbots powered by large language models (LLMs). We initiated an AI agent designed to provide customers with relevant information about banking services and insights from annual reports. We proposed a hybrid Customer Analysis Pipeline Retrieval-Augmented Generation (CAPRAG) that effectively addresses both relationship-based and contextual queries, thereby improving customer engagement in the digital banking landscape. To implement this, we developed a processing pipeline to refine text data, which we utilized in two main frameworks: Vector RAG and Graph RAG. This dual approach enables us to populate both vector and graph databases with processed data for efficient retrieval. The Cypher query component is employed to effectively query the graph database. When a user submits a query, it is first expanded by a query expansion module before being routed to construct a final query from the hybrid Knowledge Base (KB). This final query is then sent to an open-source LLM for response generation. Overall, our innovative, designed to international banks, serves bank's customers in an increasingly complex digital environment, enhancing clarity and accessibility of information. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13994</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13994</id><created>2025-01-23</created><authors><author><keyname>Nguyen</keyname><forenames>Hy</forenames></author><author><keyname>Pham</keyname><forenames>Bao</forenames></author><author><keyname>Du</keyname><forenames>Hung</forenames></author><author><keyname>Thudumu</keyname><forenames>Srikanth</forenames></author><author><keyname>Vasa</keyname><forenames>Rajesh</forenames></author><author><keyname>Mouzakis</keyname><forenames>Kon</forenames></author></authors><title>CSAOT: Cooperative Multi-Agent System for Active Object Tracking</title><categories>cs.CV cs.AI cs.RO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Object Tracking is essential for many computer vision applications, such as autonomous navigation, surveillance, and robotics. Unlike Passive Object Tracking (POT), which relies on static camera viewpoints to detect and track objects across consecutive frames, Active Object Tracking (AOT) requires a controller agent to actively adjust its viewpoint to maintain visual contact with a moving target in complex environments. Existing AOT solutions are predominantly single-agent-based, which struggle in dynamic and complex scenarios due to limited information gathering and processing capabilities, often resulting in suboptimal decision-making. Alleviating these limitations necessitates the development of a multi-agent system where different agents perform distinct roles and collaborate to enhance learning and robustness in dynamic and complex environments. Although some multi-agent approaches exist for AOT, they typically rely on external auxiliary agents, which require additional devices, making them costly. In contrast, we introduce the Collaborative System for Active Object Tracking (CSAOT), a method that leverages multi-agent deep reinforcement learning (MADRL) and a Mixture of Experts (MoE) framework to enable multiple agents to operate on a single device, thereby improving tracking performance and reducing costs. Our approach enhances robustness against occlusions and rapid motion while optimizing camera movements to extend tracking duration. We validated the effectiveness of CSAOT on various interactive maps with dynamic and stationary obstacles. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13996</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13996</id><created>2025-01-23</created><authors><author><keyname>Abbasi</keyname><forenames>Ali Farshian</forenames></author><author><keyname>Yousefi-Koma</keyname><forenames>Aghil</forenames></author><author><keyname>Firouzabadi</keyname><forenames>Soheil Dehghani</forenames></author><author><keyname>Rashidi</keyname><forenames>Parisa</forenames></author><author><keyname>Naeini</keyname><forenames>Alireza</forenames></author></authors><title>Integrating Persian Lip Reading in Surena-V Humanoid Robot for   Human-Robot Interaction</title><categories>cs.CV cs.RO</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Lip reading is vital for robots in social settings, improving their ability to understand human communication. This skill allows them to communicate more easily in crowded environments, especially in caregiving and customer service roles. Generating a Persian Lip-reading dataset, this study integrates Persian lip-reading technology into the Surena-V humanoid robot to improve its speech recognition capabilities. Two complementary methods are explored, an indirect method using facial landmark tracking and a direct method leveraging convolutional neural networks (CNNs) and long short-term memory (LSTM) networks. The indirect method focuses on tracking key facial landmarks, especially around the lips, to infer movements, while the direct method processes raw video data for action and speech recognition. The best-performing model, LSTM, achieved 89\% accuracy and has been successfully implemented into the Surena-V robot for real-time human-robot interaction. The study highlights the effectiveness of these methods, particularly in environments where verbal communication is limited. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13997</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13997</id><created>2025-01-23</created><authors><author><keyname>Dong</keyname><forenames>Xingsi</forenames></author><author><keyname>Yuan</keyname><forenames>Pengxiang</forenames></author><author><keyname>Wu</keyname><forenames>Si</forenames></author></authors><title>Predictive Learning in Energy-based Models with Attractor Structures</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Predictive models are highly advanced in understanding the mechanisms of brain function. Recent advances in machine learning further underscore the power of prediction for optimal representation in learning. However, there remains a gap in creating a biologically plausible model that explains how the neural system achieves prediction. In this paper, we introduce a framework that employs an energy-based model (EBM) to capture the nuanced processes of predicting observation after action within the neural system, encompassing prediction, learning, and inference. We implement the EBM with a hierarchical structure and integrate a continuous attractor neural network for memory, constructing a biologically plausible model. In experimental evaluations, our model demonstrates efficacy across diverse scenarios. The range of actions includes eye movement, motion in environments, head turning, and static observation while the environment changes. Our model not only makes accurate predictions for environments it was trained on, but also provides reasonable predictions for unseen environments, matching the performances of machine learning methods in multiple tasks. We hope that this study contributes to a deep understanding of how the neural system performs prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.13999</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.13999</id><created>2025-01-23</created><authors><author><keyname>Sakau</keyname><forenames>Joseph</forenames></author><author><keyname>Kozlowski</keyname><forenames>Evander</forenames></author><author><keyname>Thistledown</keyname><forenames>Roderick</forenames></author><author><keyname>Steinberger</keyname><forenames>Basil</forenames></author></authors><title>Framework for Progressive Knowledge Fusion in Large Language Models   Through Structured Conceptual Redundancy Analysis</title><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The organization of latent knowledge within large-scale models poses unique challenges when addressing overlapping representations and optimizing contextual accuracy. Conceptual redundancies embedded across layers often result in inefficiencies that affect both computational demands and task-specific outcomes. A framework was proposed to restructure these redundancies through advanced clustering techniques and dynamic thresholding, ensuring that critical semantic relationships are preserved while removing unnecessary overlaps. Evaluations revealed improved memory efficiency and faster inference times, alongside better alignment in latent knowledge clusters that enhanced interpretability. Improvements in error rates and adversarial robustness suggest that restructuring redundancies has broader implications for increasing model reliability across diverse applications. Comparative analyses highlighted reductions in resource consumption and notable gains in performance, particularly in translation and summarization tasks. Energy metrics demonstrated significant savings during training phases, further validating the practicality of the approach for real-world deployments. Representational fidelity was also enhanced, with latent space evaluations indicating better cluster alignment and higher semantic consistency. The methodology bridges a key gap in model optimization through directly addressing redundancies at the structural level. Its application opens avenues for scalable, efficient, and contextually aware systems that can adapt to complex, domain-specific tasks without compromising on performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14000</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14000</id><created>2025-01-23</created><authors><author><keyname>Nguyen</keyname><forenames>Hy</forenames></author><author><keyname>Pham</keyname><forenames>Duy Khoa</forenames></author><author><keyname>Thudumu</keyname><forenames>Srikanth</forenames></author><author><keyname>Du</keyname><forenames>Hung</forenames></author><author><keyname>Vasa</keyname><forenames>Rajesh</forenames></author><author><keyname>Mouzakis</keyname><forenames>Kon</forenames></author></authors><title>Local Control Networks (LCNs): Optimizing Flexibility in Neural Network   Data Pattern Capture</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The widespread use of Multi-layer perceptrons (MLPs) often relies on a fixed activation function (e.g., ReLU, Sigmoid, Tanh) for all nodes within the hidden layers. While effective in many scenarios, this uniformity may limit the networks ability to capture complex data patterns. We argue that employing the same activation function at every node is suboptimal and propose leveraging different activation functions at each node to increase flexibility and adaptability. To achieve this, we introduce Local Control Networks (LCNs), which leverage B-spline functions to enable distinct activation curves at each node. Our mathematical analysis demonstrates the properties and benefits of LCNs over conventional MLPs. In addition, we demonstrate that more complex architectures, such as Kolmogorov-Arnold Networks (KANs), are unnecessary in certain scenarios, and LCNs can be a more efficient alternative. Empirical experiments on various benchmarks and datasets validate our theoretical findings. In computer vision tasks, LCNs achieve marginal improvements over MLPs and outperform KANs by approximately 5\%, while also being more computationally efficient than KANs. In basic machine learning tasks, LCNs show a 1\% improvement over MLPs and a 0.6\% improvement over KANs. For symbolic formula representation tasks, LCNs perform on par with KANs, with both architectures outperforming MLPs. Our findings suggest that diverse activations at the node level can lead to improved performance and efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14001</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14001</id><created>2025-01-23</created><authors><author><keyname>Nasios</keyname><forenames>Ioannis</forenames></author></authors><title>Enhancing kelp forest detection in remote sensing images using   crowdsourced labels with Mixed Vision Transformers and ConvNeXt segmentation   models</title><categories>cs.CV cs.AI cs.LG</categories><doi>10.1080/01431161.2024.2448307</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Kelp forests, as foundation species, are vital to marine ecosystems, providing essential food and habitat for numerous organisms. This study explores the integration of crowdsourced labels with advanced artificial intelligence models to develop a fast and accurate kelp canopy detection pipeline using Landsat images. Building on the success of a machine learning competition, where this approach ranked third and performed consistently well on both local validation and public and private leaderboards, the research highlights the effectiveness of combining Mixed Vision Transformers (MIT) with ConvNeXt models. Training these models on various image sizes significantly enhanced the accuracy of the ensemble results. U-Net emerged as the best segmentation architecture, with UpperNet also contributing to the final ensemble. Key Landsat bands, such as ShortWave InfraRed (SWIR1) and Near-InfraRed (NIR), were crucial while altitude data was used in postprocessing to eliminate false positives on land. The methodology achieved a high detection rate, accurately identifying about three out of four pixels containing kelp canopy while keeping false positives low. Despite the medium resolution of Landsat satellites, their extensive historical coverage makes them effective for studying kelp forests. This work also underscores the potential of combining machine learning models with crowdsourced data for effective and scalable environmental monitoring. All running code for training all models and inference can be found at https://github.com/IoannisNasios/Kelp_Forests. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14002</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14002</id><created>2025-01-23</created><authors><author><keyname>Chen</keyname><forenames>Zui</forenames></author><author><keyname>Liu</keyname><forenames>Tianqiao</forenames></author><author><keyname>Tian</keyname><forenames>Mi</forenames></author><author><keyname>Tong</keyname><forenames>Qing</forenames></author><author><keyname>Luo</keyname><forenames>Weiqi</forenames></author><author><keyname>Liu</keyname><forenames>Zitao</forenames></author></authors><title>Advancing Math Reasoning in Language Models: The Impact of   Problem-Solving Data, Data Synthesis Methods, and Training Stages</title><categories>cs.CL cs.AI</categories><comments>ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Advancements in LLMs have significantly expanded their capabilities across various domains. However, mathematical reasoning remains a challenging area, prompting the development of math-specific LLMs. These models typically follow a two-stage training paradigm: pre-training with math-related corpora and post-training with problem datasets for SFT. Despite these efforts, the improvements in mathematical reasoning achieved through continued pre-training (CPT) are often less significant compared to those obtained via SFT. This study addresses this discrepancy by exploring alternative strategies during the pre-training phase, focusing on the use of problem-solving data over general mathematical corpora. We investigate three primary research questions: (1) Can problem-solving data enhance the model's mathematical reasoning capabilities more effectively than general mathematical corpora during CPT? (2) Are synthetic data from the same source equally effective, and which synthesis methods are most efficient? (3) How do the capabilities developed from the same problem-solving data differ between the CPT and SFT stages, and what factors contribute to these differences? Our findings indicate that problem-solving data significantly enhances the model's mathematical capabilities compared to general mathematical corpora. We also identify effective data synthesis methods, demonstrating that the tutorship amplification synthesis method achieves the best performance. Furthermore, while SFT facilitates instruction-following abilities, it underperforms compared to CPT with the same data, which can be partially attributed to its poor learning capacity for hard multi-step problem-solving data. These insights provide valuable guidance for optimizing the mathematical reasoning capabilities of LLMs, culminating in our development of a powerful mathematical base model called JiuZhang-8B. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14003</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14003</id><created>2025-01-23</created><authors><author><keyname>Ling</keyname><forenames>Yunfei</forenames></author><author><keyname>Liu</keyname><forenames>Zijie</forenames></author><author><keyname>Du</keyname><forenames>Jun</forenames></author><author><keyname>Huang</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Yuehang</forenames></author><author><keyname>Xiao</keyname><forenames>Bingjia</forenames></author><author><keyname>Fang</keyname><forenames>Xin</forenames></author></authors><title>PaMMA-Net: Plasmas magnetic measurement evolution based on data-driven   incremental accumulative prediction</title><categories>physics.plasm-ph cs.AI</categories><comments>20 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An accurate evolution model is crucial for effective control and in-depth study of fusion plasmas. Evolution methods based on physical models often encounter challenges such as insufficient robustness or excessive computational costs. Given the proven strong fitting capabilities of deep learning methods across various fields, including plasma research, this paper introduces a deep learning-based magnetic measurement evolution method named PaMMA-Net (Plasma Magnetic Measurements Incremental Accumulative Prediction Network). This network is capable of evolving magnetic measurements in tokamak discharge experiments over extended periods or, in conjunction with equilibrium reconstruction algorithms, evolving macroscopic parameters such as plasma shape. Leveraging a incremental prediction approach and data augmentation techniques tailored for magnetic measurements, PaMMA-Net achieves superior evolution results compared to existing studies. The tests conducted on real experimental data from EAST validate the high generalization capability of the proposed method. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14004</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14004</id><created>2025-01-23</created><authors><author><keyname>Zhang</keyname><forenames>Luqi</forenames></author><author><keyname>Wang</keyname><forenames>Haiping</forenames></author><author><keyname>Liu</keyname><forenames>Chong</forenames></author><author><keyname>Dong</keyname><forenames>Zhen</forenames></author><author><keyname>Yang</keyname><forenames>Bisheng</forenames></author></authors><title>ME-CPT: Multi-Task Enhanced Cross-Temporal Point Transformer for Urban   3D Change Detection</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The point clouds collected by the Airborne Laser Scanning (ALS) system provide accurate 3D information of urban land covers. By utilizing multi-temporal ALS point clouds, semantic changes in urban area can be captured, demonstrating significant potential in urban planning, emergency management, and infrastructure maintenance. Existing 3D change detection methods struggle to efficiently extract multi-class semantic information and change features, still facing the following challenges: (1) the difficulty of accurately modeling cross-temporal point clouds spatial relationships for effective change feature extraction; (2) class imbalance of change samples which hinders distinguishability of semantic features; (3) the lack of real-world datasets for 3D semantic change detection. To resolve these challenges, we propose the Multi-task Enhanced Cross-temporal Point Transformer (ME-CPT) network. ME-CPT establishes spatiotemporal correspondences between point cloud across different epochs and employs attention mechanisms to jointly extract semantic change features, facilitating information exchange and change comparison. Additionally, we incorporate a semantic segmentation task and through the multi-task training strategy, further enhance the distinguishability of semantic features, reducing the impact of class imbalance in change types. Moreover, we release a 22.5 $km^2$ 3D semantic change detection dataset, offering diverse scenes for comprehensive evaluation. Experiments on multiple datasets show that the proposed MT-CPT achieves superior performance compared to existing state-of-the-art methods. The source code and dataset will be released upon acceptance at \url{https://github.com/zhangluqi0209/ME-CPT}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14005</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14005</id><created>2025-01-23</created><authors><author><keyname>Jiang</keyname><forenames>Ning</forenames><affiliation>School of Software &amp; Microelectronics, Peking University, Beijing, China</affiliation><affiliation>Mashang Consumer Finance Co., Ltd., Chongqing, China</affiliation></author><author><keyname>Liu</keyname><forenames>Yanhong</forenames><affiliation>Mashang Consumer Finance Co., Ltd., Chongqing, China</affiliation></author><author><keyname>Zeng</keyname><forenames>Dingheng</forenames><affiliation>Mashang Consumer Finance Co., Ltd., Chongqing, China</affiliation></author><author><keyname>Feng</keyname><forenames>Yue</forenames><affiliation>Mashang Consumer Finance Co., Ltd., Chongqing, China</affiliation></author><author><keyname>Deng</keyname><forenames>Weihong</forenames><affiliation>Mashang Consumer Finance Co., Ltd., Chongqing, China</affiliation></author><author><keyname>Li</keyname><forenames>Ying</forenames><affiliation>School of Software &amp; Microelectronics, Peking University, Beijing, China</affiliation></author></authors><title>Device-aware Optical Adversarial Attack for a Portable Projector-camera   System</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Deep-learning-based face recognition (FR) systems are susceptible to adversarial examples in both digital and physical domains. Physical attacks present a greater threat to deployed systems as adversaries can easily access the input channel, allowing them to provide malicious inputs to impersonate a victim. This paper addresses the limitations of existing projector-camera-based adversarial light attacks in practical FR setups. By incorporating device-aware adaptations into the digital attack algorithm, such as resolution-aware and color-aware adjustments, we mitigate the degradation from digital to physical domains. Experimental validation showcases the efficacy of our proposed algorithm against real and spoof adversaries, achieving high physical similarity scores in FR models and state-of-the-art commercial systems. On average, there is only a 14% reduction in scores from digital to physical attacks, with high attack success rate in both white- and black-box scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14006</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14006</id><created>2025-01-23</created><authors><author><keyname>Lacombe</keyname><forenames>Armand</forenames></author><author><keyname>Sebag</keyname><forenames>Michèle</forenames></author></authors><title>Asymmetrical Latent Representation for Individual Treatment Effect   Modeling</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Conditional Average Treatment Effect (CATE) estimation, at the heart of counterfactual reasoning, is a crucial challenge for causal modeling both theoretically and applicatively, in domains such as healthcare, sociology, or advertising. Borrowing domain adaptation principles, a popular design maps the sample representation to a latent space that balances control and treated populations while enabling the prediction of the potential outcomes. This paper presents a new CATE estimation approach based on the asymmetrical search for two latent spaces called Asymmetrical Latent Representation for Individual Treatment Effect (ALRITE), where the two latent spaces are respectively intended to optimize the counterfactual prediction accuracy on the control and the treated samples. Under moderate assumptions, ALRITE admits an upper bound on the precision of the estimation of heterogeneous effects (PEHE), and the approach is empirically successfully validated compared to the state-of-the-art </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14007</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14007</id><created>2025-01-23</created><authors><author><keyname>Aguilar-Calvo</keyname><forenames>William</forenames></author><author><keyname>Núñez-Corrales</keyname><forenames>Santiago</forenames></author></authors><title>Adaptive Genetic Algorithms for Pulse-Level Quantum Error Mitigation</title><categories>quant-ph cs.AI cs.AR</categories><comments>21 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise remains a fundamental challenge in quantum computing, significantly affecting pulse fidelity and overall circuit performance. This paper introduces an adaptive algorithm for pulse-level quantum error mitigation, designed to enhance fidelity by dynamically responding to noise conditions without modifying circuit gates. By targeting pulse parameters directly, this method reduces the impact of various noise sources, improving algorithm resilience in quantum circuits. We show the latter by applying our protocol to Grover's and Deutsch-Jozsa algorithms. Experimental results show that this pulse-level strategy provides a flexible and efficient solution for increasing fidelity during the noisy execution of quantum circuits. Our work contributes to advancements in error mitigation techniques, essential for robust quantum computing. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14008</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14008</id><created>2025-01-23</created><authors><author><keyname>Wu</keyname><forenames>Cong</forenames></author><author><keyname>Chen</keyname><forenames>Jing</forenames></author><author><keyname>Zhu</keyname><forenames>Simeng</forenames></author><author><keyname>Feng</keyname><forenames>Wenqi</forenames></author><author><keyname>Du</keyname><forenames>Ruiying</forenames></author><author><keyname>Xiang</keyname><forenames>Yang</forenames></author></authors><title>WAFBOOSTER: Automatic Boosting of WAF Security Against Mutated Malicious   Payloads</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Web application firewall (WAF) examines malicious traffic to and from a web application via a set of security rules. It plays a significant role in securing Web applications against web attacks. However, as web attacks grow in sophistication, it is becoming increasingly difficult for WAFs to block the mutated malicious payloads designed to bypass their defenses. In response to this critical security issue, we have developed a novel learning-based framework called WAFBOOSTER, designed to unveil potential bypasses in WAF detections and suggest rules to fortify their security. Using a combination of shadow models and payload generation techniques, we can identify malicious payloads and remove or modify them as needed. WAFBOOSTER generates signatures for these malicious payloads using advanced clustering and regular expression matching techniques to repair any security gaps we uncover. In our comprehensive evaluation of eight real-world WAFs, WAFBOOSTER improved the true rejection rate of mutated malicious payloads from 21% to 96%, with no false rejections. WAFBOOSTER achieves a false acceptance rate 3X lower than state-of-the-art methods for generating malicious payloads. With WAFBOOSTER, we have taken a step forward in securing web applications against the ever-evolving threats. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14009</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14009</id><created>2025-01-23</created><authors><author><keyname>Parameshwaran</keyname><forenames>Aditya</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author></authors><title>Scalable and Explainable Verification of Image-based Neural Network   Controllers for Autonomous Vehicles</title><categories>cs.LG cs.AI cs.SY eess.SY</categories><comments>11 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Existing formal verification methods for image-based neural network controllers in autonomous vehicles often struggle with high-dimensional inputs, computational inefficiency, and a lack of explainability. These challenges make it difficult to ensure safety and reliability, as processing high-dimensional image data is computationally intensive and neural networks are typically treated as black boxes. To address these issues, we propose \textbf{SEVIN} (Scalable and Explainable Verification of Image-Based Neural Network Controllers), a framework that leverages a Variational Autoencoders (VAE) to encode high-dimensional images into a lower-dimensional, explainable latent space. By annotating latent variables with corresponding control actions, we generate convex polytopes that serve as structured input spaces for verification, significantly reducing computational complexity and enhancing scalability. Integrating the VAE's decoder with the neural network controller allows for formal and robustness verification using these explainable polytopes. Our approach also incorporates robustness verification under real-world perturbations by augmenting the dataset and retraining the VAE to capture environmental variations. Experimental results demonstrate that SEVIN achieves efficient and scalable verification while providing explainable insights into controller behavior, bridging the gap between formal verification techniques and practical applications in safety-critical systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14010</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14010</id><created>2025-01-23</created><authors><author><keyname>Boahen</keyname><forenames>Edem</forenames></author><author><keyname>Boedihardjo</keyname><forenames>March T.</forenames></author><author><keyname>Chiclana</keyname><forenames>Rafael</forenames></author><author><keyname>Iwen</keyname><forenames>Mark</forenames></author></authors><title>On Extended Concentration Inequalities for Fast JL Embeddings of   Infinite Sets</title><categories>cs.DS math.PR</categories><msc-class>60B20, 46B09, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Johnson-Lindenstrauss (JL) lemma allows subsets of a high-dimensional space to be embedded into a lower-dimensional space while approximately preserving all pairwise Euclidean distances. This important result has inspired an extensive literature, with a significant portion dedicated to constructing structured random matrices with fast matrix-vector multiplication algorithms that generate such embeddings for finite point sets. In this paper, we briefly consider fast JL embedding matrices for {\it infinite} subsets of $\mathbb{R}^d$. Prior work in this direction such as \cite{oymak2018isometric, mendelson2023column} has focused on constructing fast JL matrices $HD \in \mathbb{R}^{k \times d}$ by multiplying structured matrices with RIP(-like) properties $H \in \mathbb{R}^{k \times d}$ against a random diagonal matrix $D \in \mathbb{R}^{d \times d}$. However, utilizing RIP(-like) matrices $H$ in this fashion necessarily has the unfortunate side effect that the resulting embedding dimension $k$ must depend on the ambient dimension $d$ no matter how simple the infinite set is that one aims to embed. Motivated by this, we explore an alternate strategy for removing this $d$-dependence from $k$ herein: Extending a concentration inequality proven by Ailon and Liberty \cite{Ailon2008fast} in the hope of later utilizing it in a chaining argument to obtain a near-optimal result for infinite sets. %, and $(ii)$ utilizing a simple secondary Gaussian embedding of an initial fast JL embedding of a given infinite set.   Though this strategy ultimately fails to provide the near-optimal embedding dimension we seek, along the way we obtain a stronger-than-sub-exponential extension of the concentration inequality in \cite{Ailon2008fast} which may be of independent interest. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14011</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14011</id><created>2025-01-23</created><authors><author><keyname>Mishra</keyname><forenames>Sahil</forenames></author><author><keyname>Patni</keyname><forenames>Avi</forenames></author><author><keyname>Chatterjee</keyname><forenames>Niladri</forenames></author><author><keyname>Chakraborty</keyname><forenames>Tanmoy</forenames></author></authors><title>QuanTaxo: A Quantum Approach to Self-Supervised Taxonomy Expansion</title><categories>cs.SI cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A taxonomy is a hierarchical graph containing knowledge to provide valuable insights for various web applications. Online retail organizations like Microsoft and Amazon utilize taxonomies to improve product recommendations and optimize advertisement by enhancing query interpretation. However, the manual construction of taxonomies requires significant human effort. As web content continues to expand at an unprecedented pace, existing taxonomies risk becoming outdated, struggling to incorporate new and emerging information effectively. As a consequence, there is a growing need for dynamic taxonomy expansion to keep them relevant and up-to-date. Existing taxonomy expansion methods often rely on classical word embeddings to represent entities. However, these embeddings fall short in capturing hierarchical polysemy, where an entity's meaning can vary based on its position in the hierarchy and its surrounding context. To address this challenge, we introduce QuanTaxo, an innovative quantum-inspired framework for taxonomy expansion. QuanTaxo encodes entity representations in quantum space, effectively modeling hierarchical polysemy by leveraging the principles of Hilbert space to capture interference effects between entities, yielding richer and more nuanced representations. Comprehensive experiments on four real-world benchmark datasets show that QuanTaxo significantly outperforms classical embedding models, achieving substantial improvements of 18.45% in accuracy, 20.5% in Mean Reciprocal Rank, and 17.87% in Wu &amp; Palmer metrics across eight classical embedding-based baselines. We further highlight the superiority of QuanTaxo through extensive ablation and case studies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14012</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14012</id><created>2025-01-23</created><authors><author><keyname>Pan</keyname><forenames>Shuaiqun</forenames></author><author><keyname>Vermetten</keyname><forenames>Diederick</forenames></author><author><keyname>López-Ibáñez</keyname><forenames>Manuel</forenames></author><author><keyname>Bäck</keyname><forenames>Thomas</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author></authors><title>Transfer Learning of Surrogate Models via Domain Affine Transformation   Across Synthetic and Real-World Benchmarks</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Surrogate models are frequently employed as efficient substitutes for the costly execution of real-world processes. However, constructing a high-quality surrogate model often demands extensive data acquisition. A solution to this issue is to transfer pre-trained surrogate models for new tasks, provided that certain invariances exist between tasks. This study focuses on transferring non-differentiable surrogate models (e.g., random forest) from a source function to a target function, where we assume their domains are related by an unknown affine transformation, using only a limited amount of transfer data points evaluated on the target. Previous research attempts to tackle this challenge for differentiable models, e.g., Gaussian process regression, which minimizes the empirical loss on the transfer data by tuning the affine transformations. In this paper, we extend the previous work to the random forest model and assess its effectiveness on a widely-used artificial problem set - Black-Box Optimization Benchmark (BBOB) testbed, and on four real-world transfer learning problems. The results highlight the significant practical advantages of the proposed method, particularly in reducing both the data requirements and computational costs of training surrogate models for complex real-world scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14013</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14013</id><created>2025-01-23</created><authors><author><keyname>Wang</keyname><forenames>Xinya</forenames></author><author><keyname>Mathai</keyname><forenames>Tejas Sudharshan</forenames></author><author><keyname>Kim</keyname><forenames>Boah</forenames></author><author><keyname>Summers</keyname><forenames>Ronald M.</forenames></author></authors><title>Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT:   Utility for Pancreas Segmentation</title><categories>eess.IV cs.AI cs.CV</categories><comments>ISBI 2025</comments><msc-class>92C55</msc-class><acm-class>I.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiphase CT studies are routinely obtained in clinical practice for diagnosis and management of various diseases, such as cancer. However, the CT studies can be acquired with low radiation doses, different scanners, and are frequently affected by motion and metal artifacts. Prior approaches have targeted the quality improvement of one specific CT phase (e.g., non-contrast CT). In this work, we hypothesized that leveraging multiple CT phases for the quality enhancement of one phase may prove advantageous for downstream tasks, such as segmentation. A 3D progressive fusion and non-local (PFNL) network was developed. It was trained with three degraded (low-quality) phases (non-contrast, arterial, and portal venous) to enhance the quality of the portal venous phase. Then, the effect of scan quality enhancement was evaluated using a proxy task of pancreas segmentation, which is useful for tracking pancreatic cancer. The proposed approach improved the pancreas segmentation by 3% over the corresponding low-quality CT scan. To the best of our knowledge, we are the first to harness multiphase CT for scan quality enhancement and improved pancreas segmentation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14014</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14014</id><created>2025-01-23</created><authors><author><keyname>You</keyname><forenames>Di</forenames></author><author><keyname>Dragotti</keyname><forenames>Pier Luigi</forenames></author></authors><title>INDIGO+: A Unified INN-Guided Probabilistic Diffusion Algorithm for   Blind and Non-Blind Image Restoration</title><categories>cs.CV eess.IV</categories><comments>Accepted by IEEE Journal of Selected Topics in Signal Processing   (JSTSP)</comments><doi>10.1109/jstsp.2024.3454957</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative diffusion models are becoming one of the most popular prior in image restoration (IR) tasks due to their remarkable ability to generate realistic natural images. Despite achieving satisfactory results, IR methods based on diffusion models present several limitations. First of all, most non-blind approaches require an analytical expression of the degradation model to guide the sampling process. Secondly, most existing blind approaches rely on families of pre-defined degradation models for training their deep networks. The above issues limit the flexibility of these approaches and so their ability to handle real-world degradation tasks. In this paper, we propose a novel INN-guided probabilistic diffusion algorithm for non-blind and blind image restoration, namely INDIGO and BlindINDIGO, which combines the merits of the perfect reconstruction property of invertible neural networks (INN) with the strong generative capabilities of pre-trained diffusion models. Specifically, we train the forward process of the INN to simulate an arbitrary degradation process and use the inverse to obtain an intermediate image that we use to guide the reverse diffusion sampling process through a gradient step. We also introduce an initialization strategy, to further improve the performance and inference speed of our algorithm. Experiments demonstrate that our algorithm obtains competitive results compared with recently leading methods both quantitatively and visually on synthetic and real-world low-quality images. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14035</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14035</id><created>2025-01-23</created><authors><author><keyname>Benz</keyname><forenames>Nina L. Corvelo</forenames></author><author><keyname>Rodriguez</keyname><forenames>Manuel Gomez</forenames></author></authors><title>Human-Alignment Influences the Utility of AI-assisted Decision Making</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Whenever an AI model is used to predict a relevant (binary) outcome in AI-assisted decision making, it is widely agreed that, together with each prediction, the model should provide an AI confidence value. However, it has been unclear why decision makers have often difficulties to develop a good sense on when to trust a prediction using AI confidence values. Very recently, Corvelo Benz and Gomez Rodriguez have argued that, for rational decision makers, the utility of AI-assisted decision making is inherently bounded by the degree of alignment between the AI confidence values and the decision maker's confidence on their own predictions. In this work, we empirically investigate to what extent the degree of alignment actually influences the utility of AI-assisted decision making. To this end, we design and run a large-scale human subject study (n=703) where participants solve a simple decision making task - an online card game - assisted by an AI model with a steerable degree of alignment. Our results show a positive association between the degree of alignment and the utility of AI-assisted decision making. In addition, our results also show that post-processing the AI confidence values to achieve multicalibration with respect to the participants' confidence on their own predictions increases both the degree of alignment and the utility of AI-assisted decision making. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14036</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14036</id><created>2025-01-23</created><authors><author><keyname>Blot</keyname><forenames>Vincent</forenames></author><author><keyname>de Brionne</keyname><forenames>Alexandra Lorenzo</forenames></author><author><keyname>Sellami</keyname><forenames>Ines</forenames></author><author><keyname>Trassard</keyname><forenames>Olivier</forenames></author><author><keyname>Beau</keyname><forenames>Isabelle</forenames></author><author><keyname>Sonigo</keyname><forenames>Charlotte</forenames></author><author><keyname>Brunel</keyname><forenames>Nicolas J-B.</forenames></author></authors><title>Efficient Precision Control in Object Detection Models for Enhanced and   Reliable Ovarian Follicle Counting</title><categories>cs.LG</categories><comments>11 pages, 3 figures</comments><doi>10.1007/978-3-031-73158-7_17</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Image analysis is a key tool for describing the detailed mechanisms of folliculogenesis, such as evaluating the quantity of mouse Primordial ovarian Follicles (PMF) in the ovarian reserve. The development of high-resolution virtual slide scanners offers the possibility of quantifying, robustifying and accelerating the histopathological procedure. A major challenge for machine learning is to control the precision of predictions while enabling a high recall, in order to provide reproducibility. We use a multiple testing procedure that gives an overperforming way to solve the standard Precision-Recall trade-off that gives probabilistic guarantees on the precision. In addition, we significantly improve the overall performance of the models (increase of F1-score) by selecting the decision threshold using contextual biological information or using an auxiliary model. As it is model-agnostic, this contextual selection procedure paves the way to the development of a strategy that can improve the performance of any model without the need of retraining it. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14037</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14037</id><created>2025-01-23</created><authors><author><keyname>Zhu</keyname><forenames>Jianfeng</forenames></author><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Jiang</keyname><forenames>Hailong</forenames></author><author><keyname>Wang</keyname><forenames>Yulan</forenames></author><author><keyname>Zhang</keyname><forenames>Xinyu</forenames></author><author><keyname>Coifman</keyname><forenames>Karin G.</forenames></author></authors><title>Leveraging Large Language Models to Analyze Emotional and Contextual   Drivers of Teen Substance Use in Online Discussions</title><categories>cs.CL</categories><comments>28 pages, 9 figures with an appendix</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Adolescence is a critical stage often linked to risky behaviors, including substance use, with significant developmental and public health implications. Social media provides a lens into adolescent self-expression, but interpreting emotional and contextual signals remains complex. This study applies Large Language Models (LLMs) to analyze adolescents' social media posts, uncovering emotional patterns (e.g., sadness, guilt, fear, joy) and contextual factors (e.g., family, peers, school) related to substance use. Heatmap and machine learning analyses identified key predictors of substance use-related posts. Negative emotions like sadness and guilt were significantly more frequent in substance use contexts, with guilt acting as a protective factor, while shame and peer influence heightened substance use risk. Joy was more common in non-substance use discussions. Peer influence correlated strongly with sadness, fear, and disgust, while family and school environments aligned with non-substance use. Findings underscore the importance of addressing emotional vulnerabilities and contextual influences, suggesting that collaborative interventions involving families, schools, and communities can reduce risk factors and foster healthier adolescent development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14038</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14038</id><created>2025-01-23</created><authors><author><keyname>Sang</keyname><forenames>Lu</forenames></author><author><keyname>Canfes</keyname><forenames>Zehranaz</forenames></author><author><keyname>Cao</keyname><forenames>Dongliang</forenames></author><author><keyname>Bernard</keyname><forenames>Florian</forenames></author><author><keyname>Cremers</keyname><forenames>Daniel</forenames></author></authors><title>Implicit Neural Surface Deformation with Explicit Velocity Fields</title><categories>cs.CV</categories><comments>ICLR 2025, 10 pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this work, we introduce the first unsupervised method that simultaneously predicts time-varying neural implicit surfaces and deformations between pairs of point clouds. We propose to model the point movement using an explicit velocity field and directly deform a time-varying implicit field using the modified level-set equation. This equation utilizes an iso-surface evolution with Eikonal constraints in a compact formulation, ensuring the integrity of the signed distance field. By applying a smooth, volume-preserving constraint to the velocity field, our method successfully recovers physically plausible intermediate shapes. Our method is able to handle both rigid and non-rigid deformations without any intermediate shape supervision. Our experimental results demonstrate that our method significantly outperforms existing works, delivering superior results in both quality and efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14040</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14040</id><created>2025-01-23</created><authors><author><keyname>Allaham</keyname><forenames>Mowafak</forenames></author><author><keyname>Kieslich</keyname><forenames>Kimon</forenames></author><author><keyname>Diakopoulos</keyname><forenames>Nicholas</forenames></author></authors><title>Global Perspectives of AI Risks and Harms: Analyzing the Negative   Impacts of AI Technologies as Prioritized by News Media</title><categories>cs.CY</categories><comments>Under review</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Emerging AI technologies have the potential to drive economic growth and innovation but can also pose significant risks to society. To mitigate these risks, governments, companies, and researchers have contributed regulatory frameworks, risk assessment approaches, and safety benchmarks, but these can lack nuance when considered in global deployment contexts. One way to understand these nuances is by looking at how the media reports on AI, as news media has a substantial influence on what negative impacts of AI are discussed in the public sphere and which impacts are deemed important. In this work, we analyze a broad and diverse sample of global news media spanning 27 countries across Asia, Africa, Europe, Middle East, North America, and Oceania to gain valuable insights into the risks and harms of AI technologies as reported and prioritized across media outlets in different countries. This approach reveals a skewed prioritization of Societal Risks followed by Legal &amp; Rights-related Risks, Content Safety Risks, Cognitive Risks, Existential Risks, and Environmental Risks, as reflected in the prevalence of these risk categories in the news coverage of different nations. Furthermore, it highlights how the distribution of such concerns varies based on the political bias of news outlets, underscoring the political nature of AI risk assessment processes and public opinion. By incorporating views from various regions and political orientations for assessing the risks and harms of AI, this work presents stakeholders, such as AI developers and policy makers, with insights into the AI risks categories prioritized in the public sphere. These insights my guide the development of more inclusive, safe, and responsible AI technologies that address the diverse concerns and needs across the world. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14042</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14042</id><created>2025-01-23</created><authors><author><keyname>Birari</keyname><forenames>Mahesh</forenames></author><author><keyname>Nagarkoti</keyname><forenames>Deepak Singh</forenames></author><author><keyname>Katsounaros</keyname><forenames>Anestis</forenames></author><author><keyname>Mudireddy</keyname><forenames>Hruday Kumar Reddy</forenames></author><author><keyname>Malik</keyname><forenames>Jagannath</forenames></author><author><keyname>Alexandropoulos</keyname><forenames>George C.</forenames></author></authors><title>Dual Dielectric Metasurface for Simultaneous Sensing and Reconfigurable   Reflections</title><categories>cs.AR cs.ET</categories><comments>5 pages, 9 figures, to be presented in EuCAP 2025</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper presents a novel dual-functional hybrid Reconfigurable Intelligent Surface (RIS) for simultaneous sensing and reconfigurable reflections. We design a novel hybrid unit cell featuring dual elements, which share the same phase center, to support both intended functionalities, with the antenna being miniaturized via a high dielectric material approach. The hybrid unit cell has a size of one eighth of the wavelength forming the foundation of an innovative metasurface that incorporates a sub-wavelength reflecting array of split-ring unit cells integrated with a load-tuning matrix. In particular, two interleaved sensing arrays of half-wavelength spacing, orthogonal polarization, and quarter-wavelength offset are embedded within the proposed dual-functional RIS, each tasked to sense the channel parameters towards one of the end communication nodes wishing to profit from the surface's reconfigurable reflections. Our full-wave simulations, indicatively centered around the frequency of $5.5$ GHz, showcase the promising performance of both designed hybrid unit cells and reflective split-ring ones. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14046</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14046</id><created>2025-01-23</created><authors><author><keyname>Palaev</keyname><forenames>Andrey</forenames></author><author><keyname>Khan</keyname><forenames>Adil</forenames></author><author><keyname>Kazmi</keyname><forenames>Syed M. Ahsan</forenames></author></authors><title>LLM-guided Instance-level Image Manipulation with Diffusion U-Net   Cross-Attention Maps</title><categories>cs.CV</categories><comments>Presented at BMVC 2024</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The advancement of text-to-image synthesis has introduced powerful generative models capable of creating realistic images from textual prompts. However, precise control over image attributes remains challenging, especially at the instance level. While existing methods offer some control through fine-tuning or auxiliary information, they often face limitations in flexibility and accuracy. To address these challenges, we propose a pipeline leveraging Large Language Models (LLMs), open-vocabulary detectors, cross-attention maps and intermediate activations of diffusion U-Net for instance-level image manipulation. Our method detects objects mentioned in the prompt and present in the generated image, enabling precise manipulation without extensive training or input masks. By incorporating cross-attention maps, our approach ensures coherence in manipulated images while controlling object positions. Our method enables precise manipulations at the instance level without fine-tuning or auxiliary information such as masks or bounding boxes. Code is available at https://github.com/Palandr123/DiffusionU-NetLLM </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14048</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14048</id><created>2025-01-23</created><authors><author><keyname>Pandya</keyname><forenames>Sneh</forenames></author><author><keyname>Patel</keyname><forenames>Purvik</forenames></author><author><keyname>Nord</keyname><forenames>Brian D.</forenames></author><author><keyname>Walmsley</keyname><forenames>Mike</forenames></author><author><keyname>Ćiprijanović</keyname><forenames>Aleksandra</forenames></author></authors><title>SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with   Equivariant Neural Networks</title><categories>cs.LG astro-ph.GA cs.AI cs.CV</categories><comments>25 pages, 5 figures, 4 tables. code available at:   https://github.com/deepskies/SIDDA</comments><report-no>FERMILAB-PUB-25-0031-CSAID</report-no><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Modern neural networks (NNs) often do not generalize well in the presence of a "covariate shift"; that is, in situations where the training and test data distributions differ, but the conditional distribution of classification labels remains unchanged. In such cases, NN generalization can be reduced to a problem of learning more domain-invariant features. Domain adaptation (DA) methods include a range of techniques aimed at achieving this; however, these methods have struggled with the need for extensive hyperparameter tuning, which then incurs significant computational costs. In this work, we introduce SIDDA, an out-of-the-box DA training algorithm built upon the Sinkhorn divergence, that can achieve effective domain alignment with minimal hyperparameter tuning and computational overhead. We demonstrate the efficacy of our method on multiple simulated and real datasets of varying complexity, including simple shapes, handwritten digits, and real astronomical observations. SIDDA is compatible with a variety of NN architectures, and it works particularly well in improving classification accuracy and model calibration when paired with equivariant neural networks (ENNs). We find that SIDDA enhances the generalization capabilities of NNs, achieving up to a $\approx40\%$ improvement in classification accuracy on unlabeled target data. We also study the efficacy of DA on ENNs with respect to the varying group orders of the dihedral group $D_N$, and find that the model performance improves as the degree of equivariance increases. Finally, we find that SIDDA enhances model calibration on both source and target data--achieving over an order of magnitude improvement in the ECE and Brier score. SIDDA's versatility, combined with its automated approach to domain alignment, has the potential to advance multi-dataset studies by enabling the development of highly generalizable models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14050</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14050</id><created>2025-01-23</created><authors><author><keyname>Liang</keyname><forenames>Jiacheng</forenames></author><author><keyname>Wang</keyname><forenames>Yuhui</forenames></author><author><keyname>Li</keyname><forenames>Changjiang</forenames></author><author><keyname>Zhu</keyname><forenames>Rongyi</forenames></author><author><keyname>Jiang</keyname><forenames>Tanqiu</forenames></author><author><keyname>Gong</keyname><forenames>Neil</forenames></author><author><keyname>Wang</keyname><forenames>Ting</forenames></author></authors><title>GraphRAG under Fire</title><categories>cs.LG cs.AI cs.CR</categories><comments>13 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their reasoning. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: compared to conventional RAG, GraphRAG's graph-based indexing and retrieval enhance resilience against simple poisoning attacks; meanwhile, the same features also create new attack surfaces. We present GRAGPoison, a novel attack that exploits shared relations in the knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GRAGPoison employs three key strategies: i) relation injection to introduce false knowledge, ii) relation enhancement to amplify poisoning influence, and iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GRAGPoison substantially outperforms existing attacks in terms of effectiveness (up to 98% success rate) and scalability (using less than 68% poisoning text). We also explore potential defensive measures and their limitations, identifying promising directions for future research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14051</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14051</id><created>2025-01-23</created><authors><author><keyname>Petersen</keyname><forenames>Jakob Krogh</forenames></author><author><keyname>Licht</keyname><forenames>Valdemar</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author><author><keyname>Munk</keyname><forenames>Asbjørn</forenames></author></authors><title>Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using   Domain-Specific Foundation Models</title><categories>cs.CV cs.AI cs.LG</categories><comments>10 pages, 2 figures. To be published in ISBI 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multi-modal models require aligned, shared embedding spaces. However, common CLIP-based approaches need large amounts of samples and do not natively support 3D or tabular data, both of which are crucial in the medical domain. To address these issues, we revisit CLIP-style alignment by training a domain-specific 3D foundation model as an image encoder and demonstrate that modality alignment is feasible with only 62 MRI scans. Our approach is enabled by a simple embedding accumulation strategy required for training in 3D, which scales the amount of negative pairs across batches in order to stabilize training. We perform a thorough evaluation of various design choices, including the choice of backbone and loss functions, and evaluate the proposed methodology on zero-shot classification and image-retrieval tasks. While zero-shot image-retrieval remains challenging, zero-shot classification results demonstrate that the proposed approach can meaningfully align the representations of 3D MRI with tabular data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14053</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14053</id><created>2025-01-23</created><authors><author><keyname>Flamich</keyname><forenames>Gergely</forenames></author><author><keyname>Sriramu</keyname><forenames>Sharang M.</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>The Redundancy of Non-Singular Channel Simulation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel simulation is an alternative to quantization and entropy coding for performing lossy source coding. Recently, channel simulation has gained significant traction in both the machine learning and information theory communities, as it integrates better with machine learning-based data compression algorithms and has better rate-distortion-perception properties than quantization. As the practical importance of channel simulation increases, it is vital to understand its fundamental limitations. Recently, Sriramu and Wagner provided an almost complete characterisation of the redundancy of channel simulation algorithms. In this paper, we complete this characterisation. First, we significantly extend a result of Li and El Gamal, and show that the redundancy of any instance of a channel simulation problem is lower bounded by the channel simulation divergence. Second, we give two proofs that the asymptotic redundancy of simulating iid non-singular channels is lower-bounded by $1/2$: one using a direct approach based on the asymptotic expansion of the channel simulation divergence and one using large deviations theory. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14056</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14056</id><created>2025-01-23</created><authors><author><keyname>Hallemeesch</keyname><forenames>Max</forenames></author><author><keyname>Pizurica</keyname><forenames>Marija</forenames></author><author><keyname>Rabaey</keyname><forenames>Paloma</forenames></author><author><keyname>Gevaert</keyname><forenames>Olivier</forenames></author><author><keyname>Demeester</keyname><forenames>Thomas</forenames></author><author><keyname>Marchal</keyname><forenames>Kathleen</forenames></author></authors><title>Prior Knowledge Injection into Deep Learning Models Predicting Gene   Expression from Whole Slide Images</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Cancer diagnosis and prognosis primarily depend on clinical parameters such as age and tumor grade, and are increasingly complemented by molecular data, such as gene expression, from tumor sequencing. However, sequencing is costly and delays oncology workflows. Recent advances in Deep Learning allow to predict molecular information from morphological features within Whole Slide Images (WSIs), offering a cost-effective proxy of the molecular markers. While promising, current methods lack the robustness to fully replace direct sequencing. Here we aim to improve existing methods by introducing a model-agnostic framework that allows to inject prior knowledge on gene-gene interactions into Deep Learning architectures, thereby increasing accuracy and robustness. We design the framework to be generic and flexibly adaptable to a wide range of architectures. In a case study on breast cancer, our strategy leads to an average increase of 983 significant genes (out of 25,761) across all 18 experiments, with 14 generalizing to an increase on an independent dataset. Our findings reveal a high potential for injection of prior knowledge to increase gene expression prediction performance from WSIs across a wide range of architectures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14064</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14064</id><created>2025-01-23</created><authors><author><keyname>Kosut</keyname><forenames>Oliver</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Switched Feedback for the Multiple-Access Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to the 2025 IEEE International Symposium on Information   Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mechanism called switched feedback is introduced; under switched feedback, each channel output goes forward to the receiver(s) or backwards to the transmitter(s) but never both. By studying the capacity of the Multiple Access Channel (MAC) with switched feedback, this work investigates the potential benefits of feedback in the MAC and explores strategies for maximizing that benefit under reliable and unreliable feedback scenarios. The study is motivated by an exploration of the tradeoffs between cooperation and transmission in the context of communication systems. Results include upper and lower bounds on the capacity region of the MAC with switched feedback. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14066</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14066</id><created>2025-01-23</created><authors><author><keyname>Hou</keyname><forenames>Benjamin</forenames></author><author><keyname>Mathai</keyname><forenames>Tejas Sudharshan</forenames></author><author><keyname>Mukherjee</keyname><forenames>Pritam</forenames></author><author><keyname>Wang</keyname><forenames>Xinya</forenames></author><author><keyname>Summers</keyname><forenames>Ronald M.</forenames></author><author><keyname>Lub</keyname><forenames>Zhiyong</forenames></author></authors><title>Efficient 2D CT Foundation Model for Contrast Phase Classification</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Purpose: The purpose of this study is to harness the efficiency of a 2D foundation model to develop a robust phase classifier that is resilient to domain shifts.   Materials and Methods: This retrospective study utilized three public datasets from separate institutions. A 2D foundation model was trained on the DeepLesion dataset (mean age: 51.2, s.d.: 17.6; 2398 males) to generate embeddings from 2D CT slices for downstream contrast phase classification. The classifier was trained on the VinDr Multiphase dataset and externally validated on the WAW-TACE dataset. The 2D model was also compared to three 3D supervised models.   Results: On the VinDr dataset (146 male, 63 female, 56 unidentified), the model achieved near-perfect AUROC scores and F1 scores of 99.2%, 94.2%, and 93.1% for non-contrast, arterial, and venous phases, respectively. The `Other' category scored lower (F1: 73.4%) due to combining multiple contrast phases into one class. On the WAW-TACE dataset (mean age: 66.1, s.d.: 10.0; 185 males), the model showed strong performance with AUROCs of 91.0% and 85.6%, and F1 scores of 87.3% and 74.1% for non-contrast and arterial phases. Venous phase performance was lower, with AUROC and F1 scores of 81.7% and 70.2% respectively, due to label mismatches. Compared to 3D supervised models, the approach trained faster, performed as well or better, and showed greater robustness to domain shifts.   Conclusion: The robustness of the 2D Foundation model may be potentially useful for automation of hanging protocols and data orchestration for clinical deployment of AI algorithms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14068</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14068</id><created>2025-01-23</created><authors><author><keyname>Xiao</keyname><forenames>Dong</forenames></author><author><keyname>Chen</keyname><forenames>Renjie</forenames></author></authors><title>Flexible 3D Cage-based Deformation via Green Coordinates on B\'{e}zier   Patches</title><categories>cs.GR</categories><comments>12 pages, 10 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Cage-based deformation is a fundamental problem in geometry processing, where a cage, a user-specified boundary of a region, is used to deform the ambient space of a given mesh. Traditional 3D cages are typically composed of triangles and quads. While quads can represent non-planar regions when their four corners are not coplanar, they form ruled surfaces with isoparametric curves being line segments, which limits their ability to handle curved and high-curvature deformations. In this work, we extend the cage for curved boundaries using B\'{e}zier patches, enabling flexible and high-curvature deformations with only a few control points. The higher-order structure of the B\'{e}zier patch also allows for the creation of a more compact and precise curved cage for the input model. Based on Green's third identity, we derive the Green coordinates for the B\'{e}zier cage, achieving shape preserving deformation with smooth surface boundaries. These coordinates are defined based on the vertex positions and normals of the B\'{e}zier control net. Given that the coordinates are approximately calculated through Riemann summation, we propose a global projection technique to ensure that the coordinates accurately conform to the linear reproduction property. Experimental results show that our method achieves high performs in handling curved and high-curvature deformations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14070</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14070</id><created>2025-01-23</created><authors><author><keyname>Jager</keyname><forenames>Gavin</forenames></author><author><keyname>Cornett</keyname><forenames>David</forenames><suffix>III</suffix></author><author><keyname>Glenn</keyname><forenames>Gavin</forenames></author><author><keyname>Aykac</keyname><forenames>Deniz</forenames></author><author><keyname>Johnson</keyname><forenames>Christi</forenames></author><author><keyname>Zhang</keyname><forenames>Robert</forenames></author><author><keyname>Shivers</keyname><forenames>Ryan</forenames></author><author><keyname>Bolme</keyname><forenames>David</forenames></author><author><keyname>Davies</keyname><forenames>Laura</forenames></author><author><keyname>Dolvin</keyname><forenames>Scott</forenames></author><author><keyname>Barber</keyname><forenames>Nell</forenames></author><author><keyname>Brogan</keyname><forenames>Joel</forenames></author><author><keyname>Burchfield</keyname><forenames>Nick</forenames></author><author><keyname>Dukes</keyname><forenames>Carl</forenames></author><author><keyname>Duncan</keyname><forenames>Andrew</forenames></author><author><keyname>Ferrell</keyname><forenames>Regina</forenames></author><author><keyname>Garrett</keyname><forenames>Austin</forenames></author><author><keyname>Goddard</keyname><forenames>Jim</forenames></author><author><keyname>Hines</keyname><forenames>Jairus</forenames></author><author><keyname>Murphy</keyname><forenames>Bart</forenames></author><author><keyname>Pharris</keyname><forenames>Sean</forenames></author><author><keyname>Stockwell</keyname><forenames>Brandon</forenames></author><author><keyname>Thompson</keyname><forenames>Leanne</forenames></author><author><keyname>Yohe</keyname><forenames>Matthew</forenames></author></authors><title>Expanding on the BRIAR Dataset: A Comprehensive Whole Body Biometric   Recognition Resource at Extreme Distances and Real-World Scenarios   (Collections 1-4)</title><categories>cs.CV cs.AI cs.LG</categories><comments>10 pages, 11 figures, 2 tables, submitted to CVPR</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The state-of-the-art in biometric recognition algorithms and operational systems has advanced quickly in recent years providing high accuracy and robustness in more challenging collection environments and consumer applications. However, the technology still suffers greatly when applied to non-conventional settings such as those seen when performing identification at extreme distances or from elevated cameras on buildings or mounted to UAVs. This paper summarizes an extension to the largest dataset currently focused on addressing these operational challenges, and describes its composition as well as methodologies of collection, curation, and annotation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14073</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14073</id><created>2025-01-23</created><authors><author><keyname>Ge</keyname><forenames>Yubin</forenames></author><author><keyname>Kirtane</keyname><forenames>Neeraja</forenames></author><author><keyname>Peng</keyname><forenames>Hao</forenames></author><author><keyname>Hakkani-Tür</keyname><forenames>Dilek</forenames></author></authors><title>LLMs are Vulnerable to Malicious Prompts Disguised as Scientific   Language</title><categories>cs.CL</categories><comments>15 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  As large language models (LLMs) have been deployed in various real-world settings, concerns about the harm they may propagate have grown. Various jailbreaking techniques have been developed to expose the vulnerabilities of these models and improve their safety. This work reveals that many state-of-the-art proprietary and open-source LLMs are vulnerable to malicious requests hidden behind scientific language. Specifically, our experiments with GPT4o, GPT4o-mini, GPT-4, LLama3-405B-Instruct, Llama3-70B-Instruct, Cohere, Gemini models on the StereoSet data demonstrate that, the models' biases and toxicity substantially increase when prompted with requests that deliberately misinterpret social science and psychological studies as evidence supporting the benefits of stereotypical biases. Alarmingly, these models can also be manipulated to generate fabricated scientific arguments claiming that biases are beneficial, which can be used by ill-intended actors to systematically jailbreak even the strongest models like GPT. Our analysis studies various factors that contribute to the models' vulnerabilities to malicious requests in academic language. Mentioning author names and venues enhances the persuasiveness of some models, and the bias scores can increase as dialogues progress. Our findings call for a more careful investigation on the use of scientific data in the training of LLMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14079</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14079</id><created>2025-01-23</created><authors><author><keyname>Lai</keyname><forenames>Po-Ting</forenames></author><author><keyname>Wei</keyname><forenames>Chih-Hsuan</forenames></author><author><keyname>Tian</keyname><forenames>Shubo</forenames></author><author><keyname>Leaman</keyname><forenames>Robert</forenames></author><author><keyname>Lu</keyname><forenames>Zhiyong</forenames></author></authors><title>Enhancing Biomedical Relation Extraction with Directionality</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biological relation networks contain rich information for understanding the biological mechanisms behind the relationship of entities such as genes, proteins, diseases, and chemicals. The vast growth of biomedical literature poses significant challenges updating the network knowledge. The recent Biomedical Relation Extraction Dataset (BioRED) provides valuable manual annotations, facilitating the develop-ment of machine-learning and pre-trained language model approaches for automatically identifying novel document-level (inter-sentence context) relationships. Nonetheless, its annotations lack directionality (subject/object) for the entity roles, essential for studying complex biological networks. Herein we annotate the entity roles of the relationships in the BioRED corpus and subsequently propose a novel multi-task language model with soft-prompt learning to jointly identify the relationship, novel findings, and entity roles. Our results in-clude an enriched BioRED corpus with 10,864 directionality annotations. Moreover, our proposed method outperforms existing large language models such as the state-of-the-art GPT-4 and Llama-3 on two benchmarking tasks. Our source code and dataset are available at https://github.com/ncbi-nlp/BioREDirect. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14081</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14081</id><created>2025-01-23</created><authors><author><keyname>Treust</keyname><forenames>Maël Le</forenames></author><author><keyname>Tomala</keyname><forenames>Tristan</forenames></author></authors><title>Single-Letter Characterization of the Mismatched Distortion-Rate   Function</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The mismatched distortion-rate problem has remained open since its formulation by Lapidoth in 1997. In this paper, we characterize the mismatched distortion-rate function. Our single-letter solution highlights the adequate conditional distributions for the encoder and the decoder. The achievability result relies on a time-sharing argument that allows to convexify the upper bound of Lapidoth. We show that it is sufficient to consider two regimes, one with a large rate and another one with a small rate. Our main contribution is the converse proof. Suppose that the encoder selects a single-letter conditional distribution distinct from the one in the solution, we construct an encoding strategy that leads to the same expected cost for both encoder and decoder. This ensures that the encoder cannot gain by changing the single-letter conditional distribution. This argument relies on a careful identification of the sequence of auxiliary random variables. By building on Caratheodory's Theorem we show that the cardinality of the auxiliary random variables is equal to the one of the source alphabet plus three. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14082</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14082</id><created>2025-01-23</created><authors><author><keyname>Ramesh</keyname><forenames>Vignav</forenames></author><author><keyname>Li</keyname><forenames>Kenneth</forenames></author></authors><title>Communicating Activations Between Language Model Agents</title><categories>cs.CL cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Communication between multiple language model (LM) agents has been shown to scale up the reasoning ability of LMs. While natural language has been the dominant medium for inter-LM communication, it is not obvious this should be the standard: not only does natural language communication incur high inference costs that scale quickly with the number of both agents and messages, but also the decoding process abstracts away too much rich information that could be otherwise accessed from the internal activations. In this work, we propose a simple technique whereby LMs communicate via activations; concretely, we pause an LM $\textit{B}$'s computation at an intermediate layer, combine its current activation with another LM $\textit{A}$'s intermediate activation via some function $\textit{f}$, then pass $\textit{f}$'s output into the next layer of $\textit{B}$ and continue the forward pass till decoding is complete. This approach scales up LMs on new tasks with zero additional parameters and data, and saves a substantial amount of compute over natural language communication. We test our method with various functional forms $\textit{f}$ on two experimental setups--multi-player coordination games and reasoning benchmarks--and find that it achieves up to $27.0\%$ improvement over natural language communication across datasets with $&lt;$$1/4$ the compute, illustrating the superiority and robustness of activations as an alternative "language" for communication between LMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14084</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14084</id><created>2025-01-23</created><authors><author><keyname>Kiesler</keyname><forenames>Natalie</forenames></author><author><keyname>Smith</keyname><forenames>Jacqueline</forenames></author><author><keyname>Leinonen</keyname><forenames>Juho</forenames></author><author><keyname>Fox</keyname><forenames>Armando</forenames></author><author><keyname>MacNeil</keyname><forenames>Stephen</forenames></author><author><keyname>Ihantola</keyname><forenames>Petri</forenames></author></authors><title>The Role of Generative AI in Software Student CollaborAItion</title><categories>cs.SE cs.AI cs.CY cs.HC</categories><comments>7 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Collaboration is a crucial part of computing education. The increase in AI capabilities over the last couple of years is bound to profoundly affect all aspects of systems and software engineering, including collaboration. In this position paper, we consider a scenario where AI agents would be able to take on any role in collaborative processes in computing education. We outline these roles, the activities and group dynamics that software development currently include, and discuss if and in what way AI could facilitate these roles and activities. The goal of our work is to envision and critically examine potential futures. We present scenarios suggesting how AI can be integrated into existing collaborations. These are contrasted by design fictions that help demonstrate the new possibilities and challenges for computing education in the AI era. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14090</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14090</id><created>2025-01-23</created><authors><author><keyname>Li</keyname><forenames>Bolian</forenames></author><author><keyname>Zhang</keyname><forenames>Ruqi</forenames></author></authors><title>Making Reliable and Flexible Decisions in Long-tailed Classification</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Long-tailed classification is challenging due to its heavy imbalance in class probabilities. While existing methods often focus on overall accuracy or accuracy for tail classes, they overlook a critical aspect: certain types of errors can carry greater risks than others in real-world long-tailed problems. For example, misclassifying patients (a tail class) as healthy individuals (a head class) entails far more serious consequences than the reverse scenario. To address this critical issue, we introduce Making Reliable and Flexible Decisions in Long-tailed Classification (RF-DLC), a novel framework aimed at reliable predictions in long-tailed problems. Leveraging Bayesian Decision Theory, we introduce an integrated gain to seamlessly combine long-tailed data distributions and the decision-making procedure. We further propose an efficient variational optimization strategy for the decision risk objective. Our method adapts readily to diverse utility matrices, which can be designed for specific tasks, ensuring its flexibility for different problem settings. In empirical evaluation, we design a new metric, False Head Rate, to quantify tail-sensitivity risk, along with comprehensive experiments on multiple real-world tasks, including large-scale image classification and uncertainty quantification, to demonstrate the reliability and flexibility of our method. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14092</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14092</id><created>2025-01-23</created><authors><author><keyname>Gilbert</keyname><forenames>Eric</forenames></author></authors><title>Capital and CHI: Technological Capture and How It Structures CHI   Research</title><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper advances a theoretical argument about the role capital plays in structuring CHI research. We introduce the concept of technological capture to theorize the mechanism by which this happens. Using this concept, we decompose the effect on CHI into four broad forms: technological capture creates market-creating, market-expanding, market-aligned, and externality-reducing CHI research. We place different CHI subcommunities into these forms -- arguing that many of their values are inherited from capital underlying the field. Rather than a disciplinary- or conference-oriented conceptualization of the field, this work theorizes CHI as tightly-coupled with capital via technological capture. The paper concludes by discussing some implications for CHI. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14094</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14094</id><created>2025-01-23</created><authors><author><keyname>Marandi</keyname><forenames>Ramtin Zargari</forenames></author><author><keyname>Frahm</keyname><forenames>Anne Svane</forenames></author><author><keyname>Milojevic</keyname><forenames>Maja</forenames></author></authors><title>Datasheets for AI and medical datasets (DAIMS): a data validation and   documentation framework before machine learning analysis in medical research</title><categories>cs.LG</categories><comments>10 pages, 1 figure, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Despite progresses in data engineering, there are areas with limited consistencies across data validation and documentation procedures causing confusions and technical problems in research involving machine learning. There have been progresses by introducing frameworks like "Datasheets for Datasets", however there are areas for improvements to prepare datasets, ready for ML pipelines. Here, we extend the framework to "Datasheets for AI and medical datasets - DAIMS." Our publicly available solution, DAIMS, provides a checklist including data standardization requirements, a software tool to assist the process of the data preparation, an extended form for data documentation and pose research questions, a table as data dictionary, and a flowchart to suggest ML analyses to address the research questions. The checklist consists of 24 common data standardization requirements, where the tool checks and validate a subset of them. In addition, we provided a flowchart mapping research questions to suggested ML methods. DAIMS can serve as a reference for standardizing datasets and a roadmap for researchers aiming to apply effective ML techniques in their medical research endeavors. DAIMS is available on GitHub and as an online app to automate key aspects of dataset evaluation, facilitating efficient preparation of datasets for ML studies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14095</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14095</id><created>2025-01-23</created><authors><author><keyname>Ramsay</keyname><forenames>Kelly</forenames></author><author><keyname>Spicker</keyname><forenames>Dylan</forenames></author></authors><title>Improved subsample-and-aggregate via the private modified winsorized   mean</title><categories>stat.ME cs.LG</categories><comments>40 pages, 2 figures</comments><msc-class>62G35, 68P27</msc-class><acm-class>G.3.7; C.2.0</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We develop a univariate, differentially private mean estimator, called the private modified winsorized mean designed to be used as the aggregator in subsample-and-aggregate. We demonstrate, via real data analysis, that common differentially private multivariate mean estimators may not perform well as the aggregator, even with a dataset with 8000 observations, motivating our developments. We show that the modified winsorized mean is minimax optimal for several, large classes of distributions, even under adversarial contamination. We also demonstrate that, empirically, the modified winsorized mean performs well compared to other private mean estimates. We consider the modified winsorized mean as the aggregator in subsample-and-aggregate, deriving a finite sample deviations bound for a subsample-and-aggregate estimate generated with the new aggregator. This result yields two important insights: (i) the optimal choice of subsamples depends on the bias of the estimator computed on the subsamples, and (ii) the rate of convergence of the subsample-and-aggregate estimator depends on the robustness of the estimator computed on the subsamples. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14098</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14098</id><created>2025-01-23</created><authors><author><keyname>Napoli</keyname><forenames>Daniela</forenames></author><author><keyname>Molyneaux</keyname><forenames>Heather</forenames></author><author><keyname>Fournier</keyname><forenames>Helene</forenames></author><author><keyname>Chiasson</keyname><forenames>Sonia</forenames></author></authors><title>Exploring User Perspectives on Data Collection, Data Sharing   Preferences, and Privacy Concerns with Remote Healthcare Technology</title><categories>cs.CY cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote healthcare technology can help tackle societal issues by improving access to quality healthcare services and enhancing diagnoses through in-place monitoring. These services can be implemented through a combination of mobile devices, applications, wearable sensors, and other smart technology. It is paramount to handle sensitive data that is collected in ways that meet users' privacy expectations. We surveyed 384 people in Canada aged 20 to 93 years old to explore participants' comfort with data collection, sharing preferences, and potential privacy concerns related to remote healthcare technology. We explore these topics within the context of various healthcare scenarios including health emergencies and managing chronic health conditions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14099</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14099</id><created>2025-01-23</created><authors><author><keyname>Molan</keyname><forenames>Jaclyn</forenames></author><author><keyname>Saad</keyname><forenames>Laura</forenames></author><author><keyname>Roesler</keyname><forenames>Eileen</forenames></author><author><keyname>McCurry</keyname><forenames>J. Malcolm</forenames></author><author><keyname>Gyory</keyname><forenames>Nathaniel</forenames></author><author><keyname>Trafton</keyname><forenames>J. Gregory</forenames></author></authors><title>The Perceived Danger (PD) Scale: Development and Validation</title><categories>cs.RO</categories><comments>9 pages, 2 figures, to be published in the Proceedings of the 2025   ACM/IEEE International Conference on Human-Robot Interaction (HRI)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  There are currently no psychometrically valid tools to measure the perceived danger of robots. To fill this gap, we provided a definition of perceived danger and developed and validated a 12-item bifactor scale through four studies. An exploratory factor analysis revealed four subdimensions of perceived danger: affective states, physical vulnerability, ominousness, and cognitive readiness. A confirmatory factor analysis confirmed the bifactor model. We then compared the perceived danger scale to the Godspeed perceived safety scale and found that the perceived danger scale is a better predictor of empirical data. We also validated the scale in an in-person setting and found that the perceived danger scale is sensitive to robot speed manipulations, consistent with previous empirical findings. Results across experiments suggest that the perceived danger scale is reliable, valid, and an adequate predictor of both perceived safety and perceived danger in human-robot interaction contexts. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14101</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14101</id><created>2025-01-23</created><authors><author><keyname>Sankaradas</keyname><forenames>Murugan</forenames></author><author><keyname>Rajendran</keyname><forenames>Ravi K.</forenames></author><author><keyname>Chakradhar</keyname><forenames>Srimat T.</forenames></author></authors><title>StreamingRAG: Real-time Contextual Retrieval and Generation Framework</title><categories>cs.CV</categories><comments>Accepted and Presented at AI4Sys, HPDC 2024</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Extracting real-time insights from multi-modal data streams from various domains such as healthcare, intelligent transportation, and satellite remote sensing remains a challenge. High computational demands and limited knowledge scope restrict the applicability of Multi-Modal Large Language Models (MM-LLMs) on these data streams. Traditional Retrieval-Augmented Generation (RAG) systems address knowledge limitations of these models, but suffer from slow preprocessing, making them unsuitable for real-time analysis. We propose StreamingRAG, a novel RAG framework designed for streaming data. StreamingRAG constructs evolving knowledge graphs capturing scene-object-entity relationships in real-time. The knowledge graph achieves temporal-aware scene representations using MM-LLMs and enables timely responses for specific events or user queries. StreamingRAG addresses limitations in existing methods, achieving significant improvements in real-time analysis (5-6x faster throughput), contextual accuracy (through a temporal knowledge graph), and reduced resource consumption (using lightweight models by 2-3x). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14102</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14102</id><created>2025-01-23</created><authors><author><keyname>Hernandez</keyname><forenames>Mario</forenames></author><author><keyname>Pinero</keyname><forenames>Fernando</forenames></author></authors><title>5G LDPC Linear Transformer for Channel Decoding</title><categories>cs.LG cs.IT math.IT</categories><comments>8 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This work introduces a novel, fully differentiable linear-time complexity transformer decoder and a transformer decoder to correct 5G New Radio (NR) LDPC. We propose a scalable approach to decode linear block codes with $O(n)$ complexity rather than $O(n^2)$ for regular transformers. The architectures' performances are compared to Belief Propagation (BP), the production-level decoding algorithm used for 5G New Radio (NR) LDPC codes. We achieve bit error rate performance that matches a regular Transformer decoder and surpases one iteration BP, also achieving competitive time performance against BP, even for larger block codes. We utilize Sionna, Nvidia's 5G &amp; 6G physical layer research software, for reproducible results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14103</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14103</id><created>2025-01-23</created><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Li</keyname><forenames>Weiliang</forenames></author><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Fu</keyname><forenames>Zihang</forenames></author><author><keyname>Tang</keyname><forenames>Tongyi</forenames></author><author><keyname>Zhang</keyname><forenames>Zhengyu</forenames></author><author><keyname>Chen</keyname><forenames>Wen-Yen</forenames></author><author><keyname>Noorshams</keyname><forenames>Nima</forenames></author><author><keyname>Jasapara</keyname><forenames>Nirav</forenames></author><author><keyname>Ding</keyname><forenames>Xiaowen</forenames></author><author><keyname>Wen</keyname><forenames>Ellie</forenames></author><author><keyname>Feng</keyname><forenames>Xue</forenames></author></authors><title>Personalized Interpolation: An Efficient Method to Tame Flexible   Optimization Window Estimation</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the realm of online advertising, optimizing conversions is crucial for delivering relevant products to users and enhancing business outcomes. Predicting conversion events is challenging due to variable delays between user interactions, such as impressions or clicks, and the actual conversions. These delays differ significantly across various advertisers and products, necessitating distinct optimization time windows for targeted conversions. To address this, we introduce a novel approach named the \textit{Personalized Interpolation} method, which innovatively builds upon existing fixed conversion window models to estimate flexible conversion windows. This method allows for the accurate estimation of conversions across a variety of delay ranges, thus meeting the diverse needs of advertisers without increasing system complexity. To validate the efficacy of our proposed method, we conducted comprehensive experiments using ads conversion model. Our experiments demonstrate that this method not only achieves high prediction accuracy but also does so more efficiently than other existing solutions. This validation underscores the potential of our Personalized Interpolation method to significantly enhance conversion optimization in real-world online advertising systems, promising improved targeting and effectiveness in advertising strategies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14105</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14105</id><created>2025-01-23</created><authors><author><keyname>Davis</keyname><forenames>Joshua</forenames></author><author><keyname>Sounack</keyname><forenames>Thomas</forenames></author><author><keyname>Sciacca</keyname><forenames>Kate</forenames></author><author><keyname>Brain</keyname><forenames>Jessie M</forenames></author><author><keyname>Durieux</keyname><forenames>Brigitte N</forenames></author><author><keyname>Agaronnik</keyname><forenames>Nicole D</forenames></author><author><keyname>Lindvall</keyname><forenames>Charlotta</forenames></author></authors><title>MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note   Sectioning</title><categories>cs.CL cs.AI cs.IR cs.LG</categories><comments>Our code is publicly available on github (   https://github.com/lindvalllab/MedSlice )</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting sections from clinical notes is crucial for downstream analysis but is challenging due to variability in formatting and labor-intensive nature of manual sectioning. While proprietary large language models (LLMs) have shown promise, privacy concerns limit their accessibility. This study develops a pipeline for automated note sectioning using open-source LLMs, focusing on three sections: History of Present Illness, Interval History, and Assessment and Plan. We fine-tuned three open-source LLMs to extract sections using a curated dataset of 487 progress notes, comparing results relative to proprietary models (GPT-4o, GPT-4o mini). Internal and external validity were assessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B outperformed GPT-4o (F1=0.92). On the external validity test set, performance remained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary models in clinical note sectioning, offering advantages in cost, performance, and accessibility. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14107</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14107</id><created>2025-01-23</created><authors><author><keyname>Chen</keyname><forenames>Jianhong</forenames></author><author><keyname>Yang</keyname><forenames>Shihao</forenames></author></authors><title>EFiGP: Eigen-Fourier Physics-Informed Gaussian Process for Inference of   Dynamic Systems</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Parameter estimation and trajectory reconstruction for data-driven dynamical systems governed by ordinary differential equations (ODEs) are essential tasks in fields such as biology, engineering, and physics. These inverse problems -- estimating ODE parameters from observational data -- are particularly challenging when the data are noisy, sparse, and the dynamics are nonlinear. We propose the Eigen-Fourier Physics-Informed Gaussian Process (EFiGP), an algorithm that integrates Fourier transformation and eigen-decomposition into a physics-informed Gaussian Process framework. This approach eliminates the need for numerical integration, significantly enhancing computational efficiency and accuracy. Built on a principled Bayesian framework, EFiGP incorporates the ODE system through probabilistic conditioning, enforcing governing equations in the Fourier domain while truncating high-frequency terms to achieve denoising and computational savings. The use of eigen-decomposition further simplifies Gaussian Process covariance operations, enabling efficient recovery of trajectories and parameters even in dense-grid settings. We validate the practical effectiveness of EFiGP on three benchmark examples, demonstrating its potential for reliable and interpretable modeling of complex dynamical systems while addressing key challenges in trajectory recovery and computational cost. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14108</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14108</id><created>2025-01-23</created><authors><author><keyname>Lewintan</keyname><forenames>Peter</forenames></author><author><keyname>Theisen</keyname><forenames>Lambert</forenames></author><author><keyname>Torrilhon</keyname><forenames>Manuel</forenames></author></authors><title>Well-Posedness of the R13 Equations Using Tensor-Valued Korn   Inequalities</title><categories>math.AP cs.NA math.FA math.NA</categories><comments>19 pages, 1 figure</comments><msc-class>76P05, 65N30, 26D10, 35Q35, 35A23, 65K10, 35A01</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we finally catch up with proving the well-posedness of the linearized R13 moment model, which describes, e.g., rarefied gas flows. As an extension of the classical fluid equations, moment models are robust and have been frequently used, yet they are challenging to analyze due to their additional equations. By effectively grouping variables, we identify a 2-by-2 block structure, allowing the analysis of the well-posedness within the abstract LBB framework of saddle point problems. Due to the unique tensorial structure of the equations, in addition to an interesting combination of tools from Stokes' and linear elasticity theory, we also need new coercivity estimates for tensor fields. These Korn-type inequalities are established by analyzing the symbol map of the symmetric and trace-free part of tensor derivative fields. Together with the corresponding right inverse of the tensorial divergence, we obtain the existence and uniqueness of weak solutions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14110</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14110</id><created>2025-01-23</created><authors><author><keyname>He</keyname><forenames>Changyang</forenames></author><author><keyname>Deng</keyname><forenames>Yue</forenames></author><author><keyname>Fabris</keyname><forenames>Alessandro</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Biega</keyname><forenames>Asia</forenames></author></authors><title>Developing a Fair Online Recruitment Framework Based on Job-seekers'   Fairness Concerns</title><categories>cs.HC</categories><comments>24 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The susceptibility to biases and discrimination is a pressing issue in today's labor markets. Though digital recruitment systems play an increasingly significant role in human resources management, thus far we lack a systematic understanding of human-centered design principles for fair online hiring. This work proposes a fair recruitment framework based on job-seekers' fairness concerns shared in an online forum. Through qualitative analysis, we uncover four overarching themes of job-seekers' fairness concerns, including discrimination against sensitive attributes, interaction biases, improper interpretations of qualifications, and power imbalance. Based on these findings, we derive design implications for algorithms and interfaces in recruitment systems, integrating them into a fair recruitment framework spanning different hiring stages and fairness considerations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14111</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14111</id><created>2025-01-23</created><authors><author><keyname>Wang</keyname><forenames>Wan</forenames></author><author><keyname>Wang</keyname><forenames>Haiyan</forenames></author><author><keyname>Sobey</keyname><forenames>Adam J.</forenames></author></authors><title>Collaborating in a competitive world: Heterogeneous Multi-Agent Decision   Making in Symbiotic Supply Chain Environments</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supply networks require collaboration in a competitive environment. To achieve this, nodes in the network often form symbiotic relationships as they can be adversely effected by the closure of companies in the network, especially where products are niche. However, balancing support for other nodes in the network against profit is challenging. Agents are increasingly being explored to define optimal strategies in these complex networks. However, to date much of the literature focuses on homogeneous agents where a single policy controls all of the nodes. This isn't realistic for many supply chains as this level of information sharing would require an exceptionally close relationship. This paper therefore compares the behaviour of this type of agent to a heterogeneous structure, where the agents each have separate polices, to solve the product ordering and pricing problem. An approach to reward sharing is developed that doesn't require sharing profit. The homogenous and heterogeneous agents exhibit different behaviours, with the homogenous retailer retaining high inventories and witnessing high levels of backlog while the heterogeneous agents show a typical order strategy. This leads to the heterogeneous agents mitigating the bullwhip effect whereas the homogenous agents do not. In the high demand environment, the agent architecture dominates performance with the Soft Actor-Critic (SAC) agents outperforming the Proximal Policy Optimisation (PPO) agents. Here, the factory controls the supply chain. In the low demand environment the homogenous agents outperform the heterogeneous agents. Control of the supply chain shifts significantly, with the retailer outperforming the factory by a significant margin. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14112</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14112</id><created>2025-01-23</created><authors><author><keyname>Santosh</keyname><forenames>T. Y. S. S.</forenames></author><author><keyname>Farag</keyname><forenames>Youssef</forenames></author><author><keyname>Grabmair</keyname><forenames>Matthias</forenames></author></authors><title>CoPERLex: Content Planning with Event-based Representations for Legal   Case Summarization</title><categories>cs.CL</categories><comments>Accepted to NAACL 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Legal professionals often struggle with lengthy judgments and require efficient summarization for quick comprehension. To address this challenge, we investigate the need for structured planning in legal case summarization, particularly through event-centric representations that reflect the narrative nature of legal case documents. We propose our framework, CoPERLex, which operates in three stages: first, it performs content selection to identify crucial information from the judgment; second, the selected content is utilized to generate intermediate plans through event-centric representations modeled as Subject-Verb-Object tuples; and finally, it generates coherent summaries based on both the content and the structured plan. Our experiments on four legal summarization datasets demonstrate the effectiveness of integrating content selection and planning components, highlighting the advantages of event-centric plans over traditional entity-centric approaches in the context of legal judgements. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14113</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14113</id><created>2025-01-23</created><authors><author><keyname>Santosh</keyname><forenames>T. Y. S. S.</forenames></author><author><keyname>Jia</keyname><forenames>Chen</forenames></author><author><keyname>Goroncy</keyname><forenames>Patrick</forenames></author><author><keyname>Grabmair</keyname><forenames>Matthias</forenames></author></authors><title>RELexED: Retrieval-Enhanced Legal Summarization with Exemplar Diversity</title><categories>cs.CL</categories><comments>Accepted to NAACL 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper addresses the task of legal summarization, which involves distilling complex legal documents into concise, coherent summaries. Current approaches often struggle with content theme deviation and inconsistent writing styles due to their reliance solely on source documents. We propose RELexED, a retrieval-augmented framework that utilizes exemplar summaries along with the source document to guide the model. RELexED employs a two-stage exemplar selection strategy, leveraging a determinantal point process to balance the trade-off between similarity of exemplars to the query and diversity among exemplars, with scores computed via influence functions. Experimental results on two legal summarization datasets demonstrate that RELexED significantly outperforms models that do not utilize exemplars and those that rely solely on similarity-based exemplar selection. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14114</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14114</id><created>2025-01-23</created><authors><author><keyname>Santosh</keyname><forenames>T. Y. S. S.</forenames></author><author><keyname>Nolasco</keyname><forenames>Isaac Misael Olguín</forenames></author><author><keyname>Grabmair</keyname><forenames>Matthias</forenames></author></authors><title>LeCoPCR: Legal Concept-guided Prior Case Retrieval for European Court of   Human Rights cases</title><categories>cs.CL</categories><comments>Accepted to NAACL 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Prior case retrieval (PCR) is crucial for legal practitioners to find relevant precedent cases given the facts of a query case. Existing approaches often overlook the underlying semantic intent in determining relevance with respect to the query case. In this work, we propose LeCoPCR, a novel approach that explicitly generate intents in the form of legal concepts from a given query case facts and then augments the query with these concepts to enhance models understanding of semantic intent that dictates relavance. To overcome the unavailability of annotated legal concepts, we employ a weak supervision approach to extract key legal concepts from the reasoning section using Determinantal Point Process (DPP) to balance quality and diversity. Experimental results on the ECtHR-PCR dataset demonstrate the effectiveness of leveraging legal concepts and DPP-based key concept extraction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14115</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14115</id><created>2025-01-23</created><authors><author><keyname>Lee</keyname><forenames>Soojeong</forenames></author><author><keyname>Caverly</keyname><forenames>Ryan J.</forenames></author></authors><title>Passivity-Based Robust Shape Control of a Cable-Driven Solar Sail Boom   for the CABLESSail Concept</title><categories>eess.SY cs.SY physics.space-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Solar sails provide a means of propulsion using solar radiation pressure, which offers the possibility of exciting new spacecraft capabilities. However, solar sails have attitude control challenges because of the significant disturbance torques that they encounter due to imperfections in the sail and its supporting structure, as well as limited actuation capabilities. The Cable-Actuated Bio-inspired Lightweight Elastic Solar Sail (CABLESSail) concept was previously proposed to overcome these challenges by controlling the shape of the sail through cable actuation. The structural flexibility of CABLESSail introduces control challenges, which necessitate the design of a robust feedback controller for this system. The purpose of the proposed research here is to design a robust controller to ensure precise and reliable control of CABLESSail's boom. Taking into account the system dynamics and the dynamic properties of the CABLESSail concept, a passivity-based proportional-derivative (PD) controller for a single boom on the CABLESSail system is designed. To reach the nonzero desired setpoints, a feedforward input is additionally applied to the control law and a time-varying feedforward input is used instead of the constant one to effectively track a time-varying desired boom tip deflection. This control law is assessed by numerical simulations and by tests using a smaller-scale prototype of Solar Cruiser. Both the simulation and the test results show that this PD control with the time-varying feedforward input robustly controls the flexible cable-actuated solar sail. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14117</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14117</id><created>2025-01-23</created><authors><author><keyname>Latreche</keyname><forenames>Sofiane</forenames></author><author><keyname>Bellahsene</keyname><forenames>Hocine</forenames></author><author><keyname>Taleb-Ahmed</keyname><forenames>Abdelmalik</forenames></author></authors><title>Some Applications envisaged for the new generation of communications   networks 6G</title><categories>cs.NI eess.SP</categories><journal-ref>The 1st National Conference on Electronics, Electrical   Engineering, Telecommunications, and Computer Vision 11/6/2023 Boumerdes,   Algeria</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Future applications such as intelligent vehicles, the Internet of Things and holographic telepresence are already highlighting the limits of existing fifth-generation (5G) mobile networks. These limitations relate to data throughput, latency, reliability, availability, processing, connection density and global coverage, whether terrestrial, submarine or space-based. To remedy this, research institutes have begun to look beyond IMT2020, and as a result, 6G should provide effective solutions to 5G shortcomings. 6G will offer high quality of service and energy efficiency to meet the demands of future applications that are unimaginable to most people. In this article, we present the future applications and services promised by 6G. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14118</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14118</id><created>2025-01-23</created><authors><author><keyname>Mulkin</keyname><forenames>Olivier</forenames></author><author><keyname>Heleno</keyname><forenames>Miguel</forenames></author><author><keyname>Ludkovski</keyname><forenames>Mike</forenames></author></authors><title>Selecting Critical Scenarios of DER Adoption in Distribution Grids Using   Bayesian Optimization</title><categories>cs.LG stat.AP stat.ML</categories><comments>10 pages, 2 tables, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new methodology to select scenarios of DER adoption most critical for distribution grids. Anticipating risks of future voltage and line flow violations due to additional PV adopters is central for utility investment planning but continues to rely on deterministic or ad hoc scenario selection. We propose a highly efficient search framework based on multi-objective Bayesian Optimization. We treat underlying grid stress metrics as computationally expensive black-box functions, approximated via Gaussian Process surrogates and design an acquisition function based on probability of scenarios being Pareto-critical across a collection of line- and bus-based violation objectives. Our approach provides a statistical guarantee and offers an order of magnitude speed-up relative to a conservative exhaustive search. Case studies on realistic feeders with 200-400 buses demonstrate the effectiveness and accuracy of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14119</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14119</id><created>2025-01-23</created><authors><author><keyname>Yotheringhay</keyname><forenames>Derek</forenames></author><author><keyname>Kirkland</keyname><forenames>Alistair</forenames></author><author><keyname>Kirkbride</keyname><forenames>Humphrey</forenames></author><author><keyname>Whitesteeple</keyname><forenames>Josiah</forenames></author></authors><title>Autonomous Structural Memory Manipulation for Large Language Models   Using Hierarchical Embedding Augmentation</title><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Transformative innovations in model architectures have introduced hierarchical embedding augmentation as a means to redefine the representation of tokens through multi-level semantic structures, offering enhanced adaptability to complex linguistic inputs. Autonomous structural memory manipulation further advances this paradigm through dynamic memory reallocation mechanisms that prioritize critical contextual features while suppressing less relevant information, enabling scalable and efficient performance across diverse tasks. Experimental results reveal substantial improvements in computational efficiency, with marked reductions in processing overhead for longer input sequences, achieved through memory reorganization strategies that adapt to evolving contextual requirements. Hierarchical embeddings not only improved contextual alignment but also facilitated task generalization by capturing relationships at varying semantic granularities, ensuring coherence across layers without introducing significant computational redundancies. Comparative analysis against baseline models demonstrated unique advantages in accuracy, efficiency, and interpretability, particularly in tasks requiring complex contextual understanding or domain-specific adaptability. The ability to dynamically adjust token representations and memory configurations contributed to the model's robustness under varied and unpredictable input conditions. Applications benefiting from these advancements include multi-domain generalization, interactive systems, and scenarios involving real-time decision-making, where traditional static memory architectures often face limitations. The proposed methodology combines advanced embedding and memory management strategies into a cohesive framework that addresses scalability challenges while preserving task-specific relevance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14120</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14120</id><created>2025-01-23</created><authors><author><keyname>Villar-Rodriguez</keyname><forenames>Esther</forenames></author><author><keyname>Osaba</keyname><forenames>Eneko</forenames></author><author><keyname>Oregi</keyname><forenames>Izaskun</forenames></author><author><keyname>Romero</keyname><forenames>Sebastián V.</forenames></author><author><keyname>Ferreiro-Vélez</keyname><forenames>Julián</forenames></author></authors><title>On the Transfer of Knowledge in Quantum Algorithms</title><categories>quant-ph cs.AI</categories><comments>12 pages, 8 figures, 4 tables. Paper submitted for its review in   Expert Systems journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The field of quantum computing is generating significant anticipation within the scientific and industrial communities due to its potential to revolutionize computing paradigms. Recognizing this potential, this paper explores the integration of transfer of knowledge techniques, traditionally used in classical artificial intelligence, into quantum computing. We present a comprehensive classification of the transfer models, focusing on Transfer Learning and Transfer Optimization. Additionally, we analyze relevant schemes in quantum computing that can benefit from knowledge sharing, and we delve into the potential synergies, supported by theoretical insights and initial experimental results. Our findings suggest that leveraging the transfer of knowledge can enhance the efficiency and effectiveness of quantum algorithms, particularly in the context of hybrid solvers. This approach not only accelerates the optimization process but also reduces the computational burden on quantum processors, making it a valuable tool for advancing quantum computing technologies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14122</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14122</id><created>2025-01-23</created><authors><author><keyname>Sarkar</keyname><forenames>Soumyendu</forenames></author><author><keyname>Babu</keyname><forenames>Ashwin Ramesh</forenames></author><author><keyname>Mousavi</keyname><forenames>Sajad</forenames></author><author><keyname>Gundecha</keyname><forenames>Vineet</forenames></author><author><keyname>Ghorbanpour</keyname><forenames>Sahand</forenames></author><author><keyname>Naug</keyname><forenames>Avisek</forenames></author><author><keyname>Gutierrez</keyname><forenames>Ricardo Luna</forenames></author><author><keyname>Guillen</keyname><forenames>Antonio</forenames></author></authors><title>Reinforcement Learning Platform for Adversarial Black-box Attacks with   Custom Distortion Filters</title><categories>cs.LG cs.AI cs.CR cs.CV</categories><comments>Under Review for 2025 AAAI Conference on Artificial Intelligence   Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Reinforcement Learning Platform for Adversarial Black-box untargeted and targeted attacks, RLAB, that allows users to select from various distortion filters to create adversarial examples. The platform uses a Reinforcement Learning agent to add minimum distortion to input images while still causing misclassification by the target model. The agent uses a novel dual-action method to explore the input image at each step to identify sensitive regions for adding distortions while removing noises that have less impact on the target model. This dual action leads to faster and more efficient convergence of the attack. The platform can also be used to measure the robustness of image classification models against specific distortion types. Also, retraining the model with adversarial samples significantly improved robustness when evaluated on benchmark datasets. The proposed platform outperforms state-of-the-art methods in terms of the average number of queries required to cause misclassification. This advances trustworthiness with a positive social impact. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14131</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14131</id><created>2025-01-23</created><authors><author><keyname>Ksontini</keyname><forenames>Emna</forenames></author><author><keyname>Mastouri</keyname><forenames>Meriem</forenames></author><author><keyname>Khalsi</keyname><forenames>Rania</forenames></author><author><keyname>Kessentini</keyname><forenames>Wael</forenames></author></authors><title>Refactoring for Dockerfile Quality: A Dive into Developer Practices and   Automation Potential</title><categories>cs.SE</categories><journal-ref>Proceedings of the 22nd ACM/IEEE International Conference on   Mining Software Repositories (MSR 2025), April 28-29 2025, Ottawa, ON, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Docker, the industry standard for packaging and deploying applications, leverages Infrastructure as Code (IaC) principles to facilitate the creation of images through Dockerfiles. However, maintaining Dockerfiles presents significant challenges. Refactoring, in particular, is often a manual and complex process. This paper explores the utility and practicality of automating Dockerfile refactoring using 600 Dockerfiles from 358 open-source projects. Our study reveals that Dockerfile image size and build duration tend to increase as projects evolve, with developers often postponing refactoring efforts until later stages in the development cycle. This trend motivates the automation of refactoring. To achieve this, we leverage In Context Learning (ICL) along with a score-based demonstration selection strategy. Our approach leads to an average reduction of 32% in image size and a 6% decrease in build duration, with improvements in understandability and maintainability observed in 77% and 91% of cases, respectively. Additionally, our analysis shows that automated refactoring reduces Dockerfile image size by 2x compared to manual refactoring and 10x compared to smell-fixing tools like PARFUM. This work establishes a foundation for automating Dockerfile refactoring, indicating that such automation could become a standard practice within CI/CD pipelines to enhance Dockerfile quality throughout every step of the software development lifecycle. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14133</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14133</id><created>2025-01-23</created><authors><author><keyname>Eunyoung</keyname><forenames>Im</forenames></author><author><keyname>Sunghoon</keyname><forenames>Kang</forenames></author><author><keyname>Hyeoneui</keyname><forenames>Kim</forenames></author></authors><title>Development of a Validation and Inspection Tool for Armband-based   Lifelog Data (VITAL) to Facilitate the Clinical Use of Wearable Data: A   Prototype and Usability Evaluation</title><categories>cs.HC cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Background: The rise of mobile technology and health apps has increased the use of person-generated health data (PGHD). PGHD holds significant potential for clinical decision-making but remains challenging to manage. Objective: This study aimed to enhance the clinical utilization of wearable health data by developing the Validation and Inspection Tool for Armband-Based Lifelog Data (VITAL), a pipeline for data integration, visualization, and quality management, and evaluating its usability. Methods: The study followed a structured process of requirement gathering, tool implementation, and usability evaluation. Requirements were identified through input from four clinicians. Wearable health data from Samsung, Apple, Fitbit, and Xiaomi devices were integrated into a standardized dataframe at 10-minute intervals, focusing on biometrics, activity, and sleep. Features of VITAL support data integration, visualization, and quality management. Usability evaluation involved seven clinicians performing tasks, completing the Unified Theory of Acceptance and Use of Technology (UTAUT) survey, and participating in interviews to identify usability issues. Results: VITAL successfully integrated wearable data, thus enabling all participants to complete tasks with minimal errors without prior participant training. UTAUT survey results were positive, with average scores of 4.2 for performance expectancy, 3.96 for effort expectancy, and 4.14 for intention to use, indicating high user satisfaction and intent to adopt the tool. Conclusions: By enhancing wearable data integration, visualization, and quality management, the VITAL prototype shows significant potential for clinical application. Positive feedback highlights its promise, while emphasizing the need for further studies to confirm its real-world effectiveness. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14136</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14136</id><created>2025-01-23</created><authors><author><keyname>Schwenke</keyname><forenames>Leonid</forenames></author><author><keyname>Atzmueller</keyname><forenames>Martin</forenames></author></authors><title>Saliency Maps are Ambiguous: Analysis of Logical Relations on First and   Second Order Attributions</title><categories>cs.LG</categories><comments>20 pages for the main article including references, 14 main article   figures, 5 tables, 7 appendix figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work uncovered potential flaws in \eg attribution or heatmap based saliency methods. A typical flaw is a confirmations bias, where the scores are compared to human expectation. Since measuring the quality of saliency methods is hard due to missing ground truth model reasoning, finding general limitations is also hard. This is further complicated, because masking-based evaluation on complex data can easily introduce a bias, as most methods cannot fully ignore inputs. In this work, we extend our previous analysis on the logical dataset framework ANDOR, where we showed that all analysed saliency methods fail to grasp all needed classification information for all possible scenarios. Specifically, this paper extends our previous work using analysis on more datasets, in order to better understand in which scenarios the saliency methods fail. Further, we apply the Global Coherence Representation as an additional evaluation method in order to enable actual input omission. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14143</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14143</id><created>2025-01-23</created><authors><author><keyname>Biswas</keyname><forenames>Parag</forenames></author><author><keyname>Rashid</keyname><forenames>Abdur</forenames></author><author><keyname>masum</keyname><forenames>abdullah al</forenames></author><author><keyname>Nasim</keyname><forenames>MD Abdullah Al</forenames></author><author><keyname>Ferdous</keyname><forenames>A. S. M Anas</forenames></author><author><keyname>Gupta</keyname><forenames>Kishor Datta</forenames></author><author><keyname>Biswas</keyname><forenames>Angona</forenames></author></authors><title>An Extensive and Methodical Review of Smart Grids for Sustainable Energy   Management-Addressing Challenges with AI, Renewable Energy Integration and   Leading-edge Technologies</title><categories>cs.LG cs.CY</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Energy management decreases energy expenditures and consumption while simultaneously increasing energy efficiency, reducing carbon emissions, and enhancing operational performance. Smart grids are a type of sophisticated energy infrastructure that increase the generation and distribution of electricity's sustainability, dependability, and efficiency by utilizing digital communication technologies. They combine a number of cutting-edge techniques and technology to improve energy resource management. A large amount of research study on the topic of smart grids for energy management has been completed in the last several years. The authors of the present study want to cover a number of topics, including smart grid benefits and components, technical developments, integrating renewable energy sources, using artificial intelligence and data analytics, cybersecurity, and privacy. Smart Grids for Energy Management are an innovative field of study aiming at tackling various difficulties and magnifying the efficiency, dependability, and sustainability of energy systems, including: 1) Renewable sources of power like solar and wind are intermittent and unpredictable 2) Defending smart grid system from various cyber-attacks 3) Incorporating an increasing number of electric vehicles into the system of power grid without overwhelming it. Additionally, it is proposed to use AI and data analytics for better performance on the grid, reliability, and energy management. It also looks into how AI and data analytics can be used to optimize grid performance, enhance reliability, and improve energy management. The authors will explore these significant challenges and ongoing research. Lastly, significant issues in this field are noted, and recommendations for further work are provided. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14144</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14144</id><created>2025-01-23</created><authors><author><keyname>Sheng</keyname><forenames>Dongming</forenames></author><author><keyname>Han</keyname><forenames>Kexin</forenames></author><author><keyname>Li</keyname><forenames>Hao</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Huang</keyname><forenames>Yucheng</forenames></author><author><keyname>Lang</keyname><forenames>Jun</forenames></author><author><keyname>Liu</keyname><forenames>Wenqiang</forenames></author></authors><title>Test-Time Code-Switching for Cross-lingual Aspect Sentiment Triplet   Extraction</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Aspect Sentiment Triplet Extraction (ASTE) is a thriving research area with impressive outcomes being achieved on high-resource languages. However, the application of cross-lingual transfer to the ASTE task has been relatively unexplored, and current code-switching methods still suffer from term boundary detection issues and out-of-dictionary problems. In this study, we introduce a novel Test-Time Code-SWitching (TT-CSW) framework, which bridges the gap between the bilingual training phase and the monolingual test-time prediction. During training, a generative model is developed based on bilingual code-switched training data and can produce bilingual ASTE triplets for bilingual inputs. In the testing stage, we employ an alignment-based code-switching technique for test-time augmentation. Extensive experiments on cross-lingual ASTE datasets validate the effectiveness of our proposed method. We achieve an average improvement of 3.7% in terms of weighted-averaged F1 in four datasets with different languages. Additionally, we set a benchmark using ChatGPT and GPT-4, and demonstrate that even smaller generative models fine-tuned with our proposed TT-CSW framework surpass ChatGPT and GPT-4 by 14.2% and 5.0% respectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14147</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14147</id><created>2025-01-23</created><authors><author><keyname>Yu</keyname><forenames>Javier</forenames></author><author><keyname>Chen</keyname><forenames>Timothy</forenames></author><author><keyname>Schwager</keyname><forenames>Mac</forenames></author></authors><title>HAMMER: Heterogeneous, Multi-Robot Semantic Gaussian Splatting</title><categories>cs.RO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  3D Gaussian Splatting offers expressive scene reconstruction, modeling a broad range of visual, geometric, and semantic information. However, efficient real-time map reconstruction with data streamed from multiple robots and devices remains a challenge. To that end, we propose HAMMER, a server-based collaborative Gaussian Splatting method that leverages widely available ROS communication infrastructure to generate 3D, metric-semantic maps from asynchronous robot data-streams with no prior knowledge of initial robot positions and varying on-device pose estimators. HAMMER consists of (i) a frame alignment module that transforms local SLAM poses and image data into a global frame and requires no prior relative pose knowledge, and (ii) an online module for training semantic 3DGS maps from streaming data. HAMMER handles mixed perception modes, adjusts automatically for variations in image pre-processing among different devices, and distills CLIP semantic codes into the 3D scene for open-vocabulary language queries. In our real-world experiments, HAMMER creates higher-fidelity maps (2x) compared to competing baselines and is useful for downstream tasks, such as semantic goal-conditioned navigation (e.g., ``go to the couch"). Accompanying content available at hammer-project.github.io. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14148</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14148</id><created>2025-01-23</created><authors><author><keyname>Roy</keyname><forenames>Shuvendu</forenames></author><author><keyname>Etemad</keyname><forenames>Ali</forenames></author></authors><title>SelfPrompt: Confidence-Aware Semi-Supervised Tuning for Robust   Vision-Language Model Adaptation</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present SelfPrompt, a novel prompt-tuning approach for vision-language models (VLMs) in a semi-supervised learning setup. Existing methods for tuning VLMs in semi-supervised setups struggle with the negative impact of the miscalibrated VLMs on pseudo-labelling, and the accumulation of noisy pseudo-labels. SelfPrompt addresses these challenges by introducing a cluster-guided pseudo-labelling method that improves pseudo-label accuracy, and a confidence-aware semi-supervised learning module that maximizes the utilization of unlabelled data by combining supervised learning and weakly-supervised learning. Additionally, we investigate our method in an active semi-supervised learning setup, where the labelled set is strategically selected to ensure the best utilization of a limited labelling budget. To this end, we propose a weakly-supervised sampling technique that selects a diverse and representative labelled set, which can be seamlessly integrated into existing methods to enhance their performance. We conduct extensive evaluations across 13 datasets, significantly surpassing state-of-the-art performances with average improvements of 6.23% in standard semi-supervised learning, 6.25% in active semi-supervised learning, and 4.9% in base-to-novel generalization, using a 2-shot setup. Furthermore, SelfPrompt shows excellent generalization in single-shot settings, achieving an average improvement of 11.78%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14149</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14149</id><created>2025-01-23</created><authors><author><keyname>Rahman</keyname><forenames>Ashiqur</forenames></author><author><keyname>Seethi</keyname><forenames>Venkata Devesh Reddy</forenames></author><author><keyname>Yunker</keyname><forenames>Austin</forenames></author><author><keyname>Kral</keyname><forenames>Zachary</forenames></author><author><keyname>Kettimuthu</keyname><forenames>Rajkumar</forenames></author><author><keyname>Alhoori</keyname><forenames>Hamed</forenames></author></authors><title>Effective Defect Detection Using Instance Segmentation for NDI</title><categories>cs.CV cs.LG</categories><comments>6 pages, 2 figures, 2 tables. Published at AI2ASE 2025 workshop at   AAAI2025. Accepted publication is available at https://ai-2-ase.github.io/</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Ultrasonic testing is a common Non-Destructive Inspection (NDI) method used in aerospace manufacturing. However, the complexity and size of the ultrasonic scans make it challenging to identify defects through visual inspection or machine learning models. Using computer vision techniques to identify defects from ultrasonic scans is an evolving research area. In this study, we used instance segmentation to identify the presence of defects in the ultrasonic scan images of composite panels that are representative of real components manufactured in aerospace. We used two models based on Mask-RCNN (Detectron 2) and YOLO 11 respectively. Additionally, we implemented a simple statistical pre-processing technique that reduces the burden of requiring custom-tailored pre-processing techniques. Our study demonstrates the feasibility and effectiveness of using instance segmentation in the NDI pipeline by significantly reducing data pre-processing time, inspection time, and overall costs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14151</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14151</id><created>2025-01-23</created><authors><author><keyname>Mendez-Flores</keyname><forenames>Efrain</forenames></author><author><keyname>Pourshahidi</keyname><forenames>Agaton</forenames></author><author><keyname>Egerstedt</keyname><forenames>Magnus</forenames></author></authors><title>RaccoonBot: An Autonomous Wire-Traversing Solar-Tracking Robot for   Persistent Environmental Monitoring</title><categories>cs.RO</categories><comments>Pre-print submitted to the 2025 IEEE International Conference on   Robotics &amp; Automation (ICRA 2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Environmental monitoring is used to characterize the health and relationship between organisms and their environments. In forest ecosystems, robots can serve as platforms to acquire such data, even in hard-to-reach places where wire-traversing platforms are particularly promising due to their efficient displacement. This paper presents the RaccoonBot, which is a novel autonomous wire-traversing robot for persistent environmental monitoring, featuring a fail-safe mechanical design with a self-locking mechanism in case of electrical shortage. The robot also features energy-aware mobility through a novel Solar tracking algorithm, that allows the robot to find a position on the wire to have direct contact with solar power to increase the energy harvested. Experimental results validate the electro-mechanical features of the RaccoonBot, showing that it is able to handle wire perturbations, different inclinations, and achieving energy autonomy. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14152</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14152</id><created>2025-01-23</created><authors><author><keyname>Bertsimas</keyname><forenames>Dimitris</forenames></author><author><keyname>Everest</keyname><forenames>Lisa</forenames></author><author><keyname>Stoumpou</keyname><forenames>Vasiliki</forenames></author></authors><title>Multimodal Prescriptive Deep Learning</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a multimodal deep learning framework, Prescriptive Neural Networks (PNNs), that combines ideas from optimization and machine learning, and is, to the best of our knowledge, the first prescriptive method to handle multimodal data. The PNN is a feedforward neural network trained on embeddings to output an outcome-optimizing prescription. In two real-world multimodal datasets, we demonstrate that PNNs prescribe treatments that are able to significantly improve estimated outcomes in transcatheter aortic valve replacement (TAVR) procedures by reducing estimated postoperative complication rates by 32% and in liver trauma injuries by reducing estimated mortality rates by over 40%. In four real-world, unimodal tabular datasets, we demonstrate that PNNs outperform or perform comparably to other well-known, state-of-the-art prescriptive models; importantly, on tabular datasets, we also recover interpretability through knowledge distillation, fitting interpretable Optimal Classification Tree models onto the PNN prescriptions as classification targets, which is critical for many real-world applications. Finally, we demonstrate that our multimodal PNN models achieve stability across randomized data splits comparable to other prescriptive methods and produce realistic prescriptions across the different datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14155</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14155</id><created>2025-01-23</created><authors><author><keyname>Ao</keyname><forenames>Ruicheng</forenames></author><author><keyname>Jiang</keyname><forenames>Jiashuo</forenames></author><author><keyname>Simchi-Levi</keyname><forenames>David</forenames></author></authors><title>Learning to Price with Resource Constraints: From Full Information to   Machine-Learned Prices</title><categories>math.OC cs.LG</categories><comments>28 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We study the dynamic pricing problem with knapsack, addressing the challenge of balancing exploration and exploitation under resource constraints. We introduce three algorithms tailored to different informational settings: a Boundary Attracted Re-solve Method for full information, an online learning algorithm for scenarios with no prior information, and an estimate-then-select re-solve algorithm that leverages machine-learned informed prices with known upper bound of estimation errors. The Boundary Attracted Re-solve Method achieves logarithmic regret without requiring the non-degeneracy condition, while the online learning algorithm attains an optimal $O(\sqrt{T})$ regret. Our estimate-then-select approach bridges the gap between these settings, providing improved regret bounds when reliable offline data is available. Numerical experiments validate the effectiveness and robustness of our algorithms across various scenarios. This work advances the understanding of online resource allocation and dynamic pricing, offering practical solutions adaptable to different informational structures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14158</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14158</id><created>2025-01-23</created><authors><author><keyname>Safari</keyname><forenames>Mojtaba</forenames></author><author><keyname>Eidex</keyname><forenames>Zach</forenames></author><author><keyname>Chang</keyname><forenames>Chih-Wei</forenames></author><author><keyname>Qiu</keyname><forenames>Richard L. J.</forenames></author><author><keyname>Yang</keyname><forenames>Xiaofeng</forenames></author></authors><title>Advancing MRI Reconstruction: A Systematic Review of Deep Learning and   Compressed Sensing Integration</title><categories>cs.CV cs.AI physics.med-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Magnetic resonance imaging (MRI) is a non-invasive imaging modality and provides comprehensive anatomical and functional insights into the human body. However, its long acquisition times can lead to patient discomfort, motion artifacts, and limiting real-time applications. To address these challenges, strategies such as parallel imaging have been applied, which utilize multiple receiver coils to speed up the data acquisition process. Additionally, compressed sensing (CS) is a method that facilitates image reconstruction from sparse data, significantly reducing image acquisition time by minimizing the amount of data collection needed. Recently, deep learning (DL) has emerged as a powerful tool for improving MRI reconstruction. It has been integrated with parallel imaging and CS principles to achieve faster and more accurate MRI reconstructions. This review comprehensively examines DL-based techniques for MRI reconstruction. We categorize and discuss various DL-based methods, including end-to-end approaches, unrolled optimization, and federated learning, highlighting their potential benefits. Our systematic review highlights significant contributions and underscores the potential of DL in MRI reconstruction. Additionally, we summarize key results and trends in DL-based MRI reconstruction, including quantitative metrics, the dataset, acceleration factors, and the progress of and research interest in DL techniques over time. Finally, we discuss potential future directions and the importance of DL-based MRI reconstruction in advancing medical imaging. To facilitate further research in this area, we provide a GitHub repository that includes up-to-date DL-based MRI reconstruction publications and public datasets-https://github.com/mosaf/Awesome-DL-based-CS-MRI. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14159</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14159</id><created>2025-01-23</created><authors><author><keyname>Allman</keyname><forenames>Maxwell</forenames></author><author><keyname>Ashlagi</keyname><forenames>Itai</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author><author><keyname>Yu</keyname><forenames>Sophie H.</forenames></author></authors><title>From signaling to interviews in random matching markets</title><categories>cs.GT econ.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many two-sided labor markets, interviews are conducted before matches are formed. An increase in the number of interviews in the market for medical residencies raised the demand for signaling mechanisms, in which applicants can send a limited number of signals to communicate interest. We study the role of signaling mechanisms in reducing the number of interviews in centralized random matching markets with post-interview shocks. For the market to clear we focus on interim stability, which extends the notion of stability to ensure that agents do not regret not interviewing with each other. A matching is almost interim stable if it is interim stable after removing a vanishingly small fraction of agents.   We first study signaling mechanisms in random matching markets when agents on the short side, long side, or both sides signal their top~$d$ preferred partners. Interviews graphs are formed by including all pairs where at least one party has signaled the other. We show that when $d = \omega(1)$, short-side signaling leads to almost interim stable matchings. Long-side signaling is only effective when the market is almost balanced. Conversely, when the interview shocks are negligible and $d = o(\log n)$, both-side signaling fails to achieve almost interim stability. For larger $d \ge \Omega(\log^2 n)$, short-side signaling achieves perfect interim stability, while long-side signaling fails in imbalanced markets. We build on our findings to propose a signaling mechanism for multi-tiered random markets. Our analysis identifies conditions under which signaling mechanisms are incentive compatible. A technical contribution is the analysis of a message-passing algorithm that efficiently determines interim stability and matching outcomes by leveraging local neighborhood structures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14163</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14163</id><created>2025-01-23</created><authors><author><keyname>Leibmann</keyname><forenames>Leon</forenames></author><author><keyname>Weld</keyname><forenames>Galen</forenames></author><author><keyname>Zhang</keyname><forenames>Amy X.</forenames></author><author><keyname>Althoff</keyname><forenames>Tim</forenames></author></authors><title>Reddit Rules and Rulers: Quantifying the Link Between Rules and   Perceptions of Governance across Thousands of Communities</title><categories>cs.SI cs.CY cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rules are a critical component of the functioning of nearly every online community, yet it is challenging for community moderators to make data-driven decisions about what rules to set for their communities. The connection between a community's rules and how its membership feels about its governance is not well understood. In this work, we conduct the largest-to-date analysis of rules on Reddit, collecting a set of 67,545 unique rules across 5,225 communities which collectively account for more than 67% of all content on Reddit. More than just a point-in-time study, our work measures how communities change their rules over a 5+ year period. We develop a method to classify these rules using a taxonomy of 17 key attributes extended from previous work. We assess what types of rules are most prevalent, how rules are phrased, and how they vary across communities of different types. Using a dataset of communities' discussions about their governance, we are the first to identify the rules most strongly associated with positive community perceptions of governance: rules addressing who participates, how content is formatted and tagged, and rules about commercial activities. We conduct a longitudinal study to quantify the impact of adding new rules to communities, finding that after a rule is added, community perceptions of governance immediately improve, yet this effect diminishes after six months. Our results have important implications for platforms, moderators, and researchers. We make our classification model and rules datasets public to support future research on this topic. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14164</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14164</id><created>2025-01-23</created><authors><author><keyname>Pinilla</keyname><forenames>Samuel</forenames></author><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author></authors><title>WaveMax: Radar Waveform Design via Convex Maximization of FrFT Phase   Retrieval</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ambiguity function (AF) is a critical tool in radar waveform design, representing the two-dimensional correlation between a transmitted signal and its time-delayed, frequency-shifted version. Obtaining a radar signal to match a specified AF magnitude is a bi-variate variant of the well-known phase retrieval problem. Prior approaches to this problem were either limited to a few classes of waveforms or lacked a computable procedure to estimate the signal. Our recent work provided a framework for solving this problem for both band- and time-limited signals using non-convex optimization. In this paper, we introduce a novel approach WaveMax that formulates waveform recovery as a convex optimization problem by relying on the fractional Fourier transform (FrFT)-based AF. We exploit the fact that AF of the FrFT of the original signal is equivalent to a rotation of the original AF. In particular, we reconstruct the radar signal by solving a low-rank minimization problem, which approximates the waveform using the leading eigenvector of a matrix derived from the AF. Our theoretical analysis shows that unique waveform reconstruction is achievable with a sample size no more than three times the signal frequencies or time samples. Numerical experiments validate the efficacy of WaveMax in recovering signals from noiseless and noisy AF, including scenarios with randomly and uniformly sampled sparse data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14165</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14165</id><created>2025-01-23</created><authors><author><keyname>Maddireddy</keyname><forenames>Kritin</forenames></author><author><keyname>Methukula</keyname><forenames>Santhosh Kotekal</forenames></author><author><keyname>Sridhar</keyname><forenames>Chandrasekar</forenames></author><author><keyname>Vaidhyanathan</keyname><forenames>Karthik</forenames></author></authors><title>LoCoML: A Framework for Real-World ML Inference Pipelines</title><categories>cs.SE cs.AI</categories><comments>The paper has been accepted for presentation at the 4th International   Conference on AI Engineering (CAIN) 2025 co-located with 47th IEEE/ACM   International Conference on Software Engineering (ICSE) 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The widespread adoption of machine learning (ML) has brought forth diverse models with varying architectures, and data requirements, introducing new challenges in integrating these systems into real-world applications. Traditional solutions often struggle to manage the complexities of connecting heterogeneous models, especially when dealing with varied technical specifications. These limitations are amplified in large-scale, collaborative projects where stakeholders contribute models with different technical specifications. To address these challenges, we developed LoCoML, a low-code framework designed to simplify the integration of diverse ML models within the context of the \textit{Bhashini Project} - a large-scale initiative aimed at integrating AI-driven language technologies such as automatic speech recognition, machine translation, text-to-speech, and optical character recognition to support seamless communication across more than 20 languages. Initial evaluations show that LoCoML adds only a small amount of computational load, making it efficient and effective for large-scale ML integration. Our practical insights show that a low-code approach can be a practical solution for connecting multiple ML models in a collaborative environment. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14166</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14166</id><created>2025-01-23</created><authors><author><keyname>Nguyen</keyname><forenames>Cong-Duy</forenames></author><author><keyname>Wu</keyname><forenames>Xiaobao</forenames></author><author><keyname>Nguyen</keyname><forenames>Thong</forenames></author><author><keyname>Zhao</keyname><forenames>Shuai</forenames></author><author><keyname>Le</keyname><forenames>Khoi</forenames></author><author><keyname>Nguyen</keyname><forenames>Viet-Anh</forenames></author><author><keyname>Yichao</keyname><forenames>Feng</forenames></author><author><keyname>Luu</keyname><forenames>Anh Tuan</forenames></author></authors><title>Enhancing Multimodal Entity Linking with Jaccard Distance-based   Conditional Contrastive Learning and Contextual Visual Augmentation</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Previous research on multimodal entity linking (MEL) has primarily employed contrastive learning as the primary objective. However, using the rest of the batch as negative samples without careful consideration, these studies risk leveraging easy features and potentially overlook essential details that make entities unique. In this work, we propose JD-CCL (Jaccard Distance-based Conditional Contrastive Learning), a novel approach designed to enhance the ability to match multimodal entity linking models. JD-CCL leverages meta-information to select negative samples with similar attributes, making the linking task more challenging and robust. Additionally, to address the limitations caused by the variations within the visual modality among mentions and entities, we introduce a novel method, CVaCPT (Contextual Visual-aid Controllable Patch Transform). It enhances visual representations by incorporating multi-view synthetic images and contextual textual representations to scale and shift patch representations. Experimental results on benchmark MEL datasets demonstrate the strong effectiveness of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14170</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14170</id><created>2025-01-23</created><authors><author><keyname>Gu</keyname><forenames>Yile</forenames></author><author><keyname>Xiong</keyname><forenames>Yifan</forenames></author><author><keyname>Mace</keyname><forenames>Jonathan</forenames></author><author><keyname>Jiang</keyname><forenames>Yuting</forenames></author><author><keyname>Hu</keyname><forenames>Yigong</forenames></author><author><keyname>Kasikci</keyname><forenames>Baris</forenames></author><author><keyname>Cheng</keyname><forenames>Peng</forenames></author></authors><title>Argos: Agentic Time-Series Anomaly Detection with Autonomous Rule   Generation via Large Language Models</title><categories>cs.LG cs.DC cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Observability in cloud infrastructure is critical for service providers, driving the widespread adoption of anomaly detection systems for monitoring metrics. However, existing systems often struggle to simultaneously achieve explainability, reproducibility, and autonomy, which are three indispensable properties for production use. We introduce Argos, an agentic system for detecting time-series anomalies in cloud infrastructure by leveraging large language models (LLMs). Argos proposes to use explainable and reproducible anomaly rules as intermediate representation and employs LLMs to autonomously generate such rules. The system will efficiently train error-free and accuracy-guaranteed anomaly rules through multiple collaborative agents and deploy the trained rules for low-cost online anomaly detection. Through evaluation results, we demonstrate that Argos outperforms state-of-the-art methods, increasing $F_1$ scores by up to $9.5\%$ and $28.3\%$ on public anomaly detection datasets and an internal dataset collected from Microsoft, respectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14171</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14171</id><created>2025-01-23</created><authors><author><keyname>Yang</keyname><forenames>Hanyeol</forenames></author><author><keyname>Kim</keyname><forenames>Sunggyu</forenames></author><author><keyname>Yoo</keyname><forenames>Yongseon</forenames></author><author><keyname>Lee</keyname><forenames>Jong-min</forenames></author></authors><title>Fully Guided Neural Schr\"odinger bridge for Brain MR image synthesis</title><categories>eess.IV cs.CV</categories><comments>9 pages,4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-modal brain MRI provides essential complementary information for clinical diagnosis. However, acquiring all modalities is often challenging due to time and cost constraints. To address this, various methods have been proposed to generate missing modalities from available ones. Traditional approaches can be broadly categorized into two main types: paired and unpaired methods. While paired methods offer superior performance, obtaining large-scale paired datasets is challenging in real-world scenarios. Conversely, unpaired methods facilitate large-scale data collection but struggle to preserve critical image features, such as tumors. In this paper, we propose Fully Guided Schr\"odinger Bridges (FGSB), a novel framework based on Neural Schr\"odinger Bridges, to overcome these limitations. FGSB achieves stable, high-quality generation of missing modalities using minimal paired data. Furthermore, when provided with ground truth or a segmentation network for specific regions, FGSB can generate missing modalities while preserving these critical areas with reduced data requirements. Our proposed model consists of two consecutive phases. 1) Generation Phase: Fuses a generated image, a paired reference image, and Gaussian noise, employing iterative refinement to mitigate issues such as mode collapse and improve generation quality 2) Training Phase: Learns the mapping from the generated image to the target modality. Experiments demonstrate that FGSB achieves comparable generation performance to methods trained on large datasets, while using data from only two subjects. Moreover, the utilization of lesion information with FGSB significantly enhances its ability to preserve crucial lesion features. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14172</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14172</id><created>2025-01-23</created><authors><author><keyname>Nettur</keyname><forenames>Suresh Babu</forenames></author><author><keyname>Karpurapu</keyname><forenames>Shanthi</forenames></author><author><keyname>Nettur</keyname><forenames>Unnati</forenames></author><author><keyname>Gajja</keyname><forenames>Likhit Sagar</forenames></author><author><keyname>Myneni</keyname><forenames>Sravanthy</forenames></author><author><keyname>Dusi</keyname><forenames>Akhil</forenames></author><author><keyname>Posham</keyname><forenames>Lalithya</forenames></author></authors><title>UltraLightSqueezeNet: A Deep Learning Architecture for Malaria   Classification with up to 54x fewer trainable parameters for resource   constrained devices</title><categories>cs.LG cs.AI cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Lightweight deep learning approaches for malaria detection have gained attention for their potential to enhance diagnostics in resource constrained environments. For our study, we selected SqueezeNet1.1 as it is one of the most popular lightweight architectures. SqueezeNet1.1 is a later version of SqueezeNet1.0 and is 2.4 times more computationally efficient than the original model. We proposed and implemented three ultra-lightweight architecture variants to SqueezeNet1.1 architecture, namely Variant 1 (one fire module), Variant 2 (two fire modules), and Variant 3 (four fire modules), which are even more compact than SqueezeNetV1.1 (eight fire modules). These models were implemented to evaluate the best performing variant that achieves superior computational efficiency without sacrificing accuracy in malaria blood cell classification. The models were trained and evaluated using the NIH Malaria dataset. We assessed each model's performance based on metrics including accuracy, recall, precision, F1-score, and Area Under the Curve (AUC). The results show that the SqueezeNet1.1 model achieves the highest performance across all metrics, with a classification accuracy of 97.12%. Variant 3 (four fire modules) offers a competitive alternative, delivering almost identical results (accuracy 96.55%) with a 6x reduction in computational overhead compared to SqueezeNet1.1. Variant 2 and Variant 1 perform slightly lower than Variant 3, with Variant 2 (two fire modules) reducing computational overhead by 28x, and Variant 1 (one fire module) achieving a 54x reduction in trainable parameters compared to SqueezeNet1.1. These findings demonstrate that our SqueezeNet1.1 architecture variants provide a flexible approach to malaria detection, enabling the selection of a variant that balances resource constraints and performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14173</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14173</id><created>2025-01-23</created><authors><author><keyname>Nurre</keyname><forenames>Nicholas P.</forenames></author><author><keyname>Taheri</keyname><forenames>Ehsan</forenames></author></authors><title>Constrained Fuel and Time Optimal 6DOF Powered Descent Guidance Using   Indirect Optimization</title><categories>math.OC cs.SY eess.SY</categories><comments>40 pages, 31 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Powered descent guidance (PDG) problems subject to six-degrees-of-freedom (6DOF) dynamics allow for enforcement of practical attitude constraints. However, numerical solutions to 6DOF PDG problems are challenging due to fast rotational dynamics coupled with translational dynamics, and the presence of highly nonlinear state/control path inequality constraints. In this work, constrained fuel- and time-optimal 6DOF PDG problems are solved leveraging a regularized indirect method, subject to inequality constraints on the thrust magnitude, thruster gimbal angle, rocket tilt angle, glideslope angle, and angular velocity magnitude. To overcome the challenges associated with solving the resulting multipoint boundary-value problems (MPBVPs), the state-only path inequality constraints (SOPICs) are enforced through an interior penalty function method, which embeds the resulting MPBVPs into a multi-parameter smooth neighboring families of two-point BVPs. Extremal solutions are obtained using an indirect multiple-shooting solution method with numerical continuation. Moreover, an empirical relation is derived for the directly-adjoined Lagrange multipliers associated with SOPICs. The fuel- and time-optimal trajectories are compared against solutions of DIDO -- a capable pseudospectral-based software for solving practical constrained optimal control problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14174</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14174</id><created>2025-01-23</created><authors><author><keyname>Baek</keyname><forenames>Junyeob</forenames></author><author><keyname>Wu</keyname><forenames>Yi-Fu</forenames></author><author><keyname>Singh</keyname><forenames>Gautam</forenames></author><author><keyname>Ahn</keyname><forenames>Sungjin</forenames></author></authors><title>Dreamweaver: Learning Compositional World Representations from Pixels</title><categories>cs.CV cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Humans have an innate ability to decompose their perceptions of the world into objects and their attributes, such as colors, shapes, and movement patterns. This cognitive process enables us to imagine novel futures by recombining familiar concepts. However, replicating this ability in artificial intelligence systems has proven challenging, particularly when it comes to modeling videos into compositional concepts and generating unseen, recomposed futures without relying on auxiliary data, such as text, masks, or bounding boxes. In this paper, we propose Dreamweaver, a neural architecture designed to discover hierarchical and compositional representations from raw videos and generate compositional future simulations. Our approach leverages a novel Recurrent Block-Slot Unit (RBSU) to decompose videos into their constituent objects and attributes. In addition, Dreamweaver uses a multi-future-frame prediction objective to capture disentangled representations for dynamic concepts more effectively as well as static concepts. In experiments, we demonstrate our model outperforms current state-of-the-art baselines for world modeling when evaluated under the DCI framework across multiple datasets. Furthermore, we show how the modularized concept representations of our model enable compositional imagination, allowing the generation of novel videos by recombining attributes from different objects. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14175</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14175</id><created>2025-01-23</created><authors><author><keyname>Jeje</keyname><forenames>Mofe O.</forenames></author></authors><title>Cybersecurity Assessment of Smart Grid Exposure Using a Machine Learning   Based Approach</title><categories>cs.LG cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Given that disturbances to the stable and normal operation of power systems have grown phenomenally, particularly in terms of unauthorized access to confidential and critical data, injection of malicious software, and exploitation of security vulnerabilities in a poorly patched software among others; then developing, as a countermeasure, an assessment solutions with machine learning capabilities to match up in real-time, with the growth and fast pace of these cyber-attacks, is not only critical to the security, reliability and safe operation of power system, but also germane to guaranteeing advanced monitoring and efficient threat detection. Using the Mississippi State University and Oak Ridge National Laboratory dataset, the study used an XGB Classifier modeling approach in machine learning to diagnose and assess power system disturbances, in terms of Attack Events, Natural Events and No-Events. As test results show, the model, in all the three sub-datasets, generally demonstrates good performance on all metrics, as it relates to accurately identifying and classifying all the three power system events. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14176</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14176</id><created>2025-01-23</created><authors><author><keyname>Rentschler</keyname><forenames>Micah</forenames></author><author><keyname>Roberts</keyname><forenames>Jesse</forenames></author></authors><title>RL + Transformer = A General-Purpose Problem Solver</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  What if artificial intelligence could not only solve problems for which it was trained but also learn to teach itself to solve new problems (i.e., meta-learn)? In this study, we demonstrate that a pre-trained transformer fine-tuned with reinforcement learning over multiple episodes develops the ability to solve problems that it has never encountered before - an emergent ability called In-Context Reinforcement Learning (ICRL). This powerful meta-learner not only excels in solving unseen in-distribution environments with remarkable sample efficiency, but also shows strong performance in out-of-distribution environments. In addition, we show that it exhibits robustness to the quality of its training data, seamlessly stitches together behaviors from its context, and adapts to non-stationary environments. These behaviors demonstrate that an RL-trained transformer can iteratively improve upon its own solutions, making it an excellent general-purpose problem solver. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14179</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14179</id><created>2025-01-23</created><authors><author><keyname>Li</keyname><forenames>Wenwen</forenames></author><author><keyname>Shi</keyname><forenames>Kangwei</forenames></author><author><keyname>Chai</keyname><forenames>Yidong</forenames></author></authors><title>AI Chatbots as Professional Service Agents: Developing a Professional   Identity</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid expansion of large language model (LLM) applications, there is an emerging shift in the role of LLM-based AI chatbots from serving merely as general inquiry tools to acting as professional service agents. However, current studies often overlook a critical aspect of professional service agents: the act of communicating in a manner consistent with their professional identities. This is of particular importance in the healthcare sector, where effective communication with patients is essential for achieving professional goals, such as promoting patient well-being by encouraging healthy behaviors. To bridge this gap, we propose LAPI (LLM-based Agent with a Professional Identity), a novel framework for designing professional service agent tailored for medical question-and-answer (Q\&amp;A) services, ensuring alignment with a specific professional identity. Our method includes a theory-guided task planning process that decomposes complex professional tasks into manageable subtasks aligned with professional objectives and a pragmatic entropy method designed to generate professional and ethical responses with low uncertainty. Experiments on various LLMs show that the proposed approach outperforms baseline methods, including few-shot prompting, chain-of-thought prompting, across key metrics such as fluency, naturalness, empathy, patient-centricity, and ROUGE-L scores. Additionally, the ablation study underscores the contribution of each component to the overall effectiveness of the approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14182</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14182</id><created>2025-01-23</created><authors><author><keyname>Hakemi</keyname><forenames>Shahin</forenames></author><author><keyname>Akhtar</keyname><forenames>Naveed</forenames></author><author><keyname>Hassan</keyname><forenames>Ghulam Mubashar</forenames></author><author><keyname>Mian</keyname><forenames>Ajmal</forenames></author></authors><title>Post-hoc Spurious Correlation Neutralization with Single-Weight   Fictitious Class Unlearning</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural network training tends to exploit the simplest features as shortcuts to greedily minimize training loss. However, some of these features might be spuriously correlated with the target labels, leading to incorrect predictions by the model. Several methods have been proposed to address this issue. Focusing on suppressing the spurious correlations with model training, they not only incur additional training cost, but also have limited practical utility as the model misbehavior due to spurious relations is usually discovered after its deployment. It is also often overlooked that spuriousness is a subjective notion. Hence, the precise questions that must be investigated are; to what degree a feature is spurious, and how we can proportionally distract the model's attention from it for reliable prediction. To this end, we propose a method that enables post-hoc neutralization of spurious feature impact, controllable to an arbitrary degree. We conceptualize spurious features as fictitious sub-classes within the original classes, which can be eliminated by a class removal scheme. We then propose a unique precise class removal technique that employs a single-weight modification, which entails negligible performance compromise for the remaining classes. We perform extensive experiments, demonstrating that by editing just a single weight in a post-hoc manner, our method achieves highly competitive, or better performance against the state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14183</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14183</id><created>2025-01-23</created><authors><author><keyname>Kang</keyname><forenames>Junhyeok</forenames></author><author><keyname>Shin</keyname><forenames>Yooju</forenames></author><author><keyname>Lee</keyname><forenames>Jae-Gil</forenames></author></authors><title>VarDrop: Enhancing Training Efficiency by Reducing Variate Redundancy in   Periodic Time Series Forecasting</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variate tokenization, which independently embeds each variate as separate tokens, has achieved remarkable improvements in multivariate time series forecasting. However, employing self-attention with variate tokens incurs a quadratic computational cost with respect to the number of variates, thus limiting its training efficiency for large-scale applications. To address this issue, we propose VarDrop, a simple yet efficient strategy that reduces the token usage by omitting redundant variate tokens during training. VarDrop adaptively excludes redundant tokens within a given batch, thereby reducing the number of tokens used for dot-product attention while preserving essential information. Specifically, we introduce k-dominant frequency hashing (k-DFH), which utilizes the ranked dominant frequencies in the frequency domain as a hash value to efficiently group variate tokens exhibiting similar periodic behaviors. Then, only representative tokens in each group are sampled through stratified sampling. By performing sparse attention with these selected tokens, the computational cost of scaled dot-product attention is significantly alleviated. Experiments conducted on public benchmark datasets demonstrate that VarDrop outperforms existing efficient baselines. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14184</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14184</id><created>2025-01-23</created><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author></authors><title>Tight Sample Complexity Bounds for Parameter Estimation Under Quantum   Differential Privacy for Qubits</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>This is a short note with the intension of soliciting feedback from   the larger academic community on the topic and the presented results. Any   feedback, particularly around ideas on how to extend these results to qudits,   is welcome and appreciated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note provides tight upper and lower bounds for minimal number of samples (copies of quantum states) required to attain a prescribed accuracy (measured by error variance) for scalar parameters using unbiased estimators under quantum local differential privacy for qubits. In the small privacy budget $\epsilon$ regime, i.e., $\epsilon\ll 1$, the sample complexity scales as $\Theta(\epsilon^{-2})$. This bound matches that of classical parameter estimation under differential privacy. The lower bound loosens (converges to zero) in the large privacy budget regime, i.e., $\epsilon\gg 1$, but that case is not particularly interesting as tight bounds for parameter estimation in the noiseless case are widely known. That being said, extensions to systems with higher dimensions and tightening the bounds for the large privacy budget regime are interesting avenues for future research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14186</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14186</id><created>2025-01-23</created><authors><author><keyname>Bekele</keyname><forenames>Yared W.</forenames></author></authors><title>GeoSim.AI: AI assistants for numerical simulations in geomechanics</title><categories>cs.CE</categories><comments>13 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The ability to accomplish tasks via natural language instructions is one of the most efficient forms of interaction between humans and technology. This efficiency has been translated into practical applications with generative AI tools now allowing users to get things done through natural language queries. The emergence of advanced Large Language Models (LLMs) marks a pivotal shift in this direction. With ongoing advancements in the field of generative AI, integrating natural language commands into sophisticated technical fields in science and engineering is becoming increasingly feasible. This paper introduces GeoSim.AI - a suite of AI assistants for numerical simulations in geomechanics - thereby demonstrating the transformative potential of generative AI in geotechnical engineering. We investigate how AI assistants powered by LLMs can streamline the process of creating complex simulation inputs and interpreting results by translating natural language instructions or image inputs into precise technical commands and scripts. This approach aims to bridge the gap between human intent and the intricate requirements of numerical modeling tools, potentially revolutionizing how researchers and engineers interact with simulation software. We present demonstrations involving AI assistants for performing slope stability analyses in various software packages. The demonstrations highlight the potential of this technology to significantly enhance productivity and accessibility in computational geomechanics. GeoSim.AI is under active development, continuously expanding the suite of AI assistants for various numerical simulation problems in geotechnical engineering. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14189</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14189</id><created>2025-01-23</created><authors><author><keyname>Mahmud</keyname><forenames>Saaduddin</forenames></author><author><keyname>Goldfajn</keyname><forenames>Dorian Benhamou</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models</title><categories>cs.AI cs.LG cs.MA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Distributed Constraint Optimization Problems (DCOPs) offer a powerful framework for multi-agent coordination but often rely on labor-intensive, manual problem construction. To address this, we introduce VL-DCOPs, a framework that takes advantage of large multimodal foundation models (LFMs) to automatically generate constraints from both visual and linguistic instructions. We then introduce a spectrum of agent archetypes for solving VL-DCOPs: from a neuro-symbolic agent that delegates some of the algorithmic decisions to an LFM, to a fully neural agent that depends entirely on an LFM for coordination. We evaluate these agent archetypes using state-of-the-art LLMs (large language models) and VLMs (vision language models) on three novel VL-DCOP tasks and compare their respective advantages and drawbacks. Lastly, we discuss how this work extends to broader frontier challenges in the DCOP literature. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14190</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14190</id><created>2025-01-23</created><authors><author><keyname>Wang</keyname><forenames>Shuai</forenames></author><author><keyname>Xu</keyname><forenames>Yang</forenames></author><author><keyname>Zheng</keyname><forenames>Hui</forenames></author><author><keyname>Li</keyname><forenames>Baotian</forenames></author></authors><title>High-Precision Fabric Defect Detection via Adaptive Shape Convolutions   and Large Kernel Spatial Modeling</title><categories>cs.CV</categories><comments>8 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Detecting fabric defects in the textile industry remains a challenging task due to the diverse and complex nature of defect patterns. Traditional methods often suffer from slow inference speeds, limited accuracy, and inadequate recognition rates, particularly in scenarios involving intricate or subtle defects. To overcome these limitations, we introduce Fab-ASLKS, an advanced fabric defect detection framework built upon the YOLOv8s architecture. Fab-ASLKS incorporates two key modules: (1) the Adaptive Shape Convolution Module (ASCM), which leverages adaptive shape convolution within the Neck to enhance feature fusion and improve efficiency by extending the capabilities of the standard C2f structure, and (2) the Large Kernel Shift Convolution Module (LKSCM), designed to emulate large kernel effects within the Backbone, enabling superior spatial information extraction. These modules collaboratively optimize feature extraction and information integration across the network. Extensive experiments conducted on the Tianchi fabric defect detection dataset demonstrate that Fab-ASLKS achieves a 5% improvement in mAP@50 over the baseline, showcasing its capability to deliver high precision and efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14193</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14193</id><created>2025-01-23</created><authors><author><keyname>Adeel</keyname><forenames>Muhammad</forenames></author><author><keyname>Ali</keyname><forenames>Hasnain</forenames></author><author><keyname>Soomro</keyname><forenames>Afaque Manzoor</forenames></author><author><keyname>Waqas</keyname><forenames>Muhammad</forenames></author></authors><title>Fabrication of Soft and Comfortable Pressure-Sensing Shoe Sole for   Intuitive Monitoring of Human Quality Gaits</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The study discusses the design and fabrication of flexible pressure sensors using Ecoflex/Graphene composites. The fabricated sensor is used for the application of intuitive monitoring of human quality gaits and implementation of the soft and comfortable shoe sole for rehabilitation of the patients with foot disorder is also taken into consideration. The sensor is fabricated using molding and casting technique by sandwiching the thin film Ecoflex/Graphene composites between the copper (Cu) electrodes with the dimension of 15 x 15 mm2 with high sensitivity. There are five pressure sensors integrated in the shoe sole, a sensor at the forefoot, three sensors at the midfoot and one sensor at the lower foot (heel). The behavior of the sensor is negative piezoresistive in which the resistance decreases as the pressure increases. The sensors are embedded in a soft and comfortable shoe sole and then integrated with a laptop or mobile application to monitor and analyze human gait in real-time. Furthermore, a dedicated Graphical User Interface (GUI) is designed to read the data. The pressure sensors are integrated with ESP32 microcontroller which wirelessly transmit data to the GUI and smart phones which could be further used in the intuitive monitoring, rehabilitation of the patients with foot disorder or neuromotor diseases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14194</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14194</id><created>2025-01-23</created><authors><author><keyname>Ayyubi</keyname><forenames>Hammad</forenames></author><author><keyname>Liu</keyname><forenames>Junzhang</forenames></author><author><keyname>Asgarov</keyname><forenames>Ali</forenames></author><author><keyname>Hakim</keyname><forenames>Zaber Ibn Abdul</forenames></author><author><keyname>Sarker</keyname><forenames>Najibul Haque</forenames></author><author><keyname>Wang</keyname><forenames>Zhecan</forenames></author><author><keyname>Tang</keyname><forenames>Chia-Wei</forenames></author><author><keyname>Alomari</keyname><forenames>Hani</forenames></author><author><keyname>Atabuzzaman</keyname><forenames>Md.</forenames></author><author><keyname>Lin</keyname><forenames>Xudong</forenames></author><author><keyname>Dyava</keyname><forenames>Naveen Reddy</forenames></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames></author><author><keyname>Thomas</keyname><forenames>Chris</forenames></author></authors><title>ENTER: Event Based Interpretable Reasoning for VideoQA</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we present ENTER, an interpretable Video Question Answering (VideoQA) system based on event graphs. Event graphs convert videos into graphical representations, where video events form the nodes and event-event relationships (temporal/causal/hierarchical) form the edges. This structured representation offers many benefits: 1) Interpretable VideoQA via generated code that parses event-graph; 2) Incorporation of contextual visual information in the reasoning process (code generation) via event graphs; 3) Robust VideoQA via Hierarchical Iterative Update of the event graphs. Existing interpretable VideoQA systems are often top-down, disregarding low-level visual information in the reasoning plan generation, and are brittle. While bottom-up approaches produce responses from visual data, they lack interpretability. Experimental results on NExT-QA, IntentQA, and EgoSchema demonstrate that not only does our method outperform existing top-down approaches while obtaining competitive performance against bottom-up approaches, but more importantly, offers superior interpretability and explainability in the reasoning process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14195</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14195</id><created>2025-01-23</created><authors><author><keyname>Hu</keyname><forenames>Runyi</forenames></author><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Li</keyname><forenames>Yiming</forenames></author><author><keyname>Li</keyname><forenames>Jiwei</forenames></author><author><keyname>Guo</keyname><forenames>Qing</forenames></author><author><keyname>Qiu</keyname><forenames>Han</forenames></author><author><keyname>Zhang</keyname><forenames>Tianwei</forenames></author></authors><title>VideoShield: Regulating Diffusion-based Video Generation Models via   Watermarking</title><categories>cs.CV</categories><comments>International Conference on Learning Representations (ICLR) 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Artificial Intelligence Generated Content (AIGC) has advanced significantly, particularly with the development of video generation models such as text-to-video (T2V) models and image-to-video (I2V) models. However, like other AIGC types, video generation requires robust content control. A common approach is to embed watermarks, but most research has focused on images, with limited attention given to videos. Traditional methods, which embed watermarks frame-by-frame in a post-processing manner, often degrade video quality. In this paper, we propose VideoShield, a novel watermarking framework specifically designed for popular diffusion-based video generation models. Unlike post-processing methods, VideoShield embeds watermarks directly during video generation, eliminating the need for additional training. To ensure video integrity, we introduce a tamper localization feature that can detect changes both temporally (across frames) and spatially (within individual frames). Our method maps watermark bits to template bits, which are then used to generate watermarked noise during the denoising process. Using DDIM Inversion, we can reverse the video to its original watermarked noise, enabling straightforward watermark extraction. Additionally, template bits allow precise detection for potential temporal and spatial modification. Extensive experiments across various video models (both T2V and I2V models) demonstrate that our method effectively extracts watermarks and detects tamper without compromising video quality. Furthermore, we show that this approach is applicable to image generation models, enabling tamper detection in generated images as well. Codes and models are available at \href{https://github.com/hurunyi/VideoShield}{https://github.com/hurunyi/VideoShield}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14196</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14196</id><created>2025-01-23</created><authors><author><keyname>Dritsas</keyname><forenames>Ioannis</forenames></author></authors><title>PASER: A Physics-Inspired Theory for Stimulated Growth and Real-Time   Optimization in On-Demand Platforms</title><categories>physics.soc-ph cs.SI econ.TH</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper introduces an innovative framework for understanding on-demand platforms by quantifying positive network effects, trust, revenue dynamics, and the influence of demand on platform operations at per-minute or even per-second granularity. Drawing inspiration from physics, the framework provides both a theoretical and pragmatic perspective, offering a pictorial and quantitative representation of how on-demand platforms create value. It seeks to demystify their nuanced operations by providing practical, tangible, and highly applicable metrics, platform design templates, and real-time optimization tools for strategic what-if scenario planning. Its model demonstrates strong predictive power and is deeply rooted in raw data. The framework offers a deterministic insight into the workings of diverse platforms like Uber, Airbnb, and food delivery services. Furthermore, it generalizes to model all on-demand service platforms with cyclical operations. It works synergistically with machine learning, game theory, and agent-based models by providing a solid quantitative core rooted in raw data, based on physical truths, and is capable of delivering tangible predictions for real-time operational adjustments. The framework's mathematical model was rigorously validated using highly detailed historical data retrieved with near 100% certainty. Applying data-driven induction, distinct qualities were identified in big data sets via an iterative process. Through analogical thinking, a clear and highly intuitive mapping between the elements, operational principles, and dynamic behaviors of a well-known physical system was established to create a physics-inspired lens for Uber. This novel quantitative framework was named PASER (Profit Amplification by Stimulated Emission of Revenue), drawing an analogy to its physical counterpart, the LASER (Light Amplification by Stimulated Emission of Radiation). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14197</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14197</id><created>2025-01-23</created><authors><author><keyname>Hao</keyname><forenames>Yitong</forenames></author><author><keyname>He</keyname><forenames>Enbo</forenames></author><author><keyname>Zhang</keyname><forenames>Yue</forenames></author><author><keyname>Yin</keyname><forenames>Guisheng</forenames></author></authors><title>Bi-directional Curriculum Learning for Graph Anomaly Detection: Dual   Focus on Homogeneity and Heterogeneity</title><categories>cs.LG cs.SI stat.ML</categories><comments>8pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph anomaly detection (GAD) aims to identify nodes from a graph that are significantly different from normal patterns. Most previous studies are model-driven, focusing on enhancing the detection effect by improving the model structure. However, these approaches often treat all nodes equally, neglecting the different contributions of various nodes to the training. Therefore, we introduce graph curriculum learning as a simple and effective plug-and-play module to optimize GAD methods. The existing graph curriculum learning mainly focuses on the homogeneity of graphs and treats nodes with high homogeneity as easy nodes. In fact, GAD models can handle not only graph homogeneity but also heterogeneity, which leads to the unsuitability of these existing methods. To address this problem, we propose an innovative Bi-directional Curriculum Learning strategy (BCL), which considers nodes with higher and lower similarity to neighbor nodes as simple nodes in the direction of focusing on homogeneity and focusing on heterogeneity, respectively, and prioritizes their training. Extensive experiments show that BCL can be quickly integrated into existing detection processes and significantly improves the performance of ten GAD anomaly detection models on seven commonly used datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14198</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14198</id><created>2025-01-23</created><authors><author><keyname>Deng</keyname><forenames>Zeyun</forenames></author><author><keyname>Campbell</keyname><forenames>Joseph</forenames></author></authors><title>Sparse Mixture-of-Experts for Non-Uniform Noise Reduction in MRI Images</title><categories>eess.IV cs.CV</categories><comments>Accepted to the WACV Workshop on Image Quality</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic Resonance Imaging (MRI) is an essential diagnostic tool in clinical settings, but its utility is often hindered by noise artifacts introduced during the imaging process.Effective denoising is critical for enhancing image quality while preserving anatomical structures. However, traditional denoising methods, which often assume uniform noise distributions, struggle to handle the non-uniform noise commonly present in MRI images. In this paper, we introduce a novel approach leveraging a sparse mixture-of-experts framework for MRI image denoising. Each expert is a specialized denoising convolutional neural network fine-tuned to target specific noise characteristics associated with different image regions. Our method demonstrates superior performance over state-of-the-art denoising techniques on both synthetic and real-world brain MRI datasets. Furthermore, we show that it generalizes effectively to unseen datasets, highlighting its robustness and adaptability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14199</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14199</id><created>2025-01-23</created><authors><author><keyname>Hu</keyname><forenames>Yulong</forenames></author><author><keyname>Dong</keyname><forenames>Tingting</forenames></author><author><keyname>Li</keyname><forenames>Sen</forenames></author></authors><title>Coordinating Ride-Pooling with Public Transit using Reward-Guided   Conservative Q-Learning: An Offline Training and Online Fine-Tuning   Reinforcement Learning Framework</title><categories>cs.LG cs.AI cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel reinforcement learning (RL) framework, termed Reward-Guided Conservative Q-learning (RG-CQL), to enhance coordination between ride-pooling and public transit within a multimodal transportation network. We model each ride-pooling vehicle as an agent governed by a Markov Decision Process (MDP) and propose an offline training and online fine-tuning RL framework to learn the optimal operational decisions of the multimodal transportation systems, including rider-vehicle matching, selection of drop-off locations for passengers, and vehicle routing decisions, with improved data efficiency. During the offline training phase, we develop a Conservative Double Deep Q Network (CDDQN) as the action executor and a supervised learning-based reward estimator, termed the Guider Network, to extract valuable insights into action-reward relationships from data batches. In the online fine-tuning phase, the Guider Network serves as an exploration guide, aiding CDDQN in effectively and conservatively exploring unknown state-action pairs. The efficacy of our algorithm is demonstrated through a realistic case study using real-world data from Manhattan. We show that integrating ride-pooling with public transit outperforms two benchmark cases solo rides coordinated with transit and ride-pooling without transit coordination by 17% and 22% in the achieved system rewards, respectively. Furthermore, our innovative offline training and online fine-tuning framework offers a remarkable 81.3% improvement in data efficiency compared to traditional online RL methods with adequate exploration budgets, with a 4.3% increase in total rewards and a 5.6% reduction in overestimation errors. Experimental results further demonstrate that RG-CQL effectively addresses the challenges of transitioning from offline to online RL in large-scale ride-pooling systems integrated with transit. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14204</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14204</id><created>2025-01-23</created><authors><author><keyname>Liang</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Guan</keyname><forenames>Chaofeng</forenames></author><author><keyname>Lu</keyname><forenames>Jiaying</forenames></author><author><keyname>Chen</keyname><forenames>Huiyao</forenames></author><author><keyname>Wang</keyname><forenames>Huan</forenames></author><author><keyname>Hu</keyname><forenames>Haoji</forenames></author></authors><title>Dynamic Token Reduction during Generation for Vision Language Models</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Vision-Language Models (VLMs) have achieved notable success in multimodal tasks but face practical limitations due to the quadratic complexity of decoder attention mechanisms and autoregressive generation. Existing methods like FASTV and VTW have achieved notable results in reducing redundant visual tokens, but these approaches focus on pruning tokens in a single forward pass without systematically analyzing the redundancy of visual tokens throughout the entire generation process. In this paper, we introduce a dynamic pruning strategy tailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the compression rate during generation. Our analysis of the distribution of attention reveals that the importance of visual tokens decreases throughout the generation process, inspiring us to adopt a more aggressive compression rate. By integrating a lightweight predictor based on attention distribution, our approach enables flexible adjustment of pruning rates based on the attention distribution. Our experimental results demonstrate that our method not only reduces computational demands but also maintains the quality of responses. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14205</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14205</id><created>2025-01-23</created><authors><author><keyname>Xu</keyname><forenames>Minrui</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author><author><keyname>Brinton</keyname><forenames>Christopher G.</forenames></author></authors><title>Serving Long-Context LLMs at the Mobile Edge: Test-Time Reinforcement   Learning-based Model Caching and Inference Offloading</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large Language Models (LLMs) can perform zero-shot learning on unseen tasks and few-shot learning on complex reasoning tasks. However, resource-limited mobile edge networks struggle to support long-context LLM serving for LLM agents during multi-round interactions with users. Unlike stateless computation offloading and static service offloading in edge computing, optimizing LLM serving at edge servers is challenging because LLMs continuously learn from context which raises accuracy, latency, and resource consumption dynamics. In this paper, we propose a joint model caching and inference offloading framework that utilizes test-time deep reinforcement learning (T2DRL) to optimize deployment and execution strategies for long-context LLM serving. In this framework, we analyze the performance convergence and design an optimization problem considering the utilization of context windows in LLMs. Furthermore, the T2DRL algorithm can learn in both the training phase and the testing phase to proactively manage cached models and service requests and adapt to context changes and usage patterns during execution. To further enhance resource allocation efficiency, we propose a double Dutch auction (DDA) mechanism, which dynamically matches supply and demand while maximizing social welfare. Finally, experimental results demonstrate that the T2DRL algorithm can reduce system costs by at least 30% compared to baselines while guaranteeing the performance of LLM agents in real-world perception and reasoning tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14208</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14208</id><created>2025-01-23</created><authors><author><keyname>Zhou</keyname><forenames>Huayi</forenames></author><author><keyname>Wang</keyname><forenames>Ruixiang</forenames></author><author><keyname>Tai</keyname><forenames>Yunxin</forenames></author><author><keyname>Deng</keyname><forenames>Yueci</forenames></author><author><keyname>Liu</keyname><forenames>Guiliang</forenames></author><author><keyname>Jia</keyname><forenames>Kui</forenames></author></authors><title>You Only Teach Once: Learn One-Shot Bimanual Robotic Manipulation from   Video Demonstrations</title><categories>cs.RO cs.CV</categories><comments>under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bimanual robotic manipulation is a long-standing challenge of embodied intelligence due to its characteristics of dual-arm spatial-temporal coordination and high-dimensional action spaces. Previous studies rely on pre-defined action taxonomies or direct teleoperation to alleviate or circumvent these issues, often making them lack simplicity, versatility and scalability. Differently, we believe that the most effective and efficient way for teaching bimanual manipulation is learning from human demonstrated videos, where rich features such as spatial-temporal positions, dynamic postures, interaction states and dexterous transitions are available almost for free. In this work, we propose the YOTO (You Only Teach Once), which can extract and then inject patterns of bimanual actions from as few as a single binocular observation of hand movements, and teach dual robot arms various complex tasks. Furthermore, based on keyframes-based motion trajectories, we devise a subtle solution for rapidly generating training demonstrations with diverse variations of manipulated objects and their locations. These data can then be used to learn a customized bimanual diffusion policy (BiDP) across diverse scenes. In experiments, YOTO achieves impressive performance in mimicking 5 intricate long-horizon bimanual tasks, possesses strong generalization under different visual and spatial conditions, and outperforms existing visuomotor imitation learning methods in accuracy and efficiency. Our project link is https://hnuzhy.github.io/projects/YOTO. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14210</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14210</id><created>2025-01-23</created><authors><author><keyname>Ayyubi</keyname><forenames>Hammad</forenames></author><author><keyname>Feng</keyname><forenames>Xuande</forenames></author><author><keyname>Liu</keyname><forenames>Junzhang</forenames></author><author><keyname>Lin</keyname><forenames>Xudong</forenames></author><author><keyname>Wang</keyname><forenames>Zhecan</forenames></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames></author></authors><title>PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location   Prediction</title><categories>cs.CV cs.AI cs.LG</categories><comments>NAACL 2025 Findings</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The task of predicting time and location from images is challenging and requires complex human-like puzzle-solving ability over different clues. In this work, we formalize this ability into core skills and implement them using different modules in an expert pipeline called PuzzleGPT. PuzzleGPT consists of a perceiver to identify visual clues, a reasoner to deduce prediction candidates, a combiner to combinatorially combine information from different clues, a web retriever to get external knowledge if the task can't be solved locally, and a noise filter for robustness. This results in a zero-shot, interpretable, and robust approach that records state-of-the-art performance on two datasets -- TARA and WikiTilo. PuzzleGPT outperforms large VLMs such as BLIP-2, InstructBLIP, LLaVA, and even GPT-4V, as well as automatically generated reasoning pipelines like VisProg, by at least 32% and 38%, respectively. It even rivals or surpasses finetuned models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14211</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14211</id><created>2025-01-23</created><authors><author><keyname>Chen</keyname><forenames>Qian</forenames></author><author><keyname>Li</keyname><forenames>Lei</forenames></author><author><keyname>Li</keyname><forenames>Qian</forenames></author><author><keyname>Wu</keyname><forenames>Jianghua</forenames></author><author><keyname>Wang</keyname><forenames>Akang</forenames></author><author><keyname>Sun</keyname><forenames>Ruoyu</forenames></author><author><keyname>Luo</keyname><forenames>Xiaodong</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Shi</keyname><forenames>Qingjiang</forenames></author></authors><title>When GNNs meet symmetry in ILPs: an orbit-based feature augmentation   approach</title><categories>cs.LG math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A common characteristic in integer linear programs (ILPs) is symmetry, allowing variables to be permuted without altering the underlying problem structure. Recently, GNNs have emerged as a promising approach for solving ILPs. However, a significant challenge arises when applying GNNs to ILPs with symmetry: classic GNN architectures struggle to differentiate between symmetric variables, which limits their predictive accuracy. In this work, we investigate the properties of permutation equivariance and invariance in GNNs, particularly in relation to the inherent symmetry of ILP formulations. We reveal that the interaction between these two factors contributes to the difficulty of distinguishing between symmetric variables. To address this challenge, we explore the potential of feature augmentation and propose several guiding principles for constructing augmented features. Building on these principles, we develop an orbit-based augmentation scheme that first groups symmetric variables and then samples augmented features for each group from a discrete uniform distribution. Empirical results demonstrate that our proposed approach significantly enhances both training efficiency and predictive performance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14216</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14216</id><created>2025-01-23</created><authors><author><keyname>Lin</keyname><forenames>Haowei</forenames></author><author><keyname>Li</keyname><forenames>Shanda</forenames></author><author><keyname>Ye</keyname><forenames>Haotian</forenames></author><author><keyname>Yang</keyname><forenames>Yiming</forenames></author><author><keyname>Ermon</keyname><forenames>Stefano</forenames></author><author><keyname>Liang</keyname><forenames>Yitao</forenames></author><author><keyname>Ma</keyname><forenames>Jianzhu</forenames></author></authors><title>TFG-Flow: Training-free Guidance in Multimodal Generative Flow</title><categories>cs.LG cs.AI cs.CE</categories><journal-ref>ICLR 2025</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an unconditional generative model and a predictor for a target property (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. As a highly efficient technique for steering generative models toward flexible outcomes, training-free guidance has gained increasing attention in diffusion models. However, existing methods only handle data in continuous spaces, while many scientific applications involve both continuous and discrete data (referred to as multimodality). Another emerging trend is the growing use of the simple and general flow matching framework in building generative foundation models, where guided generation remains under-explored. To address this, we introduce TFG-Flow, a novel training-free guidance method for multimodal generative flow. TFG-Flow addresses the curse-of-dimensionality while maintaining the property of unbiased sampling in guiding discrete variables. We validate TFG-Flow on four molecular design tasks and show that TFG-Flow has great potential in drug design by generating molecules with desired properties. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14220</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14220</id><created>2025-01-23</created><authors><author><keyname>Sun</keyname><forenames>Yuan</forenames></author></authors><title>Analysis of heralded higher-fidelity two-qubit entangling gates with   self-correction</title><categories>quant-ph cs.AR physics.atom-ph</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the quantum error correction (QEC) and noisy intermediate-scale quantum (NISQ) algorithms to function with high efficiency, the raw fidelity of quantum logic gates on physical qubits needs to satisfy strict requirement. The neutral atom quantum computing equipped with Rydberg blockade gates has made impressive progress recently, which makes it worthwhile to explore its potential in the two-qubit entangling gates, including Controlled-PHASE gate and in particular the CZ gate. Provided the quantum coherence is well preserved, improving the fidelity of Rydberg blockade gates calls for special mechanisms to deal with adverse effects caused by realistic experimental conditions. Here the heralded very-high-fidelity Rydberg blockade Controlled-PHASE gate is designed to address these issues, which contains self-correction and projection as the key steps. This trailblazing method can be built on the basis of the previously established buffer-atom-mediated gate, and a special form of symmetry under PT transformation plays a crucial role in the process. We further analyze the performance with respect to a few typical sources of imperfections. This procedure can also be regarded as quantum hardware error correction or mitigation. While this paper by itself does not cover every single subtle issue and still contains many over-simplifications, we find it reasonable to anticipate very-high-fidelity two-qubit quantum logic gate operated in the sense of heralded but probabilistic, whose gate error can reduce to the level of $10^{-4}$--$10^{-6}$ or even lower with reasonably high possibilities. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14224</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14224</id><created>2025-01-23</created><authors><author><keyname>Bai</keyname><forenames>Jiaxin</forenames></author><author><keyname>Wang</keyname><forenames>Zihao</forenames></author><author><keyname>Zhou</keyname><forenames>Yukun</forenames></author><author><keyname>Yin</keyname><forenames>Hang</forenames></author><author><keyname>Fei</keyname><forenames>Weizhi</forenames></author><author><keyname>Hu</keyname><forenames>Qi</forenames></author><author><keyname>Deng</keyname><forenames>Zheye</forenames></author><author><keyname>Cheng</keyname><forenames>Jiayang</forenames></author><author><keyname>Zheng</keyname><forenames>Tianshi</forenames></author><author><keyname>Tsang</keyname><forenames>Hong Ting</forenames></author><author><keyname>Gao</keyname><forenames>Yisen</forenames></author><author><keyname>Xie</keyname><forenames>Zhongwei</forenames></author><author><keyname>Li</keyname><forenames>Yufei</forenames></author><author><keyname>Fan</keyname><forenames>Lixin</forenames></author><author><keyname>Yuan</keyname><forenames>Binhang</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaofang</forenames></author><author><keyname>Song</keyname><forenames>Yangqiu</forenames></author></authors><title>Top Ten Challenges Towards Agentic Neural Graph Databases</title><categories>cs.AI cs.DB cs.LG</categories><comments>12 Pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graph databases (GDBs) like Neo4j and TigerGraph excel at handling interconnected data but lack advanced inference capabilities. Neural Graph Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for predictive analysis and reasoning over incomplete or noisy data. However, NGDBs rely on predefined queries and lack autonomy and adaptability. This paper introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs with three core functionalities: autonomous query construction, neural query execution, and continuous learning. We identify ten key challenges in realizing Agentic NGDBs: semantic unit representation, abductive reasoning, scalable query execution, and integration with foundation models like large language models (LLMs). By addressing these challenges, Agentic NGDBs can enable intelligent, self-improving systems for modern data-driven applications, paving the way for adaptable and autonomous data management solutions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14225</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14225</id><created>2025-01-23</created><authors><author><keyname>Ye</keyname><forenames>Rong</forenames></author><author><keyname>Zhang</keyname><forenames>Yongxin</forenames></author><author><keyname>Zhang</keyname><forenames>Yikai</forenames></author><author><keyname>Kuang</keyname><forenames>Haoyu</forenames></author><author><keyname>Wei</keyname><forenames>Zhongyu</forenames></author><author><keyname>Sun</keyname><forenames>Peng</forenames></author></authors><title>Multi-agent KTO: Reinforcing Strategic Interactions of Large Language   Model in Language Game</title><categories>cs.CL cs.AI cs.HC</categories><comments>Preprint. Code and data will be available at   https://reneeye.github.io/MaKTO.html</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Achieving Artificial General Intelligence (AGI) requires AI agents that can not only make stratigic decisions but also engage in flexible and meaningful communication. Inspired by Wittgenstein's language game theory in Philosophical Investigations, we propose that language agents can learn through in-context interaction rather than traditional multi-stage frameworks that separate decision-making from language expression. Using Werewolf, a social deduction game that tests language understanding, strategic interaction, and adaptability, we develop the Multi-agent Kahneman &amp; Tversky's Optimization (MaKTO). MaKTO engages diverse models in extensive gameplay to generate unpaired desirable and unacceptable responses, then employs KTO to refine the model's decision-making process. In 9-player Werewolf games, MaKTO achieves a 61% average win rate across various models, outperforming GPT-4o and two-stage RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably, MaKTO also demonstrates human-like performance, winning 60% against expert players and showing only 49% detectability in Turing-style blind tests. These results showcase MaKTO's superior decision-making, strategic adaptation, and natural language generation in complex social deduction games. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14228</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14228</id><created>2025-01-23</created><authors><author><keyname>Mollick</keyname><forenames>Md. Abu Ahnaf</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Mahfujur</forenames></author><author><keyname>Asadujjaman</keyname><forenames>D. M.</forenames></author><author><keyname>Tamim</keyname><forenames>Abdullah</forenames></author><author><keyname>Dristi</keyname><forenames>Nosin Anjum</forenames></author><author><keyname>Hossen</keyname><forenames>Md. Takbir</forenames></author></authors><title>Detection and Classification of Acute Lymphoblastic Leukemia Utilizing   Deep Transfer Learning</title><categories>cs.CV cs.AI</categories><comments>4 pages, 4 figures, Submitted to UCICS</comments><msc-class>68T07</msc-class><acm-class>J.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A mutation in the DNA of a single cell that compromises its function initiates leukemia,leading to the overproduction of immature white blood cells that encroach upon the space required for the generation of healthy blood cells.Leukemia is treatable if identified in its initial stages. However,its diagnosis is both arduous and time consuming. This study proposes a novel approach for diagnosing leukemia across four stages Benign,Early,Pre,and Pro using deep learning techniques.We employed two Convolutional Neural Network (CNN) models as MobileNetV2 with an altered head and a custom model. The custom model consists of multiple convolutional layers,each paired with corresponding max pooling layers.We utilized MobileNetV2 with ImageNet weights,adjusting the head to integrate the final results.The dataset used is the publicly available "Acute Lymphoblastic Leukemia (ALL) Image Dataset", and we applied the Synthetic Minority Oversampling Technique (SMOTE) to augment and balance the training dataset.The custom model achieved an accuracy of 98.6%, while MobileNetV2 attained a superior accuracy of 99.69%. The pretrained model showed promising results,indicating an increased likelihood of real-world application. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14230</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14230</id><created>2025-01-23</created><authors><author><keyname>Wang</keyname><forenames>Hanrui</forenames></author><author><keyname>Chang</keyname><forenames>Ching-Chun</forenames></author><author><keyname>Lu</keyname><forenames>Chun-Shien</forenames></author><author><keyname>Leckie</keyname><forenames>Christopher</forenames></author><author><keyname>Echizen</keyname><forenames>Isao</forenames></author></authors><title>GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy   Algorithm</title><categories>cs.CV cs.CR cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  A critical requirement for deep learning models is ensuring their robustness against adversarial attacks. These attacks commonly introduce noticeable perturbations, compromising the visual fidelity of adversarial examples. Another key challenge is that while white-box algorithms can generate effective adversarial perturbations, they require access to the model gradients, limiting their practicality in many real-world scenarios. Existing attack mechanisms struggle to achieve similar efficacy without access to these gradients. In this paper, we introduce GreedyPixel, a novel pixel-wise greedy algorithm designed to generate high-quality adversarial examples using only query-based feedback from the target model. GreedyPixel improves computational efficiency in what is typically a brute-force process by perturbing individual pixels in sequence, guided by a pixel-wise priority map. This priority map is constructed by ranking gradients obtained from a surrogate model, providing a structured path for perturbation. Our results demonstrate that GreedyPixel achieves attack success rates comparable to white-box methods without the need for gradient information, and surpasses existing algorithms in black-box settings, offering higher success rates, reduced computational time, and imperceptible perturbations. These findings underscore the advantages of GreedyPixel in terms of attack efficacy, time efficiency, and visual quality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14231</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14231</id><created>2025-01-23</created><authors><author><keyname>Li</keyname><forenames>Yihui</forenames></author><author><keyname>Lv</keyname><forenames>Chengxin</forenames></author><author><keyname>Yang</keyname><forenames>Hongyu</forenames></author><author><keyname>Huang</keyname><forenames>Di</forenames></author></authors><title>Micro-macro Wavelet-based Gaussian Splatting for 3D Reconstruction from   Unconstrained Images</title><categories>cs.CV</categories><comments>11 pages, 6 figures,accepted by AAAI 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D reconstruction from unconstrained image collections presents substantial challenges due to varying appearances and transient occlusions. In this paper, we introduce Micro-macro Wavelet-based Gaussian Splatting (MW-GS), a novel approach designed to enhance 3D reconstruction by disentangling scene representations into global, refined, and intrinsic components. The proposed method features two key innovations: Micro-macro Projection, which allows Gaussian points to capture details from feature maps across multiple scales with enhanced diversity; and Wavelet-based Sampling, which leverages frequency domain information to refine feature representations and significantly improve the modeling of scene appearances. Additionally, we incorporate a Hierarchical Residual Fusion Network to seamlessly integrate these features. Extensive experiments demonstrate that MW-GS delivers state-of-the-art rendering performance, surpassing existing methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14232</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14232</id><created>2025-01-23</created><authors><author><keyname>Yang</keyname><forenames>Jianyi</forenames></author><author><keyname>Li</keyname><forenames>Pengfei</forenames></author><author><keyname>Li</keyname><forenames>Tongxin</forenames></author><author><keyname>Wierman</keyname><forenames>Adam</forenames></author><author><keyname>Ren</keyname><forenames>Shaolei</forenames></author></authors><title>Learning-Augmented Online Control for Decarbonizing Water   Infrastructures</title><categories>eess.SY cs.SY</categories><comments>Accepted by e-Energy 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Water infrastructures are essential for drinking water supply, irrigation, fire protection, and other critical applications. However, water pumping systems, which are key to transporting water to the point of use, consume significant amounts of energy and emit millions of tons of greenhouse gases annually. With the wide deployment of digital water meters and sensors in these infrastructures, Machine Learning (ML) has the potential to optimize water supply control and reduce greenhouse gas emissions. Nevertheless, the inherent vulnerability of ML methods in terms of worst-case performance raises safety concerns when deployed in critical water infrastructures. To address this challenge, we propose a learning-augmented online control algorithm, termed LAOC, designed to dynamically schedule the activation and/or speed of water pumps. To ensure safety, we introduce a novel design of safe action sets for online control problems. By leveraging these safe action sets, LAOC can provably guarantee safety constraints while utilizing ML predictions to reduce energy and environmental costs. Our analysis reveals the tradeoff between safety requirements and average energy/environmental cost performance. Additionally, we conduct an experimental study on a building water supply system to demonstrate the empirical performance of LAOC. The results indicate that LAOC can effectively reduce environmental and energy costs while guaranteeing safety constraints. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14233</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14233</id><created>2025-01-23</created><authors><author><keyname>Dong</keyname><forenames>Xiaochong</forenames></author><author><keyname>Liu</keyname><forenames>Yilin</forenames></author><author><keyname>Zhang</keyname><forenames>Xuemin</forenames></author><author><keyname>Mei</keyname><forenames>Shengwei</forenames></author></authors><title>A Data-driven Dynamic Temporal Correlation Modeling Framework for   Renewable Energy Scenario Generation</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Renewable energy power is influenced by the atmospheric system, which exhibits nonlinear and time-varying features. To address this, a dynamic temporal correlation modeling framework is proposed for renewable energy scenario generation. A novel decoupled mapping path is employed for joint probability distribution modeling, formulating regression tasks for both marginal distributions and the correlation structure using proper scoring rules to ensure the rationality of the modeling process. The scenario generation process is divided into two stages. Firstly, the dynamic correlation network models temporal correlations based on a dynamic covariance matrix, capturing the time-varying features of renewable energy while enhancing the interpretability of the black-box model. Secondly, the implicit quantile network models the marginal quantile function in a nonparametric, continuous manner, enabling scenario generation through marginal inverse sampling. Experimental results demonstrate that the proposed dynamic correlation quantile network outperforms state-of-the-art methods in quantifying uncertainty and capturing dynamic correlation for short-term renewable energy scenario generation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14234</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14234</id><created>2025-01-23</created><authors><author><keyname>An</keyname><forenames>Bonan</forenames></author><author><keyname>Mei</keyname><forenames>Weidong</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Chen</keyname><forenames>Zhi</forenames></author></authors><title>STAR-RIS-Enabled Multi-Path Beam Routing with Passive Beam Splitting</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconfigurable intelligent surfaces (RISs) can be densely deployed in the environment to create multi-reflection line-of-sight (LoS) links for signal coverage enhancement. However, conventional reflection-only RISs can only achieve half-space reflection, which limits the LoS path diversity. In contrast, simultaneously transmitting and reflecting RISs (STAR-RISs) can achieve full-space reflection and transmission, thereby creating more LoS paths. Hence, in this paper, we study a new multi-STAR-RIS-aided communication system, where a multi-antenna base station (BS) transmits to multiple single-antenna users by exploiting the signal beam routing over a set of cascaded LoS paths each formed by multiple STAR-RISs. To reveal essential insights, we first consider a simplified single-user case, aiming to maximize its received signal power by jointly optimizing the active beamforming at the BS, the BS's power allocation over different paths, the number of selected beam-routing paths, the selected STAR-RISs for each path, as well as their amplitude and phase shifts for transmission/reflection. However, this problem is difficult to be optimally solved as different paths may be intricately coupled at their shared STAR-RISs. To tackle this difficulty, we first derive the optimal solution to this problem in closed-form for a given set of paths. The clique-based approach in graph theory is then applied to solve the remaining multi-path selection problem efficiently. Next, we extend the proposed clique-based method to the multi-user case to maximize the minimum received signal power among all users, subject to additional constraints on the disjointness of the selected paths for different users. Simulation results show that our proposed STAR-RIS-enabled beam routing outperforms the conventional beam routing with reflection-only RISs in both single- and multi-user cases. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14238</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14238</id><created>2025-01-23</created><authors><author><keyname>Mohammadi</keyname><forenames>Marzieh</forenames></author><author><keyname>Salarpour</keyname><forenames>Amir</forenames></author><author><keyname>MohajerAnsari</keyname><forenames>Pedram</forenames></author></authors><title>Point-LN: A Lightweight Framework for Efficient Point Cloud   Classification Using Non-Parametric Positional Encoding</title><categories>cs.CV cs.AI cs.LG cs.RO</categories><comments>This paper has been accepted for presentation at the 29th   International Computer Conference, Computer Society of Iran (CSICC) 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce Point-LN, a novel lightweight framework engineered for efficient 3D point cloud classification. Point-LN integrates essential non-parametric components-such as Farthest Point Sampling (FPS), k-Nearest Neighbors (k-NN), and non-learnable positional encoding-with a streamlined learnable classifier that significantly enhances classification accuracy while maintaining a minimal parameter footprint. This hybrid architecture ensures low computational costs and rapid inference speeds, making Point-LN ideal for real-time and resource-constrained applications. Comprehensive evaluations on benchmark datasets, including ModelNet40 and ScanObjectNN, demonstrate that Point-LN achieves competitive performance compared to state-of-the-art methods, all while offering exceptional efficiency. These results establish Point-LN as a robust and scalable solution for diverse point cloud classification tasks, highlighting its potential for widespread adoption in various computer vision applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14240</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14240</id><created>2025-01-23</created><authors><author><keyname>Huang</keyname><forenames>Wen</forenames></author><author><keyname>Gu</keyname><forenames>Yanmei</forenames></author><author><keyname>Wang</keyname><forenames>Zhiming</forenames></author><author><keyname>Zhu</keyname><forenames>Huijia</forenames></author><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author></authors><title>Generalizable Audio Deepfake Detection via Latent Space Refinement and   Augmentation</title><categories>eess.AS cs.SD</categories><comments>Accepted to ICASSP 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in speech synthesis technologies, like text-to-speech (TTS) and voice conversion (VC), have made detecting deepfake speech increasingly challenging. Spoofing countermeasures often struggle to generalize effectively, particularly when faced with unseen attacks. To address this, we propose a novel strategy that integrates Latent Space Refinement (LSR) and Latent Space Augmentation (LSA) to improve the generalization of deepfake detection systems. LSR introduces multiple learnable prototypes for the spoof class, refining the latent space to better capture the intricate variations within spoofed data. LSA further diversifies spoofed data representations by applying augmentation techniques directly in the latent space, enabling the model to learn a broader range of spoofing patterns. We evaluated our approach on four representative datasets, i.e. ASVspoof 2019 LA, ASVspoof 2021 LA and DF, and In-The-Wild. The results show that LSR and LSA perform well individually, and their integration achieves competitive results, matching or surpassing current state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14246</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14246</id><created>2025-01-24</created><authors><author><keyname>Feng</keyname><forenames>Tianzhi</forenames></author><author><keyname>Wu</keyname><forenames>Chennan</forenames></author><author><keyname>Niu</keyname><forenames>Yi</forenames></author><author><keyname>Li</keyname><forenames>Fu</forenames></author><author><keyname>Fu</keyname><forenames>Boxun</forenames></author><author><keyname>Zhao</keyname><forenames>Zhifu</forenames></author><author><keyname>Wang</keyname><forenames>Xiaotian</forenames></author><author><keyname>Shi</keyname><forenames>Guangming</forenames></author></authors><title>Adaptive Progressive Attention Graph Neural Network for EEG Emotion   Recognition</title><categories>eess.SP cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, numerous neuroscientific studies have shown that human emotions are closely linked to specific brain regions, with these regions exhibiting variability across individuals and emotional states. To fully leverage these neural patterns, we propose an Adaptive Progressive Attention Graph Neural Network (APAGNN), which dynamically captures the spatial relationships among brain regions during emotional processing. The APAGNN employs three specialized experts that progressively analyze brain topology. The first expert captures global brain patterns, the second focuses on region-specific features, and the third examines emotion-related channels. This hierarchical approach enables increasingly refined analysis of neural activity. Additionally, a weight generator integrates the outputs of all three experts, balancing their contributions to produce the final predictive label. Extensive experiments on three publicly available datasets (SEED, SEED-IV and MPED) demonstrate that the proposed method enhances EEG emotion recognition performance, achieving superior results compared to baseline methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14249</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14249</id><created>2025-01-24</created><authors><author><keyname>Phan</keyname><forenames>Long</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gatti</keyname><forenames>Alice</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Han</keyname><forenames>Ziwen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Nathaniel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hu</keyname><forenames>Josephina</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Hugh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shi</keyname><forenames>Sean</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Choi</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Agrawal</keyname><forenames>Anish</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chopra</keyname><forenames>Arnav</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Khoja</keyname><forenames>Adam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kim</keyname><forenames>Ryan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hausenloy</keyname><forenames>Jason</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Oliver</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mazeika</keyname><forenames>Mantas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Anderson</keyname><forenames>Daron</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Nguyen</keyname><forenames>Tung</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mahmood</keyname><forenames>Mobeen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Feng</keyname><forenames>Fiona</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Feng</keyname><forenames>Steven Y.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhao</keyname><forenames>Haoran</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yu</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gangal</keyname><forenames>Varun</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zou</keyname><forenames>Chelsea</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Zihan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Jessica P.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kumar</keyname><forenames>Pawan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pokutnyi</keyname><forenames>Oleksandr</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gerbicz</keyname><forenames>Robert</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Popov</keyname><forenames>Serguei</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Levin</keyname><forenames>John-Clark</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kazakov</keyname><forenames>Mstyslav</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Schmitt</keyname><forenames>Johannes</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Galgon</keyname><forenames>Geoff</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sanchez</keyname><forenames>Alvaro</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lee</keyname><forenames>Yongki</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yeadon</keyname><forenames>Will</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sauers</keyname><forenames>Scott</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Roth</keyname><forenames>Marc</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Agu</keyname><forenames>Chidozie</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Riis</keyname><forenames>Søren</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Giska</keyname><forenames>Fabian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Utpala</keyname><forenames>Saiteja</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Giboney</keyname><forenames>Zachary</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Goshu</keyname><forenames>Gashaw M.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Xavier</keyname><forenames>Joan of Arc</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Crowson</keyname><forenames>Sarah-Jane</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Naiya</keyname><forenames>Mohinder Maheshbhai</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Burns</keyname><forenames>Noah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Finke</keyname><forenames>Lennart</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cheng</keyname><forenames>Zerui</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Park</keyname><forenames>Hyunwoo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Fournier-Facio</keyname><forenames>Francesco</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wydallis</keyname><forenames>John</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Nandor</keyname><forenames>Mark</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Singh</keyname><forenames>Ankit</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gehrunger</keyname><forenames>Tim</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cai</keyname><forenames>Jiaqi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>McCarty</keyname><forenames>Ben</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Duclosel</keyname><forenames>Darling</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Nam</keyname><forenames>Jungbae</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zampese</keyname><forenames>Jennifer</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hoerr</keyname><forenames>Ryan G.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bacho</keyname><forenames>Aras</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Loume</keyname><forenames>Gautier Abou</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Galal</keyname><forenames>Abdallah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cao</keyname><forenames>Hangrui</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Garretson</keyname><forenames>Alexis C</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sileo</keyname><forenames>Damien</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ren</keyname><forenames>Qiuyu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cojoc</keyname><forenames>Doru</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Arkhipov</keyname><forenames>Pavel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Qazi</keyname><forenames>Usman</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Lianghui</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Motwani</keyname><forenames>Sumeet</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>de Witt</keyname><forenames>Christian Schroeder</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Taylor</keyname><forenames>Edwin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Veith</keyname><forenames>Johannes</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Singer</keyname><forenames>Eric</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hartman</keyname><forenames>Taylor D.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rissone</keyname><forenames>Paolo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jin</keyname><forenames>Jaehyeok</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shi</keyname><forenames>Jack Wei Lun</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Willcocks</keyname><forenames>Chris G.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Robinson</keyname><forenames>Joshua</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mikov</keyname><forenames>Aleksandar</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Prabhu</keyname><forenames>Ameya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tang</keyname><forenames>Longke</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Alapont</keyname><forenames>Xavier</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Uro</keyname><forenames>Justine Leon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhou</keyname><forenames>Kevin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Santos</keyname><forenames>Emily de Oliveira</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Maksimov</keyname><forenames>Andrey Pupasov</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vendrow</keyname><forenames>Edward</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zenitani</keyname><forenames>Kengo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Guillod</keyname><forenames>Julien</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Yuqi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vendrow</keyname><forenames>Joshua</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kuchkin</keyname><forenames>Vladyslav</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ze-An</keyname><forenames>Ng</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Marion</keyname><forenames>Pierre</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Efremov</keyname><forenames>Denis</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lynch</keyname><forenames>Jayson</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Liang</keyname><forenames>Kaiqu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gritsevskiy</keyname><forenames>Andrew</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Martinez</keyname><forenames>Dakotah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pageler</keyname><forenames>Ben</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Crispino</keyname><forenames>Nick</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zvonkine</keyname><forenames>Dimitri</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Fraga</keyname><forenames>Natanael Wildner</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Soori</keyname><forenames>Saeed</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Press</keyname><forenames>Ori</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tang</keyname><forenames>Henry</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Salazar</keyname><forenames>Julian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Green</keyname><forenames>Sean R.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Brüssel</keyname><forenames>Lina</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Twayana</keyname><forenames>Moon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dieuleveut</keyname><forenames>Aymeric</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rogers</keyname><forenames>T. Ryan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Wenjin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Bikun</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yang</keyname><forenames>Jinzhou</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rao</keyname><forenames>Arun</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Loiseau</keyname><forenames>Gabriel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kalinin</keyname><forenames>Mikhail</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lukas</keyname><forenames>Marco</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Manolescu</keyname><forenames>Ciprian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mishra</keyname><forenames>Subrata</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kamdoum</keyname><forenames>Ariel Ghislain Kemogne</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kreiman</keyname><forenames>Tobias</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hogg</keyname><forenames>Tad</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jin</keyname><forenames>Alvin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bosio</keyname><forenames>Carlo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sun</keyname><forenames>Gongbo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Coppola</keyname><forenames>Brian P</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tarver</keyname><forenames>Tim</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Heidinger</keyname><forenames>Haline</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sayous</keyname><forenames>Rafael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ivanov</keyname><forenames>Stefan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cavanagh</keyname><forenames>Joseph M</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shen</keyname><forenames>Jiawei</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Imperial</keyname><forenames>Joseph Marvin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Schwaller</keyname><forenames>Philippe</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Senthilkuma</keyname><forenames>Shaipranesh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bran</keyname><forenames>Andres M</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dehghan</keyname><forenames>Ali</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Algaba</keyname><forenames>Andres</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Verbeken</keyname><forenames>Brecht</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Noever</keyname><forenames>David</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>P</keyname><forenames>Ragavendran</forenames><suffix>V</suffix><affiliation>Michael Pokorny</affiliation></author><author><keyname>Schut</keyname><forenames>Lisa</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sucholutsky</keyname><forenames>Ilia</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zheltonozhskii</keyname><forenames>Evgenii</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lim</keyname><forenames>Derek</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stanley</keyname><forenames>Richard</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sivarajan</keyname><forenames>Shankar</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yang</keyname><forenames>Tong</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Maar</keyname><forenames>John</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wykowski</keyname><forenames>Julian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Oller</keyname><forenames>Martí</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sandlin</keyname><forenames>Jennifer</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sahu</keyname><forenames>Anmol</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hu</keyname><forenames>Yuzheng</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Fish</keyname><forenames>Sara</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Heydari</keyname><forenames>Nasser</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Apronti</keyname><forenames>Archimedes</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rawal</keyname><forenames>Kaivalya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vilchis</keyname><forenames>Tobias Garcia</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zu</keyname><forenames>Yuexuan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lackner</keyname><forenames>Martin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Koppel</keyname><forenames>James</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Nguyen</keyname><forenames>Jeremy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Antonenko</keyname><forenames>Daniil S.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chern</keyname><forenames>Steffi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhao</keyname><forenames>Bingchen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Arsene</keyname><forenames>Pierrot</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Goldfarb</keyname><forenames>Alan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ivanov</keyname><forenames>Sergey</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Poświata</keyname><forenames>Rafał</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Chenguang</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Daofeng</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Crisostomi</keyname><forenames>Donato</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Achilleos</keyname><forenames>Andrea</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Myklebust</keyname><forenames>Benjamin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sen</keyname><forenames>Archan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Perrella</keyname><forenames>David</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kaparov</keyname><forenames>Nurdin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Inlow</keyname><forenames>Mark H</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zang</keyname><forenames>Allen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Thornley</keyname><forenames>Elliott</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Orel</keyname><forenames>Daniil</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Poritski</keyname><forenames>Vladislav</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ben-David</keyname><forenames>Shalev</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Berger</keyname><forenames>Zachary</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Whitfill</keyname><forenames>Parker</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Foster</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Munro</keyname><forenames>Daniel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ho</keyname><forenames>Linh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hava</keyname><forenames>Dan Bar</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kuchkin</keyname><forenames>Aleksey</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lauff</keyname><forenames>Robert</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Holmes</keyname><forenames>David</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sommerhage</keyname><forenames>Frank</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Schneider</keyname><forenames>Keith</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kazibwe</keyname><forenames>Zakayo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stambaugh</keyname><forenames>Nate</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Singh</keyname><forenames>Mukhwinder</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Magoulas</keyname><forenames>Ilias</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Clarke</keyname><forenames>Don</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kim</keyname><forenames>Dae Hyun</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dias</keyname><forenames>Felipe Meneguitti</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Elser</keyname><forenames>Veit</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Agarwal</keyname><forenames>Kanu Priya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vilchis</keyname><forenames>Victor Efren Guadarrama</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Klose</keyname><forenames>Immo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Demian</keyname><forenames>Christoph</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Anantheswaran</keyname><forenames>Ujjwala</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zweiger</keyname><forenames>Adam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Albani</keyname><forenames>Guglielmo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Jeffery</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Daans</keyname><forenames>Nicolas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Radionov</keyname><forenames>Maksim</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rozhoň</keyname><forenames>Václav</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ma</keyname><forenames>Ziqiao</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stump</keyname><forenames>Christian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Berkani</keyname><forenames>Mohammed</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Platnick</keyname><forenames>Jacob</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Nevirkovets</keyname><forenames>Volodymyr</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Basler</keyname><forenames>Luke</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Piccardo</keyname><forenames>Marco</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jeanplong</keyname><forenames>Ferenc</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cohen</keyname><forenames>Niv</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tkadlec</keyname><forenames>Josef</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rosu</keyname><forenames>Paul</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Padlewski</keyname><forenames>Piotr</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Barzowski</keyname><forenames>Stanislaw</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Montgomery</keyname><forenames>Kyle</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Menezes</keyname><forenames>Aline</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Patel</keyname><forenames>Arkil</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Zixuan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tucker-Foltz</keyname><forenames>Jamie</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stade</keyname><forenames>Jack</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Goertzen</keyname><forenames>Tom</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kazemi</keyname><forenames>Fereshteh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Milbauer</keyname><forenames>Jeremiah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ambay</keyname><forenames>John Arnold</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shukla</keyname><forenames>Abhishek</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Labrador</keyname><forenames>Yan Carlos Leyva</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Givré</keyname><forenames>Alan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wolff</keyname><forenames>Hew</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rossbach</keyname><forenames>Vivien</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Aziz</keyname><forenames>Muhammad Fayez</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kaddar</keyname><forenames>Younesse</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chen</keyname><forenames>Yanxu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Robin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pan</keyname><forenames>Jiayi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Terpin</keyname><forenames>Antonio</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Muennighoff</keyname><forenames>Niklas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Schoelkopf</keyname><forenames>Hailey</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zheng</keyname><forenames>Eric</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Carmi</keyname><forenames>Avishy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jones</keyname><forenames>Adam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shah</keyname><forenames>Jainam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Brown</keyname><forenames>Ethan D. L.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhu</keyname><forenames>Kelin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bartolo</keyname><forenames>Max</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wheeler</keyname><forenames>Richard</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ho</keyname><forenames>Andrew</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Barkan</keyname><forenames>Shaul</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Jiaqi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stehberger</keyname><forenames>Martin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kretov</keyname><forenames>Egor</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sridhar</keyname><forenames>Kaustubh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>EL-Wasif</keyname><forenames>Zienab</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Anji</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pyda</keyname><forenames>Daniel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tam</keyname><forenames>Joanna</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cunningham</keyname><forenames>David M.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Goryachev</keyname><forenames>Vladimir</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Patramanis</keyname><forenames>Demosthenes</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Krause</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Redenti</keyname><forenames>Andrew</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bugas</keyname><forenames>Daniel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Aldous</keyname><forenames>David</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lai</keyname><forenames>Jesyin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Coleman</keyname><forenames>Shannon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bahaloo</keyname><forenames>Mohsen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Xu</keyname><forenames>Jiangnan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lee</keyname><forenames>Sangwon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhao</keyname><forenames>Sandy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tang</keyname><forenames>Ning</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cohen</keyname><forenames>Michael K.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Carroll</keyname><forenames>Micah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Paradise</keyname><forenames>Orr</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kirchner</keyname><forenames>Jan Hendrik</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Steinerberger</keyname><forenames>Stefan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ovchynnikov</keyname><forenames>Maksym</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Matos</keyname><forenames>Jason O.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shenoy</keyname><forenames>Adithya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Junior</keyname><forenames>Benedito Alves de Oliveira</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Nie</keyname><forenames>Yuzhou</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Giordano</keyname><forenames>Paolo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Petersen</keyname><forenames>Philipp</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sztyber-Betley</keyname><forenames>Anna</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shukla</keyname><forenames>Priti</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Crozier</keyname><forenames>Jonathan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pinto</keyname><forenames>Antonella</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Verma</keyname><forenames>Shreyas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Joshi</keyname><forenames>Prashant</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yong</keyname><forenames>Zheng-Xin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tee</keyname><forenames>Allison</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Andréoletti</keyname><forenames>Jérémy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Weller</keyname><forenames>Orion</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Singhal</keyname><forenames>Raghav</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Gang</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ivanov</keyname><forenames>Alexander</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Khoury</keyname><forenames>Seri</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mostaghimi</keyname><forenames>Hamid</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Thaman</keyname><forenames>Kunvar</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chen</keyname><forenames>Qijia</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Khánh</keyname><forenames>Tran Quoc</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Loader</keyname><forenames>Jacob</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cavalleri</keyname><forenames>Stefano</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Szlyk</keyname><forenames>Hannah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Brown</keyname><forenames>Zachary</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Roberts</keyname><forenames>Jonathan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Alley</keyname><forenames>William</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sun</keyname><forenames>Kunyang</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stendall</keyname><forenames>Ryan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lamparth</keyname><forenames>Max</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Reuel</keyname><forenames>Anka</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Ting</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Xu</keyname><forenames>Hanmeng</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Raparthi</keyname><forenames>Sreenivas Goud</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hernández-Cámara</keyname><forenames>Pablo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Martin</keyname><forenames>Freddie</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Malishev</keyname><forenames>Dmitry</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Preu</keyname><forenames>Thomas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Korbak</keyname><forenames>Tomek</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Abramovitch</keyname><forenames>Marcus</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Williamson</keyname><forenames>Dominic</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chen</keyname><forenames>Ziye</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bálint</keyname><forenames>Biró</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bari</keyname><forenames>M Saiful</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kassani</keyname><forenames>Peyman</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Zihao</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ansarinejad</keyname><forenames>Behzad</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Goswami</keyname><forenames>Laxman Prasad</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sun</keyname><forenames>Yewen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Elgnainy</keyname><forenames>Hossam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tordera</keyname><forenames>Daniel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Balabanian</keyname><forenames>George</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Anderson</keyname><forenames>Earth</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kvistad</keyname><forenames>Lynna</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Moyano</keyname><forenames>Alejandro José</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Maheshwari</keyname><forenames>Rajat</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sakor</keyname><forenames>Ahmad</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Eron</keyname><forenames>Murat</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>McAlister</keyname><forenames>Isaac C.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gimenez</keyname><forenames>Javier</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Enyekwe</keyname><forenames>Innocent</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>O.</keyname><forenames>Andrew Favre D.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shah</keyname><forenames>Shailesh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhou</keyname><forenames>Xiaoxiang</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kamalov</keyname><forenames>Firuz</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Clark</keyname><forenames>Ronald</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Abdoli</keyname><forenames>Sherwin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Santens</keyname><forenames>Tim</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Meer</keyname><forenames>Khalida</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Harrison K</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ramakrishnan</keyname><forenames>Kalyan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chen</keyname><forenames>Evan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tomasiello</keyname><forenames>Alessandro</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>De Luca</keyname><forenames>G. Bruno</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Looi</keyname><forenames>Shi-Zhuo</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Le</keyname><forenames>Vinh-Kha</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kolt</keyname><forenames>Noam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mündler</keyname><forenames>Niels</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Semler</keyname><forenames>Avi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rodman</keyname><forenames>Emma</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Drori</keyname><forenames>Jacob</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Fossum</keyname><forenames>Carl J</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jagota</keyname><forenames>Milind</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pradeep</keyname><forenames>Ronak</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Fan</keyname><forenames>Honglu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shah</keyname><forenames>Tej</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Eicher</keyname><forenames>Jonathan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chen</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Thaman</keyname><forenames>Kushal</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Merrill</keyname><forenames>William</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Harris</keyname><forenames>Carter</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gross</keyname><forenames>Jason</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gusev</keyname><forenames>Ilya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sharma</keyname><forenames>Asankhaya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Agnihotri</keyname><forenames>Shashank</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhelnov</keyname><forenames>Pavel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Usawasutsakorn</keyname><forenames>Siranut</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mofayezi</keyname><forenames>Mohammadreza</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bogdanov</keyname><forenames>Sergei</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Piperski</keyname><forenames>Alexander</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Carauleanu</keyname><forenames>Marc</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>David K.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ler</keyname><forenames>Dylan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Leventov</keyname><forenames>Roman</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Soroko</keyname><forenames>Ignat</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jansen</keyname><forenames>Thorben</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lauer</keyname><forenames>Pascal</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Duersch</keyname><forenames>Joshua</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Taamazyan</keyname><forenames>Vage</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Morak</keyname><forenames>Wiktor</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ma</keyname><forenames>Wenjie</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Held</keyname><forenames>William</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Huy</keyname><forenames>Tran Đuc</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Xian</keyname><forenames>Ruicheng</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zebaze</keyname><forenames>Armel Randy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mohamed</keyname><forenames>Mohanad</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Leser</keyname><forenames>Julian Noah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yuan</keyname><forenames>Michelle X</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yacar</keyname><forenames>Laila</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lengler</keyname><forenames>Johannes</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shahrtash</keyname><forenames>Hossein</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Oliveira</keyname><forenames>Edson</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jackson</keyname><forenames>Joseph W.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gonzalez</keyname><forenames>Daniel Espinosa</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zou</keyname><forenames>Andy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chidambaram</keyname><forenames>Muthu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Manik</keyname><forenames>Timothy</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Haffenden</keyname><forenames>Hector</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stander</keyname><forenames>Dashiell</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dasouqi</keyname><forenames>Ali</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Duc</keyname><forenames>Emilien</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Golshani</keyname><forenames>Bita</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Stap</keyname><forenames>David</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Uzhou</keyname><forenames>Mikalai</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhidkovskaya</keyname><forenames>Alina Borisovna</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lewark</keyname><forenames>Lukas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vincze</keyname><forenames>Mátyás</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wehr</keyname><forenames>Dustin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tang</keyname><forenames>Colin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hossain</keyname><forenames>Zaki</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Phillips</keyname><forenames>Shaun</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Muzhen</keyname><forenames>Jiang</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ekström</keyname><forenames>Fredrik</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hammon</keyname><forenames>Angela</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Patel</keyname><forenames>Oam</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Remy</keyname><forenames>Nicolas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Farhidi</keyname><forenames>Faraz</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Medley</keyname><forenames>George</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mohammadzadeh</keyname><forenames>Forough</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Peñaflor</keyname><forenames>Madellene</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kassahun</keyname><forenames>Haile</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Friedrich</keyname><forenames>Alena</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sparrow</keyname><forenames>Claire</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sakal</keyname><forenames>Taom</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dhamane</keyname><forenames>Omkar</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mirabadi</keyname><forenames>Ali Khajegili</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hallman</keyname><forenames>Eric</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Battaglia</keyname><forenames>Mike</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Maghsoudimehrabani</keyname><forenames>Mohammad</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hoang</keyname><forenames>Hieu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Amit</keyname><forenames>Alon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hulbert</keyname><forenames>Dave</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pereira</keyname><forenames>Roberto</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Weber</keyname><forenames>Simon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mensah</keyname><forenames>Stephen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Andre</keyname><forenames>Nathan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Peristyy</keyname><forenames>Anton</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Harjadi</keyname><forenames>Chris</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gupta</keyname><forenames>Himanshu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Malina</keyname><forenames>Stephen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Albanie</keyname><forenames>Samuel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cai</keyname><forenames>Will</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mehkary</keyname><forenames>Mustafa</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Reidegeld</keyname><forenames>Frank</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dick</keyname><forenames>Anna-Katharina</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Friday</keyname><forenames>Cary</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Sidhu</keyname><forenames>Jasdeep</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kim</keyname><forenames>Wanyoung</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Costa</keyname><forenames>Mariana</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gurdogan</keyname><forenames>Hubeyb</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Weber</keyname><forenames>Brian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kumar</keyname><forenames>Harsh</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Jiang</keyname><forenames>Tong</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Agarwal</keyname><forenames>Arunim</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ceconello</keyname><forenames>Chiara</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vaz</keyname><forenames>Warren S.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhuang</keyname><forenames>Chao</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Park</keyname><forenames>Haon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Tawfeek</keyname><forenames>Andrew R.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Aggarwal</keyname><forenames>Daattavya</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kirchhof</keyname><forenames>Michael</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Dai</keyname><forenames>Linjie</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Kim</keyname><forenames>Evan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ferret</keyname><forenames>Johan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Wang</keyname><forenames>Yuzhou</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yan</keyname><forenames>Minghao</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Burdzy</keyname><forenames>Krzysztof</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhang</keyname><forenames>Lixin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Franca</keyname><forenames>Antonio</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Pham</keyname><forenames>Diana T.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Loh</keyname><forenames>Kang Yong</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Robinson</keyname><forenames>Joshua</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Gul</keyname><forenames>Shreen</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Chhablani</keyname><forenames>Gunjan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Du</keyname><forenames>Zhehang</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Cosma</keyname><forenames>Adrian</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>White</keyname><forenames>Colin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Riblet</keyname><forenames>Robin</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Saxena</keyname><forenames>Prajvi</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Votava</keyname><forenames>Jacob</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vinnikov</keyname><forenames>Vladimir</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Delaney</keyname><forenames>Ethan</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Halasyamani</keyname><forenames>Shiv</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Shahid</keyname><forenames>Syed M.</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Mourrat</keyname><forenames>Jean-Christophe</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Vetoshkin</keyname><forenames>Lavr</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bacho</keyname><forenames>Renas</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Ginis</keyname><forenames>Vincent</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Maksapetyan</keyname><forenames>Aleksandr</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>de la Rosa</keyname><forenames>Florencia</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Li</keyname><forenames>Xiuyu</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Malod</keyname><forenames>Guillaume</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Lang</keyname><forenames>Leon</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Laurendeau</keyname><forenames>Julien</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Adesanya</keyname><forenames>Fatimah</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Portier</keyname><forenames>Julien</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Hollom</keyname><forenames>Lawrence</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Souza</keyname><forenames>Victor</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Zhou</keyname><forenames>Yuchen Anna</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Yalın</keyname><forenames>Yiğit</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Obikoya</keyname><forenames>Gbenga Daniel</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Arnaboldi</keyname><forenames>Luca</forenames><affiliation>Michael Pokorny</affiliation></author><author><keyname>Rai</keyname><affiliation>Michael Pokorny</affiliation></author><author><keyname>Bigi</keyname><forenames>Filippo</forenames><affiliation>Quinn</affiliation></author><author><keyname>Bacho</keyname><forenames>Kaniuar</forenames><affiliation>Quinn</affiliation></author><author><keyname>Clavier</keyname><forenames>Pierre</forenames><affiliation>Quinn</affiliation></author><author><keyname>Recchia</keyname><forenames>Gabriel</forenames><affiliation>Quinn</affiliation></author><author><keyname>Popescu</keyname><forenames>Mara</forenames><affiliation>Quinn</affiliation></author><author><keyname>Shulga</keyname><forenames>Nikita</forenames><affiliation>Quinn</affiliation></author><author><keyname>Tanwie</keyname><forenames>Ngefor Mildred</forenames><affiliation>Quinn</affiliation></author><author><keyname>Lux</keyname><forenames>Thomas C. H.</forenames><affiliation>Quinn</affiliation></author><author><keyname>Rank</keyname><forenames>Ben</forenames><affiliation>Quinn</affiliation></author><author><keyname>Ni</keyname><forenames>Colin</forenames><affiliation>Quinn</affiliation></author><author><keyname>Yakimchyk</keyname><forenames>Alesia</forenames><affiliation>Quinn</affiliation></author><author><keyname>Huanxu</keyname><affiliation>Quinn</affiliation></author><author><keyname>Liu</keyname><affiliation>Tony</affiliation></author><author><keyname>Häggström</keyname><forenames>Olle</forenames><affiliation>Tony</affiliation></author><author><keyname>Verkama</keyname><forenames>Emil</forenames><affiliation>Tony</affiliation></author><author><keyname>Narayan</keyname><forenames>Himanshu</forenames><affiliation>Tony</affiliation></author><author><keyname>Gundlach</keyname><forenames>Hans</forenames><affiliation>Tony</affiliation></author><author><keyname>Brito-Santana</keyname><forenames>Leonor</forenames><affiliation>Tony</affiliation></author><author><keyname>Amaro</keyname><forenames>Brian</forenames><affiliation>Tony</affiliation></author><author><keyname>Vajipey</keyname><forenames>Vivek</forenames><affiliation>Tony</affiliation></author><author><keyname>Grover</keyname><forenames>Rynaa</forenames><affiliation>Tony</affiliation></author><author><keyname>Fan</keyname><forenames>Yiyang</forenames><affiliation>Tony</affiliation></author><author><keyname>Silva</keyname><forenames>Gabriel Poesia Reis e</forenames><affiliation>Tony</affiliation></author><author><keyname>Xin</keyname><forenames>Linwei</forenames><affiliation>Tony</affiliation></author><author><keyname>Kratish</keyname><forenames>Yosi</forenames><affiliation>Tony</affiliation></author><author><keyname>Łucki</keyname><forenames>Jakub</forenames><affiliation>Tony</affiliation></author><author><keyname>Li</keyname><forenames>Wen-Ding</forenames><affiliation>Tony</affiliation></author><author><keyname>Xu</keyname><forenames>Justin</forenames><affiliation>Tony</affiliation></author><author><keyname>Scaria</keyname><forenames>Kevin Joseph</forenames><affiliation>Tony</affiliation></author><author><keyname>Vargus</keyname><forenames>Freddie</forenames><affiliation>Tony</affiliation></author><author><keyname>Habibi</keyname><forenames>Farzad</forenames><affiliation>Tony</affiliation></author><author><keyname>Long</keyname><affiliation>Tony</affiliation></author><author><keyname>Lian</keyname></author><author><keyname>Rodolà</keyname><forenames>Emanuele</forenames></author><author><keyname>Robins</keyname><forenames>Jules</forenames></author><author><keyname>Cheng</keyname><forenames>Vincent</forenames></author><author><keyname>Grabb</keyname><forenames>Declan</forenames></author><author><keyname>Bosio</keyname><forenames>Ida</forenames></author><author><keyname>Fruhauff</keyname><forenames>Tony</forenames></author><author><keyname>Akov</keyname><forenames>Ido</forenames></author><author><keyname>Lo</keyname><forenames>Eve J. Y.</forenames></author><author><keyname>Qi</keyname><forenames>Hao</forenames></author><author><keyname>Jiang</keyname><forenames>Xi</forenames></author><author><keyname>Segev</keyname><forenames>Ben</forenames></author><author><keyname>Fan</keyname><forenames>Jingxuan</forenames></author><author><keyname>Martinson</keyname><forenames>Sarah</forenames></author><author><keyname>Wang</keyname><forenames>Erik Y.</forenames></author><author><keyname>Hausknecht</keyname><forenames>Kaylie</forenames></author><author><keyname>Brenner</keyname><forenames>Michael P.</forenames></author><author><keyname>Mao</keyname><forenames>Mao</forenames></author><author><keyname>Jiang</keyname><forenames>Yibo</forenames></author><author><keyname>Zhang</keyname><forenames>Xinyu</forenames></author><author><keyname>Avagian</keyname><forenames>David</forenames></author><author><keyname>Scipio</keyname><forenames>Eshawn Jessica</forenames></author><author><keyname>Siddiqi</keyname><forenames>Muhammad Rehan</forenames></author><author><keyname>Ragoler</keyname><forenames>Alon</forenames></author><author><keyname>Tan</keyname><forenames>Justin</forenames></author><author><keyname>Patil</keyname><forenames>Deepakkumar</forenames></author><author><keyname>Plecnik</keyname><forenames>Rebeka</forenames></author><author><keyname>Kirtland</keyname><forenames>Aaron</forenames></author><author><keyname>Montecillo</keyname><forenames>Roselynn Grace</forenames></author><author><keyname>Durand</keyname><forenames>Stephane</forenames></author><author><keyname>Bodur</keyname><forenames>Omer Faruk</forenames></author><author><keyname>Adoul</keyname><forenames>Zahra</forenames></author><author><keyname>Zekry</keyname><forenames>Mohamed</forenames></author><author><keyname>Douville</keyname><forenames>Guillaume</forenames></author><author><keyname>Karakoc</keyname><forenames>Ali</forenames></author><author><keyname>Santos</keyname><forenames>Tania C. B.</forenames></author><author><keyname>Shamseldeen</keyname><forenames>Samir</forenames></author><author><keyname>Karim</keyname><forenames>Loukmane</forenames></author><author><keyname>Liakhovitskaia</keyname><forenames>Anna</forenames></author><author><keyname>Resman</keyname><forenames>Nate</forenames></author><author><keyname>Farina</keyname><forenames>Nicholas</forenames></author><author><keyname>Gonzalez</keyname><forenames>Juan Carlos</forenames></author><author><keyname>Maayan</keyname><forenames>Gabe</forenames></author><author><keyname>Hoback</keyname><forenames>Sarah</forenames></author><author><keyname>Pena</keyname><forenames>Rodrigo De Oliveira</forenames></author><author><keyname>Sherman</keyname><forenames>Glen</forenames></author><author><keyname>Mariji</keyname><forenames>Hodjat</forenames></author><author><keyname>Pouriamanesh</keyname><forenames>Rasoul</forenames></author><author><keyname>Wu</keyname><forenames>Wentao</forenames></author><author><keyname>Demir</keyname><forenames>Gözdenur</forenames></author><author><keyname>Mendoza</keyname><forenames>Sandra</forenames></author><author><keyname>Alarab</keyname><forenames>Ismail</forenames></author><author><keyname>Cole</keyname><forenames>Joshua</forenames></author><author><keyname>Ferreira</keyname><forenames>Danyelle</forenames></author><author><keyname>Johnson</keyname><forenames>Bryan</forenames></author><author><keyname>Milliron</keyname><forenames>Hsiaoyun</forenames></author><author><keyname>Safdari</keyname><forenames>Mohammad</forenames></author><author><keyname>Dai</keyname><forenames>Liangti</forenames></author><author><keyname>Arthornthurasuk</keyname><forenames>Siriphan</forenames></author><author><keyname>Pronin</keyname><forenames>Alexey</forenames></author><author><keyname>Fan</keyname><forenames>Jing</forenames></author><author><keyname>Ramirez-Trinidad</keyname><forenames>Angel</forenames></author><author><keyname>Cartwright</keyname><forenames>Ashley</forenames></author><author><keyname>Pottmaier</keyname><forenames>Daphiny</forenames></author><author><keyname>Taheri</keyname><forenames>Omid</forenames></author><author><keyname>Outevsky</keyname><forenames>David</forenames></author><author><keyname>Stepanic</keyname><forenames>Stanley</forenames></author><author><keyname>Perry</keyname><forenames>Samuel</forenames></author><author><keyname>Askew</keyname><forenames>Luke</forenames></author><author><keyname>Rodríguez</keyname><forenames>Raúl Adrián Huerta</forenames></author><author><keyname>Dendane</keyname><forenames>Abdelkader</forenames></author><author><keyname>Ali</keyname><forenames>Sam</forenames></author><author><keyname>Lorena</keyname><forenames>Ricardo</forenames></author><author><keyname>Iyer</keyname><forenames>Krishnamurthy</forenames></author><author><keyname>Salauddin</keyname><forenames>Sk Md</forenames></author><author><keyname>Islam</keyname><forenames>Murat</forenames></author><author><keyname>Gonzalez</keyname><forenames>Juan</forenames></author><author><keyname>Ducey</keyname><forenames>Josh</forenames></author><author><keyname>Campbell</keyname><forenames>Russell</forenames></author><author><keyname>Somrak</keyname><forenames>Maja</forenames></author><author><keyname>Mavroudis</keyname><forenames>Vasilios</forenames></author><author><keyname>Vergo</keyname><forenames>Eric</forenames></author><author><keyname>Qin</keyname><forenames>Juehang</forenames></author><author><keyname>Borbás</keyname><forenames>Benjámin</forenames></author><author><keyname>Chu</keyname><forenames>Eric</forenames></author><author><keyname>Lindsey</keyname><forenames>Jack</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Anil</forenames></author><author><keyname>Jallon</keyname><forenames>Antoine</forenames></author><author><keyname>McInnis</keyname><forenames>I. M. J.</forenames></author><author><keyname>Hoover</keyname><forenames>Alex</forenames></author><author><keyname>Möller</keyname><forenames>Sören</forenames></author><author><keyname>Bian</keyname><forenames>Song</forenames></author><author><keyname>Lai</keyname><forenames>John</forenames></author><author><keyname>Patwardhan</keyname><forenames>Tejal</forenames></author><author><keyname>Yue</keyname><forenames>Summer</forenames></author><author><keyname>Wang</keyname><forenames>Alexandr</forenames></author><author><keyname>Hendrycks</keyname><forenames>Dan</forenames></author></authors><title>Humanity's Last Exam</title><categories>cs.LG cs.AI cs.CL</categories><comments>25 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 3,000 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at https://lastexam.ai. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14250</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14250</id><created>2025-01-24</created><authors><author><keyname>Zhao</keyname><forenames>Yi</forenames></author><author><keyname>Zhang</keyname><forenames>Youzhi</forenames></author></authors><title>Siren: A Learning-Based Multi-Turn Attack Framework for Simulating   Real-World Human Jailbreak Behaviors</title><categories>cs.CL cs.AI cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Large language models (LLMs) are widely used in real-world applications, raising concerns about their safety and trustworthiness. While red-teaming with jailbreak prompts exposes the vulnerabilities of LLMs, current efforts focus primarily on single-turn attacks, overlooking the multi-turn strategies used by real-world adversaries. Existing multi-turn methods rely on static patterns or predefined logical chains, failing to account for the dynamic strategies during attacks. We propose Siren, a learning-based multi-turn attack framework designed to simulate real-world human jailbreak behaviors. Siren consists of three stages: (1) training set construction utilizing Turn-Level LLM feedback (Turn-MF), (2) post-training attackers with supervised fine-tuning (SFT) and direct preference optimization (DPO), and (3) interactions between the attacking and target LLMs. Experiments demonstrate that Siren achieves an attack success rate (ASR) of 90% with LLaMA-3-8B as the attacker against Gemini-1.5-Pro as the target model, and 70% with Mistral-7B against GPT-4o, significantly outperforming single-turn baselines. Moreover, Siren with a 7B-scale model achieves performance comparable to a multi-turn baseline that leverages GPT-4o as the attacker, while requiring fewer turns and employing decomposition strategies that are better semantically aligned with attack goals. We hope Siren inspires the development of stronger defenses against advanced multi-turn jailbreak attacks under realistic scenarios. Code is available at https://github.com/YiyiyiZhao/siren. Warning: This paper contains potentially harmful text. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14253</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14253</id><created>2025-01-24</created><authors><author><keyname>Tanaka</keyname><forenames>Tomonari</forenames></author><author><keyname>Hanada</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Yang</keyname><forenames>Hanting</forenames></author><author><keyname>Aoyama</keyname><forenames>Tatsuya</forenames></author><author><keyname>Inatsu</keyname><forenames>Yu</forenames></author><author><keyname>Akahane</keyname><forenames>Satoshi</forenames></author><author><keyname>Okura</keyname><forenames>Yoshito</forenames></author><author><keyname>Hashimoto</keyname><forenames>Noriaki</forenames></author><author><keyname>Murayama</keyname><forenames>Taro</forenames></author><author><keyname>Lee</keyname><forenames>Hanju</forenames></author><author><keyname>Kojima</keyname><forenames>Shinya</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Distributionally Robust Coreset Selection under Covariate Shift</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Coreset selection, which involves selecting a small subset from an existing training dataset, is an approach to reducing training data, and various approaches have been proposed for this method. In practical situations where these methods are employed, it is often the case that the data distributions differ between the development phase and the deployment phase, with the latter being unknown. Thus, it is challenging to select an effective subset of training data that performs well across all deployment scenarios. We therefore propose Distributionally Robust Coreset Selection (DRCS). DRCS theoretically derives an estimate of the upper bound for the worst-case test error, assuming that the future covariate distribution may deviate within a defined range from the training distribution. Furthermore, by selecting instances in a way that suppresses the estimate of the upper bound for the worst-case test error, DRCS achieves distributionally robust training instance selection. This study is primarily applicable to convex training computation, but we demonstrate that it can also be applied to deep learning under appropriate approximations. In this paper, we focus on covariate shift, a type of data distribution shift, and demonstrate the effectiveness of DRCS through experiments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14256</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14256</id><created>2025-01-24</created><authors><author><keyname>Zhou</keyname><forenames>Yiyun</forenames></author><author><keyname>Han</keyname><forenames>Wenkang</forenames></author><author><keyname>Chen</keyname><forenames>Jingyuan</forenames></author></authors><title>Revisiting Applicable and Comprehensive Knowledge Tracing in Large-Scale   Data</title><categories>cs.LG cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge Tracing (KT) is a fundamental component of Intelligent Tutoring Systems (ITS), enabling the modeling of students' knowledge states to predict future performance. The introduction of Deep Knowledge Tracing (DKT), the first deep learning-based KT (DLKT) model, has brought significant advantages in terms of applicability and comprehensiveness. However, recent DLKT models, such as Attentive Knowledge Tracing (AKT), have often prioritized predictive performance at the expense of these benefits. While deep sequential models like DKT have shown potential, they face challenges related to parallel computing, storage decision modification, and limited storage capacity. To address these limitations, we propose DKT2, a novel KT model that leverages the recently developed xLSTM architecture. DKT2 enhances input representation using the Rasch model and incorporates Item Response Theory (IRT) for interpretability, allowing for the decomposition of learned knowledge into familiar and unfamiliar knowledge. By integrating this knowledge with predicted questions, DKT2 generates comprehensive knowledge states. Extensive experiments conducted across three large-scale datasets demonstrate that DKT2 consistently outperforms 17 baseline models in various prediction tasks, underscoring its potential for real-world educational applications. This work bridges the gap between theoretical advancements and practical implementation in KT.Our code and datasets will be available at https://github.com/codebase-2025/DKT2. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14257</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14257</id><created>2025-01-24</created><authors><author><keyname>Nitin</keyname><forenames>Vikram</forenames></author><author><keyname>Krishna</keyname><forenames>Rahul</forenames></author><author><keyname>Valle</keyname><forenames>Luiz Lemos do</forenames></author><author><keyname>Ray</keyname><forenames>Baishakhi</forenames></author></authors><title>C2SaferRust: Transforming C Projects into Safer Rust with NeuroSymbolic   Techniques</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, there has been a lot of interest in converting C code to Rust, to benefit from the memory and thread safety guarantees of Rust. C2Rust is a rule-based system that can automatically convert C code to functionally identical Rust, but the Rust code that it produces is non-idiomatic, i.e., makes extensive use of unsafe Rust, a subset of the language that doesn't have memory or thread safety guarantees. At the other end of the spectrum are LLMs, which produce idiomatic Rust code, but these have the potential to make mistakes and are constrained in the length of code they can process. In this paper, we present C2SaferRust, a novel approach to translate C to Rust that combines the strengths of C2Rust and LLMs. We first use C2Rust to convert C code to non-idiomatic, unsafe Rust. We then decompose the unsafe Rust code into slices that can be individually translated to safer Rust by an LLM. After processing each slice, we run end-to-end test cases to verify that the code still functions as expected. We also contribute a benchmark of 7 real-world programs, translated from C to unsafe Rust using C2Rust. Each of these programs also comes with end-to-end test cases. On this benchmark, we are able to reduce the number of raw pointers by up to 38%, and reduce the amount of unsafe code by up to 28%, indicating an increase in safety. The resulting programs still pass all test cases. C2SaferRust also shows convincing gains in performance against two previous techniques for making Rust code safer. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14259</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14259</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Huisheng</forenames></author><author><keyname>Zhao</keyname><forenames>H. Vicky</forenames></author></authors><title>Optimal Investment under Mutual Strategy Influence among Agents</title><categories>eess.SY cs.SY math.OC q-fin.MF q-fin.PM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In financial markets, agents often mutually influence each other's investment strategies and adjust their strategies to align with others. However, there is limited quantitative study of agents' investment strategies in such scenarios. In this work, we formulate the optimal investment differential game problem to study the mutual influence among agents. We derive the analytical solutions for agents' optimal strategies and propose a fast algorithm to find approximate solutions with low computational complexity. We theoretically analyze the impact of mutual influence on agents' optimal strategies and terminal wealth. When the mutual influence is strong and approaches infinity, we show that agents' optimal strategies converge to the asymptotic strategy. Furthermore, in general cases, we prove that agents' optimal strategies are linear combinations of the asymptotic strategy and their rational strategies without others' influence. We validate the performance of the fast algorithm and verify the correctness of our analysis using numerical experiments. This work is crucial to comprehend mutual influence among agents and design effective mechanisms to guide their strategies in financial markets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14264</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14264</id><created>2025-01-24</created><authors><author><keyname>Tang</keyname><forenames>Xiaojun</forenames></author><author><keyname>Wang</keyname><forenames>Jingru</forenames></author><author><keyname>Huang</keyname><forenames>Guangwei</forenames></author><author><keyname>Chen</keyname><forenames>Guannan</forenames></author><author><keyname>Zheng</keyname><forenames>Rui</forenames></author><author><keyname>Huai</keyname><forenames>Lian</forenames></author><author><keyname>Liu</keyname><forenames>Yuyu</forenames></author><author><keyname>Jiang</keyname><forenames>Xingqun</forenames></author></authors><title>CDI: Blind Image Restoration Fidelity Evaluation based on Consistency   with Degraded Image</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advancements in Blind Image Restoration (BIR) methods, based on Generative Adversarial Networks and Diffusion Models, have significantly improved visual quality. However, they present significant challenges for Image Quality Assessment (IQA), as the existing Full-Reference IQA methods often rate images with high perceptual quality poorly. In this paper, we reassess the Solution Non-Uniqueness and Degradation Indeterminacy issues of BIR, and propose constructing a specific BIR IQA system. In stead of directly comparing a restored image with a reference image, the BIR IQA evaluates fidelity by calculating the Consistency with Degraded Image (CDI). Specifically, we propose a wavelet domain Reference Guided CDI algorithm, which can acquire the consistency with a degraded image for various types without requiring knowledge of degradation parameters. The supported degradation types include down sampling, blur, noise, JPEG and complex combined degradations etc. In addition, we propose a Reference Agnostic CDI, enabling BIR fidelity evaluation without reference images. Finally, in order to validate the rationality of CDI, we create a new Degraded Images Switch Display Comparison Dataset (DISDCD) for subjective evaluation of BIR fidelity. Experiments conducted on DISDCD verify that CDI is markedly superior to common Full Reference IQA methods for BIR fidelity evaluation. The source code and the DISDCD dataset will be publicly available shortly. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14265</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14265</id><created>2025-01-24</created><authors><author><keyname>Huang</keyname><forenames>Guoxi</forenames></author><author><keyname>Anantrasirichai</keyname><forenames>Nantheera</forenames></author><author><keyname>Ye</keyname><forenames>Fei</forenames></author><author><keyname>Qi</keyname><forenames>Zipeng</forenames></author><author><keyname>Lin</keyname><forenames>RuiRui</forenames></author><author><keyname>Yang</keyname><forenames>Qirui</forenames></author><author><keyname>Bull</keyname><forenames>David</forenames></author></authors><title>Bayesian Neural Networks for One-to-Many Mapping in Image Enhancement</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In image enhancement tasks, such as low-light and underwater image enhancement, a degraded image can correspond to multiple plausible target images due to dynamic photography conditions, such as variations in illumination. This naturally results in a one-to-many mapping challenge. To address this, we propose a Bayesian Enhancement Model (BEM) that incorporates Bayesian Neural Networks (BNNs) to capture data uncertainty and produce diverse outputs. To achieve real-time inference, we introduce a two-stage approach: Stage I employs a BNN to model the one-to-many mappings in the low-dimensional space, while Stage II refines fine-grained image details using a Deterministic Neural Network (DNN). To accelerate BNN training and convergence, we introduce a dynamic \emph{Momentum Prior}. Extensive experiments on multiple low-light and underwater image enhancement benchmarks demonstrate the superiority of our method over deterministic models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14266</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14266</id><created>2025-01-24</created><authors><author><keyname>Kosieradzki</keyname><forenames>Mitch</forenames></author><author><keyname>Choi</keyname><forenames>Seongjin</forenames></author></authors><title>TrajFlow: A Generative Framework for Occupancy Density Estimation Using   Normalizing Flows</title><categories>cs.LG</categories><comments>10 pages 6 figures 3 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In transportation systems and autonomous vehicles, intelligent agents must understand the future motion of traffic participants to effectively plan motion trajectories. At the same time, the motion of traffic participants is inherently uncertain. In this paper, we propose TrajFlow, a generative framework for estimating the occupancy density of traffic participants. Our framework utilizes a causal encoder to extract semantically meaningful embeddings of the observed trajectory, as well as a normalizing flow to decode these embeddings and determine the most likely future location of traffic participants at some time point in the future. Our formulation differs from existing approaches because we model the marginal distribution of spatial locations instead of the joint distribution of unobserved trajectories. The advantages of a marginal formulation are numerous. First, we demonstrate that the marginal formulation produces higher accuracy on challenging trajectory forecasting benchmarks. Second, the marginal formulation allows for a fully continuous sampling of future locations. Finally, marginal densities are better suited for downstream tasks as they allow for the computation of per-agent motion trajectories and occupancy grids, the two most commonly used representations for motion forecasting. We present a novel architecture based entirely on neural differential equations as an implementation of this framework and provide ablations to demonstrate the advantages of a continuous implementation over a more traditional discrete neural network based approach. The code is available at https://github.com/kosieram21/TrajFlow . </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14268</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14268</id><created>2025-01-24</created><authors><author><keyname>Jiang</keyname><forenames>Zhenhao</forenames></author><author><keyname>Chen</keyname><forenames>Chenghao</forenames></author><author><keyname>Feng</keyname><forenames>Hao</forenames></author><author><keyname>Yang</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Jin</forenames></author><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Jia</keyname><forenames>Jia</forenames></author><author><keyname>Hu</keyname><forenames>Ning</forenames></author></authors><title>Pre-train and Fine-tune: Recommenders as Large Models</title><categories>cs.IR cs.AI</categories><comments>Accepted by WWW2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In reality, users have different interests in different periods, regions, scenes, etc. Such changes in interest are so drastic that they are difficult to be captured by recommenders. Existing multi-domain learning can alleviate this problem. However, the structure of the industrial recommendation system is complex, the amount of data is huge, and the training cost is extremely high, so it is difficult to modify the structure of the industrial recommender and re-train it. To fill this gap, we consider recommenders as large pre-trained models and fine-tune them. We first propose the theory of the information bottleneck for fine-tuning and present an explanation for the fine-tuning technique in recommenders. To tailor for recommendation, we design an information-aware adaptive kernel (IAK) technique to fine-tune the pre-trained recommender. Specifically, we define fine-tuning as two phases: knowledge compression and knowledge matching and let the training stage of IAK explicitly approximate these two phases. Our proposed approach designed from the essence of fine-tuning is well interpretable. Extensive online and offline experiments show the superiority of our proposed method. Besides, we also share unique and important lessons we learned when deploying the method in a large-scale online platform. We also present the potential issues of fine-tuning techniques in recommendation systems and the corresponding solutions. The recommender with IAK technique has been deployed on the homepage of a billion-scale online food platform for several months and has yielded considerable profits in our business. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14269</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14269</id><created>2025-01-24</created><authors><author><keyname>Zhang</keyname><forenames>Shengzhe</forenames></author><author><keyname>Chen</keyname><forenames>Liyi</forenames></author><author><keyname>Shen</keyname><forenames>Dazhong</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Xiong</keyname><forenames>Hui</forenames></author></authors><title>Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential   Recommendation</title><categories>cs.IR cs.AI</categories><comments>Accepted to WWW 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-modal sequential recommendation (SR) leverages multi-modal data to learn more comprehensive item features and user preferences than traditional SR methods, which has become a critical topic in both academia and industry. Existing methods typically focus on enhancing multi-modal information utility through adaptive modality fusion to capture the evolving of user preference from user-item interaction sequences. However, most of them overlook the interference caused by redundant interest-irrelevant information contained in rich multi-modal data. Additionally, they primarily rely on implicit temporal information based solely on chronological ordering, neglecting explicit temporal signals that could more effectively represent dynamic user interest over time. To address these limitations, we propose a Hierarchical time-aware Mixture of experts for multi-modal Sequential Recommendation (HM4SR) with a two-level Mixture of Experts (MoE) and a multi-task learning strategy. Specifically, the first MoE, named Interactive MoE, extracts essential user interest-related information from the multi-modal data of each item. Then, the second MoE, termed Temporal MoE, captures user dynamic interests by introducing explicit temporal embeddings from timestamps in modality encoding. To further address data sparsity, we propose three auxiliary supervision tasks: sequence-level category prediction (CP) for item feature understanding, contrastive learning on ID (IDCL) to align sequence context with user interests, and placeholder contrastive learning (PCL) to integrate temporal information with modalities for dynamic interest modeling. Extensive experiments on four public datasets verify the effectiveness of HM4SR compared to several state-of-the-art approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14270</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14270</id><created>2025-01-24</created><authors><author><keyname>Jayarathne</keyname><forenames>Harindu</forenames></author><author><keyname>Wickremasinghe</keyname><forenames>Tharindu</forenames></author><author><keyname>Hemachandra</keyname><forenames>Kasun T.</forenames></author><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author></authors><title>Max-Min Fairness for IRS-Assisted Secure Two-Way Communications</title><categories>cs.IT math.IT</categories><comments>This paper has been accepted for presentation at IEEE Wireless   Communications and Networking Conference (WCNC) 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates an intelligent reflective surface (IRS) assisted secure multi-user two-way communication system. The aim of this paper is to enhance the physical layer security by optimizing the minimum secrecy-rate among all user-pairs in the presence of a malicious user. The optimization problem is converted into an alternating optimization problem consisting of two sub-problems. Transmit power optimization is handled using a fractional programming method, whereas IRS phase shift optimization is handled with semi-definite programming. The convergence of the proposed algorithm is investigated numerically. The performance gain in minimum secrecy-rate is quantified for four different user configurations in comparison to the baseline scheme. Results indicate a 3.6-fold gain in minimum secrecy rate over the baseline scheme when the IRS is positioned near a legitimate user, even when the malicious user is located close to the same legitimate user. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14271</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14271</id><created>2025-01-24</created><authors><author><keyname>Mitsuka</keyname><forenames>Yoshihiro</forenames></author><author><keyname>Golestan</keyname><forenames>Shadan</forenames></author><author><keyname>Sufiyan</keyname><forenames>Zahin</forenames></author><author><keyname>Schoepp</keyname><forenames>Sheila</forenames></author><author><keyname>Miwa</keyname><forenames>Shotaro</forenames></author><author><keyname>Zaïane</keyname><forenames>Osmar R.</forenames></author></authors><title>TLXML: Task-Level Explanation of Meta-Learning via Influence Functions</title><categories>cs.LG</categories><comments>22 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The scheme of adaptation via meta-learning is seen as an ingredient for solving the problem of data shortage or distribution shift in real-world applications, but it also brings the new risk of inappropriate updates of the model in the user environment, which increases the demand for explainability. Among the various types of XAI methods, establishing a method of explanation based on past experience in meta-learning requires special consideration due to its bi-level structure of training, which has been left unexplored. In this work, we propose influence functions for explaining meta-learning that measure the sensitivities of training tasks to adaptation and inference. We also argue that the approximation of the Hessian using the Gauss-Newton matrix resolves computational barriers peculiar to meta-learning. We demonstrate the adequacy of the method through experiments on task distinction and task distribution distinction using image classification tasks with MAML and Prototypical Network. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14273</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14273</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Tianrui</forenames></author><author><keyname>Ge</keyname><forenames>Meng</forenames></author><author><keyname>Gong</keyname><forenames>Cheng</forenames></author><author><keyname>Qiang</keyname><forenames>Chunyu</forenames></author><author><keyname>Wang</keyname><forenames>Haoyu</forenames></author><author><keyname>Huang</keyname><forenames>Zikang</forenames></author><author><keyname>Jiang</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Xiaobao</forenames></author><author><keyname>Chen</keyname><forenames>Xie</forenames></author><author><keyname>Wang</keyname><forenames>Longbiao</forenames></author><author><keyname>Dang</keyname><forenames>Jianwu</forenames></author></authors><title>Characteristic-Specific Partial Fine-Tuning for Efficient Emotion and   Speaker Adaptation in Codec Language Text-to-Speech Models</title><categories>eess.AS cs.SD</categories><comments>13 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently, emotional speech generation and speaker cloning have garnered significant interest in text-to-speech (TTS). With the open-sourcing of codec language TTS models trained on massive datasets with large-scale parameters, adapting these general pre-trained TTS models to generate speech with specific emotional expressions and target speaker characteristics has become a topic of great attention. Common approaches, such as full and adapter-based fine-tuning, often overlook the specific contributions of model parameters to emotion and speaker control. Treating all parameters uniformly during fine-tuning, especially when the target data has limited content diversity compared to the pre-training corpus, results in slow training speed and an increased risk of catastrophic forgetting. To address these challenges, we propose a characteristic-specific partial fine-tuning strategy, short as CSP-FT. First, we use a weighted-sum approach to analyze the contributions of different Transformer layers in a pre-trained codec language TTS model for emotion and speaker control in the generated speech. We then selectively fine-tune the layers with the highest and lowest characteristic-specific contributions to generate speech with target emotional expression and speaker identity. Experimental results demonstrate that our method achieves performance comparable to, or even surpassing, full fine-tuning in generating speech with specific emotional expressions and speaker identities. Additionally, CSP-FT delivers approximately 2x faster training speeds, fine-tunes only around 8% of parameters, and significantly reduces catastrophic forgetting. Furthermore, we show that codec language TTS models perform competitively with self-supervised models in speaker identification and emotion classification tasks, offering valuable insights for developing universal speech processing models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14275</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14275</id><created>2025-01-24</created><authors><author><keyname>Mahdavi</keyname><forenames>Sadegh</forenames></author><author><keyname>Li</keyname><forenames>Muchen</forenames></author><author><keyname>Liu</keyname><forenames>Kaiwen</forenames></author><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author><author><keyname>Sigal</keyname><forenames>Leonid</forenames></author><author><keyname>Liao</keyname><forenames>Renjie</forenames></author></authors><title>Leveraging Online Olympiad-Level Math Problems for LLMs Training and   Contamination-Resistant Evaluation</title><categories>cs.CL cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Advances in Large Language Models (LLMs) have sparked interest in their ability to solve Olympiad-level math problems. However, the training and evaluation of these models are constrained by the limited size and quality of available datasets, as creating large-scale data for such advanced problems requires extensive effort from human experts. In addition, current benchmarks are prone to contamination, leading to unreliable evaluations. In this paper, we present an automated pipeline that leverages the rich resources of the Art of Problem Solving (AoPS) forum, which predominantly features Olympiad-level problems and community-driven solutions. Using open-source LLMs, we develop a method to extract question-answer pairs from the forum, resulting in AoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our experiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their reasoning abilities across various benchmarks. Moreover, we build an automatic pipeline that introduces LiveAoPSBench, an evolving evaluation set with timestamps, derived from the latest forum data, providing a contamination-resistant benchmark for assessing LLM performance. Notably, we observe a significant decline in LLM performance over time, suggesting their success on older examples may stem from pre-training exposure rather than true reasoning ability. Our work presents a scalable approach to creating and maintaining large-scale, high-quality datasets for advanced math reasoning, offering valuable insights into the capabilities and limitations of LLMs in this domain. Our benchmark and code is available at https://github.com/DSL-Lab/aops </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14276</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14276</id><created>2025-01-24</created><authors><author><keyname>Liang</keyname><forenames>Yuxuan</forenames></author><author><keyname>Li</keyname><forenames>Xu</forenames></author><author><keyname>Chen</keyname><forenames>Xiaolei</forenames></author><author><keyname>Chen</keyname><forenames>Haotian</forenames></author><author><keyname>Zheng</keyname><forenames>Yi</forenames></author><author><keyname>Lai</keyname><forenames>Chenghang</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author><author><keyname>Xue</keyname><forenames>Xiangyang</forenames></author></authors><title>Global Semantic-Guided Sub-image Feature Weight Allocation in   High-Resolution Large Vision-Language Models</title><categories>cs.CV cs.AI</categories><comments>10 pages, 10 figures and tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the demand for high-resolution image processing in Large Vision-Language Models (LVLMs) grows, sub-image partitioning has become a popular approach for mitigating visual information loss associated with fixed-resolution processing. However, existing partitioning methods uniformly process sub-images, resulting in suboptimal image understanding. In this work, we reveal that the sub-images with higher semantic relevance to the entire image encapsulate richer visual information for preserving the model's visual understanding ability. Therefore, we propose the Global Semantic-guided Weight Allocator (GSWA) module, which dynamically allocates weights to sub-images based on their relative information density, emulating human visual attention mechanisms. This approach enables the model to focus on more informative regions, overcoming the limitations of uniform treatment. We integrate GSWA into the InternVL2-2B framework to create SleighVL, a lightweight yet high-performing model. Extensive experiments demonstrate that SleighVL outperforms models with comparable parameters and remains competitive with larger models. Our work provides a promising direction for more efficient and contextually aware high-resolution image processing in LVLMs, advancing multimodal system development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14277</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14277</id><created>2025-01-24</created><authors><author><keyname>Lee</keyname><forenames>JongMin</forenames></author><author><keyname>Yoo</keyname><forenames>Sungjoo</forenames></author></authors><title>Dense-SfM: Structure from Motion with Dense Consistent Matching</title><categories>cs.CV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We present Dense-SfM, a novel Structure from Motion (SfM) framework designed for dense and accurate 3D reconstruction from multi-view images. Sparse keypoint matching, which traditional SfM methods often rely on, limits both accuracy and point density, especially in texture-less areas. Dense-SfM addresses this limitation by integrating dense matching with a Gaussian Splatting (GS) based track extension which gives more consistent, longer feature tracks. To further improve reconstruction accuracy, Dense-SfM is equipped with a multi-view kernelized matching module leveraging transformer and Gaussian Process architectures, for robust track refinement across multi-views. Evaluations on the ETH3D and Texture-Poor SfM datasets show that Dense-SfM offers significant improvements in accuracy and density over state-of-the-art methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14278</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14278</id><created>2025-01-24</created><authors><author><keyname>Park</keyname><forenames>Jaehyun</forenames></author><author><keyname>Park</keyname><forenames>Dongmin</forenames></author><author><keyname>Lee</keyname><forenames>Jae-Gil</forenames></author></authors><title>Active Learning for Continual Learning: Keeping the Past Alive in the   Present</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continual learning (CL) enables deep neural networks to adapt to ever-changing data distributions. In practice, there may be scenarios where annotation is costly, leading to active continual learning (ACL), which performs active learning (AL) for the CL scenarios when reducing the labeling cost by selecting the most informative subset is preferable. However, conventional AL strategies are not suitable for ACL, as they focus solely on learning the new knowledge, leading to catastrophic forgetting of previously learned tasks. Therefore, ACL requires a new AL strategy that can balance the prevention of catastrophic forgetting and the ability to quickly learn new tasks. In this paper, we propose AccuACL, Accumulated informativeness-based Active Continual Learning, by the novel use of the Fisher information matrix as a criterion for sample selection, derived from a theoretical analysis of the Fisher-optimality preservation properties within the framework of ACL, while also addressing the scalability issue of Fisher information-based AL. Extensive experiments demonstrate that AccuACL significantly outperforms AL baselines across various CL algorithms, increasing the average accuracy and forgetting by 23.8% and 17.0%, respectively, in average. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14279</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14279</id><created>2025-01-24</created><authors><author><keyname>Lei</keyname><forenames>Yiming</forenames></author><author><keyname>Nguyen</keyname><forenames>Michael</forenames></author><author><keyname>Liu</keyname><forenames>Tzu Chia</forenames></author><author><keyname>Oh</keyname><forenames>Hyounkyun</forenames></author></authors><title>Deep Learning-Powered Classification of Thoracic Diseases in Chest   X-Rays</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chest X-rays play a pivotal role in diagnosing respiratory diseases such as pneumonia, tuberculosis, and COVID-19, which are prevalent and present unique diagnostic challenges due to overlapping visual features and variability in image quality. Severe class imbalance and the complexity of medical images hinder automated analysis. This study leverages deep learning techniques, including transfer learning on pre-trained models (AlexNet, ResNet, and InceptionNet), to enhance disease detection and classification. By fine-tuning these models and incorporating focal loss to address class imbalance, significant performance improvements were achieved. Grad-CAM visualizations further enhance model interpretability, providing insights into clinically relevant regions influencing predictions. The InceptionV3 model, for instance, achieved a 28% improvement in AUC and a 15% increase in F1-Score. These findings highlight the potential of deep learning to improve diagnostic workflows and support clinical decision-making. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14280</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14280</id><created>2025-01-24</created><authors><author><keyname>Kindle</keyname><forenames>Julien</forenames></author><author><keyname>Loetscher</keyname><forenames>Michael</forenames></author><author><keyname>Alessandretti</keyname><forenames>Andrea</forenames></author><author><keyname>Cadena</keyname><forenames>Cesar</forenames></author><author><keyname>Hutter</keyname><forenames>Marco</forenames></author></authors><title>Enhancing Robotic Precision in Construction: A Modular Factor   Graph-Based Framework to Deflection and Backlash Compensation Using   High-Accuracy Accelerometers</title><categories>cs.RO</categories><comments>8 pages, 7 figures, Accepted on November 2024 at IEEE Robotics and   Automation Letters</comments><journal-ref>IEEE Robotics and Automation Letters, vol. 10, no. 1, pp. 288-295,   Jan. 2025</journal-ref><doi>10.1109/LRA.2024.3506276</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Accurate positioning is crucial in the construction industry, where labor shortages highlight the need for automation. Robotic systems with long kinematic chains are required to reach complex workspaces, including floors, walls, and ceilings. These requirements significantly impact positioning accuracy due to effects such as deflection and backlash in various parts along the kinematic chain. In this work, we introduce a novel approach that integrates deflection and backlash compensation models with high-accuracy accelerometers, significantly enhancing position accuracy. Our method employs a modular framework based on a factor graph formulation to estimate the state of the kinematic chain, leveraging acceleration measurements to inform the model. Extensive testing on publicly released datasets, reflecting real-world construction disturbances, demonstrates the advantages of our approach. The proposed method reduces the $95\%$ error threshold in the xy-plane by $50\%$ compared to the state-of-the-art Virtual Joint Method, and by $31\%$ when incorporating base tilt compensation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14284</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14284</id><created>2025-01-24</created><authors><author><keyname>Ahouei</keyname><forenames>Saba Sadeghi</forenames></author><author><keyname>Antipov</keyname><forenames>Denis</forenames></author><author><keyname>Neumann</keyname><forenames>Aneta</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author></authors><title>Feature-based Evolutionary Diversity Optimization of Discriminating   Instances for Chance-constrained Optimization Problems</title><categories>cs.NE math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithm selection is crucial in the field of optimization, as no single algorithm performs perfectly across all types of optimization problems. Finding the best algorithm among a given set of algorithms for a given problem requires a detailed analysis of the problem's features. To do so, it is important to have a diverse set of benchmarking instances highlighting the difference in algorithms' performance. In this paper, we evolve diverse benchmarking instances for chance-constrained optimization problems that contain stochastic components characterized by their expected values and variances. These instances clearly differentiate the performance of two given algorithms, meaning they are easy to solve by one algorithm and hard to solve by the other. We introduce a $(\mu+1)~EA$ for feature-based diversity optimization to evolve such differentiating instances. We study the chance-constrained maximum coverage problem with stochastic weights on the vertices as an example of chance-constrained optimization problems. The experimental results demonstrate that our method successfully generates diverse instances based on different features while effectively distinguishing the performance between a pair of algorithms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14285</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14285</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Shengcai</forenames></author><author><keyname>Lv</keyname><forenames>Haoze</forenames></author><author><keyname>Wang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Tang</keyname><forenames>Ke</forenames></author></authors><title>Cascaded Large-Scale TSP Solving with Unified Neural Guidance: Bridging   Local and Population-based Search</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traveling salesman problem (TSP) is a fundamental NP-hard optimization problem. This work presents UNiCS, a novel unified neural-guided cascaded solver for solving large-scale TSP instances. UNiCS comprises a local search (LS) phase and a population-based search (PBS) phase, both guided by a learning component called unified neural guidance (UNG). Specifically, UNG guides solution generation across both phases and determines appropriate phase transition timing to effectively combine the complementary strengths of LS and PBS. While trained only on simple distributions with relatively small-scale TSP instances, UNiCS generalizes effectively to challenging TSP benchmarks containing much larger instances (10,000-71,009 nodes) with diverse node distributions entirely unseen during training. Experimental results on the large-scale TSP instances demonstrate that UNiCS consistently outperforms state-of-the-art methods, with its advantage remaining consistent across various runtime budgets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14287</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14287</id><created>2025-01-24</created><authors><author><keyname>Yang</keyname><forenames>Xilin</forenames></author><author><keyname>Fanous</keyname><forenames>Michael John</forenames></author><author><keyname>Chen</keyname><forenames>Hanlong</forenames></author><author><keyname>Lee</keyname><forenames>Ryan</forenames></author><author><keyname>Costa</keyname><forenames>Paloma Casteleiro</forenames></author><author><keyname>Li</keyname><forenames>Yuhang</forenames></author><author><keyname>Huang</keyname><forenames>Luzhe</forenames></author><author><keyname>Zhang</keyname><forenames>Yijie</forenames></author><author><keyname>Ozcan</keyname><forenames>Aydogan</forenames></author></authors><title>Snapshot multi-spectral imaging through defocusing and a Fourier imager   network</title><categories>physics.optics cs.CV cs.LG physics.app-ph</categories><comments>22 Pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-spectral imaging, which simultaneously captures the spatial and spectral information of a scene, is widely used across diverse fields, including remote sensing, biomedical imaging, and agricultural monitoring. Here, we introduce a snapshot multi-spectral imaging approach employing a standard monochrome image sensor with no additional spectral filters or customized components. Our system leverages the inherent chromatic aberration of wavelength-dependent defocusing as a natural source of physical encoding of multi-spectral information; this encoded image information is rapidly decoded via a deep learning-based multi-spectral Fourier Imager Network (mFIN). We experimentally tested our method with six illumination bands and demonstrated an overall accuracy of 92.98% for predicting the illumination channels at the input and achieved a robust multi-spectral image reconstruction on various test objects. This deep learning-powered framework achieves high-quality multi-spectral image reconstruction using snapshot image acquisition with a monochrome image sensor and could be useful for applications in biomedicine, industrial quality control, and agriculture, among others. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14288</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14288</id><created>2025-01-24</created><authors><author><keyname>Gao</keyname><forenames>Lifu</forenames></author><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Liu</keyname><forenames>Ziwei</forenames></author></authors><title>A Comprehensive Framework for Semantic Similarity Detection Using   Transformer Architectures and Enhanced Ensemble Techniques</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting AI-generated text, especially in short-context documents, is difficult because there is not enough context for accurate classification. This paper presents a new teacher-student model that uses domain adaptation and data augmentation to solve these problems. The teacher model, which combines DeBERTa-v3-large and Mamba-790m, learns semantic knowledge through domain-specific fine-tuning. The student model handles short-context text more efficiently. The system uses a Mean Squared Error (MSE) loss function to guide the student's learning, improving both accuracy and efficiency. Also, data augmentation methods like spelling correction and error injection make the model more robust. Experimental results show that this approach works better than baseline methods, proving its usefulness for real-time AI-generated text detection and other text classification tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14289</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14289</id><created>2025-01-24</created><authors><author><keyname>Monemi</keyname><forenames>Mehdi</forenames></author><author><keyname>Rasti</keyname><forenames>Mehdi</forenames></author><author><keyname>Mousavi</keyname><forenames>S. Ali</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Higher-Order Meta Distribution Analysis of Wireless Systems with   Application to the Reliability of UWB THz Networks</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication reliability, as defined by 3GPP, refers to the probability of providing a desired quality of service (QoS). This metric is typically quantified for wireless networks by averaging the QoS success indicator over spatial and temporal random variables. Recently, the meta distribution (MD) has emerged as a two-level performance analysis tool for wireless networks, offering a detailed examination of the outer level (i.e., system-level) reliability assessment versus the inner level (i.e., link-level) reliability thresholds. Most existing studies focus on first-order spatiotemporal MD reliability analyses, and the benefits of leveraging MD reliability for applications beyond this structure remain unexplored, a gap addressed in this paper. We present wireless application examples that can benefit the higher-order MD reliability analysis. Specifically, we provide the analysis and numerical results for a second-order spatial-spectral-temporal MD reliability of ultra-wideband THz communication. The results demonstrate the value of the hierarchical representation of MD reliability across three domains and the impact of the inner-layer target reliability on the overall MD reliability measure. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14291</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14291</id><created>2025-01-24</created><authors><author><keyname>Zhou</keyname><forenames>Feng</forenames></author><author><keyname>Kong</keyname><forenames>Quyu</forenames></author><author><keyname>Zhang</keyname><forenames>Yixuan</forenames></author></authors><title>Advances in Temporal Point Processes: Bayesian, Deep, and LLM Approaches</title><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Temporal point processes (TPPs) are stochastic process models used to characterize event sequences occurring in continuous time. Traditional statistical TPPs have a long-standing history, with numerous models proposed and successfully applied across diverse domains. In recent years, advances in deep learning have spurred the development of neural TPPs, enabling greater flexibility and expressiveness in capturing complex temporal dynamics. The emergence of large language models (LLMs) has further sparked excitement, offering new possibilities for modeling and analyzing event sequences by leveraging their rich contextual understanding. This survey presents a comprehensive review of recent research on TPPs from three perspectives: Bayesian, deep learning, and LLM approaches. We begin with a review of the fundamental concepts of TPPs, followed by an in-depth discussion of model design and parameter estimation techniques in these three frameworks. We also revisit classic application areas of TPPs to highlight their practical relevance. Finally, we outline challenges and promising directions for future research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14294</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14294</id><created>2025-01-24</created><authors><author><keyname>Jeoung</keyname><forenames>Sullam</forenames></author><author><keyname>Ge</keyname><forenames>Yubin</forenames></author><author><keyname>Wang</keyname><forenames>Haohan</forenames></author><author><keyname>Diesner</keyname><forenames>Jana</forenames></author></authors><title>Examining Alignment of Large Language Models through Representative   Heuristics: The Case of Political Stereotypes</title><categories>cs.CL cs.AI</categories><comments>ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Examining the alignment of large language models (LLMs) has become increasingly important, particularly when these systems fail to operate as intended. This study explores the challenge of aligning LLMs with human intentions and values, with specific focus on their political inclinations. Previous research has highlighted LLMs' propensity to display political leanings, and their ability to mimic certain political parties' stances on various issues. However, the extent and conditions under which LLMs deviate from empirical positions have not been thoroughly examined. To address this gap, our study systematically investigates the factors contributing to LLMs' deviations from empirical positions on political issues, aiming to quantify these deviations and identify the conditions that cause them.   Drawing on cognitive science findings related to representativeness heuristics -- where individuals readily recall the representative attribute of a target group in a way that leads to exaggerated beliefs -- we scrutinize LLM responses through this heuristics lens. We conduct experiments to determine how LLMs exhibit stereotypes by inflating judgments in favor of specific political parties. Our results indicate that while LLMs can mimic certain political parties' positions, they often exaggerate these positions more than human respondents do. Notably, LLMs tend to overemphasize representativeness to a greater extent than humans. This study highlights the susceptibility of LLMs to representativeness heuristics, suggeseting potential vulnerabilities to political stereotypes. We propose prompt-based mitigation strategies that demonstrate effectiveness in reducing the influence of representativeness in LLM responses. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14296</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14296</id><created>2025-01-24</created><authors><author><keyname>Schnabel</keyname><forenames>Julian A.</forenames></author><author><keyname>Trippas</keyname><forenames>Johanne R.</forenames></author><author><keyname>Scholer</keyname><forenames>Falk</forenames></author><author><keyname>Hettiachchi</keyname><forenames>Danula</forenames></author></authors><title>Multi-stage Large Language Model Pipelines Can Outperform GPT-4o in   Relevance Assessment</title><categories>cs.IR</categories><comments>WebConf'25, WWW'25</comments><acm-class>H.3.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The effectiveness of search systems is evaluated using relevance labels that indicate the usefulness of documents for specific queries and users. While obtaining these relevance labels from real users is ideal, scaling such data collection is challenging. Consequently, third-party annotators are employed, but their inconsistent accuracy demands costly auditing, training, and monitoring. We propose an LLM-based modular classification pipeline that divides the relevance assessment task into multiple stages, each utilising different prompts and models of varying sizes and capabilities. Applied to TREC Deep Learning (TREC-DL), one of our approaches showed an 18.4% Krippendorff's $\alpha$ accuracy increase over OpenAI's GPT-4o mini while maintaining a cost of about 0.2 USD per million input tokens, offering a more efficient and scalable solution for relevance assessment. This approach beats the baseline performance of GPT-4o (5 USD). With a pipeline approach, even the accuracy of the GPT-4o flagship model, measured in $\alpha$, could be improved by 9.7%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14298</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14298</id><created>2025-01-24</created><authors><author><keyname>Fields</keyname><forenames>Chris</forenames></author><author><keyname>Glazebrook</keyname><forenames>James F.</forenames></author><author><keyname>Marciano</keyname><forenames>Antonino</forenames></author><author><keyname>Zappala</keyname><forenames>Emanuele</forenames></author></authors><title>Whether a quantum computation employs nonlocal resources is   operationally undecidable</title><categories>quant-ph cs.CC</categories><comments>15 pp</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Computational complexity characterizes the usage of spatial and temporal resources by computational processes. In the classical theory of computation, e.g. in the Turing Machine model, computational processes employ only local space and time resources, and their resource usage can be accurately measured by us as users. General relativity and quantum theory, however, introduce the possibility of computational processes that employ nonlocal spatial or temporal resources. While the space and time complexity of classical computing can be given a clear operational meaning, this is no longer the case in any setting involving nonlocal resources. In such settings, theoretical analyses of resource usage cease to be reliable indicators of practical computational capability. We prove that the verifier (C) in a multiple interactive provers with shared entanglement (MIP*) protocol cannot operationally demonstrate that the "multiple" provers are independent, i.e. cannot operationally distinguish a MIP* machine from a monolithic quantum computer. Thus C cannot operationally distinguish a MIP* machine from a quantum TM, and hence cannot operationally demonstrate the solution to arbitrary problems in RE. Any claim that a MIP* machine has solved a TM-undecidable problem is, therefore, circular, as the problem of deciding whether a physical system is a MIP* machine is itself TM-undecidable. Consequently, despite the space and time complexity of classical computing having a clear operational meaning, this is no longer the case in any setting involving nonlocal resources. In such settings, theoretical analyses of resource usage cease to be reliable indicators of practical computational capability. This has practical consequences when assessing newly proposed computational frameworks based on quantum theories. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14300</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14300</id><created>2025-01-24</created><authors><author><keyname>Liang</keyname><forenames>Xujian</forenames></author><author><keyname>Gu</keyname><forenames>Zhaoquan</forenames></author></authors><title>Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large   Language Model on Knowledge Graph</title><categories>cs.AI cs.CL cs.LG cs.SI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes the naive RAG system a step further by integrating graph information, such as knowledge graph (KGs), into large-scale language models (LLMs) to mitigate hallucination. However, existing GRAG still encounter limitations: 1) simple paradigms usually fail with the complex problems due to the narrow and shallow correlations capture from KGs 2) methods of strong coupling with KGs tend to be high computation cost and time consuming if the graph is dense. In this paper, we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for enabling LLMs to think ``community by community" within KGs. To do this, FastToG employs community detection for deeper correlation capture and two stages community pruning - coarse and fine pruning for faster retrieval. Furthermore, we also develop two Community-to-Text methods to convert the graph structure of communities into textual form for better understanding by LLMs. Experimental results demonstrate the effectiveness of FastToG, showcasing higher accuracy, faster reasoning, and better explainability compared to the previous works. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14302</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14302</id><created>2025-01-24</created><authors><author><keyname>Xiao</keyname><forenames>Xi</forenames></author><author><keyname>Li</keyname><forenames>Zhengji</forenames></author><author><keyname>Wang</keyname><forenames>Wentao</forenames></author><author><keyname>Xie</keyname><forenames>Jiacheng</forenames></author><author><keyname>Lin</keyname><forenames>Houjie</forenames></author><author><keyname>Roy</keyname><forenames>Swalpa Kumar</forenames></author><author><keyname>Wang</keyname><forenames>Tianyang</forenames></author><author><keyname>Xu</keyname><forenames>Min</forenames></author></authors><title>TD-RD: A Top-Down Benchmark with Real-Time Framework for Road Damage   Detection</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object detection has witnessed remarkable advancements over the past decade, largely driven by breakthroughs in deep learning and the proliferation of large scale datasets. However, the domain of road damage detection remains relatively under explored, despite its critical significance for applications such as infrastructure maintenance and road safety. This paper addresses this gap by introducing a novel top down benchmark that offers a complementary perspective to existing datasets, specifically tailored for road damage detection. Our proposed Top Down Road Damage Detection Dataset (TDRD) includes three primary categories of road damage cracks, potholes, and patches captured from a top down viewpoint. The dataset consists of 7,088 high resolution images, encompassing 12,882 annotated instances of road damage. Additionally, we present a novel real time object detection framework, TDYOLOV10, designed to handle the unique challenges posed by the TDRD dataset. Comparative studies with state of the art models demonstrate competitive baseline results. By releasing TDRD, we aim to accelerate research in this crucial area. A sample of the dataset will be made publicly available upon the paper's acceptance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14304</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14304</id><created>2025-01-24</created><authors><author><keyname>Gan</keyname><forenames>Bingzheng</forenames></author><author><keyname>Zhao</keyname><forenames>Yufan</forenames></author><author><keyname>Zhang</keyname><forenames>Tianyi</forenames></author><author><keyname>Huang</keyname><forenames>Jing</forenames></author><author><keyname>Li</keyname><forenames>Yusu</forenames></author><author><keyname>Teo</keyname><forenames>Shu Xian</forenames></author><author><keyname>Zhang</keyname><forenames>Changwang</forenames></author><author><keyname>Shi</keyname><forenames>Wei</forenames></author></authors><title>MASTER: A Multi-Agent System with LLM Specialized MCTS</title><categories>cs.AI</categories><comments>Accepted by main NAACL 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large Language Models (LLM) are increasingly being explored for problem-solving tasks. However, their strategic planning capability is often viewed with skepticism. Recent studies have incorporated the Monte Carlo Tree Search (MCTS) algorithm to augment the planning capacity of LLM. Despite its potential, MCTS relies on extensive sampling simulations to approximate the true reward distribution, leading to two primary issues. Firstly, MCTS is effective for tasks like the Game of Go, where simulation results can yield objective rewards (e.g., 1 for a win and 0 for a loss). However, for tasks such as question answering, the result of a simulation is the answer to the question, which cannot obtain an objective reward without the ground truth. Secondly, obtaining statistically significant reward estimations typically requires a sample size exceeding 30 simulations, resulting in excessive token usage and time consumption. To address these challenges, we present Multi-Agent System with Tactical Execution and Reasoning using LLM Specialized MCTS (MASTER), a novel framework that coordinates agent recruitment and communication using LLM specialized MCTS. This system autonomously adjusts the number of agents based on task complexity and ensures focused communication among them. Comprehensive experiments across various tasks demonstrate the effectiveness of our proposed framework. It achieves 76% accuracy on HotpotQA and 80% on WebShop, setting new state-of-the-art performance on these datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14305</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14305</id><created>2025-01-24</created><authors><author><keyname>Yeung</keyname><forenames>Calvin</forenames></author><author><keyname>Yu</keyname><forenames>Jeff</forenames></author><author><keyname>Cheung</keyname><forenames>King Chau</forenames></author><author><keyname>Wong</keyname><forenames>Tat Wing</forenames></author><author><keyname>Chan</keyname><forenames>Chun Man</forenames></author><author><keyname>Wong</keyname><forenames>Kin Chi</forenames></author><author><keyname>Fujii</keyname><forenames>Keisuke</forenames></author></authors><title>A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher   Education</title><categories>cs.CY cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Automated grading has become an essential tool in education technology due to its ability to efficiently assess large volumes of student work, provide consistent and unbiased evaluations, and deliver immediate feedback to enhance learning. However, current systems face significant limitations, including the need for large datasets in few-shot learning methods, a lack of personalized and actionable feedback, and an overemphasis on benchmark performance rather than student experience. To address these challenges, we propose a Zero-Shot Large Language Model (LLM)-Based Automated Assignment Grading (AAG) system. This framework leverages prompt engineering to evaluate both computational and explanatory student responses without requiring additional training or fine-tuning. The AAG system delivers tailored feedback that highlights individual strengths and areas for improvement, thereby enhancing student learning outcomes. Our study demonstrates the system's effectiveness through comprehensive evaluations, including survey responses from higher education students that indicate significant improvements in motivation, understanding, and preparedness compared to traditional grading methods. The results validate the AAG system's potential to transform educational assessment by prioritizing learning experiences and providing scalable, high-quality feedback. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14306</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14306</id><created>2025-01-24</created><authors><author><keyname>Khod</keyname><forenames>Sunita</forenames></author><author><keyname>Dvivedi</keyname><forenames>Akshay</forenames></author><author><keyname>Goswami</keyname><forenames>Mayank</forenames></author></authors><title>Additive Manufacturing Processes Protocol Prediction by Artificial   Intelligence using X-ray Computed Tomography data</title><categories>cs.CV physics.app-ph</categories><comments>21 pages, 21 figures, 5 tables</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The quality of the part fabricated from the Additive Manufacturing (AM) process depends upon the process parameters used, and therefore, optimization is required for apt quality. A methodology is proposed to set these parameters non-iteratively without human intervention. It utilizes Artificial Intelligence (AI) to fully automate the process, with the capability to self-train any apt AI model by further assimilating the training data.This study includes three commercially available 3D printers for soft material printing based on the Material Extrusion (MEX) AM process. The samples are 3D printed for six different AM process parameters obtained by varying layer height and nozzle speed. The novelty part of the methodology is incorporating an AI-based image segmentation step in the decision-making stage that uses quality inspected training data from the Non-Destructive Testing (NDT) method. The performance of the trained AI model is compared with the two software tools based on the classical thresholding method. The AI-based Artificial Neural Network (ANN) model is trained from NDT-assessed and AI-segmented data to automate the selection of optimized process parameters. The AI-based model is 99.3 % accurate, while the best available commercial classical image method is 83.44 % accurate. The best value of overall R for training ANN is 0.82. The MEX process gives a 22.06 % porosity error relative to the design. The NDT-data trained two AI models integrated into a series pipeline for optimal process parameters are proposed and verified by classical optimization and mechanical testing methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14308</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14308</id><created>2025-01-24</created><authors><author><keyname>Lee</keyname><forenames>Insu</forenames></author><author><keyname>Kim</keyname><forenames>Jiseob</forenames></author><author><keyname>Shim</keyname><forenames>Kyuhong</forenames></author><author><keyname>Shim</keyname><forenames>Byonghyo</forenames></author></authors><title>Learning Primitive Relations for Compositional Zero-Shot Learning</title><categories>cs.CV cs.AI</categories><comments>Accepted to ICASSP 2025</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Compositional Zero-Shot Learning (CZSL) aims to identify unseen state-object compositions by leveraging knowledge learned from seen compositions. Existing approaches often independently predict states and objects, overlooking their relationships. In this paper, we propose a novel framework, learning primitive relations (LPR), designed to probabilistically capture the relationships between states and objects. By employing the cross-attention mechanism, LPR considers the dependencies between states and objects, enabling the model to infer the likelihood of unseen compositions. Experimental results demonstrate that LPR outperforms state-of-the-art methods on all three CZSL benchmark datasets in both closed-world and open-world settings. Through qualitative analysis, we show that LPR leverages state-object relationships for unseen composition prediction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14309</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14309</id><created>2025-01-24</created><authors><author><keyname>Tian</keyname><forenames>Zhibo</forenames></author><author><keyname>Quan</keyname><forenames>Ruijie</forenames></author><author><keyname>Ma</keyname><forenames>Fan</forenames></author><author><keyname>Zhan</keyname><forenames>Kun</forenames></author><author><keyname>Yang</keyname><forenames>Yi</forenames></author></authors><title>BrainGuard: Privacy-Preserving Multisubject Image Reconstructions from   Brain Activities</title><categories>cs.CV</categories><comments>AAAI 2025 oral</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reconstructing perceived images from human brain activity forms a crucial link between human and machine learning through Brain-Computer Interfaces. Early methods primarily focused on training separate models for each individual to account for individual variability in brain activity, overlooking valuable cross-subject commonalities. Recent advancements have explored multisubject methods, but these approaches face significant challenges, particularly in data privacy and effectively managing individual variability. To overcome these challenges, we introduce BrainGuard, a privacy-preserving collaborative training framework designed to enhance image reconstruction from multisubject fMRI data while safeguarding individual privacy. BrainGuard employs a collaborative global-local architecture where individual models are trained on each subject's local data and operate in conjunction with a shared global model that captures and leverages cross-subject patterns. This architecture eliminates the need to aggregate fMRI data across subjects, thereby ensuring privacy preservation. To tackle the complexity of fMRI data, BrainGuard integrates a hybrid synchronization strategy, enabling individual models to dynamically incorporate parameters from the global model. By establishing a secure and collaborative training environment, BrainGuard not only protects sensitive brain data but also improves the image reconstructions accuracy. Extensive experiments demonstrate that BrainGuard sets a new benchmark in both high-level and low-level metrics, advancing the state-of-the-art in brain decoding through its innovative design. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14310</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14310</id><created>2025-01-24</created><authors><author><keyname>Espinosa</keyname><forenames>Raquel</forenames></author><author><keyname>Sánchez</keyname><forenames>Gracia</forenames></author><author><keyname>Palma</keyname><forenames>José</forenames></author><author><keyname>Jiménez</keyname><forenames>Fernando</forenames></author></authors><title>Permutation-based multi-objective evolutionary feature selection for   high-dimensional data</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Feature selection is a critical step in the analysis of high-dimensional data, where the number of features often vastly exceeds the number of samples. Effective feature selection not only improves model performance and interpretability but also reduces computational costs and mitigates the risk of overfitting. In this context, we propose a novel feature selection method for high-dimensional data, based on the well-known permutation feature importance approach, but extending it to evaluate subsets of attributes rather than individual features. This extension more effectively captures how interactions among features influence model performance. The proposed method employs a multi-objective evolutionary algorithm to search for candidate feature subsets, with the objectives of maximizing the degradation in model performance when the selected features are shuffled, and minimizing the cardinality of the feature subset. The effectiveness of our method has been validated on a set of 24 publicly available high-dimensional datasets for classification and regression tasks, and compared against 9 well-established feature selection methods designed for high-dimensional problems, including the conventional permutation feature importance method. The results demonstrate the ability of our approach in balancing accuracy and computational efficiency, providing a powerful tool for feature selection in complex, high-dimensional datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14311</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14311</id><created>2025-01-24</created><authors><author><keyname>Suvra</keyname><forenames>Debashis Kar</forenames></author></authors><title>An Efficient Real Time DDoS Detection Model Using Machine Learning   Algorithms</title><categories>cs.LG</categories><comments>7 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Denial of Service attacks have become a significant threat to industries and governments leading to substantial financial losses. With the growing reliance on internet services, DDoS attacks can disrupt services by overwhelming servers with false traffic causing downtime and data breaches. Although various detection techniques exist, selecting an effective method remains challenging due to trade-offs between time efficiency and accuracy. This research focuses on developing an efficient real-time DDoS detection system using machine learning algorithms leveraging the UNB CICDDoS2019 dataset including various traffic features. The study aims to classify DDoS and non-DDoS traffic through various ML classifiers including Logistic Regression, K-Nearest Neighbors, Random Forest, Support Vector Machine, Naive Bayes. The dataset is preprocessed through data cleaning, standardization and feature selection techniques using Principal Component Analysis. The research explores the performance of these algorithms in terms of precision, recall and F1-score as well as time complexity to create a reliable system capable of real-time detection and mitigation of DDoS attacks. The findings indicate that RF, AdaBoost and XGBoost outperform other algorithms in accuracy and efficiency, making them ideal candidates for real-time applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14312</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14312</id><created>2025-01-24</created><authors><author><keyname>Cao</keyname><forenames>Shiyi</forenames></author><author><keyname>Wang</keyname><forenames>Yichuan</forenames></author><author><keyname>Mao</keyname><forenames>Ziming</forenames></author><author><keyname>Hsu</keyname><forenames>Pin-Lun</forenames></author><author><keyname>Yin</keyname><forenames>Liangsheng</forenames></author><author><keyname>Xia</keyname><forenames>Tian</forenames></author><author><keyname>Li</keyname><forenames>Dacheng</forenames></author><author><keyname>Liu</keyname><forenames>Shu</forenames></author><author><keyname>Zhang</keyname><forenames>Yineng</forenames></author><author><keyname>Zhou</keyname><forenames>Yang</forenames></author><author><keyname>Sheng</keyname><forenames>Ying</forenames></author><author><keyname>Gonzalez</keyname><forenames>Joseph</forenames></author><author><keyname>Stoica</keyname><forenames>Ion</forenames></author></authors><title>Locality-aware Fair Scheduling in LLM Serving</title><categories>cs.DC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large language model (LLM) inference workload dominates a wide variety of modern AI applications, ranging from multi-turn conversation to document analysis. Balancing fairness and efficiency is critical for managing diverse client workloads with varying prefix patterns. Unfortunately, existing fair scheduling algorithms for LLM serving, such as Virtual Token Counter (VTC), fail to take prefix locality into consideration and thus suffer from poor performance. On the other hand, locality-aware scheduling algorithms in existing LLM serving frameworks tend to maximize the prefix cache hit rate without considering fair sharing among clients.   This paper introduces the first locality-aware fair scheduling algorithm, Deficit Longest Prefix Match (DLPM), which can maintain a high degree of prefix locality with a fairness guarantee. We also introduce a novel algorithm, Double Deficit LPM (D$^2$LPM), extending DLPM for the distributed setup that can find a balance point among fairness, locality, and load-balancing. Our extensive evaluation demonstrates the superior performance of DLPM and D$^2$LPM in ensuring fairness while maintaining high throughput (up to 2.87$\times$ higher than VTC) and low per-client (up to 7.18$\times$ lower than state-of-the-art distributed LLM serving system) latency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14313</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14313</id><created>2025-01-24</created><authors><author><keyname>Maßny</keyname><forenames>Luis</forenames></author><author><keyname>Bitar</keyname><forenames>Rawad</forenames></author><author><keyname>Ye</keyname><forenames>Fangwei</forenames></author><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author></authors><title>Between Close Enough to Reveal and Far Enough to Protect: a New Privacy   Region for Correlated Data</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When users make personal privacy choices, correlation between their data can cause inadvertent leakage about users who do not want to share their data by other users sharing their data. As a solution, we consider local redaction mechanisms. As prior works proposed data-independent privatization mechanisms, we study the family of data-independent local redaction mechanisms and upper-bound their utility when data correlation is modeled by a stationary Markov process. In contrast, we derive a novel data-dependent mechanism, which improves the utility by leveraging a data-dependent leakage measure. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14314</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14314</id><created>2025-01-24</created><authors><author><keyname>Qi</keyname><forenames>Han</forenames></author><author><keyname>Guo</keyname><forenames>Fei</forenames></author><author><keyname>Zhu</keyname><forenames>Li</forenames></author><author><keyname>Zhang</keyname><forenames>Qiaosheng</forenames></author><author><keyname>Li</keyname><forenames>Xuelong</forenames></author></authors><title>Graph Feedback Bandits on Similar Arms: With and Without Graph   Structures</title><categories>cs.LG</categories><comments>arXiv admin note: substantial text overlap with arXiv:2405.11171</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the stochastic multi-armed bandit problem with graph feedback. Motivated by applications in clinical trials and recommendation systems, we assume that two arms are connected if and only if they are similar (i.e., their means are close to each other). We establish a regret lower bound for this problem under the novel feedback structure and introduce two upper confidence bound (UCB)-based algorithms: Double-UCB, which has problem-independent regret upper bounds, and Conservative-UCB, which has problem-dependent upper bounds. Leveraging the similarity structure, we also explore a scenario where the number of arms increases over time (referred to as the \emph{ballooning setting}). Practical applications of this scenario include Q\&amp;A platforms (e.g., Reddit, Stack Overflow, Quora) and product reviews on platforms like Amazon and Flipkart, where answers (or reviews) continuously appear, and the goal is to display the best ones at the top. We extend these two UCB-based algorithms to the ballooning setting. Under mild assumptions, we provide regret upper bounds for both algorithms and discuss their sub-linearity. Furthermore, we propose a new version of the corresponding algorithms that do not rely on prior knowledge of the graph's structural information and provide regret upper bounds. Finally, we conduct experiments to validate the theoretical results. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14315</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14315</id><created>2025-01-24</created><authors><author><keyname>Wu</keyname><forenames>Chao-Chung</forenames></author><author><keyname>Tam</keyname><forenames>Zhi Rui</forenames></author><author><keyname>Lin</keyname><forenames>Chieh-Yen</forenames></author><author><keyname>Lee</keyname><forenames>Hung-yi</forenames></author><author><keyname>Chen</keyname><forenames>Yun-Nung</forenames></author></authors><title>Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of   Token Perplexity</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Maintaining consistent model performance across domains is a fundamental challenge in machine learning. While recent work has explored using LLM-generated data for fine-tuning, its impact on cross-domain generalization remains poorly understood. In this paper, we present a systematic analysis revealing that fine-tuning with LLM-generated data not only improves target task performance but also reduces out-of-domain (OOD) degradation compared to fine-tuning with ground truth data. Through analyzing the data sequence in tasks of various domains, we demonstrate that this enhanced OOD robustness stems from a reduced prevalence of high perplexity tokens in LLM-generated sequences. Following this hypothesis we showed that masking high perplexity tokens in ground truth training data also achieves similar OOD preservation comparable to using LLM-generated data. Extensive experiments across diverse model architectures and scales, including Gemma2-2B, Mistral-7B and Llama3-8B, corroborate the consistency of our findings. To the best of our knowledge, this work provides the first mechanistic explanation for the superior OOD robustness conferred by LLM-generated training data, offering valuable insights for developing more robust fine-tuning strategies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14316</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14316</id><created>2025-01-24</created><authors><author><keyname>Chen</keyname><forenames>Hongyu</forenames></author><author><keyname>Zhou</keyname><forenames>Min</forenames></author><author><keyname>Jiang</keyname><forenames>Jing</forenames></author><author><keyname>Chen</keyname><forenames>Jiale</forenames></author><author><keyname>Lu</keyname><forenames>Yang</forenames></author><author><keyname>Xiao</keyname><forenames>Bo</forenames></author><author><keyname>Ge</keyname><forenames>Tiezheng</forenames></author><author><keyname>Zheng</keyname><forenames>Bo</forenames></author></authors><title>PAID: A Framework of Product-Centric Advertising Image Design</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In E-commerce platforms, a full advertising image is composed of a background image and marketing taglines. Automatic ad image design reduces human costs and plays a crucial role. For the convenience of users, a novel automatic framework named Product-Centric Advertising Image Design (PAID) is proposed in this work. PAID takes the product foreground image, required taglines, and target size as input and creates an ad image automatically. PAID consists of four sequential stages: prompt generation, layout generation, background image generation, and graphics rendering. Different expert models are trained to conduct these sub-tasks. A visual language model (VLM) based prompt generation model is leveraged to produce a product-matching background prompt. The layout generation model jointly predicts text and image layout according to the background prompt, product, and taglines to achieve the best harmony. An SDXL-based layout-controlled inpainting model is trained to generate an aesthetic background image. Previous ad image design methods take a background image as input and then predict the layout of taglines, which limits the spatial layout due to fixed image content. Innovatively, our PAID adjusts the stages to produce an unrestricted layout. To complete the PAID framework, we created two high-quality datasets, PITA and PIL. Extensive experimental results show that PAID creates more visually pleasing advertising images than previous methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14317</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14317</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Yuxuan</forenames></author><author><keyname>Yi</keyname><forenames>Xuanyu</forenames></author><author><keyname>Weng</keyname><forenames>Haohan</forenames></author><author><keyname>Xu</keyname><forenames>Qingshan</forenames></author><author><keyname>Wei</keyname><forenames>Xiaokang</forenames></author><author><keyname>Yang</keyname><forenames>Xianghui</forenames></author><author><keyname>Guo</keyname><forenames>Chunchao</forenames></author><author><keyname>Chen</keyname><forenames>Long</forenames></author><author><keyname>Zhang</keyname><forenames>Hanwang</forenames></author></authors><title>Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation</title><categories>cs.CV</categories><comments>14 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Triangle meshes are fundamental to 3D applications, enabling efficient modification and rasterization while maintaining compatibility with standard rendering pipelines. However, current automatic mesh generation methods typically rely on intermediate representations that lack the continuous surface quality inherent to meshes. Converting these representations into meshes produces dense, suboptimal outputs. Although recent autoregressive approaches demonstrate promise in directly modeling mesh vertices and faces, they are constrained by the limitation in face count, scalability, and structural fidelity. To address these challenges, we propose Nautilus, a locality-aware autoencoder for artist-like mesh generation that leverages the local properties of manifold meshes to achieve structural fidelity and efficient representation. Our approach introduces a novel tokenization algorithm that preserves face proximity relationships and compresses sequence length through locally shared vertices and edges, enabling the generation of meshes with an unprecedented scale of up to 5,000 faces. Furthermore, we develop a Dual-stream Point Conditioner that provides multi-scale geometric guidance, ensuring global consistency and local structural fidelity by capturing fine-grained geometric features. Extensive experiments demonstrate that Nautilus significantly outperforms state-of-the-art methods in both fidelity and scalability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14319</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14319</id><created>2025-01-24</created><authors><author><keyname>Xu</keyname><forenames>Xiaohao</forenames></author><author><keyname>Zhang</keyname><forenames>Tianyi</forenames></author><author><keyname>Zhao</keyname><forenames>Shibo</forenames></author><author><keyname>Li</keyname><forenames>Xiang</forenames></author><author><keyname>Wang</keyname><forenames>Sibo</forenames></author><author><keyname>Chen</keyname><forenames>Yongqi</forenames></author><author><keyname>Li</keyname><forenames>Ye</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author><author><keyname>Johnson-Roberson</keyname><forenames>Matthew</forenames></author><author><keyname>Scherer</keyname><forenames>Sebastian</forenames></author><author><keyname>Huang</keyname><forenames>Xiaonan</forenames></author></authors><title>Scalable Benchmarking and Robust Learning for Noise-Free Ego-Motion and   3D Reconstruction from Noisy Video</title><categories>cs.CV cs.RO</categories><comments>Accepted by ICLR 2025; 92 Pages; Project Repo:   https://github.com/Xiaohao-Xu/SLAM-under-Perturbation. arXiv admin note:   substantial text overlap with arXiv:2406.16850</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We aim to redefine robust ego-motion estimation and photorealistic 3D reconstruction by addressing a critical limitation: the reliance on noise-free data in existing models. While such sanitized conditions simplify evaluation, they fail to capture the unpredictable, noisy complexities of real-world environments. Dynamic motion, sensor imperfections, and synchronization perturbations lead to sharp performance declines when these models are deployed in practice, revealing an urgent need for frameworks that embrace and excel under real-world noise. To bridge this gap, we tackle three core challenges: scalable data generation, comprehensive benchmarking, and model robustness enhancement. First, we introduce a scalable noisy data synthesis pipeline that generates diverse datasets simulating complex motion, sensor imperfections, and synchronization errors. Second, we leverage this pipeline to create Robust-Ego3D, a benchmark rigorously designed to expose noise-induced performance degradation, highlighting the limitations of current learning-based methods in ego-motion accuracy and 3D reconstruction quality. Third, we propose Correspondence-guided Gaussian Splatting (CorrGS), a novel test-time adaptation method that progressively refines an internal clean 3D representation by aligning noisy observations with rendered RGB-D frames from clean 3D map, enhancing geometric alignment and appearance restoration through visual correspondence. Extensive experiments on synthetic and real-world data demonstrate that CorrGS consistently outperforms prior state-of-the-art methods, particularly in scenarios involving rapid motion and dynamic illumination. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14321</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14321</id><created>2025-01-24</created><authors><author><keyname>Patel</keyname><forenames>Mann</forenames></author><author><keyname>Panda</keyname><forenames>Divyajyoti</forenames></author><author><keyname>Mehta</keyname><forenames>Hilay</forenames></author><author><keyname>Patel</keyname><forenames>Parth</forenames></author><author><keyname>Parikh</keyname><forenames>Dhruv</forenames></author></authors><title>Domain Expansion: Parameter-Efficient Modules as Building Blocks for   Composite Domains</title><categories>cs.LG</categories><comments>6 pages, 3 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Parameter-Efficient Fine-Tuning (PEFT) is an efficient alternative to full scale fine-tuning, gaining popularity recently. With pre-trained model sizes growing exponentially, PEFT can be effectively utilized to fine-tune compact modules, Parameter-Efficient Modules (PEMs), trained to be domain experts over diverse domains. In this project, we explore composing such individually fine-tuned PEMs for distribution generalization over the composite domain. To compose PEMs, simple composing functions are used that operate purely on the weight space of the individually fine-tuned PEMs, without requiring any additional fine-tuning. The proposed method is applied to the task of representing the 16 Myers-Briggs Type Indicator (MBTI) composite personalities via 4 building block dichotomies, comprising of 8 individual traits which can be merged (composed) to yield a unique personality. We evaluate the individual trait PEMs and the composed personality PEMs via an online MBTI personality quiz questionnaire, validating the efficacy of PEFT to fine-tune PEMs and merging PEMs without further fine-tuning for domain composition. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14322</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14322</id><created>2025-01-24</created><authors><author><keyname>Nyiri</keyname><forenames>Eric</forenames></author><author><keyname>Gibaru</keyname><forenames>Olivier</forenames></author></authors><title>Relative Layer-Wise Relevance Propagation: a more Robust Neural Networks   eXplaination</title><categories>cs.LG cs.AI</categories><comments>arXiv admin note: text overlap with arXiv:2012.14501,   arXiv:1605.01713 by other authors</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Machine learning methods are solving very successfully a plethora of tasks, but they have the disadvantage of not providing any information about their decision. Consequently, estimating the reasoning of the system provides additional information. For this, Layer-Wise Relevance Propagation (LRP) is one of the methods in eXplainable Machine Learning (XML). Its purpose is to provide contributions of any neural network output in the domain of its input. The main drawback of current methods is mainly due to division by small values. To overcome this problem, we provide a new definition called Relative LRP where the classical conservation law is satisfied up to a multiplicative factor but without divisions by small values except for Resnet skip connection. In this article, we will focus on image classification. This allows us to visualize the contributions of a pixel to the predictions of a multi-layer neural network. Pixel contributions provide a focus to further analysis on regions of potential interest. R-LRP can be applied for any dense, CNN or residual neural networks. Moreover, R-LRP doesn't need any hyperparameters to tune contrary to other LRP methods. We then compare the R-LRP method on different datasets with simple CNN, VGG16, VGG19 and Resnet50 networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14323</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14323</id><created>2025-01-24</created><authors><author><keyname>Emre</keyname><forenames>Taha</forenames></author><author><keyname>Araújo</keyname><forenames>Teresa</forenames></author><author><keyname>Oghbaie</keyname><forenames>Marzieh</forenames></author><author><keyname>Lachinov</keyname><forenames>Dmitrii</forenames></author><author><keyname>Aresta</keyname><forenames>Guilherme</forenames></author><author><keyname>Bogunović</keyname><forenames>Hrvoje</forenames></author></authors><title>Automatic detection and prediction of nAMD activity change in retinal   OCT using Siamese networks and Wasserstein Distance for ordinality</title><categories>eess.IV cs.CV cs.LG</categories><comments>Solution to the MICCAI 2024 MARIO Challange. First 3 authors   contributed equally. Models can be found at   https://github.com/EmreTaha/Siamese-EMD-for-AMD-Change</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neovascular age-related macular degeneration (nAMD) is a leading cause of vision loss among older adults, where disease activity detection and progression prediction are critical for nAMD management in terms of timely drug administration and improving patient outcomes. Recent advancements in deep learning offer a promising solution for predicting changes in AMD from optical coherence tomography (OCT) retinal volumes. In this work, we proposed deep learning models for the two tasks of the public MARIO Challenge at MICCAI 2024, designed to detect and forecast changes in nAMD severity with longitudinal retinal OCT. For the first task, we employ a Vision Transformer (ViT) based Siamese Network to detect changes in AMD severity by comparing scan embeddings of a patient from different time points. To train a model to forecast the change after 3 months, we exploit, for the first time, an Earth Mover (Wasserstein) Distance-based loss to harness the ordinal relation within the severity change classes. Both models ranked high on the preliminary leaderboard, demonstrating that their predictive capabilities could facilitate nAMD treatment management. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14325</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14325</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Shang</keyname><forenames>Yitong</forenames></author><author><keyname>Li</keyname><forenames>Sen</forenames></author></authors><title>Joint Infrastructure Planning and Order Assignment for On-Demand   Food-Delivery Services with Coordinated Drones and Human Couriers</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the optimal infrastructure planning and order assignment problem of an on-demand food-delivery platform with a mixed fleet of drones and human couriers. The platform has two delivery modes: (a) ground delivery and (b) drone-assisted delivery (i.e., air delivery). In ground delivery, couriers directly collect and transport orders from restaurants to destinations. For air delivery, the delivery process involves three legs: initially, a human courier picks up the order from the restaurant and transports it to a nearby launchpad, where personnel load the orders onto drones and replace batteries as needed. The loaded drone then transports the order from the launchpad to a kiosk, where another courier retrieves the order from the kiosk for final delivery. The platform must determine the optimal locations for launchpads and kiosks within a transportation network, and devise an order assignment strategy that allocates food-delivery orders between ground and air delivery considering the bundling probabilities of ground deliveries and the waiting times at launchpads and kiosks. We formulate the platform's problem as a mixed-integer nonlinear program and develop a novel neural network-assisted optimization method to obtain high-quality solutions. A case study in Hong Kong validates our model and algorithm, revealing that drone delivery reduces operational costs, minimizes courier fleet size, and increases order bundling opportunities. We also find that the expansion of air delivery services may entail larger delivery times due to the trade-off between the travel time savings induced by the faster air delivery and the associated detours incurred by intermodal transfer and extra waiting times at launchpads and kiosks, which crucially depends on the distance of the orders and the sequence of activating long-distance air delivery routes versus short-distance ones. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14326</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14326</id><created>2025-01-24</created><authors><author><keyname>Jain</keyname><forenames>Ridhi</forenames></author><author><keyname>Purandare</keyname><forenames>Rahul</forenames></author></authors><title>Assessing Large Language Models in Comprehending and Verifying   Concurrent Programs across Memory Models</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  As concurrent programming becomes increasingly prevalent, effectively identifying and addressing concurrency issues such as data races and deadlocks is critical. This study evaluates the performance of several leading large language models (LLMs), including GPT-3.5-turbo, GPT-4, GPT-4o, GPT-4o-mini, and Mistral-AI's Large2, in understanding and analyzing concurrency issues within software programs. Given that relaxed memory models, such as Total Store Order (TSO) and Partial Store Order (PSO), are widely implemented and adapted in modern systems, supported even by commodity architectures like ARM and x86, our evaluation focuses not only on sequentially consistent memory models but also on these relaxed memory models. Specifically, we assess two main aspects: the models' capacity to detect concurrency problems under a sequentially consistent memory model and their ability to verify the correctness conditions of concurrent programs across both sequentially consistent and relaxed memory models. To do this, we leverage SV-COMP's pthread tests and 25 ARM Litmus tests designed to evaluate Total Store Order (TSO) and Partial Store Order (PSO) memory models. The experimental results reveal that GPT-4, GPT-4o, and Mistral-AI's Large2 demonstrate a robust understanding of concurrency issues, effectively identifying data races and deadlocks when assessed under a sequentially consistent memory model. However, despite its superior performance, all selected LLMs face significant challenges verifying program correctness under relaxed memory models. These LLMs exhibit limitations in accurately capturing memory ordering constraints, and their current capabilities fall short in verifying even small programs in these complex scenarios. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14327</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14327</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Ru</forenames></author><author><keyname>Chen</keyname><forenames>Ruijia</forenames></author><author><keyname>Cai</keyname><forenames>Anqiao Erica</forenames></author><author><keyname>Li</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Mondal</keyname><forenames>Sanbrita</forenames></author><author><keyname>Zhao</keyname><forenames>Yuhang</forenames></author></authors><title>Characterizing Visual Intents for People with Low Vision through Eye   Tracking</title><categories>cs.HC</categories><acm-class>H.5.0</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Accessing visual information is crucial yet challenging for people with low vision due to their visual conditions (e.g., low visual acuity, limited visual field). However, unlike blind people, low vision people have and prefer using their functional vision in daily tasks. Gaze patterns thus become an important indicator to uncover their visual challenges and intents, inspiring more adaptive visual support. We seek to deeply understand low vision users' gaze behaviors in different image viewing tasks, characterizing typical visual intents and the unique gaze patterns exhibited by people with different low vision conditions. We conducted a retrospective think-aloud study using eye tracking with 14 low vision participants and nine sighted controls. Participants completed various image viewing tasks and watched the playback of their gaze trajectories to reflect on their visual experiences. Based on the study, we derived a visual intent taxonomy with five intents characterized by participants' gaze behaviors and demonstrated how low vision conditions affect gaze patterns across visual intents. Our findings underscore the importance of combining visual ability information, image context, and eye tracking data in visual intent recognition, setting up a foundation for intent-aware assistive technologies for low vision. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14328</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14328</id><created>2025-01-24</created><authors><author><keyname>Joo</keyname><forenames>Nogeun</forenames></author><author><keyname>Kim</keyname><forenames>Donghyuk</forenames></author><author><keyname>Cho</keyname><forenames>Hyunjun</forenames></author><author><keyname>Noh</keyname><forenames>Junseok</forenames></author><author><keyname>Jung</keyname><forenames>Dongha</forenames></author><author><keyname>Kim</keyname><forenames>Joo-Young</forenames></author></authors><title>Securing DRAM at Scale: ARFM-Driven Row Hammer Defense with Unveiling   the Threat of Short tRC Patterns</title><categories>cs.CR cs.AR</categories><comments>12 pages, 19 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  To address the issue of powerful row hammer (RH) attacks, our study involved an extensive analysis of the prevalent attack patterns in the field. We discovered a strong correlation between the timing and density of the active-to-active command period, ${tRC}$, and the likelihood of RH attacks. In this paper, we introduce MARC, an innovative ARFM-driven RH mitigation IP that significantly reinforces existing RH mitigation IPs. MARC dynamically adjusts the frequency of RFM in response to the severity of the RH attack environment, offering a tailored security solution that not only detects the threats but also adapts to varying threat levels. MARC's detection mechanism has demonstrated remarkable efficiency, identifying over 99\% of attack patterns. Moreover, MARC is designed as a compact hardware module, facilitating tight integration either on the memory controller-side or DRAM-side within the memory system. It only occupies a negligible hardware area of 3363~\textit{$\mu m^2$}. By activating ARFM based on MARC's detection, the additional energy overhead is also negligible in normal workloads. We conduct experiments to compare the highest row count throughout the patterns, defined as max exposure, between the vanilla RH mitigation IPs and the MARC-enhanced versions of the same IPs, focusing on both DRAM-side and memory controller-side. On the DRAM-side, MARC + probabilistic scheme and MARC + counter-based tracking scheme achieve 8.1$\times$ and 1.5$\times$ improvement in max exposure ratio compared to the vanilla IPs, respectively. On the memory controller-side, the MARC + PARA and MARC + Graphene achieve 50$\times$ and 5.7$\times$ improvement in max exposure ratio compared to the vanilla IPs, respectively. MARC ensures optimal security without sacrificing system performance, making MARC a pioneering solution in the realm of RH attack mitigation. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14330</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14330</id><created>2025-01-24</created><authors><author><keyname>Choudhary</keyname><forenames>Pratyush</forenames></author><author><keyname>Das</keyname><forenames>Subhrajit</forenames></author><author><keyname>Potta</keyname><forenames>Mukul Paras</forenames></author><author><keyname>Das</keyname><forenames>Prasuj</forenames></author><author><keyname>Bichhawat</keyname><forenames>Abhishek</forenames></author></authors><title>Online Authentication Habits of Indian Users</title><categories>cs.CR cs.CY</categories><comments>Submitted on 2024-10-25. Accepted at BuildSec 2024, to be published   in IEEE Xplore. Original version: 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passwords have been long used as the primary authentication method for web services. Weak passwords used by the users have prompted the use of password management tools and two-factor authentication to ensure better account security. While prior studies have studied their adoption individually, none of these studies focuses particularly on the Indian setting, which is culturally and economically different from the countries in which these studies have been done in the past. To this end, we conducted a survey with 90 participants residing in India to better understand the mindset of people on using password managers and two-factor authentication (2FA).   Our findings suggest that a majority of the participants have used 2FA and password managers in some form, although they are sometimes unaware of their formal names. While many participants used some form of 2FA across all their accounts, browser-integrated and device-default password managers are predominantly utilized for less sensitive platforms such as e-commerce and social media rather than for more critical accounts like banking. The primary motivation for using password managers is the convenience of auto-filling. However, some participants avoid using password managers due to a lack of trust in these tools. Notably, dedicated third-party applications show low adoption for both password manager and 2FA.   Despite acknowledging the importance of secure password practices, many participants still reuse passwords across multiple accounts, prefer shorter passwords, and use commonly predictable password patterns. Overall, the study suggests that Indians are more inclined to choose default settings, underscoring the need for tailored strategies to improve user awareness and strengthen password security practices. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14334</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14334</id><created>2025-01-24</created><authors><author><keyname>Desroches</keyname><forenames>Clément</forenames></author><author><keyname>Chauvin</keyname><forenames>Martin</forenames></author><author><keyname>Ladan</keyname><forenames>Louis</forenames></author><author><keyname>Vateau</keyname><forenames>Caroline</forenames></author><author><keyname>Gosset</keyname><forenames>Simon</forenames></author><author><keyname>Cordier</keyname><forenames>Philippe</forenames></author></authors><title>Exploring the sustainable scaling of AI dilemma: A projective study of   corporations' AI environmental impacts</title><categories>cs.AI cs.CY cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid growth of artificial intelligence (AI), particularly Large Language Models (LLMs), has raised concerns regarding its global environmental impact that extends beyond greenhouse gas emissions to include consideration of hardware fabrication and end-of-life processes. The opacity from major providers hinders companies' abilities to evaluate their AI-related environmental impacts and achieve net-zero targets.In this paper, we propose a methodology to estimate the environmental impact of a company's AI portfolio, providing actionable insights without necessitating extensive AI and Life-Cycle Assessment (LCA) expertise. Results confirm that large generative AI models consume up to 4600x more energy than traditional models. Our modelling approach, which accounts for increased AI usage, hardware computing efficiency, and changes in electricity mix in line with IPCC scenarios, forecasts AI electricity use up to 2030. Under a high adoption scenario, driven by widespread Generative AI and agents adoption associated to increasingly complex models and frameworks, AI electricity use is projected to rise by a factor of 24.4.Mitigating the environmental impact of Generative AI by 2030 requires coordinated efforts across the AI value chain. Isolated measures in hardware efficiency, model efficiency, or grid improvements alone are insufficient. We advocate for standardized environmental assessment frameworks, greater transparency from the all actors of the value chain and the introduction of a "Return on Environment" metric to align AI development with net-zero goals. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14336</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14336</id><created>2025-01-24</created><authors><author><keyname>Li</keyname><forenames>Yifei</forenames></author><author><keyname>Zhou</keyname><forenames>Bole</forenames></author><author><keyname>Zhang</keyname><forenames>Jiejing</forenames></author><author><keyname>Wei</keyname><forenames>Xuechao</forenames></author><author><keyname>Li</keyname><forenames>Yinghan</forenames></author><author><keyname>Chen</keyname><forenames>Yingda</forenames></author></authors><title>RadiK: Scalable and Optimized GPU-Parallel Radix Top-K Selection</title><categories>cs.DS</categories><comments>Published at the 38th ACM International Conference on Supercomputing   (ICS '24)</comments><acm-class>F.2.2</acm-class><journal-ref>ICS '24: Proceedings of the 38th ACM International Conference on   Supercomputing, 2024, Pages 537-548</journal-ref><doi>10.1145/3650200.3656596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Top-k selection, which identifies the largest or smallest k elements from a data set, is a fundamental operation in data-intensive domains such as databases and deep learning, so its scalability and efficiency are critical for these high-performance systems. However, previous studies on its efficient GPU implementation are mostly merge-based and rely heavily on the fast but size-limited on-chip memory, thereby limiting the scalability with a restricted upper bound on k. This work introduces a scalable and optimized GPU-parallel radix top-k selection that supports significantly larger k values than existing methods without compromising efficiency, regardless of input length and batch size. Our method incorporates a novel optimization framework tailored for high memory bandwidth and resource utilization, achieving up to 2.5x speedup over the prior art for non-batch queries and up to 4.8x speedup for batch queries. In addition, we propose an adaptive scaling technique that strengthens the robustness, which further provides up to 2.7x speedup on highly adversarial input distributions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14337</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14337</id><created>2025-01-24</created><authors><author><keyname>Delavenne</keyname><forenames>Hugo</forenames><affiliation>GRACE</affiliation></author><author><keyname>Medevielle</keyname><forenames>Tanguy</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Roussel</keyname><forenames>Élina</forenames><affiliation>GRACE</affiliation></author></authors><title>Interactive Oracle Proofs of Proximity to Codes on Graphs</title><categories>cs.CC cs.CR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design an Interactive Oracle Proof of Proximity (IOPP) for codes on graphs inspired by the FRI protocol. The soundness is significantly improved compared to the FRI, the complexity parameters are comparable, and there are no restrictions on the field used, enabling to consider new codes to design code-based SNARKs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14338</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14338</id><created>2025-01-24</created><authors><author><keyname>Deb</keyname><forenames>Dibyabha</forenames></author><author><keyname>Verma</keyname><forenames>Ujjwal</forenames></author></authors><title>Correlation-Based Band Selection for Hyperspectral Image Classification</title><categories>cs.CV eess.IV</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral images offer extensive spectral information about ground objects across multiple spectral bands. However, the large volume of data can pose challenges during processing. Typically, adjacent bands in hyperspectral data are highly correlated, leading to the use of only a few selected bands for various applications. In this work, we present a correlation-based band selection approach for hyperspectral image classification. Our approach calculates the average correlation between bands using correlation coefficients to identify the relationships among different bands. Afterward, we select a subset of bands by analyzing the average correlation and applying a threshold-based method. This allows us to isolate and retain bands that exhibit lower inter-band dependencies, ensuring that the selected bands provide diverse and non-redundant information. We evaluate our proposed approach on two standard benchmark datasets: Pavia University (PA) and Salinas Valley (SA), focusing on image classification tasks. The experimental results demonstrate that our method performs competitively with other standard band selection approaches. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14340</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14340</id><created>2025-01-24</created><authors><author><keyname>Lanier</keyname><forenames>Dimitri</forenames></author><author><keyname>Béguinot</keyname><forenames>Julien</forenames></author><author><keyname>Rioul</keyname><forenames>Olivier</forenames></author></authors><title>From Classical to Quantum: Explicit Classical Distributions Achieving   Maximal Quantum $f$-Divergence</title><categories>quant-ph cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Explicit classical states achieving maximal $f$-divergence are given, allowing for a simple proof of Matsumoto's Theorem, and the systematic extension of any inequality between classical $f$-divergences to quantum $f$-divergences. Our methodology is particularly simple as it does not require any elaborate matrix analysis machinery but only basic linear algebra. It is also effective, as illustrated by two examples improving existing bounds: (i)~an improved quantum Pinsker inequality is derived between $\chi^2$ and trace norm, and leveraged to improve a bound in decoherence theory; (ii)~a new reverse quantum Pinsker inequality is derived for any quantum $f$-divergence, and compared to previous (Audenaert-Eisert and Hirche-Tomamichel) bounds. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14342</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14342</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Liang</forenames></author><author><keyname>Chen</keyname><forenames>Haonan</forenames></author><author><keyname>Yang</keyname><forenames>Nan</forenames></author><author><keyname>Huang</keyname><forenames>Xiaolong</forenames></author><author><keyname>Dou</keyname><forenames>Zhicheng</forenames></author><author><keyname>Wei</keyname><forenames>Furu</forenames></author></authors><title>Chain-of-Retrieval Augmented Generation</title><categories>cs.IR cs.CL</categories><comments>18 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces an approach for training o1-like RAG models that retrieve and reason over relevant information step by step before generating the final answer. Conventional RAG methods usually perform a single retrieval step before the generation process, which limits their effectiveness in addressing complex queries due to imperfect retrieval results. In contrast, our proposed method, CoRAG (Chain-of-Retrieval Augmented Generation), allows the model to dynamically reformulate the query based on the evolving state. To train CoRAG effectively, we utilize rejection sampling to automatically generate intermediate retrieval chains, thereby augmenting existing RAG datasets that only provide the correct final answer. At test time, we propose various decoding strategies to scale the model's test-time compute by controlling the length and number of sampled retrieval chains. Experimental results across multiple benchmarks validate the efficacy of CoRAG, particularly in multi-hop question answering tasks, where we observe more than 10 points improvement in EM score compared to strong baselines. On the KILT benchmark, CoRAG establishes a new state-of-the-art performance across a diverse range of knowledge-intensive tasks. Furthermore, we offer comprehensive analyses to understand the scaling behavior of CoRAG, laying the groundwork for future research aimed at developing factual and grounded foundation models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14345</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14345</id><created>2025-01-24</created><authors><author><keyname>Sommers</keyname><forenames>Dominique</forenames></author><author><keyname>Sidorova</keyname><forenames>Natalia</forenames></author><author><keyname>van Dongen</keyname><forenames>Boudewijn</forenames></author></authors><title>A Ground Truth Approach for Assessing Process Mining Techniques</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The assessment of process mining techniques using real-life data is often compromised by the lack of ground truth knowledge, the presence of non-essential outliers in system behavior and recording errors in event logs. Using synthetically generated data could leverage ground truth for better evaluation. Existing log generation tools inject noise directly into the logs, which does not capture many typical behavioral deviations. Furthermore, the link between the model and the log, which is needed for later assessment, becomes lost.   We propose a ground-truth approach for generating process data from either existing or synthetic initial process models, whether automatically generated or hand-made. This approach incorporates patterns of behavioral deviations and recording errors to produce a synthetic yet realistic deviating model and imperfect event log. These, together with the initial model, are required to assess process mining techniques based on ground truth knowledge. We demonstrate this approach to create datasets of synthetic process data for three processes, one of which we used in a conformance checking use case, focusing on the assessment of (relaxed) systemic alignments to expose and explain deviations in modeled and recorded behavior. Our results show that this approach, unlike traditional methods, provides detailed insights into the strengths and weaknesses of process mining techniques, both quantitatively and qualitatively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14346</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14346</id><created>2025-01-24</created><authors><author><keyname>koloski</keyname><forenames>Boshko</forenames></author><author><keyname>Lavrač</keyname><forenames>Nada</forenames></author><author><keyname>Škrlj</keyname><forenames>Blaž</forenames></author></authors><title>HorNets: Learning from Discrete and Continuous Signals with Routing   Neural Networks</title><categories>cs.LG cs.AI</categories><comments>Accepted to the ACML conference journal track with the Machine   Learning journal. The first and the last authors share an equal contribution</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Construction of neural network architectures suitable for learning from both continuous and discrete tabular data is a challenging research endeavor. Contemporary high-dimensional tabular data sets are often characterized by a relatively small instance count, requiring data-efficient learning. We propose HorNets (Horn Networks), a neural network architecture with state-of-the-art performance on synthetic and real-life data sets from scarce-data tabular domains. HorNets are based on a clipped polynomial-like activation function, extended by a custom discrete-continuous routing mechanism that decides which part of the neural network to optimize based on the input's cardinality. By explicitly modeling parts of the feature combination space or combining whole space in a linear attention-like manner, HorNets dynamically decide which mode of operation is the most suitable for a given piece of data with no explicit supervision. This architecture is one of the few approaches that reliably retrieves logical clauses (including noisy XNOR) and achieves state-of-the-art classification performance on 14 real-life biomedical high-dimensional data sets. HorNets are made freely available under a permissive license alongside a synthetic generator of categorical benchmarks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14349</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14349</id><created>2025-01-24</created><authors><author><keyname>Sakaue</keyname><forenames>Shinsaku</forenames></author><author><keyname>Tsuchiya</keyname><forenames>Taira</forenames></author><author><keyname>Bao</keyname><forenames>Han</forenames></author><author><keyname>Oki</keyname><forenames>Taihei</forenames></author></authors><title>Online Inverse Linear Optimization: Improved Regret Bound, Robustness to   Suboptimality, and Toward Tight Regret Analysis</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an online learning problem where, over $T$ rounds, a learner observes both time-varying sets of feasible actions and an agent's optimal actions, selected by solving linear optimization over the feasible actions. The learner sequentially makes predictions of the agent's underlying linear objective function, and their quality is measured by the regret, the cumulative gap between optimal objective values and those achieved by following the learner's predictions. A seminal work by B\"armann et al. (ICML 2017) showed that online learning methods can be applied to this problem to achieve regret bounds of $O(\sqrt{T})$. Recently, Besbes et al. (COLT 2021, Oper. Res. 2023) significantly improved the result by achieving an $O(n^4\ln T)$ regret bound, where $n$ is the dimension of the ambient space of objective vectors. Their method, based on the ellipsoid method, runs in polynomial time but is inefficient for large $n$ and $T$. In this paper, we obtain an $O(n\ln T)$ regret bound, improving upon the previous bound of $O(n^4\ln T)$ by a factor of $n^3$. Our method is simple and efficient: we apply the online Newton step (ONS) to appropriate exp-concave loss functions. Moreover, for the case where the agent's actions are possibly suboptimal, we establish an $O(n\ln T+\sqrt{\Delta_Tn\ln T})$ regret bound, where $\Delta_T$ is the cumulative suboptimality of the agent's actions. This bound is achieved by using MetaGrad, which runs ONS with $\Theta(\ln T)$ different learning rates in parallel. We also provide a simple instance that implies an $\Omega(n)$ lower bound, showing that our $O(n\ln T)$ bound is tight up to an $O(\ln T)$ factor. This gives rise to a natural question: can the $O(\ln T)$ factor in the upper bound be removed? For the special case of $n=2$, we show that an $O(1)$ regret bound is possible, while we delineate challenges in extending this result to higher dimensions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14350</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14350</id><created>2025-01-24</created><authors><author><keyname>Xu</keyname><forenames>Kai-Tuo</forenames></author><author><keyname>Xie</keyname><forenames>Feng-Long</forenames></author><author><keyname>Tang</keyname><forenames>Xu</forenames></author><author><keyname>Hu</keyname><forenames>Yao</forenames></author></authors><title>FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition   Models from Encoder-Decoder to LLM Integration</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present FireRedASR, a family of large-scale automatic speech recognition (ASR) models for Mandarin, designed to meet diverse requirements in superior performance and optimal efficiency across various applications. FireRedASR comprises two variants:   FireRedASR-LLM: Designed to achieve state-of-the-art (SOTA) performance and to enable seamless end-to-end speech interaction. It adopts an Encoder-Adapter-LLM framework leveraging large language model (LLM) capabilities. On public Mandarin benchmarks, FireRedASR-LLM (8.3B parameters) achieves an average Character Error Rate (CER) of 3.05%, surpassing the latest SOTA of 3.33% with an 8.4% relative CER reduction (CERR). It demonstrates superior generalization capability over industrial-grade baselines, achieving 24%-40% CERR in multi-source Mandarin ASR scenarios such as video, live, and intelligent assistant.   FireRedASR-AED: Designed to balance high performance and computational efficiency and to serve as an effective speech representation module in LLM-based speech models. It utilizes an Attention-based Encoder-Decoder (AED) architecture. On public Mandarin benchmarks, FireRedASR-AED (1.1B parameters) achieves an average CER of 3.18%, slightly worse than FireRedASR-LLM but still outperforming the latest SOTA model with over 12B parameters. It offers a more compact size, making it suitable for resource-constrained applications.   Moreover, both models exhibit competitive results on Chinese dialects and English speech benchmarks and excel in singing lyrics recognition. To advance research in speech processing, we release our models and inference code at https://github.com/FireRedTeam/FireRedASR. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14351</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14351</id><created>2025-01-24</created><authors><author><keyname>Ma</keyname><forenames>Jian</forenames></author></authors><title>Facies Classification with Copula Entropy</title><categories>cs.LG physics.geo-ph stat.AP</categories><comments>12 pages, 5 figures, 3 tables. arXiv admin note: text overlap with   arXiv:2310.16633</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose to apply copula entropy (CE) to facies classification. In our method, the correlations between geological variables and facies classes are measured with CE and then the variables associated with large negative CEs are selected for classification. We verified the proposed method on a typical facies dataset for facies classification and the experimental results show that the proposed method can select less geological variables for facies classification without sacrificing classification performance. The geological variables such selected are also interpretable to geologists with geological meanings due to the rigorous definition of CE. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14356</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14356</id><created>2025-01-24</created><authors><author><keyname>Chen</keyname><forenames>Haipeng</forenames></author><author><keyname>Wu</keyname><forenames>Sifan</forenames></author><author><keyname>Wang</keyname><forenames>Zhigang</forenames></author><author><keyname>Yin</keyname><forenames>Yifang</forenames></author><author><keyname>Jiao</keyname><forenames>Yingying</forenames></author><author><keyname>Lyu</keyname><forenames>Yingda</forenames></author><author><keyname>Liu</keyname><forenames>Zhenguang</forenames></author></authors><title>Causal-Inspired Multitask Learning for Video-Based Human Pose Estimation</title><categories>cs.CV</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video-based human pose estimation has long been a fundamental yet challenging problem in computer vision. Previous studies focus on spatio-temporal modeling through the enhancement of architecture design and optimization strategies. However, they overlook the causal relationships in the joints, leading to models that may be overly tailored and thus estimate poorly to challenging scenes. Therefore, adequate causal reasoning capability, coupled with good interpretability of model, are both indispensable and prerequisite for achieving reliable results. In this paper, we pioneer a causal perspective on pose estimation and introduce a causal-inspired multitask learning framework, consisting of two stages. \textit{In the first stage}, we try to endow the model with causal spatio-temporal modeling ability by introducing two self-supervision auxiliary tasks. Specifically, these auxiliary tasks enable the network to infer challenging keypoints based on observed keypoint information, thereby imbuing causal reasoning capabilities into the model and making it robust to challenging scenes. \textit{In the second stage}, we argue that not all feature tokens contribute equally to pose estimation. Prioritizing causal (keypoint-relevant) tokens is crucial to achieve reliable results, which could improve the interpretability of the model. To this end, we propose a Token Causal Importance Selection module to identify the causal tokens and non-causal tokens (\textit{e.g.}, background and objects). Additionally, non-causal tokens could provide potentially beneficial cues but may be redundant. We further introduce a non-causal tokens clustering module to merge the similar non-causal tokens. Extensive experiments show that our method outperforms state-of-the-art methods on three large-scale benchmark datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14358</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14358</id><created>2025-01-24</created><authors><author><keyname>Tang</keyname><forenames>Minjie</forenames></author><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author></authors><title>CSI-Free Low-Complexity Remote State Estimation over Wireless MIMO   Fading Channels using Semantic Analog Aggregation</title><categories>eess.SY cs.IT cs.SY eess.SP math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we investigate low-complexity remote system state estimation over wireless multiple-input-multiple-output (MIMO) channels without requiring prior knowledge of channel state information (CSI). We start by reviewing the conventional Kalman filtering-based state estimation algorithm, which typically relies on perfect CSI and incurs considerable computational complexity. To overcome the need for CSI, we introduce a novel semantic aggregation method, in which sensors transmit semantic measurement discrepancies to the remote state estimator through analog aggregation. To further reduce computational complexity, we introduce a constant-gain-based filtering algorithm that can be optimized offline using the constrained stochastic successive convex approximation (CSSCA) method. We derive a closed-form sufficient condition for the estimation stability of our proposed scheme via Lyapunov drift analysis. Numerical results showcase significant performance gains using the proposed scheme compared to several widely used methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14360</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14360</id><created>2025-01-24</created><authors><author><keyname>Sommers</keyname><forenames>Dominique</forenames></author><author><keyname>Sidorova</keyname><forenames>Natalia</forenames></author><author><keyname>van Dongen</keyname><forenames>Boudewijn</forenames></author></authors><title>In System Alignments we Trust! Explainable Alignments via Projections</title><categories>cs.AI cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alignments are a well-known process mining technique for reconciling system logs and normative process models. Evidence of certain behaviors in a real system may only be present in one representation - either a log or a model - but not in the other. Since for processes in which multiple entities, like objects and resources, are involved in the activities, their interactions affect the behavior and are therefore essential to take into account in the alignments.   Additionally, both logged and modeled representations of reality may be imprecise and only partially represent some of these entities, but not all. In this paper, we introduce the concept of "relaxations" through projections for alignments to deal with partially correct models and logs. Relaxed alignments help to distinguish between trustworthy and untrustworthy content of the two representations (the log and the model) to achieve a better understanding of the underlying process and expose quality issues. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14363</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14363</id><created>2025-01-24</created><authors><author><keyname>Van Caudenberg</keyname><forenames>Daimy</forenames></author><author><keyname>Bogaerts</keyname><forenames>Bart</forenames></author><author><keyname>Vendramin</keyname><forenames>Leandro</forenames></author></authors><title>Incremental SAT-Based Enumeration of Solutions to the Yang-Baxter   Equation</title><categories>cs.LO cs.DM</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We tackle the problem of enumerating set-theoretic solutions to the Yang-Baxter equation. This equation originates from statistical and quantum mechanics, but also has applications in knot theory, cryptography, quantum computation and group theory. Non-degenerate, involutive solutions have been enumerated for sets up to size 10 using constraint programming with partial static symmetry breaking; for general non-involutive solutions, a similar approach was used to enumerate solutions for sets up to size 8. In this paper, we use and extend the SAT Modulo Symmetries framework (SMS), to expand the boundaries for which solutions are known. The SMS framework relies on a minimality check; we present two solutions to this, one that stays close to the original one designed for enumerating graphs and a new incremental, SAT-based approach. With our new method, we can reproduce previously known results much faster and also report on results for sizes that have remained out of reach so far. This is an extended version of a paper to appear in the proceedings of the 31st International Conference on Tools and Algorithms for the Construction and Analysis of Systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14367</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14367</id><created>2025-01-24</created><authors><author><keyname>Shi</keyname><forenames>Kexin</forenames></author><author><keyname>Fu</keyname><forenames>Yaru</forenames></author><author><keyname>Guo</keyname><forenames>Yongna</forenames></author><author><keyname>Wang</keyname><forenames>Fu Lee</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author></authors><title>Joint System Latency and Data Freshness Optimization for Cache-enabled   Mobile Crowdsensing Networks</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile crowdsensing (MCS) networks enable large-scale data collection by leveraging the ubiquity of mobile devices. However, frequent sensing and data transmission can lead to significant resource consumption. To mitigate this issue, edge caching has been proposed as a solution for storing recently collected data. Nonetheless, this approach may compromise data freshness. In this paper, we investigate the trade-off between re-using cached task results and re-sensing tasks in cache-enabled MCS networks, aiming to minimize system latency while maintaining information freshness. To this end, we formulate a weighted delay and age of information (AoI) minimization problem, jointly optimizing sensing decisions, user selection, channel selection, task allocation, and caching strategies. The problem is a mixed-integer non-convex programming problem which is intractable. Therefore, we decompose the long-term problem into sequential one-shot sub-problems and design a framework that optimizes system latency, task sensing decision, and caching strategy subproblems. When one task is re-sensing, the one-shot problem simplifies to the system latency minimization problem, which can be solved optimally. The task sensing decision is then made by comparing the system latency and AoI. Additionally, a Bayesian update strategy is developed to manage the cached task results. Building upon this framework, we propose a lightweight and time-efficient algorithm that makes real-time decisions for the long-term optimization problem. Extensive simulation results validate the effectiveness of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14369</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14369</id><created>2025-01-24</created><authors><author><keyname>Yan</keyname><forenames>Weicai</forenames></author><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Lin</keyname><forenames>Wang</forenames></author><author><keyname>Guo</keyname><forenames>Zirun</forenames></author><author><keyname>Zhao</keyname><forenames>Zhou</forenames></author><author><keyname>Jin</keyname><forenames>Tao</forenames></author></authors><title>Low-rank Prompt Interaction for Continual Vision-Language Retrieval</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on continual learning in multi-modal tasks has been receiving increasing attention. However, most existing work overlooks the explicit cross-modal and cross-task interactions. In this paper, we innovatively propose the Low-rank Prompt Interaction (LPI) to address this general problem of multi-modal understanding, which considers both cross-modal and cross-task interactions. Specifically, as for the former, we employ multi-modal correlation modules for corresponding Transformer layers. Considering that the training parameters scale to the number of layers and tasks, we propose low-rank interaction-augmented decomposition to avoid memory explosion while enhancing the cross-modal association through sharing and separating common-specific low-rank factors. In addition, due to the multi-modal semantic differences carried by the low-rank initialization, we adopt hierarchical low-rank contrastive learning to ensure training robustness. As for the latter, we initially employ a visual analysis and identify that different tasks have clear distinctions in proximity. Therefore, we introduce explicit task contrastive constraints in the prompt learning process based on task semantic distances. Experiments on two retrieval tasks show performance improvements with the introduction of a minimal number of parameters, demonstrating the effectiveness of our method. Code is available at https://github.com/Kelvin-ywc/LPI. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14370</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14370</id><created>2025-01-24</created><authors><author><keyname>Shen</keyname><forenames>Diyou</forenames></author><author><keyname>Zhang</keyname><forenames>Yichao</forenames></author><author><keyname>Bertuletti</keyname><forenames>Marco</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>TCDM Burst Access: Breaking the Bandwidth Barrier in Shared-L1 RVV   Clusters Beyond 1000 FPUs</title><categories>cs.AR cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As computing demand and memory footprint of deep learning applications accelerate, clusters of cores sharing local (L1) multi-banked memory are widely used as key building blocks in large-scale architectures. When the cluster's core count increases, a flat all-to-all interconnect between cores and L1 memory banks becomes a physical implementation bottleneck, and hierarchical network topologies are required. However, hierarchical, multi-level intra-cluster networks are subject to internal contention which may lead to significant performance degradation, especially for SIMD or vector cores, as their memory access is bursty. We present the TCDM Burst Access architecture, a software-transparent burst transaction support to improve bandwidth utilization in clusters with many vector cores tightly coupled to a multi-banked L1 data memory. In our solution, a Burst Manager dispatches burst requests to L1 memory banks, multiple 32b words from burst responses are retired in parallel on channels with parametric data-width. We validate our design on a RISC-V Vector (RVV) many-core cluster, evaluating the benefits on different core counts. With minimal logic area overhead (less than 8%), we improve the bandwidth of a 16-, a 256-, and a 1024--Floating Point Unit (FPU) baseline clusters, without Tightly Coupled Data Memory (TCDM) Burst Access, by 118%, 226%, and 77% respectively. Reaching up to 80% of the cores-memory peak bandwidth, our design demonstrates ultra-high bandwidth utilization and enables efficient performance scaling. Implemented in 12-nm FinFET technology node, compared to the serialized access baseline, our solution achieves up to 1.9x energy efficiency and 2.76x performance in real-world kernel benchmarkings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14371</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14371</id><created>2025-01-24</created><authors><author><keyname>Ma</keyname><forenames>Xinyu</forenames></author><author><keyname>Xu</keyname><forenames>Yifeng</forenames></author><author><keyname>Lin</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Tianlong</forenames></author><author><keyname>Chu</keyname><forenames>Xu</forenames></author><author><keyname>Gao</keyname><forenames>Xin</forenames></author><author><keyname>Zhao</keyname><forenames>Junfeng</forenames></author><author><keyname>Wang</keyname><forenames>Yasha</forenames></author></authors><title>DRESSing Up LLM: Efficient Stylized Question-Answering via Style   Subspace Editing</title><categories>cs.CL cs.AI cs.LG</categories><comments>ICLR 2025 Accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce DRESS, a novel approach for generating stylized large language model (LLM) responses through representation editing. Existing methods like prompting and fine-tuning are either insufficient for complex style adaptation or computationally expensive, particularly in tasks like NPC creation or character role-playing. Our approach leverages the over-parameterized nature of LLMs to disentangle a style-relevant subspace within the model's representation space to conduct representation editing, ensuring a minimal impact on the original semantics. By applying adaptive editing strengths, we dynamically adjust the steering vectors in the style subspace to maintain both stylistic fidelity and semantic integrity. We develop two stylized QA benchmark datasets to validate the effectiveness of DRESS, and the results demonstrate significant improvements compared to baseline methods such as prompting and ITI. In short, DRESS is a lightweight, train-free solution for enhancing LLMs with flexible and effective style control, making it particularly useful for developing stylized conversational agents. Codes and benchmark datasets are available at https://github.com/ArthurLeoM/DRESS-LLM. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14373</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14373</id><created>2025-01-24</created><authors><author><keyname>Zhu</keyname><forenames>Lingwei</forenames></author><author><keyname>Wang</keyname><forenames>Han</forenames></author><author><keyname>Nagai</keyname><forenames>Yukie</forenames></author></authors><title>Fat-to-Thin Policy Optimization: Offline RL with Sparse Policies</title><categories>cs.LG</categories><comments>accepted by ICLR 2025; code available at   https://github.com/lingweizhu/fat2thin</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse continuous policies are distributions that can choose some actions at random yet keep strictly zero probability for the other actions, which are radically different from the Gaussian. They have important real-world implications, e.g. in modeling safety-critical tasks like medicine. The combination of offline reinforcement learning and sparse policies provides a novel paradigm that enables learning completely from logged datasets a safety-aware sparse policy. However, sparse policies can cause difficulty with the existing offline algorithms which require evaluating actions that fall outside of the current support. In this paper, we propose the first offline policy optimization algorithm that tackles this challenge: Fat-to-Thin Policy Optimization (FtTPO). Specifically, we maintain a fat (heavy-tailed) proposal policy that effectively learns from the dataset and injects knowledge to a thin (sparse) policy, which is responsible for interacting with the environment. We instantiate FtTPO with the general $q$-Gaussian family that encompasses both heavy-tailed and sparse policies and verify that it performs favorably in a safety-critical treatment simulation and the standard MuJoCo suite. Our code is available at \url{https://github.com/lingweizhu/fat2thin}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14377</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14377</id><created>2025-01-24</created><authors><author><keyname>Romero</keyname><forenames>Angel</forenames></author><author><keyname>Shenai</keyname><forenames>Ashwin</forenames></author><author><keyname>Geles</keyname><forenames>Ismail</forenames></author><author><keyname>Aljalbout</keyname><forenames>Elie</forenames></author><author><keyname>Scaramuzza</keyname><forenames>Davide</forenames></author></authors><title>Dream to Fly: Model-Based Reinforcement Learning for Vision-Based Drone   Flight</title><categories>cs.RO</categories><comments>11 pages, 7 Figures</comments><acm-class>I.2.9; I.2.10; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous drone racing has risen as a challenging robotic benchmark for testing the limits of learning, perception, planning, and control. Expert human pilots are able to agilely fly a drone through a race track by mapping the real-time feed from a single onboard camera directly to control commands. Recent works in autonomous drone racing attempting direct pixel-to-commands control policies (without explicit state estimation) have relied on either intermediate representations that simplify the observation space or performed extensive bootstrapping using Imitation Learning (IL). This paper introduces an approach that learns policies from scratch, allowing a quadrotor to autonomously navigate a race track by directly mapping raw onboard camera pixels to control commands, just as human pilots do. By leveraging model-based reinforcement learning~(RL) - specifically DreamerV3 - we train visuomotor policies capable of agile flight through a race track using only raw pixel observations. While model-free RL methods such as PPO struggle to learn under these conditions, DreamerV3 efficiently acquires complex visuomotor behaviors. Moreover, because our policies learn directly from pixel inputs, the perception-aware reward term employed in previous RL approaches to guide the training process is no longer needed. Our experiments demonstrate in both simulation and real-world flight how the proposed approach can be deployed on agile quadrotors. This approach advances the frontier of vision-based autonomous flight and shows that model-based RL is a promising direction for real-world robotics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14379</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14379</id><created>2025-01-24</created><authors><author><keyname>Schirris</keyname><forenames>Yoni</forenames></author><author><keyname>Voorthuis</keyname><forenames>Rosie</forenames></author><author><keyname>Opdam</keyname><forenames>Mark</forenames></author><author><keyname>Liefaard</keyname><forenames>Marte</forenames></author><author><keyname>Sonke</keyname><forenames>Gabe S</forenames></author><author><keyname>Dackus</keyname><forenames>Gwen</forenames></author><author><keyname>de Jong</keyname><forenames>Vincent</forenames></author><author><keyname>Wang</keyname><forenames>Yuwei</forenames></author><author><keyname>Van Rossum</keyname><forenames>Annelot</forenames></author><author><keyname>Steenbruggen</keyname><forenames>Tessa G</forenames></author><author><keyname>Steggink</keyname><forenames>Lars C</forenames></author><author><keyname>de Vries</keyname><forenames>Liesbeth G. E.</forenames></author><author><keyname>van de Vijver</keyname><forenames>Marc</forenames></author><author><keyname>Salgado</keyname><forenames>Roberto</forenames></author><author><keyname>Gavves</keyname><forenames>Efstratios</forenames></author><author><keyname>van Diest</keyname><forenames>Paul J</forenames></author><author><keyname>Linn</keyname><forenames>Sabine C</forenames></author><author><keyname>Teuwen</keyname><forenames>Jonas</forenames></author><author><keyname>Menezes</keyname><forenames>Renee</forenames></author><author><keyname>Kok</keyname><forenames>Marleen</forenames></author><author><keyname>Horlings</keyname><forenames>Hugo</forenames></author></authors><title>ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte   (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients   with breast cancer</title><categories>eess.IV cs.AI cs.CV</categories><comments>Under review. 54 pages including supplementary materials, 2 main   tables, 3 main figures, 14 supplementary figures, 4 supplementary tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor for patients with (triple-negative) breast cancer (BC). Computational TIL assessment (CTA) has the potential to assist pathologists in this labour-intensive task, but current CTA models rely heavily on many detailed annotations. We propose and validate a fundamentally simpler deep learning based CTA that can be trained in only ten minutes on hundredfold fewer pathologist annotations. We collected whole slide images (WSIs) with TILs scores and clinical data of 2,340 patients with BC from six cohorts including three randomised clinical trials. Morphological features were extracted from whole slide images (WSIs) using a pathology foundation model. Our label-efficient Computational stromal TIL assessment model (ECTIL) directly regresses the TILs score from these features. ECTIL trained on only a few hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five heterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all slides of five cohorts (ECTIL-combined) improved results on a held-out test set (r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that every 10% increase of ECTIL scores was associated with improved overall survival independent of clinicopathological variables (HR 0.86, p&lt;0.01), similar to the pathologist score (HR 0.87, p&lt;0.001). We demonstrate that ECTIL is highly concordant with an expert pathologist and obtains a similar hazard ratio. ECTIL has a fundamentally simpler design than existing methods and can be trained on orders of magnitude fewer annotations. Such a CTA may be used to pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a tool to assist clinicians in the diagnostic work-up of patients with BC. Our model is available under an open source licence (https://github.com/nki-ai/ectil). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14387</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14387</id><created>2025-01-24</created><authors><author><keyname>Bolettieri</keyname><forenames>Simone</forenames></author><author><keyname>Bruno</keyname><forenames>Raffaele</forenames></author><author><keyname>Mingozzi</keyname><forenames>Enzo</forenames></author></authors><title>Application-Aware Resource Allocation and Data Management for   MEC-assisted IoT Service Providers</title><categories>cs.NI</categories><journal-ref>Journal of Network and Computer Applications, Volume 181, 1 May   2021, 103020</journal-ref><doi>10.1016/j.jnca.2021.103020</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  To support the growing demand for data-intensive and low-latency IoT applications, Multi-Access Edge Computing (MEC) is emerging as an effective edge-computing approach enabling the execution of delay-sensitive processing tasks close to end-users. However, most of the existing works on resource allocation and service placement in MEC systems overlook the unique characteristics of new IoT use cases. For instance, many IoT applications require the periodic execution of computing tasks on real-time data streams that originate from devices dispersed over a wide area. Thus, users requesting IoT services are typically distant from the data producers. To fill this gap, the contribution of this work is two-fold. Firstly, we propose a MEC-compliant architectural solution to support the operation of multiple IoT service providers over a common MEC platform deployment, which enables the steering and shaping of IoT data transport within the platform. Secondly, we model the problem of service placement and data management in the proposed MEC-based solution taking into account the dependencies at the data level between IoT services and sensing resources. Our model also considers that caches can be deployed on MEC hosts, to allow the sharing of the same data between different IoT services with overlapping geographical scope, and provides support for IoT services with heterogeneous QoS requirements, such as different frequencies of periodic task execution. Due to the complexity of the optimisation problem, a heuristic algorithm is proposed using linear relaxation and rounding techniques. Extensive simulation results demonstrate the efficiency of the proposed approach, especially when traffic demands generated by the service requests are not uniform. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14389</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14389</id><created>2025-01-24</created><authors><author><keyname>Saboor</keyname><forenames>Abdul</forenames></author><author><keyname>Cui</keyname><forenames>Zhuangzhuang</forenames></author><author><keyname>Vinogradov</keyname><forenames>Evgenii</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author></authors><title>Empirical Line-of-Sight Probability Modeling for UAVs in Random Urban   Layouts</title><categories>cs.NI</categories><comments>2025 IEEE Wireless Communications and Networking Conference (WCNC):   2025 IEEE Wireless Communications and Networking Conference (WCNC) Workshops   - WCNC 2025 WS03: The 3rd International Workshop on the Internet of   Time-Critical Things (IoTime 2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Accurate Probability of Line-of-Sight (PLoS) modeling is important in evaluating the performance of Unmanned Aerial Vehicle (UAV)-based communication systems in urban environments, where real-time communication and low latency are often major requirements. Existing PLoS models often rely on simplified Manhattan grid layouts using International Telecommunication Union (ITU)-defined built-up parameters, which may not reflect the randomness of real cities. Therefore, this paper introduces the Urban LoS Simulator (ULS) to model PLoS for three random city layouts with varying building sizes and shapes constructed using ITU built-up parameters. Based on the ULS simulated data, we obtained the empirical PLoS for four standard urban environments across three different city layouts. Finally, we analyze how well Manhattan grid-based models replicate PLoS results from random and real-world layouts, providing insights into their applicability for time-critical communication systems in urban IoT networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14390</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14390</id><created>2025-01-24</created><authors><author><keyname>Çelik</keyname><forenames>Burak</forenames></author><author><keyname>Akbal</keyname><forenames>Ayhan</forenames></author></authors><title>Distinguishing Parkinson's Patients Using Voice-Based Feature Extraction   and Classification</title><categories>cs.LG</categories><comments>Presented at the 13th International Marmara Science Congress (IMASCON   2024)</comments><report-no>ISBN: 978-605-72746-7-0</report-no><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Parkinson's disease (PD) is a progressive neurodegenerative disorder that impacts motor functions and speech characteristics This study focuses on differentiating individuals with Parkinson's disease from healthy controls through the extraction and classification of speech features. Patients were further divided into 2 groups. Med On represents the patient with medication, while Med Off represents the patient without medication. The dataset consisted of patients and healthy individuals who read a predefined text using the H1N Zoom microphone in a suitable recording environment at F{\i}rat University Neurology Department. Speech recordings from PD patients and healthy controls were analyzed, and 19 key features were extracted, including jitter, luminance, zero-crossing rate (ZCR), root mean square (RMS) energy, entropy, skewness, and kurtosis.These features were visualized in graphs and statistically evaluated to identify distinctive patterns in PD patients. Using MATLAB's Classification Learner toolbox, several machine learning classification algorithm models were applied to classify groups and significant accuracy rates were achieved. The accuracy of our 3-layer artificial neural network architecture was also compared with classical machine learning algorithms. This study highlights the potential of noninvasive voice analysis combined with machine learning for early detection and monitoring of PD patients. Future research can improve diagnostic accuracy by optimizing feature selection and exploring advanced classification techniques. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14394</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14394</id><created>2025-01-24</created><authors><author><keyname>Linden</keyname><forenames>Pascal</forenames></author><author><keyname>Paul</keyname><forenames>Nathalie</forenames></author><author><keyname>Wirtz</keyname><forenames>Tim</forenames></author><author><keyname>Wrobel</keyname><forenames>Stefan</forenames></author></authors><title>Reinforcement Learning for Efficient Returns Management</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In retail warehouses, returned products are typically placed in an intermediate storage until a decision regarding further shipment to stores is made. The longer products are held in storage, the higher the inefficiency and costs of the returns management process, since enough storage area has to be provided and maintained while the products are not placed for sale. To reduce the average product storage time, we consider an alternative solution where reallocation decisions for products can be made instantly upon their arrival in the warehouse allowing only a limited number of products to still be stored simultaneously. We transfer the problem to an online multiple knapsack problem and propose a novel reinforcement learning approach to pack the items (products) into the knapsacks (stores) such that the overall value (expected revenue) is maximized. Empirical evaluations on simulated data demonstrate that, compared to the usual offline decision procedure, our approach comes with a performance gap of only 3% while significantly reducing the average storage time of a product by 96%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14397</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14397</id><created>2025-01-24</created><authors><author><keyname>Primbs</keyname><forenames>Jonas</forenames></author><author><keyname>Kern</keyname><forenames>Dustin</forenames></author><author><keyname>Menth</keyname><forenames>Michael</forenames></author><author><keyname>Krauß</keyname><forenames>Christoph</forenames></author></authors><title>Streamlining Plug-and-Charge Authorization for Electric Vehicles with   OAuth2 and OIDC</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Plug-and-Charge (PnC) process defined by ISO 15118 standardizes automated Electric Vehicle (EV) charging by enabling automatic installation of credentials and use for authentication between EV and Charge Point (CP). However, the current credential installation process is non-uniform, relies on a complex Public Key Infrastructure (PKI), lacks support for fine-grained authorization parameters, and is not very user-friendly. In this paper, we propose a streamlined approach to the initial charging authorization process by leveraging the OAuth Device Authorization Grant and Rich Authorization Requests. The proposed solution reduces technical complexity, simplifies credential installation, introduces flexible authorization constraints (e.g., time- and cost-based), and facilitates payment through OpenID Connect (OIDC). We present a proof-of-concept implementation along with performance evaluations and conduct a symbolic protocol verification using the Tamarin prover. Furthermore, our approach solves the issue of OAuth's cross-device authorization, making it suitable as a formally proven blueprint in contexts beyond EV charging. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14399</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14399</id><created>2025-01-24</created><authors><author><keyname>Sakong</keyname><forenames>Darnbi</forenames></author><author><keyname>Nguyen</keyname><forenames>Thanh Tam</forenames></author></authors><title>Handling Heterophily in Recommender Systems with Wavelet Hypergraph   Diffusion</title><categories>cs.IR cs.AI cs.DB cs.LG cs.SI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Recommender systems are pivotal in delivering personalised user experiences across various domains. However, capturing the heterophily patterns and the multi-dimensional nature of user-item interactions poses significant challenges. To address this, we introduce FWHDNN (Fusion-based Wavelet Hypergraph Diffusion Neural Networks), an innovative framework aimed at advancing representation learning in hypergraph-based recommendation tasks. The model incorporates three key components: (1) a cross-difference relation encoder leveraging heterophily-aware hypergraph diffusion to adapt message-passing for diverse class labels, (2) a multi-level cluster-wise encoder employing wavelet transform-based hypergraph neural network layers to capture multi-scale topological relationships, and (3) an integrated multi-modal fusion mechanism that combines structural and textual information through intermediate and late-fusion strategies. Extensive experiments on real-world datasets demonstrate that FWHDNN surpasses state-of-the-art methods in accuracy, robustness, and scalability in capturing high-order interconnections between users and items. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14400</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14400</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Shengjie</forenames></author><author><keyname>You</keyname><forenames>Jiacheng</forenames></author><author><keyname>Hu</keyname><forenames>Yihang</forenames></author><author><keyname>Li</keyname><forenames>Jiongye</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author></authors><title>SKIL: Semantic Keypoint Imitation Learning for Generalizable   Data-efficient Manipulation</title><categories>cs.RO cs.AI</categories><comments>22 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-world tasks such as garment manipulation and table rearrangement demand robots to perform generalizable, highly precise, and long-horizon actions. Although imitation learning has proven to be an effective approach for teaching robots new skills, large amounts of expert demonstration data are still indispensible for these complex tasks, resulting in high sample complexity and costly data collection. To address this, we propose Semantic Keypoint Imitation Learning (SKIL), a framework which automatically obtain semantic keypoints with help of vision foundation models, and forms the descriptor of semantic keypoints that enables effecient imitation learning of complex robotic tasks with significantly lower sample complexity. In real world experiments, SKIL doubles the performance of baseline methods in tasks such as picking a cup or mouse, while demonstrating exceptional robustness to variations in objects, environmental changes, and distractors. For long-horizon tasks like hanging a towel on a rack where previous methods fail completely, SKIL achieves a mean success rate of 70\% with as few as 30 demonstrations. Furthermore, SKIL naturally supports cross-embodiment learning due to its semantic keypoints abstraction, our experiments demonstrate that even human videos bring considerable improvement to the learning performance. All these results demonstrate the great success of SKIL in achieving data-efficint generalizable robotic learning. Visualizations and code are available at: https://skil-robotics.github.io/SKIL-robotics/. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14401</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14401</id><created>2025-01-24</created><authors><author><keyname>Baghel</keyname><forenames>Rhythm</forenames></author><author><keyname>Maji</keyname><forenames>Souvik</forenames></author><author><keyname>Mazumder</keyname><forenames>Pratik</forenames></author></authors><title>CVOCSemRPL: Class-Variance Optimized Clustering, Semantic Information   Injection and Restricted Pseudo Labeling based Improved Semi-Supervised   Few-Shot Learning</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Few-shot learning has been extensively explored to address problems where the amount of labeled samples is very limited for some classes. In the semi-supervised few-shot learning setting, substantial quantities of unlabeled samples are available. Such unlabeled samples are generally cheaper to obtain and can be used to improve the few-shot learning performance of the model. Some of the recent methods for this setting rely on clustering to generate pseudo-labels for the unlabeled samples. Since the quality of the representation learned by the model heavily influences the effectiveness of clustering, this might also lead to incorrect labeling of the unlabeled samples and consequently lead to a drop in the few-shot learning performance. We propose an approach for semi-supervised few-shot learning that performs a class-variance optimized clustering in order to improve the effectiveness of clustering the labeled and unlabeled samples in this setting. It also optimizes the clustering-based pseudo-labeling process using a restricted pseudo-labeling approach and performs semantic information injection in order to improve the semi-supervised few-shot learning performance of the model. We experimentally demonstrate that our proposed approach significantly outperforms recent state-of-the-art methods on the benchmark datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14402</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14402</id><created>2025-01-24</created><authors><author><keyname>Xiao</keyname><forenames>Xingwen</forenames></author><author><keyname>Gao</keyname><forenames>Chushu</forenames></author><author><keyname>Bogner</keyname><forenames>Justus</forenames></author></authors><title>On the Effectiveness of Microservices Tactics and Patterns to Reduce   Energy Consumption: An Experimental Study on Trade-Offs</title><categories>cs.SE</categories><comments>Accepted for publication at the International Conference on Software   Architecture 2025 (ICSA'25, see https://conf.researchr.org/home/icsa-2025)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context: Microservice-based systems have established themselves in the software industry. However, sustainability-related legislation and the growing costs of energy-hungry software increase the importance of energy efficiency for these systems. While some proposals for architectural tactics and patterns exist, their effectiveness as well as potential trade-offs on other quality attributes (QAs) remain unclear.   Goal: We therefore aim to study the effectiveness of microservices tactics and patterns to reduce energy consumption, as well as potential trade-offs with performance and maintainability.   Method: Using the open-source Online Boutique system, we conducted a controlled experiment with three tactics and three patterns, and analyzed the impact of each technique compared to a baseline. We also tested with three levels of simulated request loads (low, medium, high).   Results: Request load moderated the effectiveness of reducing energy consumption. All techniques (tactics and patterns) reduced the energy consumption for at least one load level, up to 5.6%. For performance, the techniques could negatively impact response time by increasing it by up to 25.9%, while some also decreased it by up to 72.5%. Two techniques increased the throughput, by 1.9% and 34.0%. For maintainability, three techniques had a negative, one a positive, and two no impact.   Conclusion: Some techniques reduced energy consumption while also improving performance. However, these techniques usually involved a trade-off in maintainability, e.g., via more code duplication and module coupling. Overall, all techniques significantly reduced energy consumption at higher loads, but most of them sacrificed one of the other QAs. This highlights that the real challenge is not simply reducing energy consumption of microservices, but to achieve energy efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14404</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14404</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Zili</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Bai</keyname><forenames>Lei</forenames></author><author><keyname>Li</keyname><forenames>Wenyuan</forenames></author><author><keyname>Zou</keyname><forenames>Zhengxia</forenames></author><author><keyname>Shi</keyname><forenames>Zhenwei</forenames></author></authors><title>Kolmogorov Arnold Neural Interpolator for Downscaling and Correcting   Meteorological Fields from In-Situ Observations</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Obtaining accurate weather forecasts at station locations is a critical challenge due to systematic biases arising from the mismatch between multi-scale, continuous atmospheric characteristic and their discrete, gridded representations. Previous works have primarily focused on modeling gridded meteorological data, inherently neglecting the off-grid, continuous nature of atmospheric states and leaving such biases unresolved. To address this, we propose the Kolmogorov Arnold Neural Interpolator (KANI), a novel framework that redefines meteorological field representation as continuous neural functions derived from discretized grids. Grounded in the Kolmogorov Arnold theorem, KANI captures the inherent continuity of atmospheric states and leverages sparse in-situ observations to correct these biases systematically. Furthermore, KANI introduces an innovative zero-shot downscaling capability, guided by high-resolution topographic textures without requiring high-resolution meteorological fields for supervision. Experimental results across three sub-regions of the continental United States indicate that KANI achieves an accuracy improvement of 40.28% for temperature and 67.41% for wind speed, highlighting its significant improvement over traditional interpolation methods. This enables continuous neural representation of meteorological variables through neural networks, transcending the limitations of conventional grid-based representations. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14406</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14406</id><created>2025-01-24</created><authors><author><keyname>Wu</keyname><forenames>Fei</forenames></author><author><keyname>Hu</keyname><forenames>Jia</forenames></author><author><keyname>Min</keyname><forenames>Geyong</forenames></author><author><keyname>Wang</keyname><forenames>Shiqiang</forenames></author></authors><title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning   of Language Models</title><categories>cs.DC cs.AI cs.LG cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on mobile devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Federated Adaptive Rank Allocation for parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated singular value decomposition (SVD) adaptation to enhance flexibility and expressiveness, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to remove inactive modules, steadily reducing local training time and peak memory usage in each round. Extensive experiments show that FedARA consistently outperforms weak baselines by an average of 8.49\% and strong baselines by 6.95\% across various datasets under data heterogeneity while significantly improving communication efficiency by 2.40\(\times\). Moreover, experiments on AGX Orin, Orin Nano and Raspberry Pi 5 devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90\% and 46.95\%, respectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14411</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14411</id><created>2025-01-24</created><authors><author><keyname>Saboor</keyname><forenames>Abdul</forenames></author><author><keyname>Cui</keyname><forenames>Zhuangzhuang</forenames></author><author><keyname>Vinogradov</keyname><forenames>Evgenii</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author></authors><title>Path Loss Modelling for UAV Communications in Urban Scenarios with   Random Obstacles</title><categories>cs.NI</categories><comments>9th European Conference on Antennas and Propagation (EuCAP)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Path Loss (PL) is vital to evaluate the performance of Unmanned Aerial Vehicles (UAVs) as Aerial Base Stations (ABSs), particularly in urban environments with complex propagation due to various obstacles. Accurately modeling PL requires a generalized Probability of Line-of-Sight (PLoS) that can consider multiple obstructions. While the existing PLoS models mostly assume a simplified Manhattan grid with uniform building sizes and spacing, they overlook the real-world variability in building dimensions. Furthermore, such models do not consider other obstacles, such as trees and streetlights, which may also impact the performance, especially in millimeter-wave (mmWave) bands. This paper introduces a Manhattan Random Simulator (MRS) to estimate PLoS for UAV-based communications in urban areas by incorporating irregular building shapes, non-uniform spacing, and additional random obstacles to create a more realistic environment. Lastly, we present the PL differences with and without obstacles for standard urban environments and derive the empirical PL for these environments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14413</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14413</id><created>2025-01-24</created><authors><author><keyname>Kyem</keyname><forenames>Blessing Agyei</forenames></author><author><keyname>Asamoah</keyname><forenames>Joshua Kofi</forenames></author><author><keyname>Aboah</keyname><forenames>Armstrong</forenames></author></authors><title>Context-CrackNet: A Context-Aware Framework for Precise Segmentation of   Tiny Cracks in Pavement images</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The accurate detection and segmentation of pavement distresses, particularly tiny and small cracks, are critical for early intervention and preventive maintenance in transportation infrastructure. Traditional manual inspection methods are labor-intensive and inconsistent, while existing deep learning models struggle with fine-grained segmentation and computational efficiency. To address these challenges, this study proposes Context-CrackNet, a novel encoder-decoder architecture featuring the Region-Focused Enhancement Module (RFEM) and Context-Aware Global Module (CAGM). These innovations enhance the model's ability to capture fine-grained local details and global contextual dependencies, respectively. Context-CrackNet was rigorously evaluated on ten publicly available crack segmentation datasets, covering diverse pavement distress scenarios. The model consistently outperformed 9 state-of-the-art segmentation frameworks, achieving superior performance metrics such as mIoU and Dice score, while maintaining competitive inference efficiency. Ablation studies confirmed the complementary roles of RFEM and CAGM, with notable improvements in mIoU and Dice score when both modules were integrated. Additionally, the model's balance of precision and computational efficiency highlights its potential for real-time deployment in large-scale pavement monitoring systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14414</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14414</id><created>2025-01-24</created><authors><author><keyname>Yao</keyname><forenames>Kai</forenames></author><author><keyname>Juarez</keyname><forenames>Marc</forenames></author></authors><title>SoK: What Makes Private Learning Unfair?</title><categories>cs.LG cs.CR</categories><comments>Systemization of Knowledge (SoK) paper. This work has been accepted   for publication in the 3rd IEEE Conference on Secure and Trustworthy Machine   Learning (SaTML'25). The final version will be available on IEEE Xplore</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Differential privacy has emerged as the most studied framework for privacy-preserving machine learning. However, recent studies show that enforcing differential privacy guarantees can not only significantly degrade the utility of the model, but also amplify existing disparities in its predictive performance across demographic groups. Although there is extensive research on the identification of factors that contribute to this phenomenon, we still lack a complete understanding of the mechanisms through which differential privacy exacerbates disparities. The literature on this problem is muddled by varying definitions of fairness, differential privacy mechanisms, and inconsistent experimental settings, often leading to seemingly contradictory results.   This survey provides the first comprehensive overview of the factors that contribute to the disparate effect of training models with differential privacy guarantees. We discuss their impact and analyze their causal role in such a disparate effect. Our analysis is guided by a taxonomy that categorizes these factors by their position within the machine learning pipeline, allowing us to draw conclusions about their interaction and the feasibility of potential mitigation strategies. We find that factors related to the training dataset and the underlying distribution play a decisive role in the occurrence of disparate impact, highlighting the need for research on these factors to address the issue. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14417</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14417</id><created>2025-01-24</created><authors><author><keyname>Hu</keyname><forenames>Junhao</forenames></author><author><keyname>Xu</keyname><forenames>Jiang</forenames></author><author><keyname>He</keyname><forenames>Yulong</forenames></author><author><keyname>Chen</keyname><forenames>Yuetao</forenames></author><author><keyname>Dan</keyname><forenames>Gengyuan</forenames></author><author><keyname>Liu</keyname><forenames>Zhixia</forenames></author><author><keyname>Zhang</keyname><forenames>Baoquan</forenames></author><author><keyname>Wan</keyname><forenames>Shining</forenames></author><author><keyname>Dong</keyname><forenames>Zhiyu</forenames></author><author><keyname>Xu</keyname><forenames>Hao</forenames></author><author><keyname>Ren</keyname><forenames>Zhihao</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author><author><keyname>Meng</keyname><forenames>Jie</forenames></author><author><keyname>He</keyname><forenames>Chao</forenames></author><author><keyname>Xie</keyname><forenames>Tao</forenames></author><author><keyname>Lin</keyname><forenames>Dayun</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author><author><keyname>Yu</keyname><forenames>Yue</forenames></author><author><keyname>Feng</keyname><forenames>Hao</forenames></author><author><keyname>Chen</keyname><forenames>Xusheng</forenames></author><author><keyname>Shan</keyname><forenames>Yizhou</forenames></author></authors><title>DeepFlow: Serverless Large Language Model Serving at Scale</title><categories>cs.DC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces DeepFlow, a scalable and serverless AI platform designed to efficiently serve large language models (LLMs) at scale in cloud environments. DeepFlow addresses key challenges such as resource allocation, serving efficiency, and cold start latencies through four main design components. First, it uses a simple serverless abstraction called the request-job-task model, which helps manage AI workloads across post-training and model serving tasks. Second, it builds an in-house serving engine FlowServe using a microkernel-inspired design, NPU-centric execution, and SPMD-based parallelism to optimize LLM serving. The system also includes novel scheduling policies tailored for both PD-disaggregated and PD-colocated configurations. With optimizations like pre-warmed pods, DRAM pre-loading, and NPU-fork, DeepFlow can scale up to 64 instances in seconds. DeepFlow has been in production for over a year, operating on a large Ascend NPU cluster and providing industrystandard APIs for fine-tuning, agent serving, and model serving to our customers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14418</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14418</id><created>2025-01-24</created><authors><author><keyname>Avarikioti</keyname><forenames>Zeta</forenames></author><author><keyname>Wang</keyname><forenames>Yuheng</forenames></author><author><keyname>Wang</keyname><forenames>Yuyi</forenames></author></authors><title>Timelock-Free Rationally-Secure Virtual Channels</title><categories>cs.CR cs.DC cs.GT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Payment channel networks (PCNs) offer a promising solution to address the limited transaction throughput of deployed blockchains. However, several attacks have recently been proposed that stress the vulnerability of PCNs to timelock and censoring attacks. To address such attacks, we introduce Thunderdome, the first timelock-free PCN. Instead, Thunderdome leverages the design rationale of virtual channels to extend a timelock-free payment channel primitive, thereby enabling multi-hop transactions without timelocks. Previous works either utilize timelocks or do not accommodate transactions between parties that do not share a channel.   At its core, Thunderdome relies on a committee of non-trusted watchtowers, known as wardens, who ensure that no honest party loses funds, even when offline, during the channel closure process. We introduce tailored incentive mechanisms to ensure that all participants follow the protocol's correct execution. Besides a traditional security proof that assumes an honest majority of the committee, we conduct a formal game-theoretic analysis to demonstrate the security of Thunderdome when all participants, including wardens, act rationally. We implement a proof of concept of Thunderdome on Ethereum to validate its feasibility and evaluate its costs. Our evaluation shows that deploying Thunderdome, including opening the underlying payment channel, costs approximately \$15 (0.0089 ETH), while the worst-case cost for closing a channel is about \$7 (0.004 ETH). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14421</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14421</id><created>2025-01-24</created><authors><author><keyname>Mathiasen</keyname><forenames>Anders Alnor</forenames></author><author><keyname>Gondelman</keyname><forenames>Léon</forenames></author><author><keyname>Ducruet</keyname><forenames>Léon</forenames></author><author><keyname>Timany</keyname><forenames>Amin</forenames></author><author><keyname>Birkedal</keyname><forenames>Lars</forenames></author></authors><title>Reasoning about Weak Isolation Levels in Separation Logic</title><categories>cs.PL cs.LO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Isolation levels, consistency guarantees among concurrently execution transactions in local- and distributed systems, have been formalized in a number of models. Thus far, no model can reason about executable implementations of databases or local transaction libraries providing weak isolation levels. Weak isolation levels are characterized by being highly concurrent and, unlike their stronger counterpart serializability, they are not equivalent to the consistency guarantees provided by a transaction library implemented using a global lock. In this paper, we formalize three weak isolation levels in separation logic, namely read uncommitted, read committed, and snapshot isolation. We define modular separation logic specifications that are independent of the underlying transaction library implementation. Historically, isolation levels have been specified using examples of executions between concurrent transactions that are not allowed to occur, and we demonstrate that our specifications correctly prohibit such examples. To show that our specifications are realizable, we formally verify that an executable implementation of a key-value database running the multi-version concurrency control algorithm from the original snapshot isolation paper satisfies our specification of snapshot isolation. Moreover, we prove implications between the specifications -- snapshot isolation implies read committed and read committed implies read uncommitted -- and thus the verification effort of the database serves as proof that all of our specifications are realizable. All results are mechanised in the Coq proof assistant on top of the Iris separation logic framework. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14425</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14425</id><created>2025-01-24</created><authors><author><keyname>Sudha</keyname><forenames>Sanjibanee</forenames></author><author><keyname>Friedrich</keyname><forenames>Jan</forenames></author><author><keyname>Rathan</keyname><forenames>Samala</forenames></author></authors><title>Central schemes for systems of non-local balance laws</title><categories>math.NA cs.NA</categories><msc-class>35L65, 65M08, , 65M12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present numerical approaches to approximate the solutions of systems of non-local balance laws. In particular, we derive a non-staggered central scheme based on the well-known Nessyahu-Tadmor scheme and show that it preserves the positivity of solutions. To reduce the numerical diffusion, we then consider a non-local version of the Kurganov-Tadmor scheme. For both schemes, an appropriate approximation of the non-local term is crucial to maintain a second-order accuracy. Numerical examples validate our theory and demonstrate its applicability to various systems of non-local problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14426</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14426</id><created>2025-01-24</created><authors><author><keyname>Fuest</keyname><forenames>Michael</forenames></author><author><keyname>Cuesta</keyname><forenames>Alfredo</forenames></author><author><keyname>Veeramachaneni</keyname><forenames>Kalyan</forenames></author></authors><title>CENTS: Generating synthetic electricity consumption time series for rare   and unseen scenarios</title><categories>cs.LG</categories><msc-class>cs.LG</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent breakthroughs in large-scale generative modeling have demonstrated the potential of foundation models in domains such as natural language, computer vision, and protein structure prediction. However, their application in the energy and smart grid sector remains limited due to the scarcity and heterogeneity of high-quality data. In this work, we propose a method for creating high-fidelity electricity consumption time series data for rare and unseen context variables (e.g. location, building type, photovoltaics). Our approach, Context Encoding and Normalizing Time Series Generation, or CENTS, includes three key innovations: (i) A context normalization approach that enables inverse transformation for time series context variables unseen during training, (ii) a novel context encoder to condition any state-of-the-art time-series generator on arbitrary numbers and combinations of context variables, (iii) a framework for training this context encoder jointly with a time-series generator using an auxiliary context classification loss designed to increase expressivity of context embeddings and improve model performance. We further provide a comprehensive overview of different evaluation metrics for generative time series models. Our results highlight the efficacy of the proposed method in generating realistic household-level electricity consumption data, paving the way for training larger foundation models in the energy domain on synthetic as well as real-world data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14427</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14427</id><created>2025-01-24</created><authors><author><keyname>Chu</keyname><forenames>Xu</forenames></author><author><keyname>Xue</keyname><forenames>Hanlin</forenames></author><author><keyname>Tan</keyname><forenames>Zhijie</forenames></author><author><keyname>Wang</keyname><forenames>Bingce</forenames></author><author><keyname>Mo</keyname><forenames>Tong</forenames></author><author><keyname>Li</keyname><forenames>Weiping</forenames></author></authors><title>GraphBC: Improving LLMs for Better Graph Data Processing</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of Large Language Models (LLMs) in various domains has led researchers to apply them to graph-related problems by converting graph data into natural language text. However, unlike graph data, natural language inherently has sequential order. We observe that when the order of nodes or edges in the natural language description of a graph is shuffled, despite describing the same graph, model performance fluctuates between high performance and random guessing. Additionally, due to the limited input context length of LLMs, current methods typically randomly sample neighbors of target nodes as representatives of their neighborhood, which may not always be effective for accurate reasoning. To address these gaps, we introduce GraphBC. This novel model framework features an Order Selector Module to ensure proper serialization order of the graph and a Subgraph Sampling Module to sample subgraphs with better structure for better reasoning. Furthermore, we propose Graph CoT obtained through distillation, and enhance LLM's reasoning and zero-shot learning capabilities for graph tasks through instruction tuning. Experiments on multiple datasets for node classification and graph question-answering demonstrate that GraphBC improves LLMs' performance and generalization ability on graph tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14430</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14430</id><created>2025-01-24</created><authors><author><keyname>Zhiyanov</keyname><forenames>Anton</forenames></author><author><keyname>Shklyaev</keyname><forenames>Alexander</forenames></author><author><keyname>Galatenko</keyname><forenames>Alexey</forenames></author><author><keyname>Galatenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Tonevitsky</keyname><forenames>Alexander</forenames></author></authors><title>Statistical Verification of Linear Classifiers</title><categories>stat.ML cs.LG math.PR math.ST stat.AP stat.TH</categories><comments>16 pages, 3 figures</comments><msc-class>62P10</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a homogeneity test closely related to the concept of linear separability between two samples. Using the test one can answer the question whether a linear classifier is merely ``random'' or effectively captures differences between two classes. We focus on establishing upper bounds for the test's \emph{p}-value when applied to two-dimensional samples. Specifically, for normally distributed samples we experimentally demonstrate that the upper bound is highly accurate. Using this bound, we evaluate classifiers designed to detect ER-positive breast cancer recurrence based on gene pair expression. Our findings confirm significance of IGFBP6 and ELOVL5 genes in this process. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14431</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14431</id><created>2025-01-24</created><authors><author><keyname>Chu</keyname><forenames>Xu</forenames></author><author><keyname>Tan</keyname><forenames>Zhijie</forenames></author><author><keyname>Xue</keyname><forenames>Hanlin</forenames></author><author><keyname>Wang</keyname><forenames>Guanyu</forenames></author><author><keyname>Mo</keyname><forenames>Tong</forenames></author><author><keyname>Li</keyname><forenames>Weiping</forenames></author></authors><title>Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes   Domains</title><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large Language Models (LLMs) are widely applied to downstream domains. However, current LLMs for high-stakes domain tasks, such as financial investment and legal QA, typically generate brief answers without reasoning processes and explanations. This limits users' confidence in making decisions based on their responses. While original CoT shows promise, it lacks self-correction mechanisms during reasoning. This work introduces Domain$o1$s, which enhances LLMs' reasoning capabilities on domain tasks through supervised fine-tuning and tree search. We construct CoT-stock-2k and CoT-legal-2k datasets for fine-tuning models that activate domain-specific reasoning steps based on their judgment. Additionally, we propose Selective Tree Exploration to spontaneously explore solution spaces and sample optimal reasoning paths to improve performance. We also introduce PROOF-Score, a new metric for evaluating domain models' explainability, complementing traditional accuracy metrics with richer assessment dimensions. Extensive experiments on stock investment recommendation and legal reasoning QA tasks demonstrate Domaino1s's leading performance and explainability. Our code is available at https://anonymous.4open.science/r/Domaino1s-006F/. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14432</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14432</id><created>2025-01-24</created><authors><author><keyname>Muñiz-Cuza</keyname><forenames>Carlos Enrique</forenames></author><author><keyname>Boehm</keyname><forenames>Matthias</forenames></author><author><keyname>Pedersen</keyname><forenames>Torben Bach</forenames></author></authors><title>CAMEO: Autocorrelation-Preserving Line Simplification for Lossy Time   Series Compression</title><categories>cs.DB cs.IR cs.IT math.IT</categories><comments>14 pages, 13 figures</comments><acm-class>E.2; H.3.2; H.2.8</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Time series data from a variety of sensors and IoT devices need effective compression to reduce storage and I/O bandwidth requirements. While most time series databases and systems rely on lossless compression, lossy techniques offer even greater space-saving with a small loss in precision. However, the unknown impact on downstream analytics applications requires a semi-manual trial-and-error exploration. We initiate work on lossy compression that provides guarantees on complex statistical features (which are strongly correlated with the accuracy of the downstream analytics). Specifically, we propose a new lossy compression method that provides guarantees on the autocorrelation and partial-autocorrelation functions (ACF/PACF) of a time series. Our method leverages line simplification techniques as well as incremental maintenance of aggregates, blocking, and parallelization strategies for effective and efficient compression. The results show that our method improves compression ratios by 2x on average and up to 54x on selected datasets, compared to previous lossy and lossless compression methods. Moreover, we maintain -- and sometimes even improve -- the forecasting accuracy by preserving the autocorrelation properties of the time series. Our framework is extensible to multivariate time series and other statistical features of the time series. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14434</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14434</id><created>2025-01-24</created><authors><author><keyname>Yuksel</keyname><forenames>Goksenin</forenames></author><author><keyname>Rau</keyname><forenames>David</forenames></author><author><keyname>Kamps</keyname><forenames>Jaap</forenames></author></authors><title>Remining Hard Negatives for Generative Pseudo Labeled Domain Adaptation</title><categories>cs.IR cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Dense retrievers have demonstrated significant potential for neural information retrieval; however, they exhibit a lack of robustness to domain shifts, thereby limiting their efficacy in zero-shot settings across diverse domains. A state-of-the-art domain adaptation technique is Generative Pseudo Labeling (GPL). GPL uses synthetic query generation and initially mined hard negatives to distill knowledge from cross-encoder to dense retrievers in the target domain. In this paper, we analyze the documents retrieved by the domain-adapted model and discover that these are more relevant to the target queries than those of the non-domain-adapted model. We then propose refreshing the hard-negative index during the knowledge distillation phase to mine better hard negatives. Our remining R-GPL approach boosts ranking performance in 13/14 BEIR datasets and 9/12 LoTTe datasets. Our contributions are (i) analyzing hard negatives returned by domain-adapted and non-domain-adapted models and (ii) applying the GPL training with and without hard-negative re-mining in LoTTE and BEIR datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14438</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14438</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Chunting</forenames></author><author><keyname>Baghdadi</keyname><forenames>Riyadh</forenames></author></authors><title>Data-efficient Performance Modeling via Pre-training</title><categories>cs.PL cs.DC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance models are essential for automatic code optimization, enabling compilers to predict the effects of code transformations on performance and guide search for optimal transformations. Building state-of-the-art performance models with deep learning, however, requires vast labeled datasets of random programs -- an expensive and time-consuming process, stretching over months. This paper introduces a self-supervised pre-training scheme with autoencoders to reduce the need for labeled data. By pre-training on a large dataset of random programs, the autoencoder learns representations of code and transformations, which are then used to embed programs for the performance model. Implemented in the Tiramisu autoscheduler, our approach improves model accuracy with less data. For example, to achieve a MAPE of 20.72%, the original model requires 18 million data points, whereas our method achieves a similar MAPE of 22.44% with only 3.6 million data points, reducing data requirements by 5x. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14439</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14439</id><created>2025-01-24</created><authors><author><keyname>Jiao</keyname><forenames>Yingying</forenames></author><author><keyname>Wang</keyname><forenames>Zhigang</forenames></author><author><keyname>Liu</keyname><forenames>Zhenguang</forenames></author><author><keyname>Fan</keyname><forenames>Shaojing</forenames></author><author><keyname>Wu</keyname><forenames>Sifan</forenames></author><author><keyname>Wu</keyname><forenames>Zheqi</forenames></author><author><keyname>Xu</keyname><forenames>Zhuoyue</forenames></author></authors><title>Optimizing Human Pose Estimation Through Focused Human and Joint Regions</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human pose estimation has given rise to a broad spectrum of novel and compelling applications, including action recognition, sports analysis, as well as surveillance. However, accurate video pose estimation remains an open challenge. One aspect that has been overlooked so far is that existing methods learn motion clues from all pixels rather than focusing on the target human body, making them easily misled and disrupted by unimportant information such as background changes or movements of other people. Additionally, while the current Transformer-based pose estimation methods has demonstrated impressive performance with global modeling, they struggle with local context perception and precise positional identification. In this paper, we try to tackle these challenges from three aspects: (1) We propose a bilayer Human-Keypoint Mask module that performs coarse-to-fine visual token refinement, which gradually zooms in on the target human body and keypoints while masking out unimportant figure regions. (2) We further introduce a novel deformable cross attention mechanism and a bidirectional separation strategy to adaptively aggregate spatial and temporal motion clues from constrained surrounding contexts. (3) We mathematically formulate the deformable cross attention, constraining that the model focuses solely on the regions centered at the target person body. Empirically, our method achieves state-of-the-art performance on three large-scale benchmark datasets. A remarkable highlight is that our method achieves an 84.8 mean Average Precision (mAP) on the challenging wrist joint, which significantly outperforms the 81.5 mAP achieved by the current state-of-the-art method on the PoseTrack2017 dataset. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14440</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14440</id><created>2025-01-24</created><authors><author><keyname>Patel</keyname><forenames>Dhiraj</forenames></author><author><keyname>Savostianov</keyname><forenames>Anton</forenames></author><author><keyname>Schaub</keyname><forenames>Michael T.</forenames></author></authors><title>Convergence of gradient based training for linear Graph Neural Networks</title><categories>cs.LG cs.DM cs.NA cs.SI math.NA</categories><comments>27 pages, 8 figures</comments><msc-class>05C82, 91020, 92B20, 68T05</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graph Neural Networks (GNNs) are powerful tools for addressing learning problems on graph structures, with a wide range of applications in molecular biology and social networks. However, the theoretical foundations underlying their empirical performance are not well understood. In this article, we examine the convergence of gradient dynamics in the training of linear GNNs. Specifically, we prove that the gradient flow training of a linear GNN with mean squared loss converges to the global minimum at an exponential rate. The convergence rate depends explicitly on the initial weights and the graph shift operator, which we validate on synthetic datasets from well-known graph models and real-world datasets. Furthermore, we discuss the gradient flow that minimizes the total weights at the global minimum. In addition to the gradient flow, we study the convergence of linear GNNs under gradient descent training, an iterative scheme viewed as a discretization of gradient flow. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14441</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14441</id><created>2025-01-24</created><authors><author><keyname>Potgieter</keyname><forenames>Hermanus L.</forenames></author><author><keyname>Mouton</keyname><forenames>Coenraad</forenames></author><author><keyname>Davel</keyname><forenames>Marelie H.</forenames></author></authors><title>Impact of Batch Normalization on Convolutional Network Representations</title><categories>cs.LG</categories><journal-ref>Communications in Computer and Information Science, vol 2326.   Springer, Cham (2025)</journal-ref><doi>10.1007/978-3-031-78255-8_14</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Batch normalization (BatchNorm) is a popular layer normalization technique used when training deep neural networks. It has been shown to enhance the training speed and accuracy of deep learning models. However, the mechanics by which BatchNorm achieves these benefits is an active area of research, and different perspectives have been proposed. In this paper, we investigate the effect of BatchNorm on the resulting hidden representations, that is, the vectors of activation values formed as samples are processed at each hidden layer. Specifically, we consider the sparsity of these representations, as well as their implicit clustering -- the creation of groups of representations that are similar to some extent. We contrast image classification models trained with and without batch normalization and highlight consistent differences observed. These findings highlight that BatchNorm's effect on representational sparsity is not a significant factor affecting generalization, while the representations of models trained with BatchNorm tend to show more advantageous clustering characteristics. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14442</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14442</id><created>2025-01-24</created><authors><author><keyname>Fernandez</keyname><forenames>Ricardo M.</forenames></author><author><keyname>Garcia-Loro</keyname><forenames>Felix</forenames></author><author><keyname>Alves</keyname><forenames>Gustavo</forenames></author><author><keyname>Lopez-Rey</keyname><forenames>Africa</forenames></author><author><keyname>Meier</keyname><forenames>Russ</forenames></author><author><keyname>Castro</keyname><forenames>Manuel</forenames></author></authors><title>New scenarios and trends in non-traditional laboratories from 2000 to   2020</title><categories>cs.CY cs.SY eess.SY</categories><comments>Transaction on learning Technologies, 20 pages</comments><journal-ref>IEEE Transactions on Learning Technologies. 17 - 1, pp. 1568 -   1587. New YorkIEEE (Institute of Electrical and Electronic Engineers)   Education Society (IEEE ES) and Computer Society (IEEE CS), 04/2024. ISSN   1932-8540</journal-ref><doi>10.1109/TLT.2024.3387280</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  For educational institutions in STEM areas, the provision of practical learning scenarios is, traditionally, a major concern. In the 21st century, the explosion of ICTs, as well as the universalization of low-cost hardware, have allowed the proliferation of technical solutions for any field; in the case of experimentation, encouraging the emergence and proliferation of non-traditional experimentation platforms. This movement has resulted in enriched practical environments, with wider adaptability for both students and teachers. In this paper, the evolution of scholar production has been analyzed at the global level from 2000 to 2020. Current and emerging experimentation scenarios have been identified, specifying the scope and boundaries between them. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14443</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14443</id><created>2025-01-24</created><authors><author><keyname>Güitta-López</keyname><forenames>Lucía</forenames></author><author><keyname>Boal</keyname><forenames>Jaime</forenames></author><author><keyname>López-López</keyname><forenames>Álvaro J.</forenames></author></authors><title>Learning more with the same effort: how randomization improves the   robustness of a robotic deep reinforcement learning agent</title><categories>cs.RO cs.AI</categories><comments>This article was accepted and published in Applied Intelligence   (10.1007/s10489-022-04227-3)</comments><acm-class>I.2.6</acm-class><journal-ref>Applied Intelligence. 53, 2023, 14903-14917</journal-ref><doi>10.1007/s10489-022-04227-3</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The industrial application of Deep Reinforcement Learning (DRL) is frequently slowed down because of the inability to generate the experience required to train the models. Collecting data often involves considerable time and economic effort that is unaffordable in most cases. Fortunately, devices like robots can be trained with synthetic experience thanks to virtual environments. With this approach, the sample efficiency problems of artificial agents are mitigated, but another issue arises: the need for efficiently transferring the synthetic experience into the real world (sim-to-real).   This paper analyzes the robustness of a state-of-the-art sim-to-real technique known as progressive neural networks (PNNs) and studies how adding diversity to the synthetic experience can complement it. To better understand the drivers that lead to a lack of robustness, the robotic agent is still tested in a virtual environment to ensure total control on the divergence between the simulated and real models.   The results show that a PNN-like agent exhibits a substantial decrease in its robustness at the beginning of the real training phase. Randomizing certain variables during simulation-based training significantly mitigates this issue. On average, the increase in the model's accuracy is around 25% when diversity is introduced in the training process. This improvement can be translated into a decrease in the required real experience for the same final robustness performance. Notwithstanding, adding real experience to agents should still be beneficial regardless of the quality of the virtual experience fed into the agent. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14447</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14447</id><created>2025-01-24</created><authors><author><keyname>Lee</keyname><forenames>Hochang</forenames></author><author><keyname>Jeong</keyname><forenames>Kyung Chul</forenames></author><author><keyname>Kim</keyname><forenames>Panjin</forenames></author></authors><title>Quantum Circuit Optimization by Graph Coloring</title><categories>quant-ph cs.CC cs.ET</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Depth optimization of a quantum circuit consisting of commuting operations is shown to be reducible to the vertex coloring problem in graph theory. The reduction immediately leads to an algorithm for circuit optimization of commuting gates utilizing any coloring solver. To examine its applicability, known quantum circuits from the literature are optimized. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14450</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14450</id><created>2025-01-24</created><authors><author><keyname>Suga</keyname><forenames>Tatsuhiro</forenames></author><author><keyname>Suzuki</keyname><forenames>Akira</forenames></author><author><keyname>Tamura</keyname><forenames>Yuma</forenames></author><author><keyname>Zhou</keyname><forenames>Xiao</forenames></author></authors><title>Changing Induced Subgraph Isomorphisms Under Extended Reconfiguration   Rules</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In a reconfiguration problem, we are given two feasible solutions of a combinatorial problem and our goal is to determine whether it is possible to reconfigure one into the other, with the steps dictated by specific reconfiguration rules. Traditionally, most studies on reconfiguration problems have focused on rules that allow changing a single element at a time. In contrast, this paper considers scenarios in which $k \ge 2$ elements can be changed simultaneously. We investigate the general reconfiguration problem of isomorphisms. For the Induced Subgraph Isomorphism Reconfiguration problem, we show that the problem remains $\textsf{PSPACE}$-complete even under stringent constraints on the pattern graph when $k$ is constant. We then give two meta-theorems applicable when $k$ is slightly less than the number of vertices in the pattern graph. In addition, we investigate the complexity of the Independent Set Reconfiguration problem, which is a special case of the Induced Subgraph Isomorphism Reconfiguration problem. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14451</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14451</id><created>2025-01-24</created><authors><author><keyname>Liang</keyname><forenames>Linfeng</forenames></author><author><keyname>Zheng</keyname><forenames>Xi</forenames></author></authors><title>MARL-OT: Multi-Agent Reinforcement Learning Guided Online Fuzzing to   Detect Safety Violation in Autonomous Driving Systems</title><categories>cs.SE cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous Driving Systems (ADSs) are safety-critical, as real-world safety violations can result in significant losses. Rigorous testing is essential before deployment, with simulation testing playing a key role. However, ADSs are typically complex, consisting of multiple modules such as perception and planning, or well-trained end-to-end autonomous driving systems. Offline methods, such as the Genetic Algorithm (GA), can only generate predefined trajectories for dynamics, which struggle to cause safety violations for ADSs rapidly and efficiently in different scenarios due to their evolutionary nature. Online methods, such as single-agent reinforcement learning (RL), can quickly adjust the dynamics' trajectory online to adapt to different scenarios, but they struggle to capture complex corner cases of ADS arising from the intricate interplay among multiple vehicles. Multi-agent reinforcement learning (MARL) has a strong ability in cooperative tasks. On the other hand, it faces its own challenges, particularly with convergence. This paper introduces MARL-OT, a scalable framework that leverages MARL to detect safety violations of ADS resulting from surrounding vehicles' cooperation. MARL-OT employs MARL for high-level guidance, triggering various dangerous scenarios for the rule-based online fuzzer to explore potential safety violations of ADS, thereby generating dynamic, realistic safety violation scenarios. Our approach improves the detected safety violation rate by up to 136.2% compared to the state-of-the-art (SOTA) testing technique. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14452</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14452</id><created>2025-01-24</created><authors><author><keyname>Papoutsidakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Alexandropoulos</keyname><forenames>George C.</forenames></author></authors><title>On the Rate-Exponent Region of Integrated Sensing and Communications   With Variable-Length Coding</title><categories>cs.IT eess.SP math.IT</categories><comments>Accepted at the IEEE Wireless Communications and Networking   Conference (WCNC) 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the achievable rate-exponent region of integrated sensing and communication systems in the presence of variable-length coding with feedback. This scheme is fundamentally different from earlier studies, as the coding methods that utilize feedback impose different constraints on the codewords. The focus herein is specifically on the Gaussian channel, where three achievable regions are analytically derived and numerically evaluated. In contrast to a setting without feedback, we show that a trade-off exists between the operations of sensing and communications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14453</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14453</id><created>2025-01-24</created><authors><author><keyname>Bhaskar</keyname><forenames>Uday</forenames></author><author><keyname>Srivastava</keyname><forenames>Varul</forenames></author><author><keyname>Vummintala</keyname><forenames>Avyukta Manjunatha</forenames></author><author><keyname>Manwani</keyname><forenames>Naresh</forenames></author><author><keyname>Gujar</keyname><forenames>Sujit</forenames></author></authors><title>Optimal Strategies for Federated Learning Maintaining Client Privacy</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Federated Learning (FL) emerged as a learning method to enable the server to train models over data distributed among various clients. These clients are protective about their data being leaked to the server, any other client, or an external adversary, and hence, locally train the model and share it with the server rather than sharing the data. The introduction of sophisticated inferencing attacks enabled the leakage of information about data through access to model parameters. To tackle this challenge, privacy-preserving federated learning aims to achieve differential privacy through learning algorithms like DP-SGD. However, such methods involve adding noise to the model, data, or gradients, reducing the model's performance.   This work provides a theoretical analysis of the tradeoff between model performance and communication complexity of the FL system. We formally prove that training for one local epoch per global round of training gives optimal performance while preserving the same privacy budget. We also investigate the change of utility (tied to privacy) of FL models with a change in the number of clients and observe that when clients are training using DP-SGD and argue that for the same privacy budget, the utility improved with increased clients. We validate our findings through experiments on real-world datasets. The results from this paper aim to improve the performance of privacy-preserving federated learning systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14455</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14455</id><created>2025-01-24</created><authors><author><keyname>Xu</keyname><forenames>Bo</forenames></author><author><keyname>Xie</keyname><forenames>Qiujie</forenames></author><author><keyname>Zhou</keyname><forenames>Jiahui</forenames></author><author><keyname>Zong</keyname><forenames>Linlin</forenames></author></authors><title>Triple Path Enhanced Neural Architecture Search for Multimodal Fake News   Detection</title><categories>cs.CV</categories><comments>This paper has been accepted into the IEEE International Conference   on Acoustics, Speech, and Signal Processing(ICASSP 2024)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Multimodal fake news detection has become one of the most crucial issues on social media platforms. Although existing methods have achieved advanced performance, two main challenges persist: (1) Under-performed multimodal news information fusion due to model architecture solidification, and (2) weak generalization ability on partial-modality contained fake news. To meet these challenges, we propose a novel and flexible triple path enhanced neural architecture search model MUSE. MUSE includes two dynamic paths for detecting partial-modality contained fake news and a static path for exploiting potential multimodal correlations. Experimental results show that MUSE achieves stable performance improvement over the baselines. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14456</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14456</id><created>2025-01-24</created><authors><author><keyname>Will</keyname><forenames>Jonathan</forenames></author><author><keyname>Treide</keyname><forenames>Nico</forenames></author><author><keyname>Thamsen</keyname><forenames>Lauritz</forenames></author><author><keyname>Kao</keyname><forenames>Odej</forenames></author></authors><title>Experimentally Evaluating the Resource Efficiency of Big Data   Autoscaling</title><categories>cs.DC</categories><comments>6 pages, 3 figures, 6 tables. IEEE Big Data 2024</comments><acm-class>C.2.4; I.2.8; I.2.6</acm-class><doi>10.1109/BigData62323.2024.10825367</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed dataflow systems like Spark and Flink enable data-parallel processing of large datasets on clusters. Yet, selecting appropriate computational resources for dataflow jobs is often challenging. For efficient execution, individual resource allocations, such as memory and CPU cores, must meet the specific resource requirements of the job. An alternative to selecting a static resource allocation for a job execution is autoscaling as implemented for example by Spark.   In this paper, we evaluate the resource efficiency of autoscaling batch data processing jobs based on resource demand both conceptually and experimentally by analyzing a new dataset of Spark job executions on Google Dataproc Serverless. In our experimental evaluation, we show that there is no significant resource efficiency gain over static resource allocations. We found that the inherent conceptual limitations of such autoscaling approaches are the inelasticity of node size as well as the inelasticity of the ratio of memory to CPU cores. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14457</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14457</id><created>2025-01-24</created><authors><author><keyname>Yu</keyname><forenames>Zeping</forenames></author><author><keyname>Ananiadou</keyname><forenames>Sophia</forenames></author></authors><title>Understanding and Mitigating Gender Bias in LLMs via Interpretable   Neuron Editing</title><categories>cs.CL</categories><comments>preprint</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large language models (LLMs) often exhibit gender bias, posing challenges for their safe deployment. Existing methods to mitigate bias lack a comprehensive understanding of its mechanisms or compromise the model's core capabilities. To address these issues, we propose the CommonWords dataset, to systematically evaluate gender bias in LLMs. Our analysis reveals pervasive bias across models and identifies specific neuron circuits, including gender neurons and general neurons, responsible for this behavior. Notably, editing even a small number of general neurons can disrupt the model's overall capabilities due to hierarchical neuron interactions. Based on these insights, we propose an interpretable neuron editing method that combines logit-based and causal-based strategies to selectively target biased neurons. Experiments on five LLMs demonstrate that our method effectively reduces gender bias while preserving the model's original capabilities, outperforming existing fine-tuning and editing approaches. Our findings contribute a novel dataset, a detailed analysis of bias mechanisms, and a practical solution for mitigating gender bias in LLMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14458</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14458</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Jing</forenames></author><author><keyname>Choromanska</keyname><forenames>Anna</forenames></author></authors><title>A Survey of Optimization Methods for Training DL Models: Theoretical   Perspective on Convergence and Generalization</title><categories>cs.LG cs.DC math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As data sets grow in size and complexity, it is becoming more difficult to pull useful features from them using hand-crafted feature extractors. For this reason, deep learning (DL) frameworks are now widely popular. The Holy Grail of DL and one of the most mysterious challenges in all of modern ML is to develop a fundamental understanding of DL optimization and generalization. While numerous optimization techniques have been introduced in the literature to navigate the exploration of the highly non-convex DL optimization landscape, many survey papers reviewing them primarily focus on summarizing these methodologies, often overlooking the critical theoretical analyses of these methods. In this paper, we provide an extensive summary of the theoretical foundations of optimization methods in DL, including presenting various methodologies, their convergence analyses, and generalization abilities. This paper not only includes theoretical analysis of popular generic gradient-based first-order and second-order methods, but it also covers the analysis of the optimization techniques adapting to the properties of the DL loss landscape and explicitly encouraging the discovery of well-generalizing optimal points. Additionally, we extend our discussion to distributed optimization methods that facilitate parallel computations, including both centralized and decentralized approaches. We provide both convex and non-convex analysis for the optimization algorithms considered in this survey paper. Finally, this paper aims to serve as a comprehensive theoretical handbook on optimization methods for DL, offering insights and understanding to both novice and seasoned researchers in the field. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14459</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14459</id><created>2025-01-24</created><authors><author><keyname>Yuksel</keyname><forenames>Goksenin</forenames></author><author><keyname>Kamps</keyname><forenames>Jaap</forenames></author></authors><title>Interpretability Analysis of Domain Adapted Dense Retrievers</title><categories>cs.IR cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Dense retrievers have demonstrated significant potential for neural information retrieval; however, they exhibit a lack of robustness to domain shifts, thereby limiting their efficacy in zero-shot settings across diverse domains. Previous research has investigated unsupervised domain adaptation techniques to adapt dense retrievers to target domains. However, these studies have not focused on explainability analysis to understand how such adaptations alter the model's behavior. In this paper, we propose utilizing the integrated gradients framework to develop an interpretability method that provides both instance-based and ranking-based explanations for dense retrievers. To generate these explanations, we introduce a novel baseline that reveals both query and document attributions. This method is used to analyze the effects of domain adaptation on input attributions for query and document tokens across two datasets: the financial question answering dataset (FIQA) and the biomedical information retrieval dataset (TREC-COVID). Our visualizations reveal that domain-adapted models focus more on in-domain terminology compared to non-adapted models, exemplified by terms such as "hedge," "gold," "corona," and "disease." This research addresses how unsupervised domain adaptation techniques influence the behavior of dense retrievers when adapted to new domains. Additionally, we demonstrate that integrated gradients are a viable choice for explaining and analyzing the internal mechanisms of these opaque neural models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14460</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14460</id><created>2025-01-24</created><authors><author><keyname>Doknic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Möller</keyname><forenames>Torsten</forenames></author></authors><title>MLMC: Interactive multi-label multi-classifier evaluation without   confusion matrices</title><categories>cs.LG</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning-based classifiers are commonly evaluated by metrics like accuracy, but deeper analysis is required to understand their strengths and weaknesses. MLMC is a visual exploration tool that tackles the challenge of multi-label classifier comparison and evaluation. It offers a scalable alternative to confusion matrices which are commonly used for such tasks, but don't scale well with a large number of classes or labels. Additionally, MLMC allows users to view classifier performance from an instance perspective, a label perspective, and a classifier perspective. Our user study shows that the techniques implemented by MLMC allow for a powerful multi-label classifier evaluation while preserving user friendliness. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14461</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14461</id><created>2025-01-24</created><authors><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author><author><keyname>Kunz</keyname><forenames>Pascal</forenames></author></authors><title>Efficient parameterized approximation</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems are NP-hard and, unless P = NP, do not admit polynomial-time exact algorithms. The fastest known exact algorithms exactly usually take time exponential in the input size. Much research effort has gone into obtaining faster exact algorithms for instances that are sufficiently well-structured, e.g., through parameterized algorithms with running time $f(k)\cdot n^{\mathcal{O}(1)}$ where n is the input size and k quantifies some structural property such as treewidth. When k is small, this is comparable to a polynomial-time exact algorithm and outperforms the fastest exact exponential-time algorithms for a large range of k.   In this work, we are interested instead in leveraging instance structure for polynomial-time approximation algorithms. We aim for polynomial-time algorithms that produce a solution of value at most or at least (depending on minimization vs. maximization) $c\mathrm{OPT}\pm f(k)$ where c is a constant. Unlike for standard parameterized algorithms, we do not assume that structural information is provided with the input. Ideally, we can obtain algorithms with small additive error, i.e., $c=1$ and $f(k)$ is polynomial or even linear in $k$. For small k, this is similarly comparable to a polynomial-time exact algorithm and will beat general case approximation for a large range of k.   We study Vertex Cover, Connected Vertex Cover, Chromatic Number, and Triangle Packing. The parameters we consider are the size of minimum modulators to graph classes on which the respective problem is tractable. For most problem-parameter combinations we give algorithms that compute a solution of size at least or at most $\mathrm{OPT}\pm k$. In the case of Vertex Cover, most of our algorithms are tight under the Unique Games Conjecture and provide better approximation guarantees than standard 2-approximations if the modulator is smaller than the optimum solution. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14465</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14465</id><created>2025-01-24</created><authors><author><keyname>Guo</keyname><forenames>Xiujing</forenames></author><author><keyname>Li</keyname><forenames>Chen</forenames></author><author><keyname>Tsuchiya</keyname><forenames>Tatsuhiro</forenames></author></authors><title>Boundary Value Test Input Generation Using Prompt Engineering with LLMs:   Fault Detection and Coverage Analysis</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As software systems grow more complex, automated testing has become essential to ensuring reliability and performance. Traditional methods for boundary value test input generation can be time-consuming and may struggle to address all potential error cases effectively, especially in systems with intricate or highly variable boundaries. This paper presents a framework for assessing the effectiveness of large language models (LLMs) in generating boundary value test inputs for white-box software testing by examining their potential through prompt engineering. Specifically, we evaluate the effectiveness of LLM-based test input generation by analyzing fault detection rates and test coverage, comparing these LLM-generated test sets with those produced using traditional boundary value analysis methods. Our analysis shows the strengths and limitations of LLMs in boundary value generation, particularly in detecting common boundary-related issues. However, they still face challenges in certain areas, especially when handling complex or less common test inputs. This research provides insights into the role of LLMs in boundary value testing, underscoring both their potential and areas for improvement in automated testing methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14466</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14466</id><created>2025-01-24</created><authors><author><keyname>Yuksel</keyname><forenames>Goksenin</forenames></author><author><keyname>Kamps</keyname><forenames>Jaap</forenames></author></authors><title>On Correlating Factors for Domain Adaptation Performance</title><categories>cs.IR stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Dense retrievers have demonstrated significant potential for neural information retrieval; however, they lack robustness to domain shifts, limiting their efficacy in zero-shot settings across diverse domains. In this paper, we set out to analyze the possible factors that lead to successful domain adaptation of dense retrievers. We include domain similarity proxies between generated queries to test and source domains. Furthermore, we conduct a case study comparing two powerful domain adaptation techniques. We find that generated query type distribution is an important factor, and generating queries that share a similar domain to the test documents improves the performance of domain adaptation methods. This study further emphasizes the importance of domain-tailored generated queries. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14469</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14469</id><created>2025-01-24</created><authors><author><keyname>Kim</keyname><forenames>Taehan</forenames></author><author><keyname>Seo</keyname><forenames>Wonduk</forenames></author></authors><title>Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware   Pesticide Design</title><categories>cs.LG cs.AI q-bio.BM q-bio.MN</categories><comments>9 pages, 2 figures, 5 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Global climate change has reduced crop resilience and pesticide efficacy, making reliance on synthetic pesticides inevitable, even though their widespread use poses significant health and environmental risks. While these pesticides remain a key tool in pest management, previous machine-learning applications in pesticide and agriculture have focused on classification or regression, leaving the fundamental challenge of generating new molecular structures or designing novel candidates unaddressed. In this paper, we propose Pesti-Gen, a novel generative model based on variational auto-encoders, designed to create pesticide candidates with optimized properties for the first time. Specifically, Pesti-Gen leverages a two-stage learning process: an initial pre-training phase that captures a generalized chemical structure representation, followed by a fine-tuning stage that incorporates toxicity-specific information. The model simultaneously optimizes over multiple toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to generate environmentally friendly pesticide candidates. Notably, Pesti-Gen achieves approximately 68\% structural validity in generating new molecular structures, demonstrating the model's effectiveness in producing optimized and feasible pesticide candidates, thereby providing a new way for safer and more sustainable pest management solutions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14473</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14473</id><created>2025-01-24</created><authors><author><keyname>Arnold</keyname><forenames>Benedikt T.</forenames></author><author><keyname>Baydoun</keyname><forenames>Khalil</forenames></author><author><keyname>Collarana</keyname><forenames>Diego</forenames></author><author><keyname>Duda</keyname><forenames>Sebastian</forenames></author><author><keyname>Gillmann</keyname><forenames>Christina</forenames></author><author><keyname>Hemid</keyname><forenames>Ahmad</forenames></author><author><keyname>Hertweck</keyname><forenames>Philipp</forenames></author><author><keyname>Moosmann</keyname><forenames>Paul</forenames></author><author><keyname>Sukhoroslov</keyname><forenames>Denis</forenames></author><author><keyname>Lange</keyname><forenames>Christoph</forenames></author></authors><title>XFSC: A Catalogue of Trustable Semantic Metadata for Data Services and   Providers</title><categories>cs.DB</categories><comments>Preprint. Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In dataspaces, federation services facilitate key functions such as enabling participating organizations to establish mutual trust and assisting them in discovering data and services available for consumption. Discovery is enabled by a catalogue, where participants publish metadata describing themselves and their data and service offerings as Verifiable Presentations (VPs), such that other participants may query them. This paper presents the Eclipse Cross Federation Services Components (XFSC) Catalogue, which originated as a catalogue reference implementation for the Gaia-X federated cloud service architecture but is also generally applicable to metadata required to be trustable. This implementation provides basic lifecycle management for DCAT-style metadata records and schemas. It validates submitted VPs for their cryptographic integrity and trustability, and for their conformance to an extensible collection of semantic schemas. The claims in the latest versions of valid VP submissions are extracted into a searchable graph database. The implementation scales to large numbers of records and is secure by design.   Filling the catalogue with content in a maintainable way requires bindings towards where data and service offerings are coming from: connectors that expose resources hosted in an organization's IT infrastructure towards the dataspace. We demonstrate the integration of our catalogue with the widely used Eclipse Dataspace Components Connector, enabling real-world use cases of the German Culture Dataspace. In addition, we discuss potential extensions and upcoming integrations of the catalogue. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14474</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14474</id><created>2025-01-24</created><authors><author><keyname>Duetting</keyname><forenames>Paul</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Ponitka</keyname><forenames>Tomasz</forenames></author><author><keyname>Soumalias</keyname><forenames>Ermis</forenames></author></authors><title>The Pseudo-Dimension of Contracts</title><categories>cs.GT cs.AI cs.LG econ.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic contract design studies scenarios where a principal incentivizes an agent to exert effort on her behalf. In this work, we focus on settings where the agent's type is drawn from an unknown distribution, and formalize an offline learning framework for learning near-optimal contracts from sample agent types. A central tool in our analysis is the notion of pseudo-dimension from statistical learning theory. Beyond its role in establishing upper bounds on the sample complexity, pseudo-dimension measures the intrinsic complexity of a class of contracts, offering a new perspective on the tradeoffs between simplicity and optimality in contract design. Our main results provide essentially optimal tradeoffs between pseudo-dimension and representation error (defined as the loss in principal's utility) with respect to linear and bounded contracts. Using these tradeoffs, we derive sample- and time-efficient learning algorithms, and demonstrate their near-optimality by providing almost matching lower bounds on the sample complexity. Conversely, for unbounded contracts, we prove an impossibility result showing that no learning algorithm exists.   Finally, we extend our techniques in three important ways. First, we provide refined pseudo-dimension and sample complexity guarantees for the combinatorial actions model, revealing a novel connection between the number of critical values and sample complexity. Second, we extend our results to menus of contracts, showing that their pseudo-dimension scales linearly with the menu size. Third, we adapt our algorithms to the online learning setting, where we show that, a polynomial number of type samples suffice to learn near-optimal bounded contracts. Combined with prior work, this establishes a formal separation between expert advice and bandit feedback for this setting. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14475</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14475</id><created>2025-01-24</created><authors><author><keyname>Zeng</keyname><forenames>Chenyu</forenames></author><author><keyname>Zhang</keyname><forenames>Yanshu</forenames></author><author><keyname>Zhou</keyname><forenames>Jiayi</forenames></author><author><keyname>Wang</keyname><forenames>Yuhan</forenames></author><author><keyname>Wang</keyname><forenames>Zilin</forenames></author><author><keyname>Liu</keyname><forenames>Yuhao</forenames></author><author><keyname>Wu</keyname><forenames>Lei</forenames></author><author><keyname>Huang</keyname><forenames>Daniel Zhengyu</forenames></author></authors><title>Point Cloud Neural Operator for Parametric PDEs on Complex and Variable   Geometries</title><categories>math.NA cs.NA</categories><comments>43 pages, 18 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Surrogate models are critical for accelerating computationally expensive simulations in science and engineering, particularly for solving parametric partial differential equations (PDEs). Key challenges in developing practical surrogate models include managing high-dimensional inputs and outputs and handling geometrically complex and variable domains, which are often represented as point clouds. In this work, we systematically investigate the formulation of neural operators on point clouds and introduce the Point Cloud Neural Operator (PCNO), a neural network-based surrogate model designed to efficiently approximate solution maps of parametric PDEs on complex and variable geometries. We evaluate the performance of PCNO on a range of pedagogical PDE problems, focusing on aspects such as boundary layers, adaptively meshed point clouds, and variable domains with topological variations. Its practicality is further demonstrated through three-dimensional applications, such as predicting pressure loads on various types of vehicles and simulating the inflation process of intricate parachute structures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14476</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14476</id><created>2025-01-24</created><authors><author><keyname>Secchini</keyname><forenames>Valeria</forenames></author><author><keyname>Garcia-Bernardo</keyname><forenames>Javier</forenames></author><author><keyname>Janský</keyname><forenames>Petr</forenames></author></authors><title>Avoiding Overfitting in Variable-Order Markov Models: a Cross-Validation   Approach</title><categories>physics.soc-ph cs.SI econ.GN q-fin.EC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher$\text{-}$order Markov chain models are widely used to represent agent transitions in dynamic systems, such as passengers in transport networks. They capture transitions in complex systems by considering not only the current state but also the path of previously visited states. For example, the likelihood of train passengers traveling from Paris (current state) to Rome could increase significantly if their journey originated in Italy (prior state). Although this approach provides a more faithful representation of the system than first$\text{-}$order models, we find that commonly used methods$-$relying on Kullback$\text{-}$Leibler divergence$-$frequently overfit the data, mistaking fluctuations for higher$\text{-}$order dependencies and undermining forecasts and resource allocation. Here, we introduce DIVOP (Detection of Informative Variable$\text{-}$Order Paths), an algorithm that employs cross$\text{-}$validation to robustly distinguish meaningful higher$\text{-}$order dependencies from noise. In both synthetic and real$\text{-}$world datasets, DIVOP outperforms two state$\text{-}$of$\text{-}$the$\text{-}$art algorithms by achieving higher precision, recall, and sparser representations of the underlying dynamics. When applied to global corporate ownership data, DIVOP reveals that tax havens appear in 82$\%$ of all significant higher$\text{-}$order dependencies, underscoring their outsized influence in corporate networks. By mitigating overfitting, DIVOP enables more reliable multi$\text{-}$step predictions and decision$\text{-}$making, paving the way toward deeper insights into the hidden structures that drive modern interconnected systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14477</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14477</id><created>2025-01-24</created><authors><author><keyname>Ma</keyname><forenames>Hao</forenames></author><author><keyname>Chen</keyname><forenames>Rujin</forenames></author><author><keyname>Jing</keyname><forenames>Ruihao</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao-Lei</forenames></author><author><keyname>Liu</keyname><forenames>Ju</forenames></author><author><keyname>Li</keyname><forenames>Xuelong</forenames></author></authors><title>Enhancing Intelligibility for Generative Target Speech Extraction via   Joint Optimization with Target Speaker ASR</title><categories>eess.AS cs.SD</categories><comments>demo: https://aisaka0v0.github.io/GenerativeTSE_demo/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Target speech extraction (TSE) isolates the speech of a specific speaker from a multi-talker overlapped speech mixture. Most existing TSE models rely on discriminative methods, typically predicting a time-frequency spectrogram mask for the target speech. However, imperfections in these masks often result in over-/under-suppression of target/non-target speech, degrading perceptual quality. Generative methods, by contrast, re-synthesize target speech based on the mixture and target speaker cues, achieving superior perceptual quality. Nevertheless, these methods often overlook speech intelligibility, leading to alterations or loss of semantic content in the re-synthesized speech. Inspired by the Whisper model's success in target speaker ASR, we propose a generative TSE framework based on the pre-trained Whisper model to address the above issues. This framework integrates semantic modeling with flow-based acoustic modeling to achieve both high intelligibility and perceptual quality. Results from multiple benchmarks demonstrate that the proposed method outperforms existing generative and discriminative baselines. We present speech samples on our demo page. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14483</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14483</id><created>2025-01-24</created><authors><author><keyname>Yassine</keyname><forenames>Walid</forenames></author><author><keyname>Charachon</keyname><forenames>Martin</forenames></author><author><keyname>Hudelot</keyname><forenames>Céline</forenames></author><author><keyname>Ardon</keyname><forenames>Roberto</forenames></author></authors><title>Registration of Longitudinal Liver Examinations for Tumor Progress   Assessment</title><categories>eess.IV cs.AI cs.CV physics.med-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Assessing cancer progression in liver CT scans is a clinical challenge, requiring a comparison of scans at different times for the same patient. Practitioners must identify existing tumors, compare them with prior exams, identify new tumors, and evaluate overall disease evolution. This process is particularly complex in liver examinations due to misalignment between exams caused by several factors. Indeed, longitudinal liver examinations can undergo different non-pathological and pathological changes due to non-rigid deformations, the appearance or disappearance of pathologies, and other variations. In such cases, existing registration approaches, mainly based on intrinsic features may distort tumor regions, biasing the tumor progress evaluation step and the corresponding diagnosis. This work proposes a registration method based only on geometrical and anatomical information from liver segmentation, aimed at aligning longitudinal liver images for aided diagnosis. The proposed method is trained and tested on longitudinal liver CT scans, with 317 patients for training and 53 for testing. Our experimental results support our claims by showing that our method is better than other registration techniques by providing a smoother deformation while preserving the tumor burden (total volume of tissues considered as tumor) within the volume. Qualitative results emphasize the importance of smooth deformations in preserving tumor appearance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14484</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14484</id><created>2025-01-24</created><authors><author><keyname>Shen</keyname><forenames>Guobin</forenames></author><author><keyname>Li</keyname><forenames>Jindong</forenames></author><author><keyname>Li</keyname><forenames>Tenglong</forenames></author><author><keyname>Zhao</keyname><forenames>Dongcheng</forenames></author><author><keyname>Zeng</keyname><forenames>Yi</forenames></author></authors><title>$SpikePack$: Enhanced Information Flow in Spiking Neural Networks with   High Hardware Compatibility</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spiking Neural Networks (SNNs) hold promise for energy-efficient, biologically inspired computing. We identify substantial informatio loss during spike transmission, linked to temporal dependencies in traditional Leaky Integrate-and-Fire (LIF) neuron-a key factor potentially limiting SNN performance. Existing SNN architectures also underutilize modern GPUs, constrained by single-bit spike storage and isolated weight-spike operations that restrict computational efficiency. We introduce ${SpikePack}$, a neuron model designed to reduce transmission loss while preserving essential features like membrane potential reset and leaky integration. ${SpikePack}$ achieves constant $\mathcal{O}(1)$ time and space complexity, enabling efficient parallel processing on GPUs and also supporting serial inference on existing SNN hardware accelerators. Compatible with standard Artificial Neural Network (ANN) architectures, ${SpikePack}$ facilitates near-lossless ANN-to-SNN conversion across various networks. Experimental results on tasks such as image classification, detection, and segmentation show ${SpikePack}$ achieves significant gains in accuracy and efficiency for both directly trained and converted SNNs over state-of-the-art models. Tests on FPGA-based platforms further confirm cross-platform flexibility, delivering high performance and enhanced sparsity. By enhancing information flow and rethinking SNN-ANN integration, ${SpikePack}$ advances efficient SNN deployment across diverse hardware platforms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14486</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14486</id><created>2025-01-24</created><authors><author><keyname>McLaughlin</keyname><forenames>Jake</forenames></author><author><keyname>Charron</keyname><forenames>Nicholas</forenames></author><author><keyname>Narasimhan</keyname><forenames>Sriram</forenames></author></authors><title>Visual-Lidar Map Alignment for Infrastructure Inspections</title><categories>cs.RO</categories><comments>8 pages, 8 figures, for associated code see   https://github.com/jakemclaughlin6/vlma</comments><msc-class>68T40 (primary), 62P30 (secondary)</msc-class><acm-class>J.2; I.4</acm-class><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Routine and repetitive infrastructure inspections present safety, efficiency, and consistency challenges as they are performed manually, often in challenging or hazardous environments. They can also introduce subjectivity and errors into the process, resulting in undesirable outcomes. Simultaneous localization and mapping (SLAM) presents an opportunity to generate high-quality 3D maps that can be used to extract accurate and objective inspection data. Yet, many SLAM algorithms are limited in their ability to align 3D maps from repeated inspections in GPS-denied settings automatically. This limitation hinders practical long-term asset health assessments by requiring tedious manual alignment for data association across scans from previous inspections. This paper introduces a versatile map alignment algorithm leveraging both visual and lidar data for improved place recognition robustness and presents an infrastructure-focused dataset tailored for consecutive inspections. By detaching map alignment from SLAM, our approach enhances infrastructure inspection pipelines, supports monitoring asset degradation over time, and invigorates SLAM research by permitting exploration beyond existing multi-session SLAM algorithms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14488</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14488</id><created>2025-01-24</created><authors><author><keyname>Hu</keyname><forenames>Yuhan</forenames></author><author><keyname>Sun</keyname><forenames>Yirong</forenames></author><author><keyname>Chen</keyname><forenames>Yanjun</forenames></author><author><keyname>Chen</keyname><forenames>Xinghao</forenames></author></authors><title>Breaking the Pre-Planning Barrier: Real-Time Adaptive Coordination of   Mission and Charging UAVs Using Graph Reinforcement Learning</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned Aerial Vehicles (UAVs) are pivotal in applications such as search and rescue and environmental monitoring, excelling in intelligent perception tasks. However, their limited battery capacity hinders long-duration and long-distance missions. Charging UAVs (CUAVs) offers a potential solution by recharging mission UAVs (MUAVs), but existing methods rely on impractical pre-planned routes, failing to enable organic cooperation and limiting mission efficiency. We introduce a novel multi-agent deep reinforcement learning model named \textbf{H}eterogeneous \textbf{G}raph \textbf{A}ttention \textbf{M}ulti-agent Deep Deterministic Policy Gradient (HGAM), designed to dynamically coordinate MUAVs and CUAVs. This approach maximizes data collection, geographical fairness, and energy efficiency by allowing UAVs to adapt their routes in real-time to current task demands and environmental conditions without pre-planning. Our model uses heterogeneous graph attention networks (GATs) to present heterogeneous agents and facilitate efficient information exchange. It operates within an actor-critic framework. Simulation results show that our model significantly improves cooperation among heterogeneous UAVs, outperforming existing methods in several metrics, including data collection rate and charging efficiency. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14490</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14490</id><created>2025-01-24</created><authors><author><keyname>Xue</keyname><forenames>Peng</forenames></author><author><keyname>Fang</keyname><forenames>Wei</forenames></author><author><keyname>Ma</keyname><forenames>Zhengyu</forenames></author><author><keyname>Huang</keyname><forenames>Zihan</forenames></author><author><keyname>Zhou</keyname><forenames>Zhaokun</forenames></author><author><keyname>Tian</keyname><forenames>Yonghong</forenames></author><author><keyname>Masquelier</keyname><forenames>Timothée</forenames></author><author><keyname>Zhou</keyname><forenames>Huihui</forenames></author></authors><title>Channel-wise Parallelizable Spiking Neuron with Multiplication-free   Dynamics and Large Temporal Receptive Fields</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spiking Neural Networks (SNNs) are distinguished from Artificial Neural Networks (ANNs) for their sophisticated neuronal dynamics and sparse binary activations (spikes) inspired by the biological neural system. Traditional neuron models use iterative step-by-step dynamics, resulting in serial computation and slow training speed of SNNs. Recently, parallelizable spiking neuron models have been proposed to fully utilize the massive parallel computing ability of graphics processing units to accelerate the training of SNNs. However, existing parallelizable spiking neuron models involve dense floating operations and can only achieve high long-term dependencies learning ability with a large order at the cost of huge computational and memory costs. To solve the dilemma of performance and costs, we propose the mul-free channel-wise Parallel Spiking Neuron, which is hardware-friendly and suitable for SNNs' resource-restricted application scenarios. The proposed neuron imports the channel-wise convolution to enhance the learning ability, induces the sawtooth dilations to reduce the neuron order, and employs the bit shift operation to avoid multiplications. The algorithm for design and implementation of acceleration methods is discussed meticulously. Our methods are validated in neuromorphic Spiking Heidelberg Digits voices, sequential CIFAR images, and neuromorphic DVS-Lip vision datasets, achieving the best accuracy among SNNs. Training speed results demonstrate the effectiveness of our acceleration methods, providing a practical reference for future research. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14491</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14491</id><created>2025-01-24</created><authors><author><keyname>Blaschke</keyname><forenames>Verena</forenames></author><author><keyname>Fedzechkina</keyname><forenames>Masha</forenames></author><author><keyname>ter Hoeve</keyname><forenames>Maartje</forenames></author></authors><title>Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer:   Tasks and Experimental Setups Matter</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-lingual transfer is a popular approach to increase the amount of training data for NLP tasks in a low-resource context. However, the best strategy to decide which cross-lingual data to include is unclear. Prior research often focuses on a small set of languages from a few language families and/or a single task. It is still an open question how these findings extend to a wider variety of languages and tasks. In this work, we analyze cross-lingual transfer for 266 languages from a wide variety of language families. Moreover, we include three popular NLP tasks: POS tagging, dependency parsing, and topic classification. Our findings indicate that the effect of linguistic similarity on transfer performance depends on a range of factors: the NLP task, the (mono- or multilingual) input representations, and the definition of linguistic similarity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14492</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14492</id><created>2025-01-24</created><authors><author><keyname>Tang</keyname><forenames>Zhengyang</forenames></author><author><keyname>Li</keyname><forenames>Ziniu</forenames></author><author><keyname>Xiao</keyname><forenames>Zhenyang</forenames></author><author><keyname>Ding</keyname><forenames>Tian</forenames></author><author><keyname>Sun</keyname><forenames>Ruoyu</forenames></author><author><keyname>Wang</keyname><forenames>Benyou</forenames></author><author><keyname>Liu</keyname><forenames>Dayiheng</forenames></author><author><keyname>Huang</keyname><forenames>Fei</forenames></author><author><keyname>Liu</keyname><forenames>Tianyu</forenames></author><author><keyname>Yu</keyname><forenames>Bowen</forenames></author><author><keyname>Lin</keyname><forenames>Junyang</forenames></author></authors><title>RealCritic: Towards Effectiveness-Driven Evaluation of Language Model   Critiques</title><categories>cs.CL cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Critiques are important for enhancing the performance of Large Language Models (LLMs), enabling both self-improvement and constructive feedback for others by identifying flaws and suggesting improvements. However, evaluating the critique capabilities of LLMs presents a significant challenge due to the open-ended nature of the task. In this work, we introduce a new benchmark designed to assess the critique capabilities of LLMs. Unlike existing benchmarks, which typically function in an open-loop fashion, our approach employs a closed-loop methodology that evaluates the quality of corrections generated from critiques. Moreover, the benchmark incorporates features such as self-critique, cross-critique, and iterative critique, which are crucial for distinguishing the abilities of advanced reasoning models from more classical ones. We implement this benchmark using eight challenging reasoning tasks. We have several interesting findings. First, despite demonstrating comparable performance in direct chain-of-thought generation, classical LLMs significantly lag behind the advanced reasoning-based model o1-mini across all critique scenarios. Second, in self-critique and iterative critique settings, classical LLMs may even underperform relative to their baseline capabilities. We hope that this benchmark will serve as a valuable resource to guide future advancements. The code and data are available at \url{https://github.com/tangzhy/RealCritic}. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14495</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14495</id><created>2025-01-24</created><authors><author><keyname>Nguyen</keyname><forenames>Van Thien</forenames></author><author><keyname>Guicquero</keyname><forenames>William</forenames></author><author><keyname>Sicard</keyname><forenames>Gilles</forenames></author></authors><title>BILLNET: A Binarized Conv3D-LSTM Network with Logic-gated residual   architecture for hardware-efficient video inference</title><categories>cs.CV cs.AR</categories><comments>Published at IEEE SiPS 2022</comments><journal-ref>2022 IEEE Workshop on Signal Processing Systems (SiPS), Rennes,   France, 2022, pp. 1-6</journal-ref><doi>10.1109/SiPS55645.2022.9919206</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Long Short-Term Memory (LSTM) and 3D convolution (Conv3D) show impressive results for many video-based applications but require large memory and intensive computing. Motivated by recent works on hardware-algorithmic co-design towards efficient inference, we propose a compact binarized Conv3D-LSTM model architecture called BILLNET, compatible with a highly resource-constrained hardware. Firstly, BILLNET proposes to factorize the costly standard Conv3D by two pointwise convolutions with a grouped convolution in-between. Secondly, BILLNET enables binarized weights and activations via a MUX-OR-gated residual architecture. Finally, to efficiently train BILLNET, we propose a multi-stage training strategy enabling to fully quantize LSTM layers. Results on Jester dataset show that our method can obtain high accuracy with extremely low memory and computational budgets compared to existing Conv3D resource-efficient models. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14496</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14496</id><created>2025-01-24</created><authors><author><keyname>Fort</keyname><forenames>Stanislav</forenames></author></authors><title>A Note on Implementation Errors in Recent Adaptive Attacks Against   Multi-Resolution Self-Ensembles</title><categories>cs.CR cs.CV cs.LG</categories><comments>4 pages, 2 figures, technical note addressing an issue in   arXiv:2411.14834v1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note documents an implementation issue in recent adaptive attacks (Zhang et al. [2024]) against the multi-resolution self-ensemble defense (Fort and Lakshminarayanan [2024]). The implementation allowed adversarial perturbations to exceed the standard $L_\infty = 8/255$ bound by up to a factor of 20$\times$, reaching magnitudes of up to $L_\infty = 160/255$. When attacks are properly constrained within the intended bounds, the defense maintains non-trivial robustness. Beyond highlighting the importance of careful validation in adversarial machine learning research, our analysis reveals an intriguing finding: properly bounded adaptive attacks against strong multi-resolution self-ensembles often align with human perception, suggesting the need to reconsider how we measure adversarial robustness. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14497</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14497</id><created>2025-01-24</created><authors><author><keyname>He</keyname><forenames>Jie</forenames></author><author><keyname>Yang</keyname><forenames>Yijun</forenames></author><author><keyname>Long</keyname><forenames>Wanqiu</forenames></author><author><keyname>Xiong</keyname><forenames>Deyi</forenames></author><author><keyname>Basulto</keyname><forenames>Victor Gutierrez</forenames></author><author><keyname>Pan</keyname><forenames>Jeff Z.</forenames></author></authors><title>Evaluating and Improving Graph to Text Generation with Large Language   Models</title><categories>cs.CL</categories><comments>NAACL 2025</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Large language models (LLMs) have demonstrated immense potential across various tasks. However, research for exploring and improving the capabilities of LLMs in interpreting graph structures remains limited. To address this gap, we conduct a comprehensive evaluation of prompting current open-source LLMs on graph-to-text generation tasks. Although we explored the optimal prompting strategies and proposed a novel and effective diversity-difficulty-based few-shot sample selection method, we found that the improvements from tuning-free approaches were incremental, as LLMs struggle with planning on complex graphs, particularly those with a larger number of triplets. To further improve LLMs in planning with graph sequences and grounding in truth, we introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks: reordering and attribution. Through extensive automatic and human evaluations, we demonstrate significant improvements in the quality of generated text from both few-shot learning and fine-tuning perspectives using the PlanGTG dataset. Our study paves the way for new research directions in graph-to-text generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14499</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14499</id><created>2025-01-24</created><authors><author><keyname>Poličar</keyname><forenames>Pavlin G.</forenames></author><author><keyname>Špendl</keyname><forenames>Martin</forenames></author><author><keyname>Curk</keyname><forenames>Tomaž</forenames></author><author><keyname>Zupan</keyname><forenames>Blaž</forenames></author></authors><title>Automated Assignment Grading with Large Language Models: Insights From a   Bioinformatics Course</title><categories>cs.LG cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing students with individualized feedback through assignments is a cornerstone of education that supports their learning and development. Studies have shown that timely, high-quality feedback plays a critical role in improving learning outcomes. However, providing personalized feedback on a large scale in classes with large numbers of students is often impractical due to the significant time and effort required. Recent advances in natural language processing and large language models (LLMs) offer a promising solution by enabling the efficient delivery of personalized feedback. These technologies can reduce the workload of course staff while improving student satisfaction and learning outcomes. Their successful implementation, however, requires thorough evaluation and validation in real classrooms. We present the results of a practical evaluation of LLM-based graders for written assignments in the 2024/25 iteration of the Introduction to Bioinformatics course at the University of Ljubljana. Over the course of the semester, more than 100 students answered 36 text-based questions, most of which were automatically graded using LLMs. In a blind study, students received feedback from both LLMs and human teaching assistants without knowing the source, and later rated the quality of the feedback. We conducted a systematic evaluation of six commercial and open-source LLMs and compared their grading performance with human teaching assistants. Our results show that with well-designed prompts, LLMs can achieve grading accuracy and feedback quality comparable to human graders. Our results also suggest that open-source LLMs perform as well as commercial LLMs, allowing schools to implement their own grading systems while maintaining privacy. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14500</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14500</id><created>2025-01-24</created><authors><author><keyname>Blackwell</keyname><forenames>Daniel</forenames></author><author><keyname>Becker</keyname><forenames>Ingolf</forenames></author><author><keyname>Clark</keyname><forenames>David</forenames></author></authors><title>NIFuzz: Estimating Quantified Information Flow with a Fuzzer</title><categories>cs.CR cs.SE</categories><comments>30 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a scalable, practical approach to quantifying information leaks in software; these errors are often overlooked and downplayed, but can seriously compromise security mechanisms such as address space layout randomisation (ASLR) and Pointer Authentication (PAC). We introduce approaches for three different metrics to estimate the size of information leaks, including a new derivation for the calculation of conditional mutual information. Together, these metrics can inform of the relative safety of the target program against different threat models and provide useful details for finding the source of any leaks. We provide an implementation of a fuzzer, NIFuzz, which is capable of dynamically computing these metrics with little overhead and has several strategies to optimise for the detection and quantification of information leaks. We evaluate NIFuzz on a set of 14 programs -- including 8 real-world CVEs and ranging up to 278k lines of code in size -- where we find that it is capable of detecting and providing good estimates for all of the known information leaks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14502</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14502</id><created>2025-01-24</created><authors><author><keyname>Cellina</keyname><forenames>Marcello</forenames></author><author><keyname>Corno</keyname><forenames>Matteo</forenames></author><author><keyname>Savaresi</keyname><forenames>Sergio Matteo</forenames></author></authors><title>LiDAR-Based Vehicle Detection and Tracking for Autonomous Racing</title><categories>cs.RO cs.CV</categories><comments>13 pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Autonomous racing provides a controlled environment for testing the software and hardware of autonomous vehicles operating at their performance limits. Competitive interactions between multiple autonomous racecars however introduce challenging and potentially dangerous scenarios. Accurate and consistent vehicle detection and tracking is crucial for overtaking maneuvers, and low-latency sensor processing is essential to respond quickly to hazardous situations. This paper presents the LiDAR-based perception algorithms deployed on Team PoliMOVE's autonomous racecar, which won multiple competitions in the Indy Autonomous Challenge series. Our Vehicle Detection and Tracking pipeline is composed of a novel fast Point Cloud Segmentation technique and a specific Vehicle Pose Estimation methodology, together with a variable-step Multi-Target Tracking algorithm. Experimental results demonstrate the algorithm's performance, robustness, computational efficiency, and suitability for autonomous racing applications, enabling fully autonomous overtaking maneuvers at velocities exceeding 275 km/h. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14503</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14503</id><created>2025-01-24</created><authors><author><keyname>Shehadeh</keyname><forenames>Mhd Ali</forenames></author><author><keyname>Kudela</keyname><forenames>Jakub</forenames></author></authors><title>Benchmarking global optimization techniques for unmanned aerial vehicle   path planning</title><categories>cs.NE cs.RO math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Unmanned Aerial Vehicle (UAV) path planning problem is a complex optimization problem in the field of robotics. In this paper, we investigate the possible utilization of this problem in benchmarking global optimization methods. We devise a problem instance generator and pick 56 representative instances, which we compare to established benchmarking suits through Exploratory Landscape Analysis to show their uniqueness. For the computational comparison, we select twelve well-performing global optimization techniques from both subfields of stochastic algorithms (evolutionary computation methods) and deterministic algorithms (Dividing RECTangles, or DIRECT-type methods). The experiments were conducted in settings with varying dimensionality and computational budgets. The results were analyzed through several criteria (number of best-found solutions, mean relative error, Friedman ranks) and utilized established statistical tests. The best-ranking methods for the UAV problems were almost universally the top-performing evolutionary techniques from recent competitions on numerical optimization at the Institute of Electrical and Electronics Engineers Congress on Evolutionary Computation. Lastly, we discussed the variable dimension characteristics of the studied UAV problems that remain still largely under-investigated. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14506</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14506</id><created>2025-01-24</created><authors><author><keyname>Yu</keyname><forenames>Jia</forenames></author><author><keyname>Yuan</keyname><forenames>Fei</forenames></author><author><keyname>Min</keyname><forenames>Rui</forenames></author><author><keyname>Yu</keyname><forenames>Jing</forenames></author><author><keyname>Chu</keyname><forenames>Pei</forenames></author><author><keyname>Li</keyname><forenames>Jiayang</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Ruijie</forenames></author><author><keyname>Li</keyname><forenames>Zhenxiang</forenames></author><author><keyname>Ren</keyname><forenames>Zhifei</forenames></author><author><keyname>Zheng</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Wenjian</forenames></author><author><keyname>Teng</keyname><forenames>Yan</forenames></author><author><keyname>Meng</keyname><forenames>Lingyu</forenames></author><author><keyname>Jin</keyname><forenames>ZhenJiang</forenames></author><author><keyname>Qiu</keyname><forenames>Jiantao</forenames></author><author><keyname>Wang</keyname><forenames>ShaSha</forenames></author><author><keyname>Tu</keyname><forenames>Zhongying</forenames></author><author><keyname>Lin</keyname><forenames>Dahua</forenames></author><author><keyname>Wang</keyname><forenames>Yu</forenames></author><author><keyname>Qiao</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Yanfeng</forenames></author><author><keyname>He</keyname><forenames>Conghui</forenames></author></authors><title>WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource   Languages</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces the open-source dataset WanJuanSiLu, designed to provide high-quality training corpora for low-resource languages, thereby advancing the research and development of multilingual models. To achieve this, we have developed a systematic data processing framework tailored for low-resource languages. This framework encompasses key stages such as data extraction, corpus cleaning, content deduplication, security filtering, quality evaluation, and theme classification. Through the implementation of this framework, we have significantly improved both the quality and security of the dataset, while maintaining its linguistic diversity. As of now, data for all five languages have been fully open-sourced. The dataset can be accessed at https://opendatalab.com/applyMultilingualCorpus, and GitHub repository is available at https://github.com/opendatalab/WanJuan3.0 </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14510</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14510</id><created>2025-01-24</created><authors><author><keyname>Chaudhry</keyname><forenames>Faiz Muhammad</forenames></author><author><keyname>Ralli</keyname><forenames>Jarno</forenames></author><author><keyname>Leudet</keyname><forenames>Jerome</forenames></author><author><keyname>Sohrab</keyname><forenames>Fahad</forenames></author><author><keyname>Pakdaman</keyname><forenames>Farhad</forenames></author><author><keyname>Corbani</keyname><forenames>Pierre</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>Deep-BrownConrady: Prediction of Camera Calibration and Distortion   Parameters Using Deep Learning and Synthetic Data</title><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This research addresses the challenge of camera calibration and distortion parameter prediction from a single image using deep learning models. The main contributions of this work are: (1) demonstrating that a deep learning model, trained on a mix of real and synthetic images, can accurately predict camera and lens parameters from a single image, and (2) developing a comprehensive synthetic dataset using the AILiveSim simulation platform. This dataset includes variations in focal length and lens distortion parameters, providing a robust foundation for model training and testing. The training process predominantly relied on these synthetic images, complemented by a small subset of real images, to explore how well models trained on synthetic data can perform calibration tasks on real-world images. Traditional calibration methods require multiple images of a calibration object from various orientations, which is often not feasible due to the lack of such images in publicly available datasets. A deep learning network based on the ResNet architecture was trained on this synthetic dataset to predict camera calibration parameters following the Brown-Conrady lens model. The ResNet architecture, adapted for regression tasks, is capable of predicting continuous values essential for accurate camera calibration in applications such as autonomous driving, robotics, and augmented reality.   Keywords: Camera calibration, distortion, synthetic data, deep learning, residual networks (ResNet), AILiveSim, horizontal field-of-view, principal point, Brown-Conrady Model. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14512</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14512</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Zhuoran</forenames></author><author><keyname>van Hoek</keyname><forenames>Senna</forenames></author><author><keyname>Horváth</keyname><forenames>Péter</forenames></author><author><keyname>Lauret</keyname><forenames>Dirk</forenames></author><author><keyname>Xu</keyname><forenames>Xiaoyun</forenames></author><author><keyname>Batina</keyname><forenames>Lejla</forenames></author></authors><title>Real-world Edge Neural Network Implementations Leak Private Interactions   Through Physical Side Channel</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Neural networks have become a fundamental component of numerous practical applications, and their implementations, which are often accelerated by hardware, are integrated into all types of real-world physical devices. User interactions with neural networks on hardware accelerators are commonly considered privacy-sensitive. Substantial efforts have been made to uncover vulnerabilities and enhance privacy protection at the level of machine learning algorithms, including membership inference attacks, differential privacy, and federated learning. However, neural networks are ultimately implemented and deployed on physical devices, and current research pays comparatively less attention to privacy protection at the implementation level. In this paper, we introduce a generic physical side-channel attack, ScaAR, that extracts user interactions with neural networks by leveraging electromagnetic (EM) emissions of physical devices. Our proposed attack is implementation-agnostic, meaning it does not require the adversary to possess detailed knowledge of the hardware or software implementations, thanks to the capabilities of deep learning-based side-channel analysis (DLSCA). Experimental results demonstrate that, through the EM side channel, ScaAR can effectively extract the class label of user interactions with neural classifiers, including inputs and outputs, on the AMD-Xilinx MPSoC ZCU104 FPGA and Raspberry Pi 3 B. In addition, for the first time, we provide side-channel analysis on edge Large Language Model (LLM) implementations on the Raspberry Pi 5, showing that EM side channel leaks interaction data, and different LLM tokens can be distinguishable from the EM traces. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14513</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14513</id><created>2025-01-24</created><authors><author><keyname>Li</keyname><forenames>Fanxing</forenames></author><author><keyname>Sun</keyname><forenames>Fangyu</forenames></author><author><keyname>Zhang</keyname><forenames>Tianbao</forenames></author><author><keyname>Zou</keyname><forenames>Danping</forenames></author></authors><title>ABPT: Amended Backpropagation through Time with Partially Differentiable   Rewards</title><categories>cs.RO cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the exact gradients of the rewards to directly optimize policy parameters via backpropagation-through-time (BPTT) enables high training performance for quadrotor tasks. However, designing a fully differentiable reward architecture is often challenging. Partially differentiable rewards will result in biased gradient propagation that degrades training performance. To overcome this limitation, we propose Amended Backpropagation-through-Time (ABPT), a novel approach that mitigates gradient bias while preserving the training efficiency of BPTT. ABPT combines 0-step and N-step returns, effectively reducing the bias by leveraging value gradients from the learned Q-value function. Additionally, it adopts entropy regularization and state initialization mechanisms to encourage exploration during training. We evaluate ABPT on four representative quadrotor flight tasks. Experimental results demonstrate that ABPT converges significantly faster and achieves higher ultimate rewards than existing learning algorithms, particularly in tasks involving partially differentiable rewards. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14514</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14514</id><created>2025-01-24</created><authors><author><keyname>Möller</keyname><forenames>Hendrik</forenames></author><author><keyname>Krautschick</keyname><forenames>Lukas</forenames></author><author><keyname>Atad</keyname><forenames>Matan</forenames></author><author><keyname>Graf</keyname><forenames>Robert</forenames></author><author><keyname>Busch</keyname><forenames>Chia-Jung</forenames></author><author><keyname>Beule</keyname><forenames>Achim</forenames></author><author><keyname>Scharf</keyname><forenames>Christian</forenames></author><author><keyname>Kaderali</keyname><forenames>Lars</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author><author><keyname>Kirschke</keyname><forenames>Jan</forenames></author><author><keyname>Schwitzing</keyname><forenames>Fabian</forenames></author></authors><title>PARASIDE: An Automatic Paranasal Sinus Segmentation and Structure   Analysis Tool for MRI</title><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Chronic rhinosinusitis (CRS) is a common and persistent sinus imflammation that affects 5 - 12\% of the general population. It significantly impacts quality of life and is often difficult to assess due to its subjective nature in clinical evaluation. We introduce PARASIDE, an automatic tool for segmenting air and soft tissue volumes of the structures of the sinus maxillaris, frontalis, sphenodalis and ethmoidalis in T1 MRI. By utilizing that segmentation, we can quantify feature relations that have been observed only manually and subjectively before. We performed an exemplary study and showed both volume and intensity relations between structures and radiology reports. While the soft tissue segmentation is good, the automated annotations of the air volumes are excellent. The average intensity over air structures are consistently below those of the soft tissues, close to perfect separability. Healthy subjects exhibit lower soft tissue volumes and lower intensities. Our developed system is the first automated whole nasal segmentation of 16 structures, and capable of calculating medical relevant features such as the Lund-Mackay score. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14520</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14520</id><created>2025-01-24</created><authors><author><keyname>Xiang</keyname><forenames>Zhe</forenames></author><author><keyname>Yu</keyname><forenames>Fei</forenames></author><author><keyname>Deng</keyname><forenames>Quan</forenames></author><author><keyname>Li</keyname><forenames>Yuandi</forenames></author><author><keyname>Wan</keyname><forenames>Zhiguo</forenames></author></authors><title>Scene Understanding Enabled Semantic Communication with Open Channel   Coding</title><categories>eess.SP cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As communication systems transition from symbol transmission to conveying meaningful information, sixth-generation (6G) networks emphasize semantic communication. This approach prioritizes high-level semantic information, improving robustness and reducing redundancy across modalities like text, speech, and images. However, traditional semantic communication faces limitations, including static coding strategies, poor generalization, and reliance on task-specific knowledge bases that hinder adaptability. To overcome these challenges, we propose a novel system combining scene understanding, Large Language Models (LLMs), and open channel coding, named \textbf{OpenSC}. Traditional systems rely on fixed domain-specific knowledge bases, limiting their ability to generalize. Our open channel coding approach leverages shared, publicly available knowledge, enabling flexible, adaptive encoding. This dynamic system reduces reliance on static task-specific data, enhancing adaptability across diverse tasks and environments. Additionally, we use scene graphs for structured semantic encoding, capturing object relationships and context to improve tasks like Visual Question Answering (VQA). Our approach selectively encodes key semantic elements, minimizing redundancy and improving transmission efficiency. Experimental results show significant improvements in both semantic understanding and efficiency, advancing the potential of adaptive, generalizable semantic communication in 6G networks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14521</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14521</id><created>2025-01-24</created><authors><author><keyname>Clevenhaus</keyname><forenames>Anna</forenames></author><author><keyname>Totzeck</keyname><forenames>Claudia</forenames></author><author><keyname>Ehrhardt</keyname><forenames>Matthias</forenames></author></authors><title>A Space Mapping approach for the calibration of financial models with   the application to the Heston model</title><categories>math.NA cs.NA q-fin.CP</categories><comments>17 pages, 3 figures</comments><report-no>IMACM 25/02</report-no><msc-class>65M06, 65K10, 91-08</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a novel approach for parameter calibration of the Heston model for pricing an Asian put option, namely space mapping. Since few parameters of the Heston model can be directly extracted from real market data, calibration to real market data is implicit and therefore a challenging task. In addition, some of the parameters in the model are non-linear, which makes it difficult to find the global minimum of the optimization problem within the calibration. Our approach is based on the idea of space mapping, exploiting the residuum of a coarse surrogate model that allows optimization and a fine model that needs to be calibrated. In our case, the pricing of an Asian option using the Heston model SDE is the fine model, and the surrogate is chosen to be the Heston model PDE pricing a European option. We formally derive a gradient descent algorithm for the PDE constrained calibration model using well-known techniques from optimization with PDEs. Our main goal is to provide evidence that the space mapping approach can be useful in financial calibration tasks. Numerical results underline the feasibility of our approach. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14522</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14522</id><created>2025-01-24</created><authors><author><keyname>Ngo</keyname><forenames>Khac-Hoang</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author></authors><title>Information Age and Correctness for Energy Harvesting Devices with   Random Access</title><categories>cs.IT math.IT</categories><comments>submitted to the International Symposium on Modeling and Optimization   in Mobile, Ad hoc, and Wireless Networks (WiOpt) 2025</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We study a large network of energy-harvesting devices that monitor two-state Markov processes and send status updates to a gateway using the slotted ALOHA protocol without feedback. We let the devices adjust their transmission probabilities according to their process state transitions and current battery levels. Using a Markovian framework, we analyze the average value of a generic state-dependent penalty function that grows whenever there is a state estimation error. The age of incorrect information (AoII) is an example of such penalty function. We propose an accurate and easy-to-compute approximation for the average penalty. Numerical results demonstrate the benefits of optimizing the transmission probabilities to minimize the average penalty. The average-AoII-minimizing strategy can be highly suboptimal in terms of average penalty when one of the process states is critical, i.e., entails a high penalty if wrongly estimated. Furthermore, minimizing the average penalty does not guarantee a low probability of misdetecting a critical state period. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14524</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14524</id><created>2025-01-24</created><authors><author><keyname>Schaerf</keyname><forenames>Ludovica</forenames></author><author><keyname>Alfarano</keyname><forenames>Andrea</forenames></author><author><keyname>Silvestri</keyname><forenames>Fabrizio</forenames></author><author><keyname>Impett</keyname><forenames>Leonardo</forenames></author></authors><title>Training-Free Style and Content Transfer by Leveraging U-Net Skip   Connections in Stable Diffusion 2.*</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Despite significant recent advances in image generation with diffusion models, their internal latent representations remain poorly understood. Existing works focus on the bottleneck layer (h-space) of Stable Diffusion's U-Net or leverage the cross-attention, self-attention, or decoding layers. Our model, SkipInject takes advantage of U-Net's skip connections. We conduct thorough analyses on the role of the skip connections and find that the residual connections passed by the third encoder block carry most of the spatial information of the reconstructed image, splitting the content from the style. We show that injecting the representations from this block can be used for text-based editing, precise modifications, and style transfer. We compare our methods state-of-the-art style transfer and image editing methods and demonstrate that our method obtains the best content alignment and optimal structural preservation tradeoff. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14525</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14525</id><created>2025-01-24</created><authors><author><keyname>Mouny</keyname><forenames>Pierre-Antoine</forenames></author><author><keyname>Benhouria</keyname><forenames>Maher</forenames></author><author><keyname>Yon</keyname><forenames>Victor</forenames></author><author><keyname>Dufour</keyname><forenames>Patrick</forenames></author><author><keyname>Huang</keyname><forenames>Linxiang</forenames></author><author><keyname>Beilliard</keyname><forenames>Yann</forenames></author><author><keyname>Rochette</keyname><forenames>Sophie</forenames></author><author><keyname>Drouin</keyname><forenames>Dominique</forenames></author><author><keyname>Ronagh</keyname><forenames>Pooya</forenames></author></authors><title>Towards a Cryogenic CMOS-Memristor Neural Decoder for Quantum Error   Correction</title><categories>quant-ph cs.AR</categories><journal-ref>2024 IEEE International Conference on Quantum Computing and   Engineering (QCE)</journal-ref><doi>10.1109/QCE60285.2024.00149</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach utilizing a scalable neural decoder application-specific integrated circuit (ASIC) based on metal oxide memristors in a 180nm CMOS technology. The ASIC architecture employs in-memory computing with memristor crossbars for efficient vector-matrix multiplications (VMM). The ASIC decoder architecture includes an input layer implemented with a VMM and an analog sigmoid activation function, a recurrent layer with analog memory, and an output layer with a VMM and a threshold activation function. Cryogenic characterization of the ASIC is conducted, demonstrating its performance at both room temperature and cryogenic temperatures down to 1.2K. Results indicate stable activation function shapes and pulse responses at cryogenic temperatures. Moreover, power consumption measurements reveal consistent behavior at room and cryogenic temperatures. Overall, this study lays the foundation for developing efficient and scalable neural decoders for quantum error correction in cryogenic environments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14526</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14526</id><created>2025-01-24</created><authors><author><keyname>Zhang</keyname><forenames>Shuhao</forenames></author><author><keyname>Swevers</keyname><forenames>Jan</forenames></author></authors><title>Robustified Time-optimal Point-to-point Motion Planning and Control   under Uncertainty</title><categories>cs.RO cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper proposes a novel approach to formulate time-optimal point-to-point motion planning and control under uncertainty. The approach defines a robustified two-stage Optimal Control Problem (OCP), in which stage 1, with a fixed time grid, is seamlessly stitched with stage 2, which features a variable time grid. Stage 1 optimizes not only the nominal trajectory, but also feedback gains and corresponding state covariances, which robustify constraints in both stages. The outcome is a minimized uncertainty in stage 1 and a minimized total motion time for stage 2, both contributing to the time optimality and safety of the total motion. A timely replanning strategy is employed to handle changes in constraints and maintain feasibility, while a tailored iterative algorithm is proposed for efficient, real-time OCP execution. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14527</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14527</id><created>2025-01-24</created><authors><author><keyname>Matthes</keyname><forenames>Daniel</forenames></author><author><keyname>Rott</keyname><forenames>Eva-Maria</forenames></author><author><keyname>Schlichting</keyname><forenames>André</forenames></author></authors><title>Diffusive transport on the real line: semi-contractive gradient flows   and their discretization</title><categories>math.AP cs.NA math.NA math.PR</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diffusive transport distance, a novel pseudo-metric between probability measures on the real line, is introduced. It generalizes Martingale optimal transport, and forms a hierarchy with the Hellinger and the Wasserstein metrics. We observe that certain classes of parabolic PDEs, among them the porous medium equation of exponent two, are formally semi-contractive metric gradient flows in the new distance. This observation is made rigorous for a suitable spatial discretization of the considered PDEs: these are semi-contractive gradient flows with respect to an adapted diffusive transport distance for measures on the point lattice. The main result is that the modulus of convexity is uniform with respect to the lattice spacing. Particularly for the quadratic porous medium equation, this is in contrast to what has been observed for discretizations of the Wasserstein gradient flow structure. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14528</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14528</id><created>2025-01-24</created><authors><author><keyname>Omer</keyname><forenames>Skala Kamaran</forenames></author><author><keyname>Hassani</keyname><forenames>Hossein</forenames></author></authors><title>Idiom Detection in Sorani Kurdish Texts</title><categories>cs.CL</categories><comments>22 pages, 8 figures, 7 tables</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Idiom detection using Natural Language Processing (NLP) is the computerized process of recognizing figurative expressions within a text that convey meanings beyond the literal interpretation of the words. While idiom detection has seen significant progress across various languages, the Kurdish language faces a considerable research gap in this area despite the importance of idioms in tasks like machine translation and sentiment analysis. This study addresses idiom detection in Sorani Kurdish by approaching it as a text classification task using deep learning techniques. To tackle this, we developed a dataset containing 10,580 sentences embedding 101 Sorani Kurdish idioms across diverse contexts. Using this dataset, we developed and evaluated three deep learning models: KuBERT-based transformer sequence classification, a Recurrent Convolutional Neural Network (RCNN), and a BiLSTM model with an attention mechanism. The evaluations revealed that the transformer model, the fine-tuned BERT, consistently outperformed the others, achieving nearly 99% accuracy while the RCNN achieved 96.5% and the BiLSTM 80%. These results highlight the effectiveness of Transformer-based architectures in low-resource languages like Kurdish. This research provides a dataset, three optimized models, and insights into idiom detection, laying a foundation for advancing Kurdish NLP. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14530</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14530</id><created>2025-01-24</created><authors><author><keyname>Zhong</keyname><forenames>Zhenguang</forenames></author><author><keyname>Tang</keyname><forenames>Jia</forenames></author></authors><title>Design and Implementation of a Psychiatry Resident Training System Based   on Large Language Models</title><categories>cs.CY cs.HC q-bio.NC</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Mental disorders have become a significant global public health issue, while the shortage of psychiatrists and inefficient training systems severely hinder the accessibility of mental health services. This paper designs and implements an artificial intelligence-based training system for psychiatrists. By integrating technologies such as large language models, knowledge graphs, and expert systems, the system constructs an intelligent and standardized training platform. It includes six functional modules: case generation, consultation dialogue, examination prescription, diagnostic decision-making, integrated traditional Chinese and Western medicine prescription, and expert evaluation, providing comprehensive support from clinical skill training to professional level assessment.The system adopts a B/S architecture, developed using the Vue.js and Node.js technology stack, and innovatively applies deep learning algorithms for case generation and doctor-patient dialogue. In a clinical trial involving 60 psychiatrists at different levels, the system demonstrated excellent performance and training outcomes: system stability reached 99.95%, AI dialogue accuracy achieved 96.5%, diagnostic accuracy reached 92.5%, and user satisfaction scored 92.3%. Experimental data showed that doctors using the system improved their knowledge mastery, clinical thinking, and diagnostic skills by 35.6%, 28.4%, and 23.7%, respectively.The research results provide an innovative solution for improving the efficiency of psychiatrist training and hold significant importance for promoting the standardization and scalability of mental health professional development. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14531</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14531</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Xiao</forenames></author><author><keyname>Borras</keyname><forenames>Hendrik</forenames></author><author><keyname>Klein</keyname><forenames>Bernhard</forenames></author><author><keyname>Fröning</keyname><forenames>Holger</forenames></author></authors><title>On Hardening DNNs against Noisy Computations</title><categories>cs.LG</categories><comments>Presented at AccML workshop co-located HiPEAC 2025</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The success of deep learning has sparked significant interest in designing computer hardware optimized for the high computational demands of neural network inference. As further miniaturization of digital CMOS processors becomes increasingly challenging, alternative computing paradigms, such as analog computing, are gaining consideration. Particularly for compute-intensive tasks such as matrix multiplication, analog computing presents a promising alternative due to its potential for significantly higher energy efficiency compared to conventional digital technology. However, analog computations are inherently noisy, which makes it challenging to maintain high accuracy on deep neural networks. This work investigates the effectiveness of training neural networks with quantization to increase the robustness against noise. Experimental results across various network architectures show that quantization-aware training with constant scaling factors enhances robustness. We compare these methods with noisy training, which incorporates a noise injection during training that mimics the noise encountered during inference. While both two methods increase tolerance against noise, noisy training emerges as the superior approach for achieving robust neural network performance, especially in complex neural architectures. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14533</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14533</id><created>2025-01-24</created><authors><author><keyname>Georgiadis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Yucel</keyname><forenames>Mehmet Kerim</forenames></author><author><keyname>Saa-Garriga</keyname><forenames>Albert</forenames></author></authors><title>CheapNVS: Real-Time On-Device Narrow-Baseline Novel View Synthesis</title><categories>cs.CV</categories><comments>Accepted to ICASSP 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-view novel view synthesis (NVS) is a notorious problem due to its ill-posed nature, and often requires large, computationally expensive approaches to produce tangible results. In this paper, we propose CheapNVS: a fully end-to-end approach for narrow baseline single-view NVS based on a novel, efficient multiple encoder/decoder design trained in a multi-stage fashion. CheapNVS first approximates the laborious 3D image warping with lightweight learnable modules that are conditioned on the camera pose embeddings of the target view, and then performs inpainting on the occluded regions in parallel to achieve significant performance gains. Once trained on a subset of Open Images dataset, CheapNVS outperforms the state-of-the-art despite being 10 times faster and consuming 6% less memory. Furthermore, CheapNVS runs comfortably in real-time on mobile devices, reaching over 30 FPS on a Samsung Tab 9+. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14534</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14534</id><created>2025-01-24</created><authors><author><keyname>Armagan</keyname><forenames>Anil</forenames></author><author><keyname>Saà-Garriga</keyname><forenames>Albert</forenames></author><author><keyname>Manganelli</keyname><forenames>Bruno</forenames></author><author><keyname>Nowak</keyname><forenames>Mateusz</forenames></author><author><keyname>Yucel</keyname><forenames>Mehmet Kerim</forenames></author></authors><title>Trick-GS: A Balanced Bag of Tricks for Efficient Gaussian Splatting</title><categories>cs.CV</categories><comments>Accepted at ICASSP'25</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian splatting (GS) for 3D reconstruction has become quite popular due to their fast training, inference speeds and high quality reconstruction. However, GS-based reconstructions generally consist of millions of Gaussians, which makes them hard to use on computationally constrained devices such as smartphones. In this paper, we first propose a principled analysis of advances in efficient GS methods. Then, we propose Trick-GS, which is a careful combination of several strategies including (1) progressive training with resolution, noise and Gaussian scales, (2) learning to prune and mask primitives and SH bands by their significance, and (3) accelerated GS training framework. Trick-GS takes a large step towards resource-constrained GS, where faster run-time, smaller and faster-convergence of models is of paramount concern. Our results on three datasets show that Trick-GS achieves up to 2x faster training, 40x smaller disk size and 2x faster rendering speed compared to vanilla GS, while having comparable accuracy. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14535</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14535</id><created>2025-01-24</created><authors><author><keyname>Laboyrie</keyname><forenames>Frederik</forenames></author><author><keyname>Yucel</keyname><forenames>Mehmet Kerim</forenames></author><author><keyname>Saa-Garriga</keyname><forenames>Albert</forenames></author></authors><title>Rethinking Encoder-Decoder Flow Through Shared Structures</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dense prediction tasks have enjoyed a growing complexity of encoder architectures, decoders, however, have remained largely the same. They rely on individual blocks decoding intermediate feature maps sequentially. We introduce banks, shared structures that are used by each decoding block to provide additional context in the decoding process. These structures, through applying them via resampling and feature fusion, improve performance on depth estimation for state-of-the-art transformer-based architectures on natural and synthetic images whilst training on large-scale datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14536</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14536</id><created>2025-01-24</created><authors><author><keyname>Garcés</keyname><forenames>Inmaculada</forenames></author><author><keyname>Ramón</keyname><forenames>José M.</forenames></author><author><keyname>Ruiz-Álvarez</keyname><forenames>Juan</forenames></author><author><keyname>Yáñez</keyname><forenames>Dionisio F.</forenames></author></authors><title>Integrating Moving Least Squares with non-linear WENO method: A novel   Partition of Unity approach in 1D</title><categories>math.NA cs.NA</categories><msc-class>41A05, 41A10, 65D05, 65M06, 65N06</msc-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The approximation of data is a fundamental challenge encountered in various fields, including computer-aided geometric design, the numerical solution of partial differential equations, or the design of curves and surfaces. Numerous methods have been developed to address this issue, providing good results when the data is continuous. Among these, the Moving Least Squares (MLS) method has proven to be an effective strategy for fitting data, finding applications in both statistics and applied mathematics. However, the presence of isolated discontinuities in the data can lead to undesirable artifacts, such as the Gibbs phenomenon, which adversely affects the quality of the approximation.   In this paper, we propose a novel approach that integrates the Moving Least Squares method with the well-established non-linear Weighted Essentially Non-Oscillatory (WENO) method. This combination aims to construct a non-linear operator that enhances the accuracy of approximations near discontinuities while maintaining the order of accuracy in smooth regions. We investigate the properties of this operator in one dimension, demonstrating its effectiveness through a series of numerical experiments that validate our theoretical findings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14537</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14537</id><created>2025-01-24</created><authors><author><keyname>Böckenhauer</keyname><forenames>Hans-Joachim</forenames></author><author><keyname>Jahn</keyname><forenames>Melvin</forenames></author><author><keyname>Komm</keyname><forenames>Dennis</forenames></author><author><keyname>Stocker</keyname><forenames>Moritz</forenames></author></authors><title>Forbidden Subgraph Problems with Predictions</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the Online Delayed Connected H-Node-Deletion Problem, an unweighted graph is revealed vertex by vertex and it must remain free of any induced copies of a specific connected induced forbidden subgraph H at each point in time. To achieve this, an algorithm must, upon each occurrence of H, identify and irrevocably delete one or more vertices. The objective is to delete as few vertices as possible. We provide tight bounds on the competitive ratio for forbidden subgraphs H that do not contain two true twins or that do not contain two false twins.   We further consider the problem within the model of predictions, where the algorithm is provided with a single bit of advice for each revealed vertex. These predictions are considered to be provided by an untrusted source and may be incorrect. We present a family of algorithms solving the Online Delayed Connected H-Node-Deletion Problem with predictions and show that it is Pareto-optimal with respect to competitivity and robustness for the online vertex cover problem for 2-connected forbidden subgraphs that do not contain two true twins or that do not contain two false twins, as well as for forbidden paths of length greater than four. We also propose subgraphs for which a better algorithm might exist. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14539</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14539</id><created>2025-01-24</created><authors><author><keyname>Yu</keyname><forenames>Yingchao</forenames></author><author><keyname>Jin</keyname><forenames>Yaochu</forenames></author><author><keyname>Xiao</keyname><forenames>Yuchen</forenames></author><author><keyname>Yan</keyname><forenames>Yuping</forenames></author></authors><title>A Recurrent Spiking Network with Hierarchical Intrinsic Excitability   Modulation for Schema Learning</title><categories>cs.NE cs.LG</categories><comments>31 pages, 9 figures</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schema, a form of structured knowledge that promotes transfer learning, is attracting growing attention in both neuroscience and artificial intelligence (AI). Current schema research in neural computation is largely constrained to a single behavioral paradigm and relies heavily on recurrent neural networks (RNNs) which lack the neural plausibility and biological interpretability. To address these limitations, this work first constructs a generalized behavioral paradigm framework for schema learning and introduces three novel cognitive tasks, thus supporting a comprehensive schema exploration. Second, we propose a new model using recurrent spiking neural networks with hierarchical intrinsic excitability modulation (HM-RSNNs). The top level of the model selects excitability properties for task-specific demands, while the bottom level fine-tunes these properties for intra-task problems. Finally, extensive visualization analyses of HM-RSNNs are conducted to showcase their computational advantages, track the intrinsic excitability evolution during schema learning, and examine neural coordination differences across tasks. Biologically inspired lesion studies further uncover task-specific distributions of intrinsic excitability within schemas. Experimental results show that HM-RSNNs significantly outperform RSNN baselines across all tasks and exceed RNNs in three novel cognitive tasks. Additionally, HM-RSNNs offer deeper insights into neural dynamics underlying schema learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14540</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14540</id><created>2025-01-24</created><authors><author><keyname>Callewaert</keyname><forenames>Benjamin</forenames></author><author><keyname>Vandevelde</keyname><forenames>Simon</forenames></author><author><keyname>Vennekens</keyname><forenames>Joost</forenames></author></authors><title>VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic   Reasoning</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A recent approach to neurosymbolic reasoning is to explicitly combine the strengths of large language models (LLMs) and symbolic solvers to tackle complex reasoning tasks. However, current approaches face significant limitations, including poor generalizability due to task-specific prompts, inefficiencies caused by the lack of separation between knowledge and queries, and restricted inferential capabilities. These shortcomings hinder their scalability and applicability across diverse domains. In this paper, we introduce VERUS-LM, a novel framework designed to address these challenges. VERUS-LM employs a generic prompting mechanism, clearly separates domain knowledge from queries, and supports a wide range of different logical reasoning tasks. This framework enhances adaptability, reduces computational cost, and allows for richer forms of reasoning, such as optimization and constraint satisfaction. We show that our approach succeeds in diverse reasoning on a novel dataset, markedly outperforming LLMs. Additionally, our system achieves competitive results on common reasoning benchmarks when compared to other state-of-the-art approaches, and significantly surpasses them on the difficult AR-LSAT dataset. By pushing the boundaries of hybrid reasoning, VERUS-LM represents a significant step towards more versatile neurosymbolic AI systems </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14542</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14542</id><created>2025-01-24</created><authors><author><keyname>de Jong</keyname><forenames>Tom</forenames></author><author><keyname>Kraus</keyname><forenames>Nicolai</forenames></author><author><keyname>Forsberg</keyname><forenames>Fredrik Nordvall</forenames></author><author><keyname>Xu</keyname><forenames>Chuangjie</forenames></author></authors><title>Ordinal Exponentiation in Homotopy Type Theory</title><categories>cs.LO math.LO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While ordinals have traditionally been studied mostly in classical frameworks, constructive ordinal theory has seen significant progress in recent years. However, a general constructive treatment of ordinal exponentiation has thus far been missing. We present two seemingly different definitions of constructive ordinal exponentiation in the setting of homotopy type theory. The first is abstract, uses suprema of ordinals, and is solely motivated by the expected equations. The second is more concrete, based on decreasing lists, and can be seen as a constructive version of a classical construction by Sierpi\'{n}ski based on functions with finite support. We show that our two approaches are equivalent (whenever it makes sense to ask the question), and use this equivalence to prove algebraic laws and decidability properties of the exponential. All our results are formalized in the proof assistant Agda. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14543</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14543</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Wenzhang</forenames></author><author><keyname>Jin</keyname><forenames>Lianjun</forenames></author><author><keyname>Ren</keyname><forenames>Lu</forenames></author><author><keyname>Mu</keyname><forenames>Chaoxu</forenames></author><author><keyname>Sun</keyname><forenames>Changyin</forenames></author></authors><title>Reducing Action Space for Deep Reinforcement Learning via Causal Effect   Estimation</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent decision-making within large and redundant action spaces remains challenging in deep reinforcement learning. Considering similar but ineffective actions at each step can lead to repetitive and unproductive trials. Existing methods attempt to improve agent exploration by reducing or penalizing redundant actions, yet they fail to provide quantitative and reliable evidence to determine redundancy. In this paper, we propose a method to improve exploration efficiency by estimating the causal effects of actions. Unlike prior methods, our approach offers quantitative results regarding the causality of actions for one-step transitions. We first pre-train an inverse dynamics model to serve as prior knowledge of the environment. Subsequently, we classify actions across the entire action space at each time step and estimate the causal effect of each action to suppress redundant actions during exploration. We provide a theoretical analysis to demonstrate the effectiveness of our method and present empirical results from simulations in environments with redundant actions to evaluate its performance. Our implementation is available at https://github.com/agi-brain/cee.git. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14544</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14544</id><created>2025-01-24</created><authors><author><keyname>Wen</keyname><forenames>Haifeng</forenames></author><author><keyname>Xing</keyname><forenames>Hong</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author></authors><title>Distributed Conformal Prediction via Message Passing</title><categories>cs.LG cs.AI stat.ML</categories><comments>16 pages, 11 figures, submitted for posssible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Post-hoc calibration of pre-trained models is critical for ensuring reliable inference, especially in safety-critical domains such as healthcare. Conformal Prediction (CP) offers a robust post-hoc calibration framework, providing distribution-free statistical coverage guarantees for prediction sets by leveraging held-out datasets. In this work, we address a decentralized setting where each device has limited calibration data and can communicate only with its neighbors over an arbitrary graph topology. We propose two message-passing-based approaches for achieving reliable inference via CP: quantile-based distributed conformal prediction (Q-DCP) and histogram-based distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile regression enhanced with tailored smoothing and regularization terms to accelerate convergence, while H-DCP uses a consensus-based histogram estimation approach. Through extensive experiments, we investigate the trade-offs between hyperparameter tuning requirements, communication overhead, coverage guarantees, and prediction set sizes across different network topologies. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14546</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14546</id><created>2025-01-24</created><authors><author><keyname>Sarmadi</keyname><forenames>Hamid</forenames></author><author><keyname>Hall</keyname><forenames>Ola</forenames></author><author><keyname>Rögnvaldsson</keyname><forenames>Thorsteinn</forenames></author><author><keyname>Ohlsson</keyname><forenames>Mattias</forenames></author></authors><title>Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite   Images by Poverty Level: Advancing Tools for Social Science Research</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the novel application of Large Language Models (LLMs) with vision capabilities to analyze satellite imagery for village-level poverty prediction. Although LLMs were originally designed for natural language understanding, their adaptability to multimodal tasks, including geospatial analysis, has opened new frontiers in data-driven research. By leveraging advancements in vision-enabled LLMs, we assess their ability to provide interpretable, scalable, and reliable insights into human poverty from satellite images. Using a pairwise comparison approach, we demonstrate that ChatGPT can rank satellite images based on poverty levels with accuracy comparable to domain experts. These findings highlight both the promise and the limitations of LLMs in socioeconomic research, providing a foundation for their integration into poverty assessment workflows. This study contributes to the ongoing exploration of unconventional data sources for welfare analysis and opens pathways for cost-effective, large-scale poverty monitoring. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14548</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14548</id><created>2025-01-24</created><authors><author><keyname>Shui</keyname><forenames>Zhongyi</forenames></author><author><keyname>Zhang</keyname><forenames>Jianpeng</forenames></author><author><keyname>Cao</keyname><forenames>Weiwei</forenames></author><author><keyname>Wang</keyname><forenames>Sinuo</forenames></author><author><keyname>Guo</keyname><forenames>Ruizhe</forenames></author><author><keyname>Lu</keyname><forenames>Le</forenames></author><author><keyname>Yang</keyname><forenames>Lin</forenames></author><author><keyname>Ye</keyname><forenames>Xianghua</forenames></author><author><keyname>Liang</keyname><forenames>Tingbo</forenames></author><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Zhang</keyname><forenames>Ling</forenames></author></authors><title>Large-scale and Fine-grained Vision-language Pre-training for Enhanced   CT Image Understanding</title><categories>cs.CV</categories><comments>Accepted by ICLR 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial intelligence (AI) shows great potential in assisting radiologists to improve the efficiency and accuracy of medical image interpretation and diagnosis. However, a versatile AI model requires large-scale data and comprehensive annotations, which are often impractical in medical settings. Recent studies leverage radiology reports as a naturally high-quality supervision for medical images, using contrastive language-image pre-training (CLIP) to develop language-informed models for radiological image interpretation. Nonetheless, these approaches typically contrast entire images with reports, neglecting the local associations between imaging regions and report sentences, which may undermine model performance and interoperability. In this paper, we propose a fine-grained vision-language model (fVLM) for anatomy-level CT image interpretation. Specifically, we explicitly match anatomical regions of CT images with corresponding descriptions in radiology reports and perform contrastive pre-training for each anatomy individually. Fine-grained alignment, however, faces considerable false-negative challenges, mainly from the abundance of anatomy-level healthy samples and similarly diseased abnormalities. To tackle this issue, we propose identifying false negatives of both normal and abnormal samples and calibrating contrastive learning from patient-level to disease-aware pairing. We curated the largest CT dataset to date, comprising imaging and report data from 69,086 patients, and conducted a comprehensive evaluation of 54 major and important disease diagnosis tasks across 15 main anatomies. Experimental results demonstrate the substantial potential of fVLM in versatile medical image interpretation. In the zero-shot classification task, we achieved an average AUC of 81.3% on 54 diagnosis tasks, surpassing CLIP and supervised methods by 12.9% and 8.0%, respectively. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14550</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14550</id><created>2025-01-24</created><authors><author><keyname>Kellison</keyname><forenames>Ariel E.</forenames></author><author><keyname>Zielinski</keyname><forenames>Laura</forenames></author><author><keyname>Bindel</keyname><forenames>David</forenames></author><author><keyname>Hsu</keyname><forenames>Justin</forenames></author></authors><title>Bean: A Language for Backward Error Analysis</title><categories>cs.PL cs.LO cs.NA math.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Backward error analysis offers a method for assessing the quality of numerical programs in the presence of floating-point rounding errors. However, techniques from the numerical analysis literature for quantifying backward error require substantial human effort, and there are currently no tools or automated methods for statically deriving sound backward error bounds. To address this gap, we propose Bean, a typed first-order programming language designed to express quantitative bounds on backward error. Bean's type system combines a graded coeffect system with strict linearity to soundly track the flow of backward error through programs. We prove the soundness of our system using a novel categorical semantics, where every Bean program denotes a triple of related transformations that together satisfy a backward error guarantee.   To illustrate Bean's potential as a practical tool for automated backward error analysis, we implement a variety of standard algorithms from numerical linear algebra in Bean, establishing fine-grained backward error bounds via typing in a compositional style. We also develop a prototype implementation of Bean that infers backward error bounds automatically. Our evaluation shows that these inferred bounds match worst-case theoretical relative backward error bounds from the literature, underscoring Bean's utility in validating a key property of numerical programs: numerical stability. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14551</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14551</id><created>2025-01-24</created><authors><author><keyname>Claucich</keyname><forenames>Estanislao</forenames></author><author><keyname>Hooker</keyname><forenames>Sara</forenames></author><author><keyname>Milone</keyname><forenames>Diego H.</forenames></author><author><keyname>Ferrante</keyname><forenames>Enzo</forenames></author><author><keyname>Echeveste</keyname><forenames>Rodrigo</forenames></author></authors><title>Fairness of Deep Ensembles: On the interplay between per-group task   difficulty and under-representation</title><categories>cs.LG</categories><comments>12 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Ensembling is commonly regarded as an effective way to improve the general performance of models in machine learning, while also increasing the robustness of predictions. When it comes to algorithmic fairness, heterogeneous ensembles, composed of multiple model types, have been employed to mitigate biases in terms of demographic attributes such as sex, age or ethnicity. Moreover, recent work has shown how in multi-class problems even simple homogeneous ensembles may favor performance of the worst-performing target classes. While homogeneous ensembles are simpler to implement in practice, it is not yet clear whether their benefits translate to groups defined not in terms of their target class, but in terms of demographic or protected attributes, hence improving fairness. In this work we show how this simple and straightforward method is indeed able to mitigate disparities, particularly benefiting under-performing subgroups. Interestingly, this can be achieved without sacrificing overall performance, which is a common trade-off observed in bias mitigation strategies. Moreover, we analyzed the interplay between two factors which may result in biases: sub-group under-representation and the inherent difficulty of the task for each group. These results revealed that, contrary to popular assumptions, having balanced datasets may be suboptimal if the task difficulty varies between subgroups. Indeed, we found that a perfectly balanced dataset may hurt both the overall performance and the gap between groups. This highlights the importance of considering the interaction between multiple forces at play in fairness. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14552</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14552</id><created>2025-01-24</created><authors><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author><author><keyname>Vera-Rivera</keyname><forenames>Angelo</forenames></author></authors><title>Next-Generation Wireless: Tracking the Evolutionary Path of 6G Mobile   Communication</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mobile communications industry is lighting-fast machinery, and discussions about 6G technologies have already begun. In this article, we intend to take the readers on a journey to discover 6G and its evolutionary stages. The journey starts with an overview of the technical constraints of 5G prompting the need for a new generation of mobile systems. The initial discussion is followed by an examination of the 6G vision, use cases, technical requirements, technology enablers, and potential network architecture. We conclude the discussion by reviewing the transformative opportunities of this technology in society, businesses and industries, along with the anticipated technological limitations of the network that will drive the development of further mobile generations. Our goal is to deliver a friendly, informative, precise, and engaging narrative that could give readers a panoramic overview of this important topic. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14554</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14554</id><created>2025-01-24</created><authors><author><keyname>Grigoriev</keyname><forenames>Alexander</forenames></author><author><keyname>Faulkner</keyname><forenames>Katherine</forenames></author></authors><title>Open Problems in Continuous Graphs</title><categories>math.CO cs.DM</categories><msc-class>05C99 (Primary) 05C85 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Inspired by notorious combinatorial optimization problems on graphs, in this paper we propose a series of related problems defined using a metric space and topology determined by a graph. Particularly, we present Independent Set, Vertex Cover, Chromatic Number and Treewidth problems on, so-called, continuous graphs where every edge is represented by a unit-length continuous interval rather than by a pair of vertices. If any point of any unit-interval edge is considered as a possible member of a hitting set or a cover, the classical combinatorial problems become trickier and many open questions arise. Notably, in many real-life applications, such continuous view on a graph is more natural than the classic combinatorial definition of a graph. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14555</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14555</id><created>2025-01-24</created><authors><author><keyname>Li</keyname><forenames>Fang</forenames></author><author><keyname>Zuo</keyname><forenames>Fei</forenames></author><author><keyname>Gupta</keyname><forenames>Gopal</forenames></author></authors><title>Exploring Answer Set Programming for Provenance Graph-Based Cyber Threat   Detection: A Novel Approach</title><categories>cs.CR cs.PL</categories><comments>The 27th International Symposium on Practical Aspects of Declarative   Languages (PADL 2025)</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Provenance graphs are useful and powerful tools for representing system-level activities in cybersecurity; however, existing approaches often struggle with complex queries and flexible reasoning. This paper presents a novel approach using Answer Set Programming (ASP) to model and analyze provenance graphs. We introduce an ASP-based representation that captures intricate relationships between system entities, including temporal and causal dependencies. Our model enables sophisticated analysis capabilities such as attack path tracing, data exfiltration detection, and anomaly identification. The declarative nature of ASP allows for concise expression of complex security patterns and policies, facilitating both real-time threat detection and forensic analysis. We demonstrate our approach's effectiveness through case studies showcasing its threat detection capabilities. Experimental results illustrate the model's ability to handle large-scale provenance graphs while providing expressive querying. The model's extensibility allows for incorporation of new system behaviors and security rules, adapting to evolving cyber threats. This work contributes a powerful, flexible, and explainable framework for reasoning about system behaviors and security incidents, advancing the development of effective threat detection and forensic investigation tools. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14556</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14556</id><created>2025-01-24</created><authors><author><keyname>Brännvall</keyname><forenames>Rickard</forenames></author><author><keyname>Svensson</keyname><forenames>Hanna</forenames></author><author><keyname>Kaliyaperumal</keyname><forenames>Kannaki</forenames></author><author><keyname>Burden</keyname><forenames>Håkan</forenames></author><author><keyname>Stenberg</keyname><forenames>Susanne</forenames></author></authors><title>A sandbox study proposal for private and distributed health data   analysis</title><categories>cs.CR cs.CY cs.DC</categories><comments>20 pages, 5 figures, 4 tables</comments><msc-class>68M14 (Primary) 92C60, 68P25, 68P20 (Secondary)</msc-class><acm-class>K.4.1; J.3.2; H.2.8; D.4.6</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a sandbox study proposal focused on the distributed processing of personal health data within the Vinnova-funded SARDIN project. The project aims to develop the Health Data Bank (H\"alsodatabanken in Swedish), a secure platform for research and innovation that complies with the European Health Data Space (EHDS) legislation. By minimizing the sharing and storage of personal data, the platform sends analysis tasks directly to the original data locations, avoiding centralization. This approach raises questions about data controller responsibilities in distributed environments and the anonymization status of aggregated statistical results. The study explores federated analysis, secure multi-party aggregation, and differential privacy techniques, informed by real-world examples from clinical research on Parkinson's disease, stroke rehabilitation, and wound analysis. To validate the proposed study, numerical experiments were conducted using four open-source datasets to assess the feasibility and effectiveness of the proposed methods. The results support the methods for the proposed sandbox study by demonstrating that differential privacy in combination with secure aggregation techniques significantly improves the privacy-utility trade-off. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14557</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14557</id><created>2025-01-24</created><authors><author><keyname>Benali</keyname><forenames>Khairidine</forenames></author></authors><title>Optimizing Grasping Precision for Industrial Pick-and-Place Tasks   Through a Novel Visual Servoing Approach</title><categories>cs.RO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The integration of robotic arm manipulators into industrial manufacturing lines has become common, thanks to their efficiency and effectiveness in executing specific tasks. With advancements in camera technology, visual sensors and perception systems have been incorporated to address more complex operations. This study introduces a novel visual serving control system designed for robotic operations in challenging environments, where accurate object pose estimation is hindered by factors such as vibrations, tool path deviations, and machining marks. To overcome these obstacles, our solution focuses on enhancing the accuracy of picking and placing tasks, ensuring reliable performance across various scenarios. This is accomplished by a novel visual servoing method based on the integration of two complementary methodologies: a technique for object localization and a separate approach for precise control through visual feedback, leveraging their strengths to address the challenges posed by the industrial context and thereby improving overall grasping accuracy. Our method employ feedback from perception sensors to adjust the control loop efficiently, enabling the robotic system to adeptly pick and place objects. We have introduced a controller capable of seamlessly managing the detection and manipulation of various shapes and types of objects within an industrial context, addressing numerous challenges that arise in such environments. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14568</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14568</id><created>2025-01-24</created><authors><author><keyname>Gerlach</keyname><forenames>Thore</forenames></author><author><keyname>Lee</keyname><forenames>Loong Kuan</forenames></author><author><keyname>Barbaresco</keyname><forenames>Frédéric</forenames></author><author><keyname>Piatkowski</keyname><forenames>Nico</forenames></author></authors><title>Hybrid Quantum-Classical Multi-Agent Pathfinding</title><categories>cs.AI quant-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths for multiple agents navigating through a shared space to reach specified goal locations. This problem becomes computationally challenging, particularly when handling large numbers of agents, as frequently encountered in practical applications like coordinating autonomous vehicles. Quantum computing (QC) is a promising candidate in overcoming such limits. However, current quantum hardware is still in its infancy and thus limited in terms of computing power and error robustness. In this work, we present the first optimal hybrid quantum-classical MAPF algorithm which is based on branch-and-cut-and-prize. QC is integrated by iteratively solving QUBO problems, based on conflict graphs. Experiments on actual quantum hardware and results on benchmark data suggest that our approach dominates previous QUBO formulations and baseline MAPF solvers. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14569</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14569</id><created>2025-01-24</created><authors><author><keyname>Jackson</keyname><forenames>Andrew</forenames></author></authors><title>Explaining the Ubiquity of Phase Transitions in Decision Problems</title><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  I present an analytic approach to establishing the presence of phase transitions in a large set of decision problems. This approach does not require extensive computational study of the problems considered. The set -- that of all paddable problems over even-sized alphabets satisfying a condition similar to not being sparse -- shown to exhibit phase transitions contains many "practical" decision problems, is very large, and also contains extremely intractable problems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14570</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14570</id><created>2025-01-24</created><authors><author><keyname>Meehinkong</keyname><forenames>Panisara</forenames></author><author><keyname>Ponnoprat</keyname><forenames>Donlapark</forenames></author></authors><title>coverforest: Conformal Predictions with Random Forest in Python</title><categories>stat.ML cs.LG stat.CO</categories><comments>In peer review</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Conformal prediction provides a framework for uncertainty quantification, specifically in the forms of prediction intervals and sets with distribution-free guaranteed coverage. While recent cross-conformal techniques such as CV+ and Jackknife+-after-bootstrap achieve better data efficiency than traditional split conformal methods, they incur substantial computational costs due to required pairwise comparisons between training and test samples' out-of-bag scores. Observing that these methods naturally extend from ensemble models, particularly random forests, we leverage existing optimized random forest implementations to enable efficient cross-conformal predictions.   We present coverforest, a Python package that implements efficient conformal prediction methods specifically optimized for random forests. coverforest supports both regression and classification tasks through various conformal prediction methods, including split conformal, CV+, Jackknife+-after-bootstrap, and adaptive prediction sets. Our package leverages parallel computing and Cython optimizations to speed up out-of-bag calculations. Our experiments demonstrate that coverforest's predictions achieve the desired level of coverage. In addition, its training and prediction times can be faster than an existing implementation by 2--9 times. The source code for the coverforest is hosted on GitHub at https://github.com/donlapark/coverforest. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14573</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14573</id><created>2025-01-24</created><authors><author><keyname>Zhang</keyname><forenames>Huang</forenames></author><author><keyname>Liu</keyname><forenames>Xixi</forenames></author><author><keyname>Altaf</keyname><forenames>Faisal</forenames></author><author><keyname>Wik</keyname><forenames>Torsten</forenames></author></authors><title>A Transferable Physics-Informed Framework for Battery Degradation   Diagnosis, Knee-Onset Detection and Knee Prediction</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The techno-economic and safety concerns of battery capacity knee occurrence call for developing online knee detection and prediction methods as an advanced battery management system (BMS) function. To address this, a transferable physics-informed framework that consists of a histogram-based feature engineering method, a hybrid physics-informed model, and a fine-tuning strategy, is proposed for online battery degradation diagnosis and knee-onset detection. The hybrid model is first developed and evaluated using a scenario-aware pipeline in protocol cycling scenarios and then fine-tuned to create a local model deployed in a dynamic cycling scenario. A 2D histogram-based feature set is found to be the best choice in both source and target scenarios. The fine-tuning strategy is proven to be effective in improving battery degradation mode estimation and degradation phase detection performance in the target scenario. Again, a strong linear correlation was found between the identified knee-onset and knee points. As a result, advanced BMS functions, such as online degradation diagnosis and prognosis, online knee-onset detection and knee prediction, aging-aware battery classification, and second-life repurposing, can be enabled through a battery performance digital twin in the cloud. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14576</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14576</id><created>2025-01-24</created><authors><author><keyname>Qiu</keyname><forenames>Yiwei</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>Li</keyname><forenames>Jiatong</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>Zeng</keyname><forenames>Yangjun</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>Zhou</keyname><forenames>Yi</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>Chen</keyname><forenames>Shi</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>Qiu</keyname><forenames>Xiaoyan</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>Zhou</keyname><forenames>Buxiang</forenames><affiliation>College of Electrical Engineering, Sichuan University</affiliation></author><author><keyname>He</keyname><forenames>Ge</forenames><affiliation>Sichuan Tsinghua Energy Internet Research Institute</affiliation></author><author><keyname>Ji</keyname><forenames>Xu</forenames><affiliation>Sichuan Tsinghua Energy Internet Research Institute</affiliation></author><author><keyname>Li</keyname><forenames>Wenying</forenames><affiliation>Sichuan Tsinghua Energy Internet Research Institute</affiliation></author></authors><title>Dynamic Operation and Control of a Multi-Stack Alkaline Water   Electrolysis System with Shared Gas Separators and Lye Circulation: A   Model-Based Study</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An emerging approach for large-scale hydrogen production using renewable energy is to integrate multiple alkaline water electrolysis (AWE) stacks into a single balance of plant (BoP) system, sharing components such as gas-lye separation and lye circulation. This configuration, termed the $N$-in-1 AWE system, packs $N$ stacks into a modular system, reducing land requirements, the complexity of plant topology, and overall capital costs. However, the coupling of these stacks through the shared BoP introduces challenges in dynamic operation under varying energy inputs, making their performance unclear compared to traditional 1-in-1 systems. To address this, we develop a state-space model of the $N$-in-1 AWE system, capturing the dynamic behaviors of lye circulation, temperature, and HTO impurity, and their impact on energy conversion efficiency. We then propose a nonlinear model predictive controller (NMPC) to coordinately optimize inter-stack electrolytic current distribution, lye flow, and cooling, enabling the system to dynamically track varying load commands while maximizing efficiency, stabilizing temperature, and limiting HTO impurity accumulation. Simulation studies on a 4,000 Nm$^3$/h-rated 4-in-1 system verify the proposed controller under dynamic operation. Comparison with 4 independent 1-in-1 systems reveals that, with proper control, the $N$-in-1 configuration offers comparable flexibility in accommodating real-world wind power inputs. The average differences in the root-mean-square errors (RMSEs) for load-tracking and stack temperature stabilization, and specific energy consumption are below 0.014 MW, 2.356 K, and 0.003 kWh/Nm$^3$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14577</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14577</id><created>2025-01-24</created><authors><author><keyname>Zeng</keyname><forenames>Qiuhao</forenames></author><author><keyname>Huang</keyname><forenames>Jerry</forenames></author><author><keyname>Lu</keyname><forenames>Peng</forenames></author><author><keyname>Xu</keyname><forenames>Gezheng</forenames></author><author><keyname>Chen</keyname><forenames>Boxing</forenames></author><author><keyname>Ling</keyname><forenames>Charles</forenames></author><author><keyname>Wang</keyname><forenames>Boyu</forenames></author></authors><title>ZETA: Leveraging Z-order Curves for Efficient Top-k Attention</title><categories>cs.LG cs.AI</categories><comments>25 pages, 4 figures, accepted in International Conference on Learning   Representations (ICLR) 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over recent years, the Transformer has become a fundamental building block for sequence modeling architectures. Yet at its core is the use of self-attention, whose memory and computational cost grow quadratically with the sequence length $N$, rendering it prohibitively expensive for long sequences. A promising approach is top-$k$ attention, which selects only the $k$ most relevant tokens and achieves performance comparable to vanilla self-attention while significantly reducing space and computational demands. However, causal masks require the current query token to only attend to past tokens, preventing the existing top-$k$ attention method from efficiently searching for the most relevant tokens in parallel, thereby limiting training efficiency. In this work, we propose ZETA, leveraging \textbf{Z}-Order Curves for \textbf{E}fficient \textbf{T}op-$k$ \textbf{A}ttention, to enable parallel querying of past tokens for entire sequences. % in both space and time complexity of $\mathcal{O}(N \log N)$. We first theoretically show that the choice of key and query dimensions involves a trade-off between the curse of dimensionality and the preservation of relative distances after projection. In light of this insight, we propose reducing the dimensionality of keys and queries in contrast to values and further leverage $Z$-order curves to map low-dimensional keys and queries into \emph{one}-dimensional space, which permits parallel sorting, thereby largely improving the efficiency for top-$k$ token selection. Experimental results demonstrate that ZETA matches the performance of standard attention on the synthetic \textsc{Multi-Query Associative Recall} task and outperforms attention and its variants on \textsc{Long Range Arena} and \textsc{WikiText-103} language modeling. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14579</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14579</id><created>2025-01-24</created><authors><author><keyname>Belikov</keyname><forenames>Alexander V.</forenames></author><author><keyname>Raoult</keyname><forenames>Sacha</forenames></author></authors><title>Knowledge Graphs Construction from Criminal Court Appeals: Insights from   the French Cassation Court</title><categories>cs.IR</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Despite growing interest, accurately and reliably representing unstructured data, such as court decisions, in a structured form, remains a challenge. Recent advancements in generative AI applied to language modeling enabled the transformation of text into knowledge graphs, unlocking new opportunities for analysis and modeling. This paper presents a framework for constructing knowledge graphs from appeals to the French Cassation Court. The framework includes a domain-specific ontology and a derived dataset, offering a foundation for structured legal data representation and analysis. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14582</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14582</id><created>2025-01-24</created><authors><author><keyname>Shepperd</keyname><forenames>Martin</forenames></author></authors><title>"Estimating software project effort using analogies": Reflections after   28 years</title><categories>cs.SE</categories><comments>5 pages, invited and accepted IEEE TSE paper for the journal's 50th   year anniversary on most influential papers</comments><doi>10.1109/TSE.2025.3534032</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Background: This invited paper is the result of an invitation to write a retrospective article on a "TSE most influential paper" as part of the journal's 50th anniversary. Objective: To reflect on the progress of software engineering prediction research using the lens of a selected, highly cited research paper and 28 years of hindsight. Methods: The paper examines (i) what was achieved, (ii) what has endured and (iii) what could have been done differently with the benefit of retrospection. Conclusions: While many specifics of software project effort prediction have evolved, key methodological issues remain relevant. The original study emphasised empirical validation with benchmarks, out-of-sample testing and data/tool sharing. Four areas for improvement are identified: (i) stronger commitment to Open Science principles, (ii) focus on effect sizes and confidence intervals, (iii) reporting variability alongside typical results and (iv) more rigorous examination of threats to validity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14585</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14585</id><created>2025-01-24</created><authors><author><keyname>Egolf</keyname><forenames>Derek</forenames></author><author><keyname>Tripakis</keyname><forenames>Stavros</forenames></author></authors><title>Accelerating Protocol Synthesis and Detecting Unrealizability with   Interpretation Reduction</title><categories>cs.LO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a novel counterexample-guided, sketch-based method for the synthesis of symbolic distributed protocols in TLA+. Our method's chief novelty lies in a new search space reduction technique called interpretation reduction, which allows to not only eliminate incorrect candidate protocols before they are sent to the verifier, but also to avoid enumerating redundant candidates in the first place. Further performance improvements are achieved by an advanced technique for exact generalization of counterexamples. Experiments on a set of established benchmarks show that our tool is almost always faster than the state of the art, often by orders of magnitude, and was also able to synthesize an entire TLA+ protocol "from scratch" in less than 3 minutes where the state of the art timed out after an hour. Our method is sound, complete, and guaranteed to terminate on unrealizable synthesis instances under common assumptions which hold in all our benchmarks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14586</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14586</id><created>2025-01-24</created><authors><author><keyname>Hippold</keyname><forenames>Patrick</forenames></author><author><keyname>Gross</keyname><forenames>Johann</forenames></author><author><keyname>Krack</keyname><forenames>Malte</forenames></author></authors><title>A sub-structuring approach for model reduction of frictionally clamped   thin-walled structures</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Thin-walled structures clamped by friction joints, such as aircraft skin panels are exposed to bending-stretching coupling and frictional contact. We propose an original sub-structuring approach, where the system is divided into thin-walled and support regions, so that geometrically nonlinear behavior is relevant only in the former, and nonlinear contact behavior only in the latter. This permits to derive reduced component models, in principle, with available techniques. The Hurty-/Craig-Bampton method, combined with an interface reduction relying on an orthogonal polynomial series, is used to construct the reduction basis for each component. To model geometrically nonlinear behavior, implicit condensation is used, where an original, engineering-oriented proposition is made for the delicate scaling of the static load cases required to estimate the coefficients of the nonlinear terms. The proposed method is validated and its computational performance is assessed for the example of a plate with frictional clamping, using finite element analysis as reference. The numerical results shed light into an interesting mutual interaction: The extent of geometric hardening is limited by the reduced boundary stiffness when more sliding occurs in the clamping. On the other hand, the frictional dissipation is increased by the tangential loading induced by membrane stretching. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14587</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14587</id><created>2025-01-24</created><authors><author><keyname>Kozák</keyname><forenames>Viktor</forenames></author><author><keyname>Košnar</keyname><forenames>Karel</forenames></author><author><keyname>Chudoba</keyname><forenames>Jan</forenames></author><author><keyname>Kulich</keyname><forenames>Miroslav</forenames></author><author><keyname>Přeučil</keyname><forenames>Libor</forenames></author></authors><title>Visual Localization via Semantic Structures in Autonomous Photovoltaic   Power Plant Inspection</title><categories>cs.CV cs.RO</categories><comments>47 pages, 22 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Inspection systems utilizing unmanned aerial vehicles (UAVs) equipped with thermal cameras are increasingly popular for the maintenance of photovoltaic (PV) power plants. However, automation of the inspection task is a challenging problem as it requires precise navigation to capture images from optimal distances and viewing angles.   This paper presents a novel localization pipeline that directly integrates PV module detection with UAV navigation, allowing precise positioning during inspection. Detections are used to identify the power plant structures in the image and associate these with the power plant model. We define visually recognizable anchor points for the initial association and use object tracking to discern global associations. We present three distinct methods for visual segmentation of PV modules based on traditional computer vision, deep learning, and their fusion, and we evaluate their performance in relation to the proposed localization pipeline.   The presented methods were verified and evaluated using custom aerial inspection data sets, demonstrating their robustness and applicability for real-time navigation. Additionally, we evaluate the influence of the power plant model's precision on the localization methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14588</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14588</id><created>2025-01-24</created><authors><author><keyname>Zhao</keyname><forenames>Jianzhe</forenames></author><author><keyname>Zhu</keyname><forenames>Feida</forenames></author><author><keyname>He</keyname><forenames>Lingyan</forenames></author><author><keyname>Tang</keyname><forenames>Zixin</forenames></author><author><keyname>Gao</keyname><forenames>Mingce</forenames></author><author><keyname>Yang</keyname><forenames>Shiyu</forenames></author><author><keyname>Guo</keyname><forenames>Guibing</forenames></author></authors><title>Data Assetization via Resources-decoupled Federated Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development of the digital economy, data is increasingly recognized as an essential resource for both work and life. However, due to privacy concerns, data owners tend to maximize the value of data through information flow rather than direct data transfer. Federated learning (FL) provides an effective approach to collaborative training models while preserving privacy. However, different data owners not only have variations in the quantity and quality of their data resources but also face mismatches between data and computing resources as model parameters and training data grow. These challenges hinder data owners' willingness to participate and reduce the effectiveness of data assetization. In this work, we first identify the resource-decoupled FL environment, which includes model owners, data owners, and computing centers. We design a Tripartite Stackelberg Model and theoretically analyze the Stackelberg-Nash Equilibrium (SNE) for participants to optimize global utility. We propose the Quality-aware Dynamic Resources-decoupled FL algorithm (QD-RDFL), in which we derive and solve the optimal strategies of all parties to achieve SHE using backward induction, and a dynamic optimization mechanism is designed to improve the optimal strategy profile by evaluating the contribution of data quality from data owners to the global model during real training. Our comprehensive experiments demonstrate that our method effectively encourages the linkage of the three parties involved, maximizing global utility and data asset value. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14591</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14591</id><created>2025-01-24</created><authors><author><keyname>Dyn</keyname><forenames>Nira</forenames></author><author><keyname>Levin</keyname><forenames>David</forenames></author></authors><title>Approximation of Set-Valued Functions with images sets in $\mathbb{R}^d$</title><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Given a finite number of samples of a continuous set-valued function F, mapping an interval to non-empty compact subsets of $\mathbb{R}^d$, $F: [a,b] \to K(\mathbb{R}^d)$, we discuss the problem of computing good approximations of F. We also discuss algorithms for a direct high-order evaluation of the graph of $F$, namely, the set $Graph(F)=\{(t,y)\ | \ y\in F(t),\ t\in [a,b]\}\in K(\mathbb{R}^{d+1})$. A set-valued function can be continuous and yet have points where the topology of the image sets changes. The main challenge in set-valued function approximation is to derive high-order approximations near these points. In a previous paper, we presented with Q. Muzaffar, an algorithm for approximating set-valued functions with 1D sets ($d=1$) as images, achieving high approximation order near points of topology change. Here we build upon the results and algorithms in the $d=1$ case, first in more detail for the important case $d=2$, and later for approximating set-valued functions and their graphs in higher dimensions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14592</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14592</id><created>2025-01-24</created><authors><author><keyname>Zhang</keyname><forenames>Jiazhen</forenames></author><author><keyname>Du</keyname><forenames>Yuexi</forenames></author><author><keyname>Dvornek</keyname><forenames>Nicha C.</forenames></author><author><keyname>Onofrey</keyname><forenames>John A.</forenames></author></authors><title>Improved Vessel Segmentation with Symmetric Rotation-Equivariant U-Net</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted by IEEE ISBI 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated segmentation plays a pivotal role in medical image analysis and computer-assisted interventions. Despite the promising performance of existing methods based on convolutional neural networks (CNNs), they neglect useful equivariant properties for images, such as rotational and reflection equivariance. This limitation can decrease performance and lead to inconsistent predictions, especially in applications like vessel segmentation where explicit orientation is absent. While existing equivariant learning approaches attempt to mitigate these issues, they substantially increase learning cost, model size, or both. To overcome these challenges, we propose a novel application of an efficient symmetric rotation-equivariant (SRE) convolutional (SRE-Conv) kernel implementation to the U-Net architecture, to learn rotation and reflection-equivariant features, while also reducing the model size dramatically. We validate the effectiveness of our method through improved segmentation performance on retina vessel fundus imaging. Our proposed SRE U-Net not only significantly surpasses standard U-Net in handling rotated images, but also outperforms existing equivariant learning methods and does so with a reduced number of trainable parameters and smaller memory cost. The code is available at https://github.com/OnofreyLab/sre_conv_segm_isbi2025. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14593</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14593</id><created>2025-01-24</created><authors><author><keyname>Wu</keyname><forenames>Tong</forenames></author><author><keyname>Kobayashi</keyname><forenames>Takumi</forenames></author></authors><title>Geometric Mean Improves Loss For Few-Shot Learning</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Few-shot learning (FSL) is a challenging task in machine learning, demanding a model to render discriminative classification by using only a few labeled samples. In the literature of FSL, deep models are trained in a manner of metric learning to provide metric in a feature space which is well generalizable to classify samples of novel classes; in the space, even a few amount of labeled training examples can construct an effective classifier. In this paper, we propose a novel FSL loss based on \emph{geometric mean} to embed discriminative metric into deep features. In contrast to the other losses such as utilizing arithmetic mean in softmax-based formulation, the proposed method leverages geometric mean to aggregate pair-wise relationships among samples for enhancing discriminative metric across class categories. The proposed loss is not only formulated in a simple form but also is thoroughly analyzed in theoretical ways to reveal its favorable characteristics which are favorable for learning feature metric in FSL. In the experiments on few-shot image classification tasks, the method produces competitive performance in comparison to the other losses. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14598</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14598</id><created>2025-01-24</created><authors><author><keyname>Kellison</keyname><forenames>Ariel Eileen</forenames></author></authors><title>Type-Based Approaches to Rounding Error Analysis</title><categories>cs.PL cs.NA math.NA</categories><comments>PhD thesis</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This dissertation explores the design and implementation of programming languages that represent rounding error analysis through typing.   The first part of this dissertation demonstrates that it is possible to design languages for forward error analysis, as illustrated with NumFuzz, a functional programming language whose type system expresses quantitative bounds on rounding error. This type system combines a sensitivity analysis, enforced through a linear typing discipline, with a novel graded monad to track the accumulation of rounding errors. We establish the soundness of the type system by relating the denotational semantics of the language to both an exact and floating-point operational semantics. To demonstrate the practical utility of NumFuzz as a tool for automated error analysis, we have developed a prototype implementation capable of automatically inferring error bounds. Our implementation produces bounds competitive with existing tools, while often achieving significantly faster analysis times.   The second part of this dissertation explores a type-based approach to backward error analysis with Bean, a first-order programming language with a linear type system that can express quantitative bounds on backward error. Bean's type system combines a graded coeffect system with strict linearity to soundly track the flow of backward error through programs. To illustrate Bean's potential as a practical tool for automated backward error analysis, we implement a variety of standard algorithms from numerical linear algebra in Bean, establishing fine-grained backward error bounds via typing in a compositional style. We also develop a prototype implementation of Bean that infers backward error bounds automatically. Our evaluation shows that these inferred bounds match worst-case theoretical relative backward error bounds from the literature. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14599</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14599</id><created>2025-01-24</created><authors><author><keyname>Brubeck</keyname><forenames>Pablo D.</forenames></author><author><keyname>Kirby</keyname><forenames>Robert C.</forenames></author></authors><title>FIAT: enabling classical and modern macroelements</title><categories>math.NA cs.NA</categories><msc-class>65N30</msc-class><acm-class>G.4; G.1.8</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many classical and modern finite element spaces are derived by dividing each computational cell into finer pieces. Such \emph{macroelements} frequently enable the enforcement of mathematically desirable properties such as divergence-free conditions or $C^1$ continuity in a simpler or more efficient manner than elements without the subdivision. Although a few modern software projects provide one-off support for particular macroelements, a general approach facilitating broad-based support has, until now, been lacking. In this work, we describe a major addition to the FIAT project to support a wide range of different macroelements. These enhancements have been integrated into the Firedrake code stack. Numerical evaluation of the new macroelement facility is provided. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14600</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14600</id><created>2025-01-24</created><authors><author><keyname>Tao</keyname><forenames>Zhen</forenames></author><author><keyname>Qiao</keyname><forenames>Ziyue</forenames></author><author><keyname>Chen</keyname><forenames>Chaoqi</forenames></author><author><keyname>Yang</keyname><forenames>Zhengyi</forenames></author><author><keyname>Du</keyname><forenames>Lun</forenames></author><author><keyname>Sun</keyname><forenames>Qingqiang</forenames></author></authors><title>On the Homophily of Heterogeneous Graphs: Understanding and Unleashing</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Homophily, the tendency of similar nodes to connect, is a fundamental phenomenon in network science and a critical factor in the performance of graph neural networks (GNNs). While existing studies primarily explore homophily in homogeneous graphs, where nodes share the same type, real-world networks are often more accurately modeled as heterogeneous graphs (HGs) with diverse node types and intricate cross-type interactions. This structural diversity complicates the analysis of homophily, as traditional homophily metrics fail to account for distinct label spaces across node types. To address this limitation, we introduce the Cross-Type Homophily Ratio, a novel metric that quantifies homophily based on the similarity of target information across different node types. Furthermore, we introduce Cross-Type Homophily-guided Heterogeneous Graph Pruning, a method designed to selectively remove low-homophily crosstype edges, thereby enhancing the Cross-Type Homophily Ratio and boosting the performance of heterogeneous graph neural networks (HGNNs). Extensive experiments on five real-world HG datasets validate the effectiveness of our approach, which delivers up to 13.36% average relative performance improvement for HGNNs, offering a fresh perspective on cross-type homophily in heterogeneous graph learning. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14603</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14603</id><created>2025-01-24</created><authors><author><keyname>Sarathchandra</keyname><forenames>Sankani</forenames></author><author><keyname>Eldeeb</keyname><forenames>Eslam</forenames></author><author><keyname>Shehab</keyname><forenames>Mohammad</forenames></author><author><keyname>Alves</keyname><forenames>Hirley</forenames></author><author><keyname>Mikhaylov</keyname><forenames>Konstantin</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV   Networks</title><categories>cs.LG cs.AI</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Age-of-information (AoI) and transmission power are crucial performance metrics in low energy wireless networks, where information freshness is of paramount importance. This study examines a power-limited internet of things (IoT) network supported by a flying unmanned aerial vehicle(UAV) that collects data. Our aim is to optimize the UAV flight trajectory and scheduling policy to minimize a varying AoI and transmission power combination. To tackle this variation, this paper proposes a meta-deep reinforcement learning (RL) approach that integrates deep Q-networks (DQNs) with model-agnostic meta-learning (MAML). DQNs determine optimal UAV decisions, while MAML enables scalability across varying objective functions. Numerical results indicate that the proposed algorithm converges faster and adapts to new objectives more effectively than traditional deep RL methods, achieving minimal AoI and transmission power overall. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14604</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14604</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Chaoyu</forenames></author><author><keyname>Budd</keyname><forenames>Chris</forenames></author><author><keyname>Schönlieb</keyname><forenames>Carola-Bibiane</forenames></author></authors><title>Inverse Evolution Data Augmentation for Neural PDE Solvers</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural networks have emerged as promising tools for solving partial differential equations (PDEs), particularly through the application of neural operators. Training neural operators typically requires a large amount of training data to ensure accuracy and generalization. In this paper, we propose a novel data augmentation method specifically designed for training neural operators on evolution equations. Our approach utilizes insights from inverse processes of these equations to efficiently generate data from random initialization that are combined with original data. To further enhance the accuracy of the augmented data, we introduce high-order inverse evolution schemes. These schemes consist of only a few explicit computation steps, yet the resulting data pairs can be proven to satisfy the corresponding implicit numerical schemes. In contrast to traditional PDE solvers that require small time steps or implicit schemes to guarantee accuracy, our data augmentation method employs explicit schemes with relatively large time steps, thereby significantly reducing computational costs. Accuracy and efficacy experiments confirm the effectiveness of our approach. Additionally, we validate our approach through experiments with the Fourier Neural Operator and UNet on three common evolution equations that are Burgers' equation, the Allen-Cahn equation and the Navier-Stokes equation. The results demonstrate a significant improvement in the performance and robustness of the Fourier Neural Operator when coupled with our inverse evolution data augmentation method. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14605</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14605</id><created>2025-01-24</created><authors><author><keyname>Sanchez</keyname><forenames>Jules</forenames></author><author><keyname>Deschaud</keyname><forenames>Jean-Emmanuel</forenames></author><author><keyname>Goulette</keyname><forenames>François</forenames></author></authors><title>3DLabelProp: Geometric-Driven Domain Generalization for LiDAR Semantic   Segmentation in Autonomous Driving</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Domain generalization aims to find ways for deep learning models to maintain their performance despite significant domain shifts between training and inference datasets. This is particularly important for models that need to be robust or are costly to train. LiDAR perception in autonomous driving is impacted by both of these concerns, leading to the emergence of various approaches. This work addresses the challenge by proposing a geometry-based approach, leveraging the sequential structure of LiDAR sensors, which sets it apart from the learning-based methods commonly found in the literature. The proposed method, called 3DLabelProp, is applied on the task of LiDAR Semantic Segmentation (LSS). Through extensive experimentation on seven datasets, it is demonstrated to be a state-of-the-art approach, outperforming both naive and other domain generalization methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14607</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14607</id><created>2025-01-24</created><authors><author><keyname>Liang</keyname><forenames>Tianming</forenames></author><author><keyname>Lin</keyname><forenames>Kun-Yu</forenames></author><author><keyname>Tan</keyname><forenames>Chaolei</forenames></author><author><keyname>Zhang</keyname><forenames>Jianguo</forenames></author><author><keyname>Zheng</keyname><forenames>Wei-Shi</forenames></author><author><keyname>Hu</keyname><forenames>Jian-Fang</forenames></author></authors><title>ReferDINO: Referring Video Object Segmentation with Visual Grounding   Foundations</title><categories>cs.CV</categories><comments>Project page: https://isee-laboratory.github.io/ReferDINO</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Referring video object segmentation (RVOS) aims to segment target objects throughout a video based on a text description. Despite notable progress in recent years, current RVOS models remain struggle to handle complicated object descriptions due to their limited video-language understanding. To address this limitation, we present \textbf{ReferDINO}, an end-to-end RVOS model that inherits strong vision-language understanding from the pretrained visual grounding foundation models, and is further endowed with effective temporal understanding and object segmentation capabilities. In ReferDINO, we contribute three technical innovations for effectively adapting the foundation models to RVOS: 1) an object-consistent temporal enhancer that capitalizes on the pretrained object-text representations to enhance temporal understanding and object consistency; 2) a grounding-guided deformable mask decoder that integrates text and grounding conditions to generate accurate object masks; 3) a confidence-aware query pruning strategy that significantly improves the object decoding efficiency without compromising performance. We conduct extensive experiments on five public RVOS benchmarks to demonstrate that our proposed ReferDINO outperforms state-of-the-art methods significantly. Project page: \url{https://isee-laboratory.github.io/ReferDINO} </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14608</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14608</id><created>2025-01-24</created><authors><author><keyname>Mahata</keyname><forenames>Shipra</forenames></author><author><keyname>Rathan</keyname><forenames>Samala</forenames></author><author><keyname>Ruiz-Álvarez</keyname><forenames>Juan</forenames></author><author><keyname>Yáñez</keyname><forenames>Dionisio F.</forenames></author></authors><title>A general correction for numerical integration rules over piece-wise   continuous functions</title><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This article presents a novel approach to enhance the accuracy of classical quadrature rules by incorporating correction terms. The proposed method is particularly effective when the position of an isolated discontinuity in the function and the jump in the function and its derivatives at that position are known. Traditional numerical integration rules are exact for polynomials of certain degree. However, they may not provide accurate results for piece-wise polynomials or functions with discontinuities without modifying the location and number of data points in the formula. Our proposed correction terms address this limitation, enabling the integration rule to conserve its accuracy even in the presence of a jump discontinuity. The numerical experiments that we present support the theoretical results obtained. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14609</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14609</id><created>2025-01-24</created><authors><author><keyname>Barman</keyname><forenames>Siddharth</forenames></author><author><keyname>Verma</keyname><forenames>Paritosh</forenames></author></authors><title>Fair Division Beyond Monotone Valuations</title><categories>cs.GT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the problem of fairly dividing resources -- a cake or indivisible items -- amongst a set of agents with heterogeneous preferences. This problem has been extensively studied in the literature, however, a majority of the existing work has focused on settings wherein the agents' preferenes are monotone, i.e., increasing the quantity of resource doesn't decrease an agent's value for it. Despite this, the study of non-monotone preferences is as motivated as the study of monotone preferences. We focus on fair division beyond monotone valuations.   We prove the existence of fair allocations, develop efficient algorithms to compute them, and prove lower bounds on the number of such fair allocations. For the case of indivisible items, we show that EF3 and EQ3 allocations always exist as long as the valuations of all agents are nonnegative. While nonnegativity suffices, we show that it's not required: EF3 allocations exist even if the valuations are (possibly negative) subadditive functions that satisfy a mild condition. In route to obtaining these results, we establish the existence of envy-free cake divisions for burnt cakes when the valuations are subadditive and the entire cake has a nonnegative value. This is in stark contrast to the well-known nonexistence of envy-free allocations for burnt cakes.   In addition to the existence results, we develop an FPTAS for computing equitable cake divisions for nonnegative valuations. For indivisible items, we give an efficient algorithm to compute nearly equitable allocations which works when the valuations are nonnegative, or when they are subadditive subject to a mild condition. This result has implications beyond fair division, e.g., in facility, graph partitioning, among others. Finally, we show that such fair allocations are plenty in number, and increase exponentially (polynomially) in the number of agents (items). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14610</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14610</id><created>2025-01-24</created><authors><author><keyname>Olalere</keyname><forenames>Feyisayo</forenames></author><author><keyname>van der Heijden</keyname><forenames>Kiki</forenames></author><author><keyname>Stronks</keyname><forenames>Christiaan H.</forenames></author><author><keyname>Briaire</keyname><forenames>Jeroen</forenames></author><author><keyname>Frijns</keyname><forenames>Johan HM</forenames></author><author><keyname>van Gerven</keyname><forenames>Marcel</forenames></author></authors><title>Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently   Enhance Speech Separation in Real-World Listening Scenes</title><categories>cs.SD cs.AI eess.AS</categories><comments>10 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Speech separation approaches for single-channel, dry speech mixtures have significantly improved. However, real-world spatial and reverberant acoustic environments remain challenging, limiting the effectiveness of these approaches for assistive hearing devices like cochlear implants (CIs). To address this, we quantify the impact of real-world acoustic scenes on speech separation and explore how spatial cues can enhance separation quality efficiently. We analyze performance based on implicit spatial cues (inherent in the acoustic input and learned by the model) and explicit spatial cues (manually calculated spatial features added as auxiliary inputs). Our findings show that spatial cues (both implicit and explicit) improve separation for mixtures with spatially separated and nearby talkers. Furthermore, spatial cues enhance separation when spectral cues are ambiguous, such as when voices are similar. Explicit spatial cues are particularly beneficial when implicit spatial cues are weak. For instance, single CI microphone recordings provide weaker implicit spatial cues than bilateral CIs, but even single CIs benefit from explicit cues. These results emphasize the importance of training models on real-world data to improve generalizability in everyday listening scenarios. Additionally, our statistical analyses offer insights into how data properties influence model performance, supporting the development of efficient speech separation approaches for CIs and other assistive devices in real-world settings. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14613</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14613</id><created>2025-01-24</created><authors><author><keyname>Besançon</keyname><forenames>Mathieu</forenames></author><author><keyname>Designolle</keyname><forenames>Sébastien</forenames></author><author><keyname>Halbey</keyname><forenames>Jannis</forenames></author><author><keyname>Hendrych</keyname><forenames>Deborah</forenames></author><author><keyname>Kuzinowicz</keyname><forenames>Dominik</forenames></author><author><keyname>Pokutta</keyname><forenames>Sebastian</forenames></author><author><keyname>Troppens</keyname><forenames>Hannah</forenames></author><author><keyname>Herrmannsdoerfer</keyname><forenames>Daniel Viladrich</forenames></author><author><keyname>Wirth</keyname><forenames>Elias</forenames></author></authors><title>Improved algorithms and novel applications of the FrankWolfe.jl library</title><categories>math.OC cs.MS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Frank-Wolfe (FW) algorithms have emerged as an essential class of methods for constrained optimization, especially on large-scale problems. In this paper, we summarize the algorithmic design choices and progress made in the last years of the development of FrankWolfe.jl, a Julia package gathering high-performance implementations of state-of-the-art FW variants. We review key use cases of the library in the recent literature, which match its original dual purpose: first, becoming the de-facto toolbox for practitioners applying FW methods to their problem, and second, offering a modular ecosystem to algorithm designers who experiment with their own variants and implementations of algorithmic blocks. Finally, we demonstrate the performance of several FW variants on important problem classes in several experiments, which we curated in a separate repository for continuous benchmarking. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14615</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14615</id><created>2025-01-24</created><authors><author><keyname>Abante</keyname><forenames>Jordi</forenames></author><author><keyname>Piga</keyname><forenames>Angelo</forenames></author><author><keyname>Ros</keyname><forenames>Berta</forenames></author><author><keyname>López-León</keyname><forenames>Clara F</forenames></author><author><keyname>Canals</keyname><forenames>Josep M</forenames></author><author><keyname>Soriano</keyname><forenames>Jordi</forenames></author></authors><title>Single-neuron deep generative model uncovers underlying physics of   neuronal activity in Ca imaging data</title><categories>q-bio.NC cs.LG</categories><comments>12 pages, 5 figures, ECCB 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Calcium imaging has become a powerful alternative to electrophysiology for studying neuronal activity, offering spatial resolution and the ability to measure large populations of neurons in a minimally invasive manner. This technique has broad applications in neuroscience, neuroengineering, and medicine, enabling researchers to explore the relationship between neuron location and activity. Recent advancements in deep generative models (DGMs) have facilitated the modeling of neuronal population dynamics, uncovering latent representations that provide insights into behavior prediction and neuronal variance. However, these models often rely on spike inference algorithms and primarily focus on population-level dynamics, limiting their applicability for single-neuron analyses. To address this gap, we propose a novel framework for single-neuron representation learning using autoregressive variational autoencoders (AVAEs). Our approach embeds individual neurons' spatiotemporal signals into a reduced-dimensional space without the need for spike inference algorithms. The AVAE excels over traditional linear methods by generating more informative and discriminative latent representations, improving tasks such as visualization, clustering, and the understanding of neuronal activity. Additionally, the reconstruction performance of the AVAE outperforms the state of the art, demonstrating its ability to accurately recover the original fluorescence signal from the learned representation. Using realistic simulations, we show that our model captures underlying physical properties and connectivity patterns, enabling it to distinguish between different firing and connectivity types. These findings position the AVAE as a versatile and powerful tool for advancing single-neuron analysis and lays the groundwork for future integration of multimodal single-cell datasets in neuroscience. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14616</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14616</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Yen-Chun</forenames></author><author><keyname>Mak</keyname><forenames>Simon</forenames></author></authors><title>QuIP: Experimental design for expensive simulators with many Qualitative   factors via Integer Programming</title><categories>stat.AP cs.RO</categories><comments>40 pages, 6 figures, submitted to JCGS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need to explore and/or optimize expensive simulators with many qualitative factors arises in broad scientific and engineering problems. Our motivating application lies in path planning - the exploration of feasible paths for navigation, which plays an important role in robotics, surgical planning and assembly planning. Here, the feasibility of a path is evaluated via expensive virtual experiments, and its parameter space is typically discrete and high-dimensional. A carefully selected experimental design is thus essential for timely decision-making. We propose here a novel framework, called QuIP, for experimental design of Qualitative factors via Integer Programming under a Gaussian process surrogate model with an exchangeable covariance function. For initial design, we show that its asymptotic D-optimal design can be formulated as a variant of the well-known assignment problem in operations research, which can be efficiently solved to global optimality using state-of-the-art integer programming solvers. For sequential design (specifically, for active learning or black-box optimization), we show that its design criterion can similarly be formulated as an assignment problem, thus enabling efficient and reliable optimization with existing solvers. We then demonstrate the effectiveness of QuIP over existing methods in a suite of path planning experiments and an application to rover trajectory optimization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14617</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14617</id><created>2025-01-24</created><authors><author><keyname>Sarumi</keyname><forenames>Olufunke O.</forenames></author><author><keyname>Welch</keyname><forenames>Charles</forenames></author><author><keyname>Flek</keyname><forenames>Lucie</forenames></author><author><keyname>Schlötterer</keyname><forenames>Jörg</forenames></author></authors><title>Funzac at CoMeDi Shared Task: Modeling Annotator Disagreement from   Word-In-Context Perspectives</title><categories>cs.CL</categories><comments>Accepted to CoMeDi Shared Task at COLING 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we evaluate annotator disagreement in Word-in-Context (WiC) tasks exploring the relationship between contextual meaning and disagreement as part of the CoMeDi shared task competition. While prior studies have modeled disagreement by analyzing annotator attributes with single-sentence inputs, this shared task incorporates WiC to bridge the gap between sentence-level semantic representation and annotator judgment variability. We describe three different methods that we developed for the shared task, including a feature enrichment approach that combines concatenation, element-wise differences, products, and cosine similarity, Euclidean and Manhattan distances to extend contextual embedding representations, a transformation by Adapter blocks to obtain task-specific representations of contextual embeddings, and classifiers of varying complexities, including ensembles. The comparison of our methods demonstrates improved performance for methods that include enriched and task-specfic features. While the performance of our method falls short in comparison to the best system in subtask 1 (OGWiC), it is competitive to the official evaluation results in subtask 2 (DisWiC). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14619</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14619</id><created>2025-01-24</created><authors><author><keyname>Giannopoulos</keyname><forenames>Anastasios</forenames></author><author><keyname>Spantideas</keyname><forenames>Sotirios</forenames></author><author><keyname>George</keyname><forenames>Levis</forenames></author><author><keyname>Alexandros</keyname><forenames>Kalafatelis</forenames></author><author><keyname>Trakadas</keyname><forenames>Panagiotis</forenames></author></authors><title>COMIX: Generalized Conflict Management in O-RAN xApps -- Architecture,   Workflow, and a Power Control case</title><categories>cs.NI</categories><comments>14 pages, 8 figures, 3 tables</comments><msc-class>D.2, H.4, I.2, I.6, J.6</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Open Radio Access Network (O-RAN) is transforming the telecommunications landscape by enabling flexible, intelligent, and multi-vendor networks. Central to its architecture are xApps hosted on the Near-Real-Time RAN Intelligent Controller (Near-RT RIC), which optimize network functions in real time. However, the concurrent operation of multiple xApps with conflicting objectives can lead to suboptimal performance. This paper introduces a generalized Conflict Management scheme for Multi-Channel Power Control in O-RAN xApps (COMIX), designed to detect and resolve conflicts between xApps. To demonstrate COMIX, we focus on two Deep Reinforcement Learning (DRL)-based xApps for power control: one maximizes the data rare across UEs, and the other optimizes system-level energy efficiency. COMIX employs a standardized Conflict Mitigation Framework (CMF) for conflict detection and resolution and leverages the Network Digital Twin (NDT) to evaluate the impact of conflicting actions before applying them to the live network. We validate the framework using a realistic multi-channel power control scenario under various conflict resolution policies, demonstrating its effectiveness in balancing antagonistic objectives. Our results highlight significant network energy savings achieved through the conflict management scheme compared to baseline CMF-free methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14620</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14620</id><created>2025-01-24</created><authors><author><keyname>Wu</keyname><forenames>Han</forenames></author><author><keyname>Joudeh</keyname><forenames>Hamdi</forenames></author></authors><title>Strong Converse Exponent for Remote Lossy Source Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Past works on remote lossy source coding studied the rate under average distortion and the error exponent of excess distortion probability. In this work, we look into how fast the excess distortion probability converges to 1 at small rates, also known as exponential strong converse. We characterize its exponent by establishing matched upper and lower bounds. From the exponent, we also recover two previous results on lossy source coding and biometric authentication. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14622</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14622</id><created>2025-01-24</created><authors><author><keyname>Vujinovic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Kovacevic</keyname><forenames>Aleksandar</forenames></author></authors><title>ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy   Representation Learning</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Learning efficient representations for decision-making policies is a challenge in imitation learning (IL). Current IL methods require expert demonstrations, which are expensive to collect. Consequently, they often have underdeveloped world models. Self-supervised learning (SSL) offers an alternative by allowing models to learn from diverse, unlabeled data, including failures. However, SSL methods often operate in raw input space, making them inefficient. In this work, we propose ACT-JEPA, a novel architecture that integrates IL and SSL to enhance policy representations. We train a policy to predict (1) action sequences and (2) abstract observation sequences. The first objective uses action chunking to improve action prediction and reduce compounding errors. The second objective extends this idea of chunking by predicting abstract observation sequences. We utilize Joint-Embedding Predictive Architecture to predict in abstract representation space, allowing the model to filter out irrelevant details, improve efficiency, and develop a robust world model. Our experiments show that ACT-JEPA improves the quality of representations by learning temporal environment dynamics. Additionally, the model's ability to predict abstract observation sequences results in representations that effectively generalize to action sequence prediction. ACT-JEPA performs on par with established baselines across a range of decision-making tasks. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14625</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14625</id><created>2025-01-24</created><authors><author><keyname>Huang</keyname><forenames>David</forenames></author><author><keyname>Marmolejo-Cossío</keyname><forenames>Francisco</forenames></author><author><keyname>Lock</keyname><forenames>Edwin</forenames></author><author><keyname>Parkes</keyname><forenames>David</forenames></author></authors><title>Accelerated Preference Elicitation with LLM-Based Proxies</title><categories>cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bidders in combinatorial auctions face significant challenges when describing their preferences to an auctioneer. Classical work on preference elicitation focuses on query-based techniques inspired from proper learning--often via proxies that interface between bidders and an auction mechanism--to incrementally learn bidder preferences as needed to compute efficient allocations. Although such elicitation mechanisms enjoy theoretical query efficiency, the amount of communication required may still be too cognitively taxing in practice.   We propose a family of efficient LLM-based proxy designs for eliciting preferences from bidders using natural language. Our proposed mechanism combines LLM pipelines and DNF-proper-learning techniques to quickly approximate preferences when communication is limited. To validate our approach, we create a testing sandbox for elicitation mechanisms that communicate in natural language. In our experiments, our most promising LLM proxy design reaches approximately efficient outcomes with five times fewer queries than classical proper learning based elicitation mechanisms. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14630</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14630</id><created>2025-01-24</created><authors><author><keyname>Schilder</keyname><forenames>André</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Extracting Problem Structure with LLMs for Optimized SAT Local Search</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Local search preprocessing makes Conflict-Driven Clause Learning (CDCL) solvers faster by providing high-quality starting points and modern SAT solvers have incorporated this technique into their preprocessing steps. However, these tools rely on basic strategies that miss the structural patterns in problems. We present a method that applies Large Language Models (LLMs) to analyze Python-based encoding code. This reveals hidden structural patterns in how problems convert into SAT. Our method automatically generates specialized local search algorithms that find these patterns and use them to create strong initial assignments. This works for any problem instance from the same encoding type. Our tests show encouraging results, achieving faster solving times compared to baseline preprocessing systems. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14631</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14631</id><created>2025-01-24</created><authors><author><keyname>Szafarczyk</keyname><forenames>Robert</forenames></author><author><keyname>Nabi</keyname><forenames>Syed Waqar</forenames></author><author><keyname>Vanderbauwhede</keyname><forenames>Wim</forenames></author></authors><title>Dynamic Loop Fusion in High-Level Synthesis</title><categories>cs.AR</categories><comments>To appear in the Proceedings of the 2025 ACM/SIGDA International   Symposium on Field Programmable Gate Arrays (FPGA 2025)</comments><doi>10.1145/3706628.3708871</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Dynamic High-Level Synthesis (HLS) uses additional hardware to perform memory disambiguation at runtime, increasing loop throughput in irregular codes compared to static HLS. However, most irregular codes consist of multiple sibling loops, which currently have to be executed sequentially by all HLS tools. Static HLS performs loop fusion only on regular codes, while dynamic HLS relies on loops with dependencies to run to completion before the next loop starts.   We present dynamic loop fusion for HLS, a compiler/hardware co-design approach that enables multiple loops to run in parallel, even if they contain unpredictable memory dependencies. Our only requirement is that memory addresses are monotonically non-decreasing in inner loops. We present a novel program-order schedule for HLS, inspired by polyhedral compilers, that together with our address monotonicity analysis enables dynamic memory disambiguation that does not require searching of address histories and sequential loop execution. Our evaluation shows an average speedup of 14$\times$ over static and 4$\times$ over dynamic HLS. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14633</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14633</id><created>2025-01-24</created><authors><author><keyname>Ortin</keyname><forenames>Jorge</forenames></author><author><keyname>Garcia</keyname><forenames>Paloma</forenames></author><author><keyname>Gutierrez</keyname><forenames>Fernando</forenames></author><author><keyname>Valdovinos</keyname><forenames>Antonio</forenames></author></authors><title>Channel Independent Precoder for OFDM-based Systems over Fading Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>8 pages, 7 figures</comments><journal-ref>IEEE Transactions on Broadcasting, volume: 55, issue: 4, December   2009</journal-ref><doi>10.1109/TBC.2009.2033403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an independent channel precoder for orthogonal frequency division multiplexing (OFDM) systems over fading channels. The design of the precoder is based on the information redistribution of the input modulated symbols amongst the output precoded symbols. The proposed precoder decreases the variance of the instantaneous noise power at the receiver produced by the channel variability. The employment of an interleaver together with a precoding matrix whose size does not depend on the number of data carriers in an OFDM symbol allows different configurations of time-frequency diversity which can be easily adapted to the channel conditions. The precoder is evaluated with a modified Zero Forcing (ZF) equalizer whose maximum gain is constrained by means of a clipping factor. Thus, the clipping factor limits the noise power transfer in the receiver deprecoding block in low SNR conditions. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14634</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14634</id><created>2025-01-24</created><authors><author><keyname>Ghisellini</keyname><forenames>Renato</forenames></author><author><keyname>Pareschi</keyname><forenames>Remo</forenames></author><author><keyname>Pedroni</keyname><forenames>Marco</forenames></author><author><keyname>Raggi</keyname><forenames>Giovanni Battista</forenames></author></authors><title>Recommending Actionable Strategies: A Semantic Approach to Integrating   Analytical Frameworks with Decision Heuristics</title><categories>cs.AI</categories><acm-class>I.2.7; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach for recommending actionable strategies by integrating strategic frameworks with decision heuristics through semantic analysis. While strategy frameworks provide systematic models for assessment and planning, and decision heuristics encode experiential knowledge,these traditions have historically remained separate. Our methodology bridges this gap using advanced natural language processing (NLP), demonstrated through integrating frameworks like the 6C model with the Thirty-Six Stratagems. The approach employs vector space representations and semantic similarity calculations to map framework parameters to heuristic patterns, supported by a computational architecture that combines deep semantic processing with constrained use of Large Language Models. By processing both primary content and secondary elements (diagrams, matrices) as complementary linguistic representations, we demonstrate effectiveness through corporate strategy case studies. The methodology generalizes to various analytical frameworks and heuristic sets, culminating in a plug-and-play architecture for generating recommender systems that enable cohesive integration of strategic frameworks and decision heuristics into actionable guidance. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14635</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14635</id><created>2025-01-24</created><authors><author><keyname>Kim</keyname><forenames>Kaheon</forenames></author><author><keyname>Yao</keyname><forenames>Rentian</forenames></author><author><keyname>Zhu</keyname><forenames>Changbo</forenames></author><author><keyname>Chen</keyname><forenames>Xiaohui</forenames></author></authors><title>Optimal Transport Barycenter via Nonconvex-Concave Minimax Optimization</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal transport barycenter (a.k.a. Wasserstein barycenter) is a fundamental notion of averaging that extends from the Euclidean space to the Wasserstein space of probability distributions. Computation of the unregularized barycenter for discretized probability distributions on point clouds is a challenging task when the domain dimension $d &gt; 1$. Most practical algorithms for approximating the barycenter problem are based on entropic regularization. In this paper, we introduce a nearly linear time $O(m \log{m})$ and linear space complexity $O(m)$ primal-dual algorithm, the Wasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) algorithm, for computing the exact barycenter when the input probability density functions are discretized on an $m$-point grid. The key success of the WDHA algorithm hinges on alternating between two different yet closely related Wasserstein and Sobolev optimization geometries for the primal barycenter and dual Kantorovich potential subproblems. Under reasonable assumptions, we establish the convergence rate and iteration complexity of WDHA to its stationary point when the step size is appropriately chosen. Superior computational efficacy, scalability, and accuracy over the existing Sinkhorn-type algorithms are demonstrated on high-resolution (e.g., $1024 \times 1024$ images) 2D synthetic and real data. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14636</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14636</id><created>2025-01-24</created><authors><author><keyname>Hart</keyname><forenames>Emma</forenames></author><author><keyname>Chung</keyname><forenames>Julianne</forenames></author><author><keyname>Chung</keyname><forenames>Matthias</forenames></author></authors><title>A Paired Autoencoder Framework for Inverse Problems via Bayes Risk   Minimization</title><categories>cs.LG cs.NA math.NA</categories><comments>22 pages, 9 figures</comments><msc-class>65F22, 65F55, 68T07, 68U10</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we describe a new data-driven approach for inverse problems that exploits technologies from machine learning, in particular autoencoder network structures. We consider a paired autoencoder framework, where two autoencoders are used to efficiently represent the input and target spaces separately and optimal mappings are learned between latent spaces, thus enabling forward and inverse surrogate mappings. We focus on interpretations using Bayes risk and empirical Bayes risk minimization, and we provide various theoretical results and connections to existing works on low-rank matrix approximations. Similar to end-to-end approaches, our paired approach creates a surrogate model for forward propagation and regularized inversion. However, our approach outperforms existing approaches in scenarios where training data for unsupervised learning are readily available but training pairs for supervised learning are scarce. Furthermore, we show that cheaply computable evaluation metrics are available through this framework and can be used to predict whether the solution for a new sample should be predicted well. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14637</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14637</id><created>2025-01-24</created><authors><author><keyname>van Elteren</keyname><forenames>Casper</forenames></author><author><keyname>Vasconcelos</keyname><forenames>Vítor V.</forenames></author><author><keyname>Lees</keyname><forenames>Mike H.</forenames></author></authors><title>The Paradox of Intervention: Resilience in Adaptive Multi-Role   Coordination Networks</title><categories>physics.soc-ph cs.SI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Complex adaptive networks exhibit remarkable resilience, driven by the dynamic interplay of structure (interactions) and function (state). While static-network analyses offer valuable insights, understanding how structure and function co-evolve under external interventions is critical for explaining system-level adaptation. Using a unique dataset of clandestine criminal networks, we combine empirical observations with computational modeling to test the impact of various interventions on network adaptation. Our analysis examines how networks with specialized roles adapt and form emergent structures to optimize cost-benefit trade-offs. We find that emergent sparsely connected networks exhibit greater resilience, revealing a security-efficiency trade-off. Notably, interventions can trigger a "criminal opacity amplification" effect, where criminal activity increases despite reduced network visibility. While node isolation fragments networks, it strengthens remaining active ties. In contrast, deactivating nodes (analogous to social reintegration) can unintentionally boost criminal coordination, increasing activity or connectivity. Failed interventions often lead to temporary functional surges before reverting to baseline. Surprisingly, stimulating connectivity destabilizes networks. Effective interventions require precise calibration to node roles, connection types, and external conditions. These findings challenge conventional assumptions about connectivity and intervention efficacy in complex adaptive systems across diverse domains. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14641</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14641</id><created>2025-01-24</created><authors><author><keyname>Wong</keyname><forenames>Hiu-Tung</forenames></author><author><keyname>Lee</keyname><forenames>Darrick</forenames></author><author><keyname>Yan</keyname><forenames>Hong</forenames></author></authors><title>Towards Scalable Topological Regularizers</title><categories>cs.LG math.AT</categories><comments>31 pages, accepted to ICLR 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Latent space matching, which consists of matching distributions of features in latent space, is a crucial component for tasks such as adversarial attacks and defenses, domain adaptation, and generative modelling. Metrics for probability measures, such as Wasserstein and maximum mean discrepancy, are commonly used to quantify the differences between such distributions. However, these are often costly to compute, or do not appropriately take the geometric and topological features of the distributions into consideration. Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds, and has recently been used as a topological regularizer in learning tasks. However, computation costs preclude larger scale computations, and discontinuities in the gradient lead to unstable training behavior such as in adversarial tasks. We propose the use of principal persistence measures, based on computing the persistent homology of a large number of small subsamples, as a topological regularizer. We provide a parallelized GPU implementation of this regularizer, and prove that gradients are continuous for smooth densities. Furthermore, we demonstrate the efficacy of this regularizer on shape matching, image generation, and semi-supervised learning tasks, opening the door towards a scalable regularizer for topological features. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14644</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14644</id><created>2025-01-24</created><authors><author><keyname>Rodio</keyname><forenames>Angelo</forenames></author><author><keyname>Chen</keyname><forenames>Zheng</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Whisper D-SGD: Correlated Noise Across Agents for Differentially Private   Decentralized Learning</title><categories>cs.LG cs.AI cs.CR cs.DC</categories><comments>6 pages, 3 figures, preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralized learning enables distributed agents to train a shared machine learning model through local computation and peer-to-peer communication. Although each agent retains its dataset locally, the communication of local models can still expose private information to adversaries. To mitigate these threats, local differential privacy (LDP) injects independent noise per agent, but it suffers a larger utility gap than central differential privacy (CDP). We introduce Whisper D-SGD, a novel covariance-based approach that generates correlated privacy noise across agents, unifying several state-of-the-art methods as special cases. By leveraging network topology and mixing weights, Whisper D-SGD optimizes the noise covariance to achieve network-wide noise cancellation. Experimental results show that Whisper D-SGD cancels more noise than existing pairwise-correlation schemes, substantially narrowing the CDP-LDP gap and improving model performance under the same privacy guarantees. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14646</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14646</id><created>2025-01-24</created><authors><author><keyname>Liu</keyname><forenames>Yujian</forenames></author><author><keyname>Xu</keyname><forenames>Shidang</forenames></author><author><keyname>Guo</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Dingbin</forenames></author><author><keyname>Wang</keyname><forenames>Zairan</forenames></author><author><keyname>Tan</keyname><forenames>Xianfeng</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoli</forenames></author></authors><title>SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human   Pose and Talking Head Animation</title><categories>cs.CV</categories><comments>11 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Generating talking avatar driven by audio remains a significant challenge. Existing methods typically require high computational costs and often lack sufficient facial detail and realism, making them unsuitable for applications that demand high real-time performance and visual quality. Additionally, while some methods can synchronize lip movement, they still face issues with consistency between facial expressions and upper body movement, particularly during silent periods. In this paper, we introduce SyncAnimation, the first NeRF-based method that achieves audio-driven, stable, and real-time generation of speaking avatar by combining generalized audio-to-pose matching and audio-to-expression synchronization. By integrating AudioPose Syncer and AudioEmotion Syncer, SyncAnimation achieves high-precision poses and expression generation, progressively producing audio-synchronized upper body, head, and lip shapes. Furthermore, the High-Synchronization Human Renderer ensures seamless integration of the head and upper body, and achieves audio-sync lip. The project page can be found at https://syncanimation.github.io </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14648</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14648</id><created>2025-01-24</created><authors><author><keyname>Ajmani</keyname><forenames>Leah Hope</forenames></author><author><keyname>Bhatt</keyname><forenames>Talia</forenames></author><author><keyname>Devito</keyname><forenames>Michael Ann</forenames></author></authors><title>Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering   Participant Knowledge</title><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Justice, epistemology, and marginalization are rich areas of study in HCI. And yet, we repeatedly find platforms and algorithms that push communities further into the margins. In this paper, we propose epistemic autonomy -- one's ability to govern knowledge about themselves -- as a necessary HCI paradigm for working with marginalized communities. We establish epistemic autonomy by applying the transfeminine principle of autonomy to the problem of epistemic injustice. To articulate the harm of violating one's epistemic autonomy, we present six stories from two trans women: (1) a transfem online administrator and (2) a transfem researcher. We then synthesize our definition of epistemic autonomy in research into a research paradigm. Finally, we present two variants of common HCI methods, autoethnography and asynchronous remote communities, that stem from these beliefs. We discuss how CHI is uniquely situated to champion this paradigm and, thereby, the epistemic autonomy of our research participants. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14649</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14649</id><created>2025-01-24</created><authors><author><keyname>Xu</keyname><forenames>Ziyao</forenames></author><author><keyname>Wang</keyname><forenames>Houfeng</forenames></author></authors><title>Investigating the (De)Composition Capabilities of Large Language Models   in Natural-to-Formal Language Conversion</title><categories>cs.CL</categories><comments>Accepted at NAACL 2025 main conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To achieve generalized and robust natural-to-formal language conversion (N2F), large language models (LLMs) need to have strong capabilities of decomposition and composition in N2F when faced with an unfamiliar formal language and be able to cope with compositional gaps and counter-intuitive symbolic names. To investigate whether LLMs have this set of basic capabilities in N2F, we propose the DEDC framework. This framework semi-automatically performs sample and task construction, allowing decoupled evaluation of the set of decomposition and composition capabilities of LLMs in N2F. Based on this framework, we evaluate and analyze the most advanced LLMs, and the main findings include that: (1) the LLMs are deficient in both decomposition and composition; (2) the LLMs show a wide coverage of error types that can be attributed to deficiencies in natural language understanding and the learning and use of symbolic systems; (3) compositional gaps and counter-intuitive symbolic names both affect the decomposition and composition of the LLMs. Our work provides a new perspective for investigating the basic capabilities of decomposition and composition of LLMs in N2F. The detailed analysis of deficiencies and attributions can help subsequent improvements of LLMs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14651</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14651</id><created>2025-01-24</created><authors><author><keyname>Gordon</keyname><forenames>Sanford C.</forenames></author><author><keyname>Samii</keyname><forenames>Cyrus</forenames></author><author><keyname>Su</keyname><forenames>Zhihao</forenames></author></authors><title>Data-NoMAD: A Tool for Boosting Confidence in the Integrity of Social   Science Survey Data</title><categories>cs.CR</categories><comments>18 pages, 2 figures</comments><acm-class>E.1; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To safeguard against data fabrication and enhance trust in quantitative social science, we present Data Non-Manipulation Authentication Digest (Data-NoMAD). Data-NoMAD is a tool that allows researchers to certify, and others to verify, that a dataset has not been inappropriately manipulated between the point of data collection and the point at which a replication archive is made publicly available. Data-NoMAD creates and stores a column hash digest of a raw dataset upon initial download from a survey platform (the current version works with Qualtrics and SurveyCTO), but before it is subject to appropriate manipulations such as anonymity-preserving redactions. Data-NoMAD can later be used to verify the integrity of a publicly archived dataset by identifying columns that have been deleted, added, or altered. Data-NoMAD complements existing efforts at ensuring research integrity and integrates seamlessly with extant replication practices. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14652</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14652</id><created>2025-01-24</created><authors><author><keyname>Zindari</keyname><forenames>Ali</forenames></author><author><keyname>Yazdkhasti</keyname><forenames>Parham</forenames></author><author><keyname>Rodomanov</keyname><forenames>Anton</forenames></author><author><keyname>Chavdarova</keyname><forenames>Tatjana</forenames></author><author><keyname>Stich</keyname><forenames>Sebastian U.</forenames></author></authors><title>Decoupled SGDA for Games with Intermittent Strategy Communication</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on reducing communication overhead in multiplayer games, where frequently exchanging strategies between players is not feasible and players have noisy or outdated strategies of the other players. We introduce Decoupled SGDA, a novel adaptation of Stochastic Gradient Descent Ascent (SGDA). In this approach, players independently update their strategies based on outdated opponent strategies, with periodic synchronization to align strategies. For Strongly-Convex-Strongly-Concave (SCSC) games, we demonstrate that Decoupled SGDA achieves near-optimal communication complexity comparable to the best-known GDA rates. For weakly coupled games where the interaction between players is lower relative to the non-interactive part of the game, Decoupled SGDA significantly reduces communication costs compared to standard SGDA. Our findings extend to multi-player games. To provide insights into the effect of communication frequency and convergence, we extensively study the convergence of Decoupled SGDA for quadratic minimax problems. Lastly, in settings where the noise over the players is imbalanced, Decoupled SGDA significantly outperforms federated minimax methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14653</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14653</id><created>2025-01-24</created><authors><author><keyname>Nguyen</keyname><forenames>Trong-Binh</forenames></author><author><keyname>Nguyen</keyname><forenames>Minh-Duong</forenames></author><author><keyname>Park</keyname><forenames>Jinsun</forenames></author><author><keyname>Pham</keyname><forenames>Quoc-Viet</forenames></author><author><keyname>Hwang</keyname><forenames>Won Joo</forenames></author></authors><title>Federated Domain Generalization with Data-free On-server Gradient   Matching</title><categories>cs.LG cs.AI cs.DC cs.MA</categories><comments>26 pages, 15 figures, ICLR</comments><msc-class>68Q32, 68Q32</msc-class><acm-class>I.4.0; I.2.11</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Domain Generalization (DG) aims to learn from multiple known source domains a model that can generalize well to unknown target domains. One of the key approaches in DG is training an encoder which generates domain-invariant representations. However, this approach is not applicable in Federated Domain Generalization (FDG), where data from various domains are distributed across different clients. In this paper, we introduce a novel approach, dubbed Federated Learning via On-server Matching Gradient (FedOMG), which can \emph{efficiently leverage domain information from distributed domains}. Specifically, we utilize the local gradients as information about the distributed models to find an invariant gradient direction across all domains through gradient inner product maximization. The advantages are two-fold: 1) FedOMG can aggregate the characteristics of distributed models on the centralized server without incurring any additional communication cost, and 2) FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional performance improvements by being seamlessly integrated with them. Extensive experimental evaluations on various settings to demonstrate the robustness of FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome). </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14654</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14654</id><created>2025-01-24</created><authors><author><keyname>Jiang</keyname><forenames>Yixing</forenames></author><author><keyname>Black</keyname><forenames>Kameron C.</forenames></author><author><keyname>Geng</keyname><forenames>Gloria</forenames></author><author><keyname>Park</keyname><forenames>Danny</forenames></author><author><keyname>Ng</keyname><forenames>Andrew Y.</forenames></author><author><keyname>Chen</keyname><forenames>Jonathan H.</forenames></author></authors><title>MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical   Applications</title><categories>cs.LG cs.AI cs.MA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent large language models (LLMs) have demonstrated significant advancements, particularly in their ability to serve as agents thereby surpassing their traditional role as chatbots. These agents can leverage their planning and tool utilization capabilities to address tasks specified at a high level. However, a standardized dataset to benchmark the agent capabilities of LLMs in medical applications is currently lacking, making the evaluation of LLMs on complex tasks in interactive healthcare environments challenging. To address this gap, we introduce MedAgentBench, a broad evaluation suite designed to assess the agent capabilities of large language models within medical records contexts. MedAgentBench encompasses 100 patient-specific clinically-derived tasks from 10 categories written by human physicians, realistic profiles of 100 patients with over 700,000 data elements, a FHIR-compliant interactive environment, and an accompanying codebase. The environment uses the standard APIs and communication infrastructure used in modern EMR systems, so it can be easily migrated into live EMR systems. MedAgentBench presents an unsaturated agent-oriented benchmark that current state-of-the-art LLMs exhibit some ability to succeed at. The best model (GPT-4o) achieves a success rate of 72%. However, there is still substantial space for improvement to give the community a next direction to optimize. Furthermore, there is significant variation in performance across task categories. MedAgentBench establishes this and is publicly available at https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable framework for model developers to track progress and drive continuous improvements in the agent capabilities of large language models within the medical domain. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14658</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14658</id><created>2025-01-24</created><authors><author><keyname>Chudnovsky</keyname><forenames>Maria</forenames></author><author><keyname>Codsi</keyname><forenames>Julien</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Milanič</keyname><forenames>Martin</forenames></author><author><keyname>Sivashankar</keyname><forenames>Varun</forenames></author></authors><title>Tree independence number V. Walls and claws</title><categories>math.CO cs.DM cs.DS</categories><msc-class>05C75 (Primary) 05C40, 05C85 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Given a family $\mathcal{H}$ of graphs, we say that a graph $G$ is $\mathcal{H}$-free if no induced subgraph of $G$ is isomorphic to a member of $\mathcal{H}$. Let $S_{t,t,t}$ be the graph obtained from $K_{1,3}$ by subdividing each edge $t-1$ times, and let $W_{t\times t}$ be the $t$-by-$t$ hexagonal grid. Let $\mathcal{L}_t$ be the family of all graphs $G$ such that $G$ is the line graph of some subdivision of $W_{t \times t}$. We prove that for every positive integer $t$ there exists $c(t)$ such that every $\mathcal{L}_t \cup \{S_{t,t,t}, K_{t,t}\}$-free $n$-vertex graph admits a tree decomposition in which the maximum size of an independent set in each bag is at most $c(t)\log^4n$. This is a variant of a conjecture of Dallard, Krnc, Kwon, Milani\v{c}, Munaro, \v{S}torgel, and Wiederrecht from 2024. This implies that the Maximum Weight Independent Set problem, as well as many other natural algorithmic problems, that are known to be NP-hard in general, can be solved in quasi-polynomial time if the input graph is $\mathcal{L}_t \cup \{S_{t,t,t},K_{t,t}\}$-free. As part of our proof, we show that for every positive integer $t$ there exists an integer $d$ such that every $\mathcal{L}_t \cup \{S_{t,t,t}\}$-free graph admits a balanced separator that is contained in the neighborhood of at most $d$ vertices. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14659</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14659</id><created>2025-01-24</created><authors><author><keyname>Wan</keyname><forenames>Tinglei</forenames></author><author><keyname>Su</keyname><forenames>Tonghua</forenames></author><author><keyname>Wang</keyname><forenames>Zhongjie</forenames></author></authors><title>Towards Unified Structured Light Optimization</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured light (SL) 3D reconstruction captures the precise surface shape of objects, providing high-accuracy 3D data essential for industrial inspection and robotic vision systems. However, current research on optimizing projection patterns in SL 3D reconstruction faces two main limitations: each scene requires separate training of calibration parameters, and optimization is restricted to specific types of SL, which restricts their application range. To tackle these limitations, we present a unified framework for SL optimization, adaptable to diverse lighting conditions, object types, and different types of SL. Our framework quickly determines the optimal projection pattern using only a single projected image. Key contributions include a novel global matching method for projectors, enabling precise projector-camera alignment with just one projected image, and a new projection compensation model with a photometric adjustment module to reduce artifacts from out-of-gamut clipping. Experimental results show our method achieves superior decoding accuracy across various objects, SL patterns, and lighting conditions, significantly outperforming previous methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14660</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14660</id><created>2025-01-24</created><authors><author><keyname>Hernandez</keyname><forenames>Anderson Melchor</forenames></author><author><keyname>Pastorello</keyname><forenames>Davide</forenames></author><author><keyname>De Palma</keyname><forenames>Giacomo</forenames></author></authors><title>Mean-field limit from general mixtures of experts to quantum neural   networks</title><categories>math-ph cs.LG math.MP math.PR</categories><msc-class>81P45, 49Q22, 60F05</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we study the asymptotic behavior of Mixture of Experts (MoE) trained via gradient flow on supervised learning problems. Our main result establishes the propagation of chaos for a MoE as the number of experts diverges. We demonstrate that the corresponding empirical measure of their parameters is close to a probability measure that solves a nonlinear continuity equation, and we provide an explicit convergence rate that depends solely on the number of experts. We apply our results to a MoE generated by a quantum neural network. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14661</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14661</id><created>2025-01-24</created><authors><author><keyname>Zhang</keyname><forenames>Chongzhi</forenames></author><author><keyname>Zheng</keyname><forenames>Junhao</forenames></author><author><keyname>Peng</keyname><forenames>Zhiping</forenames></author><author><keyname>Ma</keyname><forenames>Qianli</forenames></author></authors><title>Neural-Symbolic Message Passing with Dynamic Pruning</title><categories>cs.LG cs.AI</categories><comments>19 pages, 5 figures, 16 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs) is a challenging task. Recently, a line of message-passing-based research has been proposed to solve CQA. However, they perform unsatisfactorily on negative queries and fail to address the noisy messages between variable nodes in the query graph. Moreover, they offer little interpretability and require complex query data and resource-intensive training. In this paper, we propose a Neural-Symbolic Message Passing (NSMP) framework based on pre-trained neural link predictors. By introducing symbolic reasoning and fuzzy logic, NSMP can generalize to arbitrary existential first order logic queries without requiring training while providing interpretable answers. Furthermore, we introduce a dynamic pruning strategy to filter out noisy messages between variable nodes. Experimental results show that NSMP achieves a strong performance. Additionally, through complexity analysis and empirical verification, we demonstrate the superiority of NSMP in inference time over the current state-of-the-art neural-symbolic method. Compared to this approach, NSMP demonstrates faster inference times across all query types on benchmark datasets, with speedup ranging from 2$\times$ to over 150$\times$. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14662</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14662</id><created>2025-01-24</created><authors><author><keyname>Besançon</keyname><forenames>Mathieu</forenames></author></authors><title>Efficient Sparse Flow Decomposition Methods for RNA Multi-Assembly</title><categories>math.OC cs.DM</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decomposing a flow on a Directed Acyclic Graph (DAG) into a weighted sum of a small number of paths is an essential task in operations research and bioinformatics. This problem, referred to as Sparse Flow Decomposition (SFD), has gained significant interest, in particular for its application in RNA transcript multi-assembly, the identification of the multiple transcripts corresponding to a given gene and their relative abundance. Several recent approaches cast SFD variants as integer optimization problems, motivated by the NP-hardness of the formulations they consider. We propose an alternative formulation of SFD as a fitting problem on the conic hull of the flow polytope. By reformulating the problem on the flow polytope for compactness and solving it using specific variants of the Frank-Wolfe algorithm, we obtain a method converging rapidly to the minimizer of the chosen loss function while producing a parsimonious decomposition. Our approach subsumes previous formulations of SFD with exact and inexact flows and can model different priors on the error distributions. Computational experiments show that our method outperforms recent integer optimization approaches in runtime, but is also highly competitive in terms of reconstruction of the underlying transcripts, despite not explicitly minimizing the solution cardinality. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14663</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14663</id><created>2025-01-24</created><authors><author><keyname>Di Guglielmo</keyname><forenames>Giuseppe</forenames></author><author><keyname>Du</keyname><forenames>Botao</forenames></author><author><keyname>Campos</keyname><forenames>Javier</forenames></author><author><keyname>Boltasseva</keyname><forenames>Alexandra</forenames></author><author><keyname>Dixit</keyname><forenames>Akash V.</forenames></author><author><keyname>Fahim</keyname><forenames>Farah</forenames></author><author><keyname>Kudyshev</keyname><forenames>Zhaxylyk</forenames></author><author><keyname>Lopez</keyname><forenames>Santiago</forenames></author><author><keyname>Ma</keyname><forenames>Ruichao</forenames></author><author><keyname>Perdue</keyname><forenames>Gabriel N.</forenames></author><author><keyname>Tran</keyname><forenames>Nhan</forenames></author><author><keyname>Yesilyurt</keyname><forenames>Omer</forenames></author><author><keyname>Bowring</keyname><forenames>Daniel</forenames></author></authors><title>End-to-end workflow for machine learning-based qubit readout with QICK   and hls4ml</title><categories>quant-ph cs.LG</categories><report-no>FERMILAB-PUB-24-0925-ETD-PPD</report-no><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present an end-to-end workflow for superconducting qubit readout that embeds co-designed Neural Networks (NNs) into the Quantum Instrumentation Control Kit (QICK). Capitalizing on the custom firmware and software of the QICK platform, which is built on Xilinx RFSoC FPGAs, we aim to leverage machine learning (ML) to address critical challenges in qubit readout accuracy and scalability. The workflow utilizes the hls4ml package and employs quantization-aware training to translate ML models into hardware-efficient FPGA implementations via user-friendly Python APIs. We experimentally demonstrate the design, optimization, and integration of an ML algorithm for single transmon qubit readout, achieving 96% single-shot fidelity with a latency of 32ns and less than 16% FPGA look-up table resource utilization. Our results offer the community an accessible workflow to advance ML-driven readout and adaptive control in quantum information processing applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14664</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14664</id><created>2025-01-24</created><authors><author><keyname>Lashari</keyname><forenames>Muhammad Hanif</forenames></author><author><keyname>Ahmed</keyname><forenames>Shakil</forenames></author><author><keyname>Batayneh</keyname><forenames>Wafa</forenames></author><author><keyname>Khokhar</keyname><forenames>Ashfaq</forenames></author></authors><title>Predictive Position Estimation for Remote Surgery under Packet Loss   Using the Informer Framework</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and real-time position estimation of the robotic arm on the patient's side is crucial for the success of remote robotic surgery in Tactile Internet environments. This paper proposes a predictive approach using the computationally efficient Transformer-based Informer model for position estimation, combined with a Four-State Hidden Markov Model (4-State HMM) to simulate realistic packet loss scenarios. The method effectively addresses network-induced delays, jitter, and packet loss, ensuring reliable performance in remote robotic surgery. The study evaluates the Informer model on the JIGSAWS dataset, demonstrating its capability to handle sequential data challenges caused by network uncertainties. Key features, including ProbSparse attention and a generative-style decoder, enhance prediction accuracy, computational speed, and memory efficiency. Results indicate that the proposed method achieves over 90 percent accuracy across varying network conditions. Furthermore, the Informer framework outperforms traditional models such as TCN, RNN, and LSTM, highlighting its suitability for real-time remote surgery applications. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14672</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14672</id><created>2025-01-24</created><authors><author><keyname>Floch</keyname><forenames>Kristóf</forenames></author><author><keyname>Péni</keyname><forenames>Tamás</forenames></author><author><keyname>Tóth</keyname><forenames>Roland</forenames></author></authors><title>Gaussian-Process-based Adaptive Tracking Control with Dynamic Active   Learning for Autonomous Ground Vehicles</title><categories>eess.SY cs.RO cs.SY</categories><comments>Submitted to IEEE Transactions on Control Systems Technology</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This article proposes an active-learning-based adaptive trajectory tracking control method for autonomous ground vehicles to compensate for modeling errors and unmodeled dynamics. The nominal vehicle model is decoupled into lateral and longitudinal subsystems, which are augmented with online Gaussian Processes (GPs), using measurement data. The estimated mean functions of the GPs are used to construct a feedback compensator, which, together with an LPV state feedback controller designed for the nominal system, gives the adaptive control structure. To assist exploration of the dynamics, the paper proposes a new, dynamic active learning method to collect the most informative samples to accelerate the training process. To analyze the performance of the overall learning tool-chain provided controller, a novel iterative, counterexample-based algorithm is proposed for calculating the induced L2 gain between the reference trajectory and the tracking error. The analysis can be executed for a set of possible realizations of the to-be-controlled system, giving robust performance certificate of the learning method under variation of the vehicle dynamics. The efficiency of the proposed control approach is shown on a high-fidelity physics simulator and in real experiments using a 1/10 scale F1TENTH electric car. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14673</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14673</id><created>2025-01-24</created><authors><author><keyname>Khayi</keyname><forenames>Nisrine Ait</forenames></author></authors><title>State Space Models for Extractive Summarization in Low Resource   Scenarios</title><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Extractive summarization involves selecting the most relevant sentences from a text. Recently, researchers have focused on advancing methods to improve state-of-the-art results in low-resource settings. Motivated by these advancements, we propose the MPoincareSum method. This method applies the Mamba state space model to generate the semantics of reviews and sentences, which are then concatenated. A Poincare compression is used to select the most meaningful features, followed by the application of a linear layer to predict sentence relevance based on the corresponding review. Finally, we paraphrase the relevant sentences to create the final summary. To evaluate the effectiveness of MPoincareSum, we conducted extensive experiments using the Amazon review dataset. The performance of the method was assessed using ROUGE scores. The experimental results demonstrate that MPoincareSum outperforms several existing approaches in the literature </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14677</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14677</id><created>2025-01-24</created><authors><author><keyname>Yang</keyname><forenames>Peiqing</forenames></author><author><keyname>Zhou</keyname><forenames>Shangchen</forenames></author><author><keyname>Zhao</keyname><forenames>Jixin</forenames></author><author><keyname>Tao</keyname><forenames>Qingyi</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author></authors><title>MatAnyone: Stable Video Matting with Consistent Memory Propagation</title><categories>cs.CV</categories><comments>Project page: https://pq-yang.github.io/projects/MatAnyone</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Auxiliary-free human video matting methods, which rely solely on input frames, often struggle with complex or ambiguous backgrounds. To address this, we propose MatAnyone, a robust framework tailored for target-assigned video matting. Specifically, building on a memory-based paradigm, we introduce a consistent memory propagation module via region-adaptive memory fusion, which adaptively integrates memory from the previous frame. This ensures semantic stability in core regions while preserving fine-grained details along object boundaries. For robust training, we present a larger, high-quality, and diverse dataset for video matting. Additionally, we incorporate a novel training strategy that efficiently leverages large-scale segmentation data, boosting matting stability. With this new network design, dataset, and training strategy, MatAnyone delivers robust and accurate video matting results in diverse real-world scenarios, outperforming existing methods. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14678</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14678</id><created>2025-01-24</created><authors><author><keyname>Lashari</keyname><forenames>Muhammad Hanif</forenames></author><author><keyname>Ahmed</keyname><forenames>Shakil</forenames></author><author><keyname>Batayneh</keyname><forenames>Wafa</forenames></author><author><keyname>Khokhar</keyname><forenames>Ashfaq</forenames></author></authors><title>A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery   Using Informer Model</title><categories>cs.RO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precise and real-time estimation of the robotic arm's position on the patient's side is essential for the success of remote robotic surgery in Tactile Internet (TI) environments. This paper presents a prediction model based on the Transformer-based Informer framework for accurate and efficient position estimation. Additionally, it combines a Four-State Hidden Markov Model (4-State HMM) to simulate realistic packet loss scenarios. The proposed approach addresses challenges such as network delays, jitter, and packet loss to ensure reliable and precise operation in remote surgical applications. The method integrates the optimization problem into the Informer model by embedding constraints such as energy efficiency, smoothness, and robustness into its training process using a differentiable optimization layer. The Informer framework uses features such as ProbSparse attention, attention distilling, and a generative-style decoder to focus on position-critical features while maintaining a low computational complexity of O(L log L). The method is evaluated using the JIGSAWS dataset, achieving a prediction accuracy of over 90 percent under various network scenarios. A comparison with models such as TCN, RNN, and LSTM demonstrates the Informer framework's superior performance in handling position prediction and meeting real-time requirements, making it suitable for Tactile Internet-enabled robotic surgery. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14679</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14679</id><created>2025-01-24</created><authors><author><keyname>He</keyname><forenames>Rongzhao</forenames></author><author><keyname>Zheng</keyname><forenames>Weihao</forenames></author></authors><title>Surface Vision Mamba: Leveraging Bidirectional State Space Model for   Efficient Spherical Manifold Representation</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based methods have demonstrated exceptional performance in modelling long-range dependencies on spherical cortical surfaces, surpassing traditional Geometric Deep Learning (GDL) models. However, their extensive inference time and high memory demands pose challenges for application to large datasets with limited computing resources. Inspired by the state space model in computer vision, we introduce the attention-free Vision Mamba (Vim) to spherical surfaces, presenting a domain-agnostic architecture for analyzing data on spherical manifolds. Our method achieves surface patching by representing spherical data as a sequence of triangular patches derived from a subdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on multiple neurodevelopmental phenotype regression tasks using cortical surface metrics from neonatal brains. Experimental results demonstrate that SiM outperforms both attention- and GDL-based methods, delivering 4.8 times faster inference and achieving 91.7% lower memory consumption compared to the Surface Vision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity analysis further underscores the potential of SiM to identify subtle cognitive developmental patterns. The code is available at https://github.com/Rongzhao-He/surface-vision-mamba. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14680</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14680</id><created>2025-01-24</created><authors><author><keyname>Zhang</keyname><forenames>Jisi</forenames></author><author><keyname>Parada</keyname><forenames>Pablo Peso</forenames></author><author><keyname>Jalal</keyname><forenames>Md Asif</forenames></author><author><keyname>Saravanan</keyname><forenames>Karthikeyan</forenames></author></authors><title>Diffusion based Text-to-Music Generationwith Global and Local Text based   Conditioning</title><categories>eess.AS cs.SD</categories><comments>Accepted at ICASSP 2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Diffusion based Text-To-Music (TTM) models generate music corresponding to text descriptions. Typically UNet based diffusion models condition on text embeddings generated from a pre-trained large language model or from a cross-modality audio-language representation model. This work proposes a diffusion based TTM, in which the UNet is conditioned on both (i) a uni-modal language model (e.g., T5) via cross-attention and (ii) a cross-modal audio-language representation model (e.g., CLAP) via Feature-wise Linear Modulation (FiLM). The diffusion model is trained to exploit both a local text representation from the T5 and a global representation from the CLAP. Furthermore, we propose modifications that extract both global and local representations from the T5 through pooling mechanisms that we call mean pooling and self-attention pooling. This approach mitigates the need for an additional encoder (e.g., CLAP) to extract a global representation, thereby reducing the number of model parameters. Our results show that incorporating the CLAP global embeddings to the T5 local embeddings enhances text adherence (KL=1.47) compared to a baseline model solely relying on the T5 local embeddings (KL=1.54). Alternatively, extracting global text embeddings directly from the T5 local embeddings through the proposed mean pooling approach yields superior generation quality (FAD=1.89) while exhibiting marginally inferior text adherence (KL=1.51) against the model conditioned on both CLAP and T5 text embeddings (FAD=1.94 and KL=1.47). Our proposed solution is not only efficient but also compact in terms of the number of parameters required. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14683</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14683</id><created>2025-01-24</created><authors><author><keyname>Hassani</keyname><forenames>Shabnam</forenames></author><author><keyname>Sabetzadeh</keyname><forenames>Mehrdad</forenames></author><author><keyname>Amyot</keyname><forenames>Daniel</forenames></author></authors><title>An Empirical Study on LLM-based Classification of Requirements-related   Provisions in Food-safety Regulations</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As Industry 4.0 transforms the food industry, the role of software in achieving compliance with food-safety regulations is becoming increasingly critical. Food-safety regulations, like those in many legal domains, have largely been articulated in a technology-independent manner to ensure their longevity and broad applicability. However, this approach leaves a gap between the regulations and the modern systems and software increasingly used to implement them. In this article, we pursue two main goals. First, we conduct a Grounded Theory study of food-safety regulations and develop a conceptual characterization of food-safety concepts that closely relate to systems and software requirements. Second, we examine the effectiveness of two families of large language models (LLMs) -- BERT and GPT -- in automatically classifying legal provisions based on requirements-related food-safety concepts. Our results show that: (a) when fine-tuned, the accuracy differences between the best-performing models in the BERT and GPT families are relatively small. Nevertheless, the most powerful model in our experiments, GPT-4o, still achieves the highest accuracy, with an average Precision of 89% and an average Recall of 87%; (b) few-shot learning with GPT-4o increases Recall to 97% but decreases Precision to 65%, suggesting a trade-off between fine-tuning and few-shot learning; (c) despite our training examples being drawn exclusively from Canadian regulations, LLM-based classification performs consistently well on test provisions from the US, indicating a degree of generalizability across regulatory jurisdictions; and (d) for our classification task, LLMs significantly outperform simpler baselines constructed using long short-term memory (LSTM) networks and automatic keyword extraction. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14685</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14685</id><created>2025-01-24</created><authors><author><keyname>Wu</keyname><forenames>Fuping</forenames></author><author><keyname>Papiez</keyname><forenames>Bartlomiej W.</forenames></author></authors><title>Rethinking Foundation Models for Medical Image Classification through a   Benchmark Study on MedMNIST</title><categories>eess.IV cs.AI cs.CV cs.LG</categories><comments>submitted to MIDL2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Foundation models are widely employed in medical image analysis, due to their high adaptability and generalizability for downstream tasks. With the increasing number of foundation models being released, model selection has become an important issue. In this work, we study the capabilities of foundation models in medical image classification tasks by conducting a benchmark study on the MedMNIST dataset. Specifically, we adopt various foundation models ranging from convolutional to Transformer-based models and implement both end-to-end training and linear probing for all classification tasks. The results demonstrate the significant potential of these pre-trained models when transferred for medical image classification. We further conduct experiments with different image sizes and various sizes of training data. By analyzing all the results, we provide preliminary, yet useful insights and conclusions on this topic. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14687</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14687</id><created>2025-01-24</created><authors><author><keyname>Ketha</keyname><forenames>Simran</forenames></author><author><keyname>Ramaswamy</keyname><forenames>Venkatakrishnan</forenames></author></authors><title>Decoding Generalization from Memorization in Deep Neural Networks</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Overparameterized Deep Neural Networks that generalize well have been key to the dramatic success of Deep Learning in recent years. The reasons for their remarkable ability to generalize are not well understood yet. It has also been known that deep networks possess the ability to memorize training data, as evidenced by perfect or high training accuracies on models trained with corrupted data that have class labels shuffled to varying degrees. Concomitantly, such models are known to generalize poorly, i.e. they suffer from poor test accuracies, due to which it is thought that the act of memorizing substantially degrades the ability to generalize. It has, however, been unclear why the poor generalization that accompanies such memorization, comes about. One possibility is that in the process of training with corrupted data, the layers of the network irretrievably reorganize their representations in a manner that makes generalization difficult. The other possibility is that the network retains significant ability to generalize, but the trained network somehow chooses to readout in a manner that is detrimental to generalization. Here, we provide evidence for the latter possibility by demonstrating, empirically, that such models possess information in their representations for substantially improved generalization, even in the face of memorization. Furthermore, such generalization abilities can be easily decoded from the internals of the trained model, and we build a technique to do so from the outputs of specific layers of the network. We demonstrate results on multiple models trained with a number of standard datasets. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14689</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14689</id><created>2025-01-24</created><authors><author><keyname>Ryabtsev</keyname><forenames>Dmitry</forenames></author><author><keyname>Vasilyev</keyname><forenames>Boris</forenames></author><author><keyname>Shershakov</keyname><forenames>Sergey</forenames></author></authors><title>Approach to Designing CV Systems for Medical Applications: Data,   Architecture and AI</title><categories>cs.CV cs.AI</categories><comments>9 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper introduces an innovative software system for fundus image analysis that deliberately diverges from the conventional screening approach, opting not to predict specific diagnoses. Instead, our methodology mimics the diagnostic process by thoroughly analyzing both normal and pathological features of fundus structures, leaving the ultimate decision-making authority in the hands of healthcare professionals. Our initiative addresses the need for objective clinical analysis and seeks to automate and enhance the clinical workflow of fundus image examination. The system, from its overarching architecture to the modular analysis design powered by artificial intelligence (AI) models, aligns seamlessly with ophthalmological practices. Our unique approach utilizes a combination of state-of-the-art deep learning methods and traditional computer vision algorithms to provide a comprehensive and nuanced analysis of fundus structures. We present a distinctive methodology for designing medical applications, using our system as an illustrative example. Comprehensive verification and validation results demonstrate the efficacy of our approach in revolutionizing fundus image analysis, with potential applications across various medical domains. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14693</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14693</id><created>2025-01-24</created><authors><author><keyname>Deng</keyname><forenames>Naihao</forenames></author><author><keyname>Mihalcea</keyname><forenames>Rada</forenames></author></authors><title>Rethinking Table Instruction Tuning</title><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Recent advances in table understanding have focused on instruction-tuning large language models (LLMs) for table-related tasks. However, existing research has overlooked the impact of hyperparameter choices and lacks a comprehensive evaluation of the out-of-domain table understanding ability and the general capabilities of these table LLMs. In this paper, we evaluate these abilities in existing table LLMs, and reveal significant declines in both out-of-domain table understanding and general capabilities compared to their base models. Through systematic analysis, we show that hyperparameters, such as learning rate, can significantly influence both table-specific and general capabilities. Contrary to the existing table instruction-tuning works, we demonstrate that smaller learning rates and fewer training instances can enhance table understanding while preserving general capabilities. Based on our findings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B Instruct, which achieves performance on par with, or surpassing GPT-3.5 and GPT-4 on table tasks, while maintaining strong out-of-domain generalization and general capabilities. Our findings highlight the potential for reduced data annotation costs and more efficient model development through careful hyperparameter selection. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14694</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14694</id><created>2025-01-24</created><authors><author><keyname>Li</keyname><forenames>Zhong</forenames></author><author><keyname>Wang</keyname><forenames>Yuhang</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Matthijs</forenames></author></authors><title>Towards Automated Self-Supervised Learning for Truly Unsupervised Graph   Anomaly Detection</title><categories>cs.LG cs.AI</categories><comments>Manuscript submitted to Data Mining and Knowledge Discovery in May   2024 for possible publication. This is the revised version submitted in   January 2025</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Self-supervised learning (SSL) is an emerging paradigm that exploits supervisory signals generated from the data itself, and many recent studies have leveraged SSL to conduct graph anomaly detection. However, we empirically found that three important factors can substantially impact detection performance across datasets: 1) the specific SSL strategy employed; 2) the tuning of the strategy's hyperparameters; and 3) the allocation of combination weights when using multiple strategies. Most SSL-based graph anomaly detection methods circumvent these issues by arbitrarily or selectively (i.e., guided by label information) choosing SSL strategies, hyperparameter settings, and combination weights. While an arbitrary choice may lead to subpar performance, using label information in an unsupervised setting is label information leakage and leads to severe overestimation of a method's performance. Leakage has been criticized as "one of the top ten data mining mistakes", yet many recent studies on SSL-based graph anomaly detection have been using label information to select hyperparameters. To mitigate this issue, we propose to use an internal evaluation strategy (with theoretical analysis) to select hyperparameters in SSL for unsupervised anomaly detection. We perform extensive experiments using 10 recent SSL-based graph anomaly detection algorithms on various benchmark datasets, demonstrating both the prior issues with hyperparameter selection and the effectiveness of our proposed strategy. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14696</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14696</id><created>2025-01-24</created><authors><author><keyname>Koudohode</keyname><forenames>Florent</forenames></author><author><keyname>Bekiaris-Liberis</keyname><forenames>Nikolaos</forenames></author></authors><title>Predictor-Feedback Stabilization of Globally Lipschitz Nonlinear Systems   with State and Input Quantization</title><categories>math.OC cs.SY eess.SY</categories><comments>Submitted to Joint SSSC, TDS, COSY 2025. arXiv admin note: text   overlap with arXiv:2404.11194</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We develop a switched nonlinear predictor-feedback control law to achieve global asymptotic stabilization for nonlinear systems with arbitrarily long input delay, under state quantization. The proposed design generalizes the nonlinear predictor-feedback framework by incorporating quantized measurements of both the plant and actuator states into the predictor state formulation. Due to the mismatch between the (inapplicable) exact predictor state and the predictor state constructed in the presence of state quantization, a global stabilization result is possible under a global Lipschitzness assumption on the vector field, as well as under the assumption of existence of a globally Lipschitz, nominal feedback law that achieves global exponential stability of the delay and quantization-free system. To address the constraints imposed by quantization, a dynamic switching strategy is constructed, adjusting the quantizer's tunable parameter in a piecewise constant manner-initially increasing the quantization range, to capture potentially large system states and subsequently refining the precision to reduce quantization error. The global asymptotic stability of the closed-loop system is established through solutions estimates derived using backstepping transformations, combined with small-gain and input-to-state stability arguments. We also extend our approach to the case of input quantization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14699</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14699</id><created>2025-01-24</created><authors><author><keyname>Fuchi</keyname><forenames>Kazuko W.</forenames></author><author><keyname>Wolf</keyname><forenames>Eric M.</forenames></author><author><keyname>Schrock</keyname><forenames>Christopher R.</forenames></author><author><keyname>Beran</keyname><forenames>Philip S.</forenames></author></authors><title>Acceleration of RANS Solver Convergence via Initialization with Wake   Extension Models</title><categories>physics.flu-dyn cs.NA math.NA physics.comp-ph</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Use of appropriate initialization to warm-start Reynolds-averaged Navier-Stokes (RANS) simulations of turbulent flow can facilitate convergence and lead to efficient use of computational resources. In this work, a method to model downstream wake development in external turbulent flow is proposed and used for RANS solver convergence acceleration. To balance the model accuracy and cost, the proposed method divides the analysis domain into three regions: near-body, wake and off-body. An approach based on a convolutional neural network is introduced as an efficient method to predict the downstream wake development. The model training only requires data from a single simulation, and its use is demonstrated to be effective in accelerating the RANS simulation when combined with an accurate flow prediction in the near-body region. The simulation using the proposed method took 26.3x fewer iterations, achieving 16.4x speedup in wall-clock time, compared to a baseline run using freestream initialization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14700</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14700</id><created>2025-01-24</created><authors><author><keyname>Sandoval</keyname><forenames>Ilya Orson</forenames></author><author><keyname>Thompson</keyname><forenames>Isaac Symes</forenames></author><author><keyname>Mavroudis</keyname><forenames>Vasilios</forenames></author><author><keyname>Hicks</keyname><forenames>Chris</forenames></author></authors><title>An Attentive Graph Agent for Topology-Adaptive Cyber Defence</title><categories>cs.LG cs.AI cs.CR cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As cyber threats grow increasingly sophisticated, reinforcement learning is emerging as a promising technique to create intelligent, self-improving defensive systems. However, most existing autonomous defensive agents have overlooked the inherent graph structure of computer networks subject to cyber attacks, potentially missing critical information. To address this gap, we developed a custom version of the Cyber Operations Research Gym (CybORG) environment that encodes the observable network state as a directed graph, utilizing realistic and interpretable low-level features. %, like number of open ports and unexpected detected connections. We leverage a Graph Attention Network (GAT) architecture to process node, edge, and global features, and modify its output to be compatible with policy gradient methods in reinforcement learning. GAT policies offer several advantages over standard approaches based on simplistic flattened state observations. They can handle the changes in network topology that occur at runtime when dynamic connections between hosts appear. Policies can be deployed to networks that differ in size to the ones seen during training, enabling a degree of generalisation inaccessible with alternative approaches. Furthermore, the graph neural network policies outputs are explainable in terms of tangible network properties, providing enhanced interpretability of defensive actions. We verify that our low-level graph observations are meaningful enough to train GAT defensive policies that are able to adapt to changing topologies. We evaluate how our trained policies perform when deployed on networks of varying sizes with the same subnetwork structure, comparing them against policies specifically trained for each network configuration. Our study contributes to the development of robust cyber defence systems that can better adapt to real-world network security challenges. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14701</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14701</id><created>2025-01-24</created><authors><author><keyname>Torri</keyname><forenames>Vittorio</forenames></author><author><keyname>Bottelli</keyname><forenames>Annamaria</forenames></author><author><keyname>Ercolanoni</keyname><forenames>Michele</forenames></author><author><keyname>Leoni</keyname><forenames>Olivia</forenames></author><author><keyname>Ieva</keyname><forenames>Francesca</forenames></author></authors><title>NLP-based assessment of prescription appropriateness from Italian   referrals</title><categories>cs.CL cs.LG</categories><msc-class>68T50</msc-class><acm-class>I.2.7; J.1; J.3</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Objective: This study proposes a Natural Language Processing pipeline to evaluate prescription appropriateness in Italian referrals, where reasons for prescriptions are recorded only as free text, complicating automated comparisons with guidelines. The pipeline aims to derive, for the first time, a comprehensive summary of the reasons behind these referrals and a quantification of their appropriateness. While demonstrated in a specific case study, the approach is designed to generalize to other types of examinations.   Methods: Leveraging embeddings from a transformer-based model, the proposed approach clusters referral texts, maps clusters to labels, and aligns these labels with existing guidelines. We present a case study on a dataset of 496,971 referrals, consisting of all referrals for venous echocolordopplers of the lower limbs between 2019 and 2021 in the Lombardy Region. A sample of 1,000 referrals was manually annotated to validate the results.   Results: The pipeline exhibited high performance for referrals' reasons (Prec=92.43%, Rec=83.28%) and excellent results for referrals' appropriateness (Prec=93.58%, Rec=91.52%) on the annotated subset. Analysis of the entire dataset identified clusters matching guideline-defined reasons - both appropriate and inappropriate - as well as clusters not addressed in the guidelines. Overall, 34.32% of referrals were marked as appropriate, 34.07% inappropriate, 14.37% likely inappropriate, and 17.24% could not be mapped to guidelines.   Conclusions: The proposed pipeline effectively assessed prescription appropriateness across a large dataset, serving as a valuable tool for health authorities. Findings have informed the Lombardy Region's efforts to strengthen recommendations and reduce the burden of inappropriate referrals. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14702</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14702</id><created>2025-01-24</created><authors><author><keyname>Brun</keyname><forenames>Matthew Alan Le</forenames></author><author><keyname>Fowler</keyname><forenames>Simon</forenames></author><author><keyname>Dardha</keyname><forenames>Ornela</forenames></author></authors><title>Multiparty Session Types with a Bang!</title><categories>cs.PL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Replication is an alternative construct to recursion for describing infinite behaviours in the pi-calculus. In this paper we explore the implications of including type-level replication in Multiparty Session Types (MPST), a behavioural type theory for message-passing programs. We introduce MPST!, a session-typed multiparty process calculus with replication and first-class roles. We show that replication is not an equivalent alternative to recursion in MPST, and that using both replication and recursion in one type system in fact allows us to express both context-free protocols and protocols that support mutual exclusion and races. We demonstrate the expressiveness of MPST! on examples including binary tree serialisation, dining philosophers, and a model of an auction, and explore the implications of replication on the decidability of typechecking. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14704</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14704</id><created>2025-01-24</created><authors><author><keyname>Agnelli</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Moura</keyname><forenames>Fernando S.</forenames></author><author><keyname>Rautio</keyname><forenames>Siiri</forenames></author><author><keyname>Alsaker</keyname><forenames>Melody</forenames></author><author><keyname>Murthy</keyname><forenames>Rashmi</forenames></author><author><keyname>Lassas</keyname><forenames>Matti</forenames></author><author><keyname>Siltanen</keyname><forenames>Samuli</forenames></author></authors><title>Stroke classification using Virtual Hybrid Edge Detection from in silico   electrical impedance tomography data</title><categories>math.AP cs.CV cs.NA math.NA</categories><comments>21 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Electrical impedance tomography (EIT) is a non-invasive imaging method for recovering the internal conductivity of a physical body from electric boundary measurements. EIT combined with machine learning has shown promise for the classification of strokes. However, most previous works have used raw EIT voltage data as network inputs. We build upon a recent development which suggested the use of special noise-robust Virtual Hybrid Edge Detection (VHED) functions as network inputs, although that work used only highly simplified and mathematically ideal models. In this work we strengthen the case for the use of EIT, and VHED functions especially, for stroke classification. We design models with high detail and mathematical realism to test the use of VHED functions as inputs. Virtual patients are created using a physically detailed 2D head model which includes features known to create challenges in real-world imaging scenarios. Conductivity values are drawn from statistically realistic distributions, and phantoms are afflicted with either hemorrhagic or ischemic strokes of various shapes and sizes. Simulated noisy EIT electrode data, generated using the realistic Complete Electrode Model (CEM) as opposed to the mathematically ideal continuum model, is processed to obtain VHED functions. We compare the use of VHED functions as inputs against the alternative paradigm of using raw EIT voltages. Our results show that (i) stroke classification can be performed with high accuracy using 2D EIT data from physically detailed and mathematically realistic models, and (ii) in the presence of noise, VHED functions outperform raw data as network inputs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14705</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14705</id><created>2025-01-24</created><authors><author><keyname>DiCicco</keyname><forenames>Mason</forenames></author><author><keyname>Worden</keyname><forenames>Eamon</forenames></author><author><keyname>Olsen</keyname><forenames>Conner</forenames></author><author><keyname>Gangaram</keyname><forenames>Nikhil</forenames></author><author><keyname>Reichman</keyname><forenames>Daniel</forenames></author><author><keyname>Heffernan</keyname><forenames>Neil</forenames></author></authors><title>The Karp Dataset</title><categories>cs.LG cs.CL</categories><comments>Accepted to the 4th workshop on mathematical reasoning and AI at   NeurIPS 2024</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Understanding the mathematical reasoning capabilities of Large Language Models (LLMs) is a central topic in the study of artificial intelligence. This new domain necessitates the creation of datasets of reasoning tasks for both training and benchmarking the performance of LLMs. To this end, we introduce the Karp dataset: The first dataset composed of detailed proofs of NP-completeness reductions. The reductions vary in difficulty, ranging from simple exercises of undergraduate courses to more challenging reductions from academic papers. We compare the performance of state-of-the-art models on this task and demonstrate the effect of fine-tuning with the Karp dataset on reasoning capacity. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14708</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14708</id><created>2025-01-24</created><authors><author><keyname>Favaro</keyname><forenames>Pietro</forenames></author><author><keyname>Toubeau</keyname><forenames>Jean-François</forenames></author><author><keyname>Vallée</keyname><forenames>François</forenames></author><author><keyname>Dvorkin</keyname><forenames>Yury</forenames></author></authors><title>Decision-Focused Learning for Complex System Identification: HVAC   Management System Application</title><categories>eess.SY cs.LG cs.SY</categories><comments>12 pages, 9 figures, submitted to ACM e-energy 2025</comments><acm-class>J.2; I.6.3</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  As opposed to conventional training methods tailored to minimize a given statistical metric or task-agnostic loss (e.g., mean squared error), Decision-Focused Learning (DFL) trains machine learning models for optimal performance in downstream decision-making tools. We argue that DFL can be leveraged to learn the parameters of system dynamics, expressed as constraint of the convex optimization control policy, while the system control signal is being optimized, thus creating an end-to-end learning framework. This is particularly relevant for systems in which behavior changes once the control policy is applied, hence rendering historical data less applicable. The proposed approach can perform system identification - i.e., determine appropriate parameters for the system analytical model - and control simultaneously to ensure that the model's accuracy is focused on areas most relevant to control. Furthermore, because black-box systems are non-differentiable, we design a loss function that requires solely to measure the system response. We propose pre-training on historical data and constraint relaxation to stabilize the DFL and deal with potential infeasibilities in learning. We demonstrate the usefulness of the method on a building Heating, Ventilation, and Air Conditioning day-ahead management system for a realistic 15-zone building located in Denver, US. The results show that the conventional RC building model, with the parameters obtained from historical data using supervised learning, underestimates HVAC electrical power consumption. For our case study, the ex-post cost is on average six times higher than the expected one. Meanwhile, the same RC model with parameters obtained via DFL underestimates the ex-post cost only by 3%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14709</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14709</id><created>2025-01-24</created><authors><author><keyname>Ahmad</keyname><forenames>Zaheer</forenames></author><author><keyname>Shabeer</keyname><forenames>Junaid</forenames></author><author><keyname>Saleem</keyname><forenames>Usman</forenames></author><author><keyname>Qadeer</keyname><forenames>Tahir</forenames></author><author><keyname>Sami</keyname><forenames>Abdul</forenames></author><author><keyname>Khalidi</keyname><forenames>Zahira El</forenames></author><author><keyname>Mehmood</keyname><forenames>Saad</forenames></author></authors><title>Enhanced Confocal Laser Scanning Microscopy with Adaptive Physics   Informed Deep Autoencoders</title><categories>cond-mat.mtrl-sci cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a physics-informed deep learning framework to address common limitations in Confocal Laser Scanning Microscopy (CLSM), such as diffraction limited resolution, noise, and undersampling due to low laser power conditions. The optical system's point spread function (PSF) and common CLSM image degradation mechanisms namely photon shot noise, dark current noise, motion blur, speckle noise, and undersampling were modeled and were directly included into model architecture. The model reconstructs high fidelity images from heavily noisy inputs by using convolutional and transposed convolutional layers. Following the advances in compressed sensing, our approach significantly reduces data acquisition requirements without compromising image resolution. The proposed method was extensively evaluated on simulated CLSM images of diverse structures, including lipid droplets, neuronal networks, and fibrillar systems. Comparisons with traditional deconvolution algorithms such as Richardson-Lucy (RL), non-negative least squares (NNLS), and other methods like Total Variation (TV) regularization, Wiener filtering, and Wavelet denoising demonstrate the superiority of the network in restoring fine structural details with high fidelity. Assessment metrics like Structural Similarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR), underlines that the AdaptivePhysicsAutoencoder achieved robust image enhancement across diverse CLSM conditions, helping faster acquisition, reduced photodamage, and reliable performance in low light and sparse sampling scenarios holding promise for applications in live cell imaging, dynamic biological studies, and high throughput material characterization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14710</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14710</id><created>2025-01-24</created><authors><author><keyname>Leininger</keyname><forenames>Charlotte</forenames></author><author><keyname>Rittel</keyname><forenames>Simon</forenames></author><author><keyname>Bothmann</keyname><forenames>Ludwig</forenames></author></authors><title>Overcoming Fairness Trade-offs via Pre-processing: A Causal Perspective</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Training machine learning models for fair decisions faces two key challenges: The \emph{fairness-accuracy trade-off} results from enforcing fairness which weakens its predictive performance in contrast to an unconstrained model. The incompatibility of different fairness metrics poses another trade-off -- also known as the \emph{impossibility theorem}. Recent work identifies the bias within the observed data as a possible root cause and shows that fairness and predictive performance are in fact in accord when predictive performance is measured on unbiased data. We offer a causal explanation for these findings using the framework of the FiND (fictitious and normatively desired) world, a "fair" world, where protected attributes have no causal effects on the target variable. We show theoretically that (i) classical fairness metrics deemed to be incompatible are naturally satisfied in the FiND world, while (ii) fairness aligns with high predictive performance. We extend our analysis by suggesting how one can benefit from these theoretical insights in practice, using causal pre-processing methods that approximate the FiND world. Additionally, we propose a method for evaluating the approximation of the FiND world via pre-processing in practical use cases where we do not have access to the FiND world. In simulations and empirical studies, we demonstrate that these pre-processing methods are successful in approximating the FiND world and resolve both trade-offs. Our results provide actionable solutions for practitioners to achieve fairness and high predictive performance simultaneously. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14713</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14713</id><created>2025-01-24</created><authors><author><keyname>Smith</keyname><forenames>James Seale</forenames></author><author><keyname>Lin</keyname><forenames>Chi-Heng</forenames></author><author><keyname>Tuli</keyname><forenames>Shikhar</forenames></author><author><keyname>Jeelani</keyname><forenames>Haris</forenames></author><author><keyname>Gao</keyname><forenames>Shangqian</forenames></author><author><keyname>Shen</keyname><forenames>Yilin</forenames></author><author><keyname>Jin</keyname><forenames>Hongxia</forenames></author><author><keyname>Hsu</keyname><forenames>Yen-Chang</forenames></author></authors><title>FlexiGPT: Pruning and Extending Large Language Models with Low-Rank   Weight Sharing</title><categories>cs.CL cs.LG</categories><comments>Accepted to NAACL 2025 - Main Conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The rapid proliferation of large language models (LLMs) in natural language processing (NLP) has created a critical need for techniques that enable efficient deployment on memory-constrained devices without compromising performance. We present a method to prune LLMs that selectively prunes model blocks based on an importance score and replaces them with a low-parameter replacement strategy. Specifically, we propose a principled metric to replace each pruned block using a weight-sharing mechanism that leverages unpruned counterparts from the model and block-specific low-rank adapters. Furthermore, we facilitate the learning of these replacement blocks with output feature normalization and an adapter initialization scheme built on low-rank SVD reconstructions. Empirical evaluations demonstrate substantial performance gains over existing methods, achieving state-of-the-art performance on 5/6 benchmarks for a compression rate of 30% and 6/6 benchmarks for a compression rate of 40%. We also demonstrate that our approach can extend smaller models, boosting performance on 6/6 benchmarks using only ~0.3% tokens of extended training with minimal additional parameter costs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14715</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14715</id><created>2025-01-24</created><authors><author><keyname>Bansal</keyname><forenames>Aparna</forenames></author><author><keyname>Barnafi</keyname><forenames>Nicolás</forenames></author><author><keyname>Araya</keyname><forenames>Rodolfo</forenames></author><author><keyname>Pandey</keyname><forenames>Dwijendra Narain</forenames></author></authors><title>Equal order stabilized finite elements with Nitsche for stationary   Navier-Stokes problem with slip boundary conditions : a priori and a   posteriori error analysis</title><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we extend the equal-order stabilized scheme discussed in [Franca et al., Comput. Methods Appl. Mech. Engrg. 99 (1992) 209-233] to accommodate slip (i.e., Navier) boundary conditions for the stationary Navier-Stokes equations. Our analysis presents a robust formulation for implementing slip boundary conditions using Nitsche's method on arbitrarily complex boundaries. The well-posedness of the discrete problem is established under mild assumptions together with optimal convergence rates for the approximation error. Furthermore, we establish the efficiency and reliability of residual-based a posteriori error estimators for the stationary discrete problem. Several well-known numerical tests validate our theoretical findings. The proposed method fits naturally within the framework of finite element implementation, offering both accuracy and enhanced flexibility in the selection of finite element pairs. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14717</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14717</id><created>2025-01-24</created><authors><author><keyname>Deng</keyname><forenames>Naihao</forenames></author><author><keyname>Zhang</keyname><forenames>Sheng</forenames></author><author><keyname>Zhu</keyname><forenames>Henghui</forenames></author><author><keyname>Chang</keyname><forenames>Shuaichen</forenames></author><author><keyname>Zhang</keyname><forenames>Jiani</forenames></author><author><keyname>Li</keyname><forenames>Alexander Hanbo</forenames></author><author><keyname>Hang</keyname><forenames>Chung-Wei</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hideo</forenames></author><author><keyname>Hu</keyname><forenames>Yiqun</forenames></author><author><keyname>Ng</keyname><forenames>Patrick</forenames></author></authors><title>Towards Better Understanding Table Instruction Tuning: Decoupling the   Effects from Data versus Models</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent advances in natural language processing have leveraged instruction tuning to enhance Large Language Models (LLMs) for table-related tasks. However, previous works train different base models with different training data, lacking an apples-to-apples comparison across the result table LLMs. To address this, we fine-tune base models from the Mistral, OLMo, and Phi families on existing public training datasets. Our replication achieves performance on par with or surpassing existing table LLMs, establishing new state-of-the-art performance on Hitab, a table question-answering dataset. More importantly, through systematic out-of-domain evaluation, we decouple the contributions of training data and the base model, providing insight into their individual impacts. In addition, we assess the effects of table-specific instruction tuning on general-purpose benchmarks, revealing trade-offs between specialization and generalization. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14719</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14719</id><created>2025-01-24</created><authors><author><keyname>Schlicht</keyname><forenames>Ipek Baris</forenames></author><author><keyname>Zhao</keyname><forenames>Zhixue</forenames></author><author><keyname>Sayin</keyname><forenames>Burcu</forenames></author><author><keyname>Flek</keyname><forenames>Lucie</forenames></author><author><keyname>Rosso</keyname><forenames>Paolo</forenames></author></authors><title>Do LLMs Provide Consistent Answers to Health-Related Questions across   Languages?</title><categories>cs.CL cs.AI cs.HC cs.IR</categories><comments>9 pages. Short paper appeared at 47th European Conference on   Information Retrieval (ECIR 2025)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Equitable access to reliable health information is vital for public health, but the quality of online health resources varies by language, raising concerns about inconsistencies in Large Language Models (LLMs) for healthcare. In this study, we examine the consistency of responses provided by LLMs to health-related questions across English, German, Turkish, and Chinese. We largely expand the HealthFC dataset by categorizing health-related questions by disease type and broadening its multilingual scope with Turkish and Chinese translations. We reveal significant inconsistencies in responses that could spread healthcare misinformation. Our main contributions are 1) a multilingual health-related inquiry dataset with meta-information on disease categories, and 2) a novel prompt-based evaluation workflow that enables sub-dimensional comparisons between two languages through parsing. Our findings highlight key challenges in deploying LLM-based tools in multilingual contexts and emphasize the need for improved cross-lingual alignment to ensure accurate and equitable healthcare information. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14720</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14720</id><created>2025-01-24</created><authors><author><keyname>Blizard</keyname><forenames>Audrey</forenames></author><author><keyname>Stockar</keyname><forenames>Stephanie</forenames></author></authors><title>Communication-Based Distributed Control of Large-Scale District Heating   Networks</title><categories>eess.SY cs.SY</categories><comments>Submitted to ECC 2025</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a non-cooperative distributed model predictive controller for the control of large-scale District Heating Networks. To enable the design of this controller a novel information passing scheme and feasibility restoration method are created, allowing the local controllers to achieve a global consensus while minimizing a local cost function. The effectiveness of this controller is demonstrated on an 18-user District Heating Network decomposed into six subsystems. The results show that the developed control scheme effectively uses flexibility to manage the buildings' heat demands reducing the total losses by 14% and the return temperature by 37%. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14721</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14721</id><created>2025-01-24</created><authors><author><keyname>Church</keyname><forenames>Kenneth</forenames></author></authors><title>Comparable Corpora: Opportunities for New Research Directions</title><categories>cs.CL</categories><comments>Keynote in https://comparable.lisn.upsaclay.fr/bucc2025/, workshop   associated with Coling-2025</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Most conference papers present new results, but this paper will focus more on opportunities for the audience to make their own contributions. This paper is intended to challenge the community to think more broadly about what we can do with comparable corpora. We will start with a review of the history, and then suggest new directions for future research. This was a keynote at BUCC-2025, a workshop associated with Coling-2025. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14723</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14723</id><created>2025-01-24</created><authors><author><keyname>Ehrlich</keyname><forenames>Ryan</forenames></author><author><keyname>Brown</keyname><forenames>Bradley</forenames></author><author><keyname>Juravsky</keyname><forenames>Jordan</forenames></author><author><keyname>Clark</keyname><forenames>Ronald</forenames></author><author><keyname>Ré</keyname><forenames>Christopher</forenames></author><author><keyname>Mirhoseini</keyname><forenames>Azalia</forenames></author></authors><title>CodeMonkeys: Scaling Test-Time Compute for Software Engineering</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scaling test-time compute is a promising axis for improving LLM capabilities. However, test-time compute can be scaled in a variety of ways, and effectively combining different approaches remains an active area of research. Here, we explore this problem in the context of solving real-world GitHub issues from the SWE-bench dataset. Our system, named CodeMonkeys, allows models to iteratively edit a codebase by jointly generating and running a testing script alongside their draft edit. We sample many of these multi-turn trajectories for every issue to generate a collection of candidate edits. This approach lets us scale "serial" test-time compute by increasing the number of iterations per trajectory and "parallel" test-time compute by increasing the number of trajectories per problem. With parallel scaling, we can amortize up-front costs across multiple downstream samples, allowing us to identify relevant codebase context using the simple method of letting an LLM read every file. In order to select between candidate edits, we combine voting using model-generated tests with a final multi-turn trajectory dedicated to selection. Overall, CodeMonkeys resolves 57.4% of issues from SWE-bench Verified using a budget of approximately 2300 USD. Our selection method can also be used to combine candidates from different sources. Selecting over an ensemble of edits from existing top SWE-bench Verified submissions obtains a score of 66.2% and outperforms the best member of the ensemble on its own. We fully release our code and data at https://scalingintelligence.stanford.edu/pubs/codemonkeys. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14724</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14724</id><created>2025-01-24</created><authors><author><keyname>Terjék</keyname><forenames>Dávid</forenames></author><author><keyname>González-Sánchez</keyname><forenames>Diego</forenames></author></authors><title>MLPs at the EOC: Concentration of the NTK</title><categories>cs.LG stat.ML</categories><comments>36 pages, 1 figure</comments><msc-class>68T07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the concentration of the Neural Tangent Kernel (NTK) $K_\theta : \mathbb{R}^{m_0} \times \mathbb{R}^{m_0} \to \mathbb{R}^{m_l \times m_l}$ of $l$-layer Multilayer Perceptrons (MLPs) $N : \mathbb{R}^{m_0} \times \Theta \to \mathbb{R}^{m_l}$ equipped with activation functions $\phi(s) = a s + b \vert s \vert$ for some $a,b \in \mathbb{R}$ with the parameter $\theta \in \Theta$ being initialized at the Edge Of Chaos (EOC). Without relying on the gradient independence assumption that has only been shown to hold asymptotically in the infinitely wide limit, we prove that an approximate version of gradient independence holds at finite width. Showing that the NTK entries $K_\theta(x_{i_1},x_{i_2})$ for $i_1,i_2 \in [1:n]$ over a dataset $\{x_1,\cdots,x_n\} \subset \mathbb{R}^{m_0}$ concentrate simultaneously via maximal inequalities, we prove that the NTK matrix $K(\theta) = [\frac{1}{n} K_\theta(x_{i_1},x_{i_2}) : i_1,i_2 \in [1:n]] \in \mathbb{R}^{nm_l \times nm_l}$ concentrates around its infinitely wide limit $\overset{\scriptscriptstyle\infty}{K} \in \mathbb{R}^{nm_l \times nm_l}$ without the need for linear overparameterization. Our results imply that in order to accurately approximate the limit, hidden layer widths have to grow quadratically as $m_k = k^2 m$ for some $m \in \mathbb{N}+1$ for sufficient concentration. For such MLPs, we obtain the concentration bound $\mathbb{P}( \Vert K(\theta) - \overset{\scriptscriptstyle\infty}{K} \Vert \leq O((\Delta_\phi^{-2} + m_l^{\frac{1}{2}} l) \kappa_\phi^2 m^{-\frac{1}{2}})) \geq 1-O(m^{-1})$ modulo logarithmic terms, where we denoted $\Delta_\phi = \frac{b^2}{a^2+b^2}$ and $\kappa_\phi = \frac{\vert a \vert + \vert b \vert}{\sqrt{a^2 + b^2}}$. This reveals in particular that the absolute value ($\Delta_\phi=1$, $\kappa_\phi=1$) beats the ReLU ($\Delta_\phi=\frac{1}{2}$, $\kappa_\phi=\sqrt{2}$) in terms of the concentration of the NTK. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14725</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14725</id><created>2025-01-24</created><authors><author><keyname>Drabik</keyname><forenames>Karolina</forenames></author><author><keyname>Dürr</keyname><forenames>Anita</forenames></author><author><keyname>Frei</keyname><forenames>Fabian</forenames></author><author><keyname>Mazowiecki</keyname><forenames>Filip</forenames></author><author><keyname>Węgrzycki</keyname><forenames>Karol</forenames></author></authors><title>Fined-Grained Complexity of Ambiguity Problems on Automata and Directed   Graphs</title><categories>cs.FL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Two fundamental classes of finite automata are deterministic and nondeterministic ones (DFAs and NFAs). Natural intermediate classes arise from bounds on an NFA's allowed ambiguity, i.e. number of accepting runs per word: unambiguous, finitely ambiguous, and polynomially ambiguous finite automata. It is known that deciding whether a given NFA is unambiguous and whether it is polynomially ambiguous is possible in quadratic time, and deciding finite ambiguity is possible in cubic time. We provide matching lower bounds showing these running times to be optimal, assuming popular fine-grained complexity hypotheses.   We improve the upper bounds for unary automata, which are essentially directed graphs with a source and a target. In this view, unambiguity asks whether all walks from the source to the target have different lengths. The running time analysis of our algorithm reduces to bounding the entry-wise 1-norm of a GCD matrix, yielding a near-linear upper bound. For finite and polynomial ambiguity, we provide simple linear-time algorithms in the unary case.   Finally, we study the twins property for weighted automata over the tropical semiring, which characterises the determinisability of unambiguous weighted automata. It occurs naturally in our context as deciding the twins property is an intermediate step in determinisability algorithms for weighted automata with bounded ambiguity. We show that Allauzen and Mohri's quadratic-time algorithm checking the twins property is optimal up to the same fine-grained hypotheses as for unambiguity. For unary automata, we show that the problem can be rephrased to whether all cycles in a weighted directed graph have the same average weight and give a linear-time algorithm. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14726</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14726</id><created>2025-01-24</created><authors><author><keyname>Wang</keyname><forenames>Shaofei</forenames></author><author><keyname>Simon</keyname><forenames>Tomas</forenames></author><author><keyname>Santesteban</keyname><forenames>Igor</forenames></author><author><keyname>Bagautdinov</keyname><forenames>Timur</forenames></author><author><keyname>Li</keyname><forenames>Junxuan</forenames></author><author><keyname>Agrawal</keyname><forenames>Vasu</forenames></author><author><keyname>Prada</keyname><forenames>Fabian</forenames></author><author><keyname>Yu</keyname><forenames>Shoou-I</forenames></author><author><keyname>Nalbone</keyname><forenames>Pace</forenames></author><author><keyname>Gramlich</keyname><forenames>Matt</forenames></author><author><keyname>Lubachersky</keyname><forenames>Roman</forenames></author><author><keyname>Wu</keyname><forenames>Chenglei</forenames></author><author><keyname>Romero</keyname><forenames>Javier</forenames></author><author><keyname>Saragih</keyname><forenames>Jason</forenames></author><author><keyname>Zollhoefer</keyname><forenames>Michael</forenames></author><author><keyname>Geiger</keyname><forenames>Andreas</forenames></author><author><keyname>Tang</keyname><forenames>Siyu</forenames></author><author><keyname>Saito</keyname><forenames>Shunsuke</forenames></author></authors><title>Relightable Full-Body Gaussian Codec Avatars</title><categories>cs.CV cs.GR</categories><comments>14 pages, 9 figures. Project page:   https://neuralbodies.github.io/RFGCA</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose Relightable Full-Body Gaussian Codec Avatars, a new approach for modeling relightable full-body avatars with fine-grained details including face and hands. The unique challenge for relighting full-body avatars lies in the large deformations caused by body articulation and the resulting impact on appearance caused by light transport. Changes in body pose can dramatically change the orientation of body surfaces with respect to lights, resulting in both local appearance changes due to changes in local light transport functions, as well as non-local changes due to occlusion between body parts. To address this, we decompose the light transport into local and non-local effects. Local appearance changes are modeled using learnable zonal harmonics for diffuse radiance transfer. Unlike spherical harmonics, zonal harmonics are highly efficient to rotate under articulation. This allows us to learn diffuse radiance transfer in a local coordinate frame, which disentangles the local radiance transfer from the articulation of the body. To account for non-local appearance changes, we introduce a shadow network that predicts shadows given precomputed incoming irradiance on a base mesh. This facilitates the learning of non-local shadowing between the body parts. Finally, we use a deferred shading approach to model specular radiance transfer and better capture reflections and highlights such as eye glints. We demonstrate that our approach successfully models both the local and non-local light transport required for relightable full-body avatars, with a superior generalization ability under novel illumination conditions and unseen poses. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14728</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14728</id><created>2025-01-24</created><authors><author><keyname>Yan</keyname><forenames>Zehong</forenames></author><author><keyname>Qi</keyname><forenames>Peng</forenames></author><author><keyname>Hsu</keyname><forenames>Wynne</forenames></author><author><keyname>Lee</keyname><forenames>Mong Li</forenames></author></authors><title>Mitigating GenAI-powered Evidence Pollution for Out-of-Context   Multimodal Misinformation Detection</title><categories>cs.MM cs.CL cs.CV cs.CY</categories><comments>12 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While large generative artificial intelligence (GenAI) models have achieved significant success, they also raise growing concerns about online information security due to their potential misuse for generating deceptive content. Out-of-context (OOC) multimodal misinformation detection, which often retrieves Web evidence to identify the repurposing of images in false contexts, faces the issue of reasoning over GenAI-polluted evidence to derive accurate predictions. Existing works simulate GenAI-powered pollution at the claim level with stylistic rewriting to conceal linguistic cues, and ignore evidence-level pollution for such information-seeking applications. In this work, we investigate how polluted evidence affects the performance of existing OOC detectors, revealing a performance degradation of more than 9 percentage points. We propose two strategies, cross-modal evidence reranking and cross-modal claim-evidence reasoning, to address the challenges posed by polluted evidence. Extensive experiments on two benchmark datasets show that these strategies can effectively enhance the robustness of existing out-of-context detectors amidst polluted evidence. </abstract></arXiv></metadata></record>
<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><header><identifier>oai:arXiv.org:2501.14729</identifier><datestamp>2025-01-27</datestamp><setSpec>cs</setSpec></header><metadata><arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd"><id>2501.14729</id><created>2025-01-24</created><authors><author><keyname>Zhou</keyname><forenames>Xin</forenames></author><author><keyname>Liang</keyname><forenames>Dingkang</forenames></author><author><keyname>Tu</keyname><forenames>Sifan</forenames></author><author><keyname>Chen</keyname><forenames>Xiwu</forenames></author><author><keyname>Ding</keyname><forenames>Yikang</forenames></author><author><keyname>Zhang</keyname><forenames>Dingyuan</forenames></author><author><keyname>Tan</keyname><forenames>Feiyang</forenames></author><author><keyname>Zhao</keyname><forenames>Hengshuang</forenames></author><author><keyname>Bai</keyname><forenames>Xiang</forenames></author></authors><title>HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene   Understanding and Generation</title><categories>cs.CV</categories><comments>Work in progress. The code will be available at   https://github.com/LMD0311/HERMES</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driving World Models (DWMs) have become essential for autonomous driving by enabling future scene prediction. However, existing DWMs are limited to scene generation and fail to incorporate scene understanding, which involves interpreting and reasoning about the driving environment. In this paper, we present a unified Driving World Model named HERMES. We seamlessly integrate 3D scene understanding and future scene evolution (generation) through a unified framework in driving scenarios. Specifically, HERMES leverages a Bird's-Eye View (BEV) representation to consolidate multi-view spatial information while preserving geometric relationships and interactions. We also introduce world queries, which incorporate world knowledge into BEV features via causal attention in the Large Language Model (LLM), enabling contextual enrichment for understanding and generation tasks. We conduct comprehensive studies on nuScenes and OmniDrive-nuScenes datasets to validate the effectiveness of our method. HERMES achieves state-of-the-art performance, reducing generation error by 32.4% and improving understanding metrics such as CIDEr by 8.0%. The model and code will be publicly released at https://github.com/LMD0311/HERMES. </abstract></arXiv></metadata></record>
